---
editor_options:
  markdown:
    wrap: 72
---

# Clinic Trail


## Regulation

-   ICH Guideline for Good Clinical Practice E6 -- current version
-   ICH E9 Statistical principles for clinical trials
-   Declaration of Helsinki -- Ethical Principles for Medical research
    Involving Human Subjects -- current version
-   ISO 14155 -- Clinical investigation of medical devices for human
    subjects -- Good Clinical Practice -- current version
-   ISO 20916 - In vitro diagnostic medical devices --- Clinical
    performance studies using specimens from human subjects --- Good
    study practice -- current version
-   EMA (European Medicines Agency) Missing data in confirmatory
    clinical trials
-   EMA (European Medicines Agency) Investigation of bioequivalence
-   Eegulation (EU) 536/2014

试者分配给分析集。

## Randomization

### Simple randomization

Randomization based on a single sequence of random assignments is known
as simple randomization.

> 对于两个治疗组（对照组与治疗组），硬币的侧面（即正面-对照组，反面-治疗）确定每个受试者的分配。其他方法包括使用经过洗牌的纸牌（例如，偶数控制，奇数处理）或掷骰子（例如，低于并等于3控制，超过3处理）这种随机方法简单易行，可在临床研究中实施。在大型临床研究中，可以相信简单随机会在组之间生成相似数量的主题。但是，在相对较小的样本量临床研究中，随机化结果可能会出现问题，从而导致组中参与者的数量不相等。

```{r Simple-Randomization,echo = T,message = FALSE, error = FALSE, warning = FALSE}
set.seed(888)
treatment <- c("A","B")
simple.list <- sample(treatment, 20, replace=TRUE)
cat(simple.list,sep="\n")
table(simple.list)
```

### Block randomization

The block randomization method is designed to randomize subjects into
groups that result in equal sample sizes. This method is used to ensure
a balance in sample size across groups over time. Blocks are small and
balanced with predetermined group assignments, which keeps the numbers
of subjects in each group similar at all times. The block size is
determined by the researcher and should be a multiple of the number of
groups (i.e., with two treatment groups, block size of either 4, 6, or
8). Blocks are best used in smaller increments as researchers can more
easily control balance.

> 块随机化方法旨在将受试者随机分组，从而产生相同的样本量。使用此方法可确保随着时间的推移，各个组之间的样本量保持平衡。区块很小，并且通过预定的小组分配来平衡，这使每个小组中的被试人数始终保持相似。区块大小由研究人员确定，并且应为组数的倍数（即，对于两个治疗组，区块大小为4、6或8）。最好以较小的增量使用块，因为研究人员可以更轻松地控制平衡。

After block size has been determined, all possible balanced combinations
of assignment within the block (i.e., equal number for all groups within
the block) must be calculated. Blocks are then randomly chosen to
determine the patients' assignment into the groups.

> 确定块大小后，必须计算该块内分配的所有可能平衡组合（即，该块内所有组的数量均相等）。然后随机选择块来确定患者的分组。

**Example 以区组长度4为例**

-   一个区组内的4个研究对象可以有6种排列方式：1. AABB, 2. ABAB, 3.
    ABBA, 4. BAAB, 5. BABA, 6. BBAA
-   确定好所有的排列形式后，接下来需要将6个区组随机排列。我们可以用各种方式（如SPSS、Excel、SAS等）产生一串随机数字.
    因为只有6种排列方式，因此可以只选择1-6之间的数字，25126423121362555343526422
-   按照上述随机数字排列区组

**BLOCKED RANDOMIZATION USING THE PROC PLAN**

    * randomization within block;
    %macro ran_block (blockNum);
    …
    %if &seed= %then %do;
     proc plan;
     factors N=&blocksize / noprint;
     output data=One out=Two
     run;
    %end;
    %else %do;
     Proc plan seed=%eval (&seed+blockNum);
     Factors N=&blockSize / noprint;
     Output data=One out=Two;
     Run;
    %end;
    …
    %mend ran_block;

**BLOCKED RANDOMIZATION USING psych Package**

```{r psych,echo = T,message = FALSE, error = FALSE, warning = FALSE}
library("psych")
my.cond <- block.random (n=96,c( drug=2,time=3,imp=2)) 
headtail(my.cond) 
## Visualizing block randomization
pairs.panels (my.cond)
```

**BLOCKED RANDOMIZATION USING blockrand Package**

```{r blockrand,echo = T,message = FALSE, error = FALSE, warning = FALSE}
### Generate a block randomization for a clinical trial;
library("blockrand")
set.seed(888)
block.list <- blockrand(n=20, num.levels = 2,block.sizes = c(2,2))
block.list
block.list2 <- blockrand(n=20, num.levels = 2,block.sizes = c(1,2))
block.list2
plot(block.list2)
```

### Stratified randomization

The stratified randomization method addresses the need to control and
balance the influence of covariates. This method can be used to achieve
balance among groups in terms of subjects' baseline characteristics
(covariates). Specific covariates must be identified by the researcher
who understands the potential influence each covariate has on the
dependent variable. Stratified randomization is achieved by generating a
separate block for each combination of covariates, and subjects are
assigned to the appropriate block of covariates. After all subjects have
been identified and assigned into blocks, simple randomization is
performed within each block to assign subjects to one of the groups.

> 分层随机方法解决了控制和平衡协变量影响的需求。此方法可用于在受试者的基线特征（协变量）方面实现组间的平衡。研究人员必须确定特定的协变量，他们必须了解每个协变量对因变量的潜在影响。分层随机化是通过为协变量的每种组合生成一个单独的块来实现的，并将主题分配给合适的协变量块。在确定了所有主题并将其分配到块中之后，在每个块内执行简单的随机化以将主题分配给其中一个组。

$$
\begin{array}{|l|c|c|}
\hline \text { Stratum } & \text { Age Group } & \text { Severity Score } \\
\hline 1 & \geq 50 \text { years } & \geq 7 \\
\hline 2 & <50 \text { years } & \geq 7 \\
\hline 3 & \geq 50 \text { years } & <7 \\
\hline 4 & <50 \text { years } & <7 \\
\hline
\end{array}
$$

```{r Stratified,echo = T,message = FALSE, error = FALSE, warning = FALSE}
over50.severe.list <- blockrand(n=100, num.levels = 2,
                                block.sizes = c(1,2,3,4), 
                                stratum='Over 50, Severe',id.prefix='O50_S', block.prefix='O50_S')
headtail(over50.severe.list)
```

## Phase I Trials Design

### Introduction

The primary aims of Phase 1 Clinical Trials are to determine the
**safety, tolerability and pharmacokinetics (PK)** of a compound. Trials
have historically been conducted in the logical sequence of single
ascending dose, multiple ascending dose, examination of preliminary
effect of food on exposure, and potential drug-drug interaction, with
assessments to determine the effect of gender, age, bioavailability and
bioequivalence performed as necessary. Additional studies may be
performed, including definitive electrocardiogram (ECG) investigations
to thoroughly evaluate the QT/QTc prolongation potential of a compound,
which can increase the risk of potentially fatal proarrhythmias.

> 1期临床试验的主要目的是确定化合物的安全性，耐受性和药代动力学（PK)。
> 历史上，按单次递增剂量，多次递增剂量，检查食物对暴露的初步效果以及潜在的药物相互作用的逻辑顺序进行试验，并进行评估以确定性别，年龄，生物利用率和生物等效性的影响
> 必要的。
> 可能还会进行其他研究，包括确定性心电图（ECG）检查，以彻底评估化合物的QT
> / QTc延长潜力，这可能会增加致命性心律失常的风险。

#### Single ascending dose

Single ascending dose These are studies in which a small group of
subjects receive a single dose of the compound in a clinical setting,
usually a Clinical Research Unit (CRU). Close safety monitoring and
usually PK assessments are performed for a predetermined time. If the
compound is deemed to be well tolerated, and the PK data are broadly as
expected, dose escalation occurs, either within the same group or a
further group of healthy subjects, according to the approved protocol.
Dose escalation usually continues until the maximum dose has been
attained per the protocol unless predefined maximum exposure is reached
or intolerable side effects become apparent. Additionally, dose
escalation may be discontinued (or may proceed more cautiously than
planned) if there is evidence of a supra-proportional relationship
between dose and exposure, such that exposures at higher dose levels
become difficult to predict.

> 一小部分受试者在临床环境（通常是临床研究单位（CRU））中接受单剂量的化合物。在预定的时间内进行密切的安全监控和通常的PK评估。如果认为该化合物具有良好的耐受性，并且PK数据大致符合预期，则根据批准的方案，在同一组或另一组健康受试者中会发生剂量增加。除非根据预定义的最大暴露量或出现无法忍受的副作用，否则剂量递增通常会一直持续到按照方案达到最大剂量。另外，如果有证据表明剂量与暴露量之间存在超比例关系，则可以停止剂量递增（或者可能比计划更谨慎地进行），从而难以预测更高剂量水平的暴露量。

Studies usually include sequential groups in a parallel design for
maximum exposure or are of a crossover design to provide more
information on dose linearity. To minimize the effect of bias, subjects
are usually randomly assigned to treatment using computer generated
randomization codes produced by Statisticians. Studies are usually
placebo controlled to determine whether effects observed are due to the
study drug or environmental conditions, and are often conducted in a
single (subject) blinded manner to allow informed decision on dose
escalation, with safety and PK data being available for investigator
review.

> 研究通常包括平行设计中的顺序组，以最大程度地暴露；或者交叉设计，以提供有关剂量线性的更多信息。为了使偏差的影响最小化，通常使用统计学家产生的计算机生成的随机编码将受试者随机分配到治疗中。研究通常由安慰剂控制，以确定观察到的效果是否是由于研究药物或环境条件引起的，并且通常以单（受试者）盲法进行，以允许就剂量递增做出明智的决定，并提供安全性和PK数据供研究者审查。

#### Multiple ascending dose

These studies are conducted to elucidate the pharmacokinetics (PK) and
pharmacodynamics (PD) of multiple doses of the compound, again usually
in a CRU (Clinical Research Unit). The dose levels and dosing intervals
(ie, time between consecutive doses) are selected as those that are
predicted to be safe from single dose data. Samples are collected and
analyzed to allow the determination of PK profiles and a better
understanding of how the drug is processed by the body; with multiple
dosing, a key part of the PK analysis is to identify if accumulation of
the drug occurs. As for single ascending dose studies, dose escalation
proceeds according to the protocol assuming strict safety and PK
criteria are met. Dose levels and dosing frequency are chosen to achieve
therapeutic drug levels within the systemic circulation that are
maintained at steady state for several days to allow appropriate safety
parameters to be monitored. It is usual for 2 3 dose levels to be
studied, at and above the expected therapeutic dose level(s) to
determine the 'safety margin' for repeat dose administration.

> 进行这些研究以阐明多剂量化合物的药代动力学（PK）和药效学（PD），通常也要在CRU（临床研究单位）中进行。选择剂量水平和给药间隔（即连续剂量之间的时间）作为从单剂量数据预测是安全的剂量水平和剂量间隔。收集样本并进行分析，以便确定PK曲线并更好地了解药物如何被人体处理；通过多次给药，PK分析的关键部分是确定是否发生了药物蓄积。对于单次递增剂量研究，假定符合严格的安全性和PK标准，则按照方案进行剂量递增。选择剂量水平和给药频率以达到全身循环内维持稳定状态数天的治疗药物水平，以监测合适的安全性参数。通常，在预期治疗剂量水平或更高剂量下研究2
> 3个剂量水平，以确定重复剂量给药的"安全裕度"。
 
## Phase II Trials Design

### Introduction

-   Phase IIa: Proof-of-Concept (50/100) 强调快速评估，早期无效评估

    -   Emphasise quick evaluation, early futility assessment
    -   Find proof of positive response for proposed treatment to
        recommend for further clinical trial evaluation
    -   Example Methods: One sample, Fleming Test, Simon's Design

-   Phase IIb: Dose-Finding (100/1000)
    未知的剂量反应曲线，获得正确的模型/剂量

    -   Unknown dose-response curve, get right model/doses
    -   Find dose-response curve to see dose-response relationship,
        evaluate if strong enough response & if so select Phase III
        doses
    -   Examples Methods: Contrast tests, Cochran-Armitage, MCP-Mod

 


## Phase III Trials Design

### Introduction

Phase III clinical trials are the **gold standard** to demonstrate the
effects of an experimental therapy compared to standard therapy for a
disease of interest. The first step when planning a phase III trial is
to specify the statistical hypothesis that the trial purports to test,
which is usually that the experimental therapy provides some efficacy
benefit over standard therapy, without adding significant harm. In a
phase III trial, a pre-specified number of patients from the target
population are randomized to receive experimental or standard therapy.
The patients are treated and followed up according to a protocol that
also defines the endpoints of interest, in particular the primary
endpoint which is chosen to reflect a clinical benefit of experimental
therapy over standard therapy. The trial data are typically monitored by
an independent committee who may recommend stopping the trial early, if
appropriate. The benefit of experimental therapy over standard therapy,
if any, may be observed across all patients, or may be confined to a
subset of patients.

> III期临床试验是金标准，可证明与标准疗法相比，对于目标疾病而言，实验疗法的效果。计划进行III期临床试验的第一步是明确说明该试验所要测试的统计假设，通常是实验性疗法比标准疗法具有一定的疗效，而又不会增加明显的危害。在III期试验中，将来自目标人群的预先指定数量的患者随机分配接受实验或标准治疗。根据还定义了目标终点的方案对患者进行治疗和随访，特别是选择主要终点以反映实验治疗相对于标准治疗的临床益处。审判数据通常由独立委员会进行监控，如果合适的话，委员会可能建议尽早停止审判。实验疗法相对于标准疗法的益处（如果有的话）可以在所有患者中观察到，或仅限于一部分患者。

### MEDIWOUND1

#### Study Design

| Study Synoposis   |                                                                                                                 |     |
|-------------------|-----------------------------------------------------------------------------------------------------------------|-----|
| IMP               | NexoBrid                                                                                                        |     |
| Active Ingredient | Partially purified Bromelain 部分纯化的菠萝蛋白酶                                                               |     |
| Study             | 评估NexoBrid与Gel载体和Standard of Care的疗效和安全性                                                           |     |
| Clinical Phase    | III                                                                                                             |     |
| Sample            | 划以3：3：1的比例将175名受试者随机分配到研究中（NexoBrid：SOC：凝胶载体）。该研究将在美国和美国以外的地区进行。 |     |

A multicenter, multinational, randomized, controlled, assessor blinded
study, performed in subjects with thermal burns, to evaluate the
efficacy and safety of NexoBrid compared to Gel Vehicle and compared to
Standard of Care

> 在热灼伤受试者中进行的一项多中心，多国，随机，对照，评估者盲研究，旨在评估NexoBrid与Gel载体和Standard
> of Care的疗效和安全性

#### Primary Objective

**Incidence of complete eschar removal**- Demonstrate superiority of
NexoBrid over Gel Vehicle for eschar removal as measured by incidence of
complete eschar removal at the end of the topical agent soaking period
by a blinded assessor.

> 完全去除焦糖的现象-通过盲法评估者在局部用药浸泡时间结束时完全去除焦糖的发生率来衡量，证明NexoBrid相对于凝胶载体的去除焦糖的优势。

**Efficacy evaluation Primary target variable**

-   Incidence of complete eschar removal in the topical arms (NexoBrid
    and Gel Vehicle):
-   Incidence of complete eschar removal (ER)

#### Statistical Analysis

> 使用logistic回归比较局部用药浸泡时间结束时完全去除es的患者比例（是/否/缺失）。主要分析将基于二元变量（yes
> / no）(Using the "exact" statement in the SAS procedure PROC
> LOGISTIC).
> 统计测试将基于Fisher的精确测试，因为Gel载体组中预期的数量很少。使用精确分布方法估算NexoBrid与凝胶媒介物完全去除焦char的几率及其95％置信区间

> 使用混合逻辑回归模型对患者产生随机影响，将在伤口水平上重复主要疗效分析，作为附加分析。

#### Survival data with clustered events

Two methods to analyzing survival data with clustered events are
presented.

1.  The first method is a **proportional hazards model which adopts a
    marginal approach with a working independence assumption**. This
    model can be fitted by SAS PROC PHREG with the robust sandwich
    estimate option.
2.  The second method is a **likelihood-based random effects (frailty)
    model**. In the second model, the baseline hazard could be either a
    priori determined (e.g., Weibull) or approximated by piecewise
    constant counterpart. The estimation could be carried out by
    adaptive Gaussian quadrature method which is implemented in SAS PROC
    NLMIXED.

> 两种利用聚类事件分析生存数据的方法。
> 第一种方法是比例风险模型，该模型采用带有工作独立性假设的边际方法。 SAS
> PROC
> PHREG可以使用具有鲁棒性三明治估算选项的模型来拟合此模型。第二种方法是基于可能性的随机效应（脆弱）模型。
> 在第二个模型中，基准风险可以是先验确定的（例如Weibull），也可以由分段常数对应物近似。
> 可以通过在SAS PROC NLMIXED中实现的自适应高斯正交方法进行估算。

#### CDISC

##### Initiation

    *** creation/convertion of SDTM data into ADaM adsl dataset;
    *** SDTM domains;
    libname mw10sdtm "Z:\CDISC\STUDIES\MEDIWOUND1\SDTM\Domains\20201001_Stage_3";
    *** ADaM datasets;
    libname mw10adam "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\PostHoc_FDA_Request";
    *** misc dataasets (additional datasets that don't qualify as analysis, profile, or tabulation datasets);
    libname misc "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\sas_datasets\misc";

    %include "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\Programmes\Macros\M_attrib_to_dataset_v03-4-1.sas";
    %include "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\Programmes\Macros\M_mergesupp_v01-3.sas";
    %include "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\Programmes\Macros\M_dtc2dt_V01_2_0.sas";
    %include "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\Programmes\Macros\M_imputed_date_V01_0_0.sas";
    %include "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\Programmes\Macros\M_create_adam_dataset_V01_0_0.sas";
    *%include "Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\Programmes\Macros\Macro_IncludeProgrammes_V02.sas";

    *** Import ADaM specification sheet;
    %let specification_filename = Z:\CDISC\STUDIES\MEDIWOUND1\ADaM\ADaM_Specifications\CSV\MW2010_ADaM_Specification.csv;
    proc import datafile="&specification_filename" replace
        out=specs
        dbms=csv;
        getnames=YES;
        guessingrows=max;
        delimiter=";";
    run;

##### ADSL

creation/convertion of SDTM data into ADaM adsl dataset

-   SDTM variables taken from domain DM, SUPPDM;

    -   age ranging $(A G E<35,>=35, .)$
    -   Date Convension from SDTM Date to numeric values in ADaM

-   SDTM variables taken from domain CE, SUPPCE;

-   SDTM variables taken from domain HO;

-   SDTM variables taken from domain WC

    -   Total Wounds per Patient, Start-/Stop- Date Time per actual
        treatment

-   SDTM variables taken from domain IE;

-   SDTM variables taken from domain VS (weight, height, bmi);

-   SDTM variables taken from domain DS;

-   restrict to variables that were specified in the specification
    sheet;

##### ADAE

-   get subject specific information from ADSL domain set mw10adam.adsl
    and empty_adae
-   import information from SDTM.AE; set empty_adae and ae (check for
    missing AE start dates)
-   process SDTM data; ate/time conversion (character to integer) of AE
    start date;

<!-- -->

    *** date/time conversion (character to integer) of AE start date;
    if AESTDTC ne "" then %dtc2dt(dtcvar=AESTDTC, prefix=AST, refdt= );
    drop ASTTM;

    *** Treatment Emergent AE Fflag;
    if      ASTDTM ne . and TRTSDTM ne . then do;
    if      ASTDTM >= TRTSDTM then TEAEFL = "Y";
    else if ASTDTM <  TRTSDTM then TEAEFL = "";
    end;

    *** duration;
    if AENDT ne . & ASTDT ne . then ADURN = round(AENDT - ASTDT, 0.1);
    if ADURN ne .   then ADURU = "DAYS";

    *** numeric value for severity;
    if AESEV eq "MILD"                                                  then AESEVN = 1;
    else if AESEV eq "MODERATE"                                         then AESEVN = 2;
    else if AESEV eq "SEVERE"                                           then AESEVN = 3;

    *** numeric variable for relatedness;
    if AEREL eq "NOT RELATED"                                           then AERELN = 1;
    else if AEREL eq "REMOTELY RELATED"                                 then AERELN = 2;
    else if AEREL eq "POSSIBLY RELATED"                                 then AERELN = 3;
    else if AEREL eq "PROBABLY RELATED"                                 then AERELN = 4;
    else if AEREL eq "RELATED"                                          then AERELN = 5;

    *** Drug-Related AE Flag;
    if      AERELN = 1          then AERELFL = "N";
    else if AERELN in (2,3,4,5) then AERELFL = "Y";
    else put "WARNING (user-defined): Missing Causality for " USUBJID " AE No. " AENO;

    *** numeric variable for outcome;
    if      AEOUT eq "RECOVERED/RESOLVED"                               then AEOUTN = 1;
    else if AEOUT eq "RECOVERED/RESOLVED WITH SEQUELAE"                 then AEOUTN = 2;
    else if AEOUT eq "NOT RECOVERED/NOT RESOLVED"                       then AEOUTN = 3;
    else if AEOUT eq "FATAL"                                            then AEOUTN = 4;

##### ADVS

PRE FIRST PROCEDURE (Screening visit) for all subject

    %let paramcd = TEMP\PULSE\RESP\SYSBP\DIABP\INTP;
    %let param = Temperature (C)\Pulse Rate (beats/min)\Respiratory Rate (breaths/min)\Systolic Blood Pressure (mmHg)\Diastolic Blood Pressure (mmHg)\Interpretation;

    *** PRE FIRST PROCEDURE (Screening visit) for all subjects;
    data for_advs_01_visitContainer_scr;
        set empty_advs (keep = USUBJID AVISIT PARAM PARAMCD)
            mw10adam.adsl (keep = USUBJID)
        ;
        by USUBJID;

        if first.USUBJID then do;
            do i = 1 to 6;
                AVISIT = "PRE FIRST PROCEDURE";
                PARAM = scan(strip("&param"), i, "\");
                PARAMCD = scan(strip("&paramcd"), i, "\");
                seq = 1;
                output;
            end;
        end;
        drop i;
    run;

-   all subjects with a first procedure (TRT01A ne "");
-   all subjects with a second procedure (TRT02A ne "");
-   all subjects with a third procedure (TRT03A ne "");
-   set together all 3 visitContainer;

<!-- -->

    data for_advs_01_visitContainer_trt03;
        set empty_advs (keep = USUBJID AVISIT PARAM PARAMCD)
            mw10adam.adsl (keep = USUBJID TRT03A where = (TRT03A ne ""))
        ;
        by USUBJID;

        if first.USUBJID then do;
            do i = 1 to 6;
                AVISIT = "POST THIRD PROCEDURE";
                PARAM = scan(strip("&param"), i, "\");
                PARAMCD = scan(strip("&paramcd"), i, "\");
                seq = 6;                                *** skip seq = 5 for calculation of PRE-POST difference;
                output;
            end;
        end;
        drop i TRT03A;
    run;

    *** set together all 3 visitContainer;
    data for_advs_01_visitContainer_all;
        set for_advs_01_visitContainer_scr
            for_advs_01_visitContainer_trt01
            for_advs_01_visitContainer_trt02
            for_advs_01_visitContainer_trt03
        ;
        by USUBJID;
    run;

POST-PRE DIFF PROCEDURES

    AVISIT_lag = lag1(AVISIT);
        AVAL_lag = lag1(AVAL);
        PARAM_lag = lag1(PARAM);
        PARAM_new = "Diff. " || strip(PARAM);
        
    f strip(PARAM) = strip(PARAM_lag) and strip(AVISIT) = "POST FIRST PROCEDURE" and strip(AVISIT_lag) = "PRE FIRST PROCEDURE"   then do; 
            if AVAL_lag ne . and AVAL ne . then AVAL_new = AVAL_lag - AVAL; 
            AVISIT_new = "PRE-POST DIFF FIRST PROCEDURE"; 
            seq_new = 3;
        end;
        if  strip(PARAM) =  strip(PARAM_lag) and strip(AVISIT) = "POST SECOND PROCEDURE" and strip(AVISIT_lag) = "POST FIRST PROCEDURE" then do;
            if AVAL_lag ne . and AVAL ne . then AVAL_new = AVAL_lag - AVAL;
            AVISIT_new = "PRE-POST DIFF SECOND PROCEDURE"; 
            seq_new = 5;
        end;
        if  strip(PARAM) =  strip(PARAM_lag) and strip(AVISIT) = "POST THIRD PROCEDURE" and strip(AVISIT_lag) = "POST SECOND PROCEDURE" then do; 
            if AVAL_lag ne . and AVAL ne . then AVAL_new = AVAL_lag - AVAL;
            AVISIT_new = "PRE-POST DIFF THIRD PROCEDURE"; 
            seq_new = 7;
        end;
        if  strip(PARAM) = strip(PARAM_lag) and strip(AVISIT) = "DAY 2" and strip(AVISIT_lag) = "DAY 1" then do; 
            if AVAL_lag ne . and AVAL ne . then AVAL_new = AVAL_lag - AVAL;
            AVISIT_new = "DAY 1 - DAY 2 DIFF"; 
            seq_new = 10;
        end;
    ...
        end;
        if  strip(PARAM) =  strip(PARAM_lag) and strip(AVISIT) = "DAY 7" and strip(AVISIT_lag) = "DAY 6" then do; 
            if AVAL_lag ne . and AVAL ne . then AVAL_new = AVAL_lag - AVAL;
            AVISIT_new = "DAY 6 - DAY 7 DIFF"; 
            seq_new = 20;
        end;

<!-- --------------------------------------------------------- -->


## Postmarketing Surveillance (PMS)

### Phase IV and PMS

Studies the side effects caused over time by a new treatment after it
has been approved and is on the market. These trials look for side
effects that were not seen in earlier trials and may also study how well
a new treatment works over a long period of time.

> 研究经过批准并投放市场的新疗法随时间推移所引起的副作用。
> 这些试验寻找的副作用是早期试验中未见的，也可能研究新疗法在很长一段时间内的效果。

Postmarketing surveillance (PMS), also known as post-market
surveillance, is the practice of monitoring the safety of a
pharmaceutical drug or medical device after it has been released on the
market and is an important part of the science of pharmacovigilance.
Since drugs and medical devices are approved on the basis of clinical
trials, which involve relatively small numbers of people who have been
selected for this purpose -- meaning that they normally do not have
other medical conditions that may exist in the general population --
postmarketing surveillance can further refine, or confirm or deny, the
safety of a drug or device after it is used in the general population by
large numbers of people who have a wide variety of medical conditions.
。 Postmarketing surveillance uses a number of approaches to monitor
drug and device safety, including spontaneous reporting databases,
prescription event monitoring, electronic health records, patient
registries, and record linkage between health databases.

> 上市后监视（PMS），也称为上市后监视，是监视已投放市场的药物或医疗器械的安全性的实践，并且是药物警戒学的重要组成部分。由于药品和医疗器械是根据临床试验批准的，因此涉及的人数量相对较少，这意味着他们通常不具有普通人群中可能存在的其他医疗状况，因此售后监测可以在具有广泛医疗状况的大量人在普通人群中使用药物或设备后，进一步完善，确认或否认药物或设备的安全性.
> 上市后监视使用多种方法来监视药物和设备安全，包括自发报告数据库，处方事件监视，电子健康记录，患者注册表以及健康数据库之间的记录链接。
 

## Trials Design (Phase II)

### Fleming's Two-Stage design

> One-Sample Multiple Testing Procedure for Phase II Clinical Trials

> II期临床试验，以评估特定治疗方案的抗肿瘤"疗效"和该方案的毒性。通常基于"回归概率"
> p来评估治疗效果。也就是说，接受治疗方案的合格患者发生方案中确切定义的肿瘤消退的可能性。通常，II期试验被设计为具有一个阶段，在该阶段中，N名可评估的患者应征，接受治疗并随后进行观察，从而确定经历消退的人数S。显然，可以从数据中获得p
> = S / N给出的p的点估计。
> 除了推导p的点估计值外，通常最不容易制定测试程序来决定是否需要进一步研究治疗方案。

It is the purpose of this report to inspect a one-sided multiple testing
procedure and compare its behavior with that of the obvious single-stage
test procedure, as well as with that of other multiple testing
procedures which are currently employed for such decisions. Note that,
as opposed to a single-stage procedure, in a multiple testing procedure
patients accrue in several stages, testing being performed at each stage
after appropriate patient accrual has been completed. Such a procedure
has the property that patient accruat could be terminated, and a final
decision reached, after any test. This feature is particularly appealing
in a clinical setting where there are compelling ethical reasons to
terminate a Phase II trial early if the initial proportion of patients
experiencing a tumor regression is low.

> 本报告的目的是检查单面多重测试程序，并将其行为与明显的单阶段测试程序以及当前用于此类决策的其他多重测试程序的行为进行比较。注意，与单阶段过程相反，在多个测试过程中，患者分多个阶段累积，在适当的患者累积完成后，在每个阶段进行测试。这样的程序具有可以在任何测试后终止患者累积并达到最终决定的特性。如果有令人信服的伦理理由，如果最初经历肿瘤消退的患者比例很低，则有令人信服的伦理理由提早终止II期临床试验

**Single"Stage Procedure**

The single-stage procedure can be based upon the statistic
$\hat{p}=S / N$, by rejecting $H_{0}$ whenever $\hat{p}$ is large.
Hence, the required sample size $N$ can be determined by observing that
$S$ has a binomial distribution, $\operatorname{Bin}(N, p) ;$ i.e.
$\operatorname{pr}(S=x)=\left(\frac{N}{x}\right) p^{x}(1-p)^{N-x}$ for
$x=$ $0,1,2, \ldots, N$. Alternatively, one can observe that, for
$N p \geqslant 10, \quad Y(p) \equiv$
$(S-N p) /\{N p(1-p)\}^{\frac{1}{2}}$ has approximately a normal
distribution with zero mean and unit variance. The single-stage
procedure would then reject $H_{0}$ whenever
$Y\left(p_{0}\right)>Z_{1-\alpha} ;$ i.e. whenever
$S \geqslant N p_{0}+Z_{1-\alpha}\left\{N p_{0}\left(1-p_{0}\right)\right\}^{\frac{1}{2}}$,
where $Z_{u}$ denotes the $u$ -quantile of the normal distribution. It
is straightforward to show that the sample size required for this
singlestage procedure to have significance level $\alpha$ and power
$1-\beta$ is approximately $$
\left.N=\mathbf{(}\left[Z_{1-\beta}\left\{p_{\mathrm{A}}\left(1-p_{\mathrm{A}}\right)\right\}^{\frac{1}{2}}+Z_{1-\alpha}\left\{p_{0}\left(1-p_{0}\right)\right\}^{\frac{1}{2}}\right] /\left(p_{\mathrm{A}}-p_{0}\right)\right)^{2}
$$ $S$ has a discrete binomial distribution rather than a continuous
normal distribution. In fact, calculations have shown that, to avoid the
possibility of obtaining an anti-conservative test procedure as a result
of this discreteness, the single-stage procedure should more
appropriately reject $H_{0}$ whenever $$
S \geqslant\left[N p_{0}+Z_{1-\alpha}\left\{N p_{0}\left(1-p_{0}\right)\right\}^{\frac{1}{3}}\right]^{*}+1,
$$

**Mulfiple Testing Procedures**

> 由于前面提到的道德考虑以及稍后讨论的效率考虑，考虑对单阶段过程进行多种测试替代是很有意义的。

Suppose that one decides to perform $K$ tests and to allow $n_{i}$
patients to accrue between the $(i-1)$ th and $i$ th tests, so
$N \equiv n_{1}+\cdots+n_{K}$. Let $s_{1}$, $i=1, \ldots, K$, represent
the number of regressions among the $n_{i}$ patients, so $S=$
$s_{1}+\cdots+s_{K} .$ Furthermore, denote the set of acceptance points
(of $H_{0}$ ) by $\left(a_{1}, a_{2}, \ldots, a_{K}\right)$ and the set
of rejection points (of $H_{0}$ ) by
$\left(r_{1}, r_{2}, \ldots, r_{K}\right)$. Setting $a_{K}=r_{K}-1$,
Schultz et al. (1973) defined the general multiple testing procedure as
follows. At Test $g(g=1, \ldots, K)$,

-   if $\sum_{i=1}^{\mathrm{g}} s_{i} \leqslant a_{\mathrm{g}}$, stop
    sampling and reject $H_{\mathrm{A}}: p \geqslant p_{\mathrm{A}}$
    (or, with greater certainty, reject
    $\left.\tilde{H}_{\mathrm{A}}: p \geqslant \tilde{p}_{\mathrm{A}}\right)$
-   if $\sum_{i=1}^{\mathrm{g}} s_{i} \geqslant r_{\mathrm{g}}$, stop
    sampling and reject $H_{0}: p \leqslant p_{0}$
-   if $a_{\mathrm{g}}<\sum_{i=1}^{\mathrm{g}} s_{i}<r_{\mathrm{g}}$,
    continue to Test $\mathrm{g}+1$

### Simon's 2-Stage Design

**Reference**: Simon, R. (1989). Optimal two-stage designs for phase II
clinical trials. Controlled Clinical Trials, 10(1), 1--10.
[doi:10.1016/0197-2456(89)90015-9](doi:10.1016/0197-2456(89)90015-9){.uri}

癌症治疗的 II 期研究是用于获得治疗抗肿瘤效果程度的初步估计的非对照试验。
I
期试验提供有关治疗的最大耐受剂量的信息，这很重要，因为大多数癌症治疗必须以最大剂量进行才能获得最大效果。然而，I
期试验通常每个剂量水平仅治疗 3 至 6 名患者，并且患者的癌症诊断各不相同
[1]。因此，这些试验提供很少或根本没有关于抗肿瘤活性的信息。肿瘤缩小至少
50% 的患者比例是大多数 II
期试验的主要终点，尽管这种反应的持久性也令人感兴趣。此类试验不受控制，不能确定治疗的"有效性"或药物在治疗疾病中的作用。新抗癌药物的
II
期试验的目的是确定该药物是否对特定类型的肿瘤具有足够的活性以保证其进一步开发。进一步的开发可能意味着将药物与其他药物结合，对病情较轻的患者进行评估，或启动
III 期研究，将生存结果与标准治疗的结果进行比较。

联合方案的 II
期试验，以确定治疗是否有足够的前景，以保证对标准治疗进行主要的对照临床评估。此处开发的设计基于检验零假设$H_0: P \le P_0$.
即真实响应概率小于某个无趣的水平
$P_0$.如果原假设为真，那么我们要求得出结论认为该药物有足够的希望可以在其他临床试验中接受进一步研究的概率应该小于$\alpha$。我们还要求，如果一个指定的替代假设
$P \ge P_1$真实反应概率至少是某个理想的目标水平$P_1$
为真，那么拒绝该药物进行进一步研究的概率应该小于$\beta$。除了这些限制之外，我们还希望尽量减少接受低活性药物治疗的患者数量。出于管理多机构临床试验的实际考虑，我们将把注意力集中在两阶段设计上。

Simon's Design is 2-stage design with early futility stopping, tests
null "poor" response vs alternative "good" response. If the numbers of
patients studied in the first and second stage are denoted by $n_{1}$
and $n_{2}$ respectively, then the expected sample size is
$\mathrm{EN}=n_{1}+(1-$ PET) $n_{2}$, where PET represents the
probability of early termination after the first stage. The decision of
whether or not to terminate after the first stage will be based on the
number of responses observed for those $n_{1}$ patients. The expected
sample size EN and the probability of early termination depend on the
true probability of response $p$. We will terminate the experiment at
the end of the first stage and reject the drug if $r_{1}$ or fewer
responses are observed. This occurs with probability PET
$=B\left(r_{1} ; p, n_{1}\right)$, where $B$ denotes the cumulative
binomial distribution. We will reject the drug at the end of the second
stage if $r$ or fewer responses are observed. Hence the probability of
rejecting a drug with success probability $p$ is $$
B\left(r_{1} ; p, n_{1}\right)+\sum_{x=r_{1}+1}^{\min \left[n_{1}, r\right]} b\left(x ; p, n_{1}\right) B\left(r-x ; p, n_{2}\right),
$$ where $b$ denotes the binomial probability mass function.

For specified values of $p_{0}, p_{1}, \alpha$, and $\beta$ we have
determined optimal designs by enumeration using exact binomial
probabilities. For each value of total sample size $n$ and each value of
$n_{1}$ in the range $(1, n-1)$ we determined the integer values of
$r_{1}$ and $r$, which satisfied the two constraints and minimized the
expected sample size when $p=p_{0}$. This was found by searching over
the range $r_{1} \in\left(0, n_{1}\right)$. For each value of $r_{1}$ we
determined the maximum value of $r$ that satisfied the type 2 error
constraint. We then examine whether that set of parameters
$\left(n, n_{1}, r_{1}, r\right)$ satisfied the type 1 error constraint.
If it did, then we compared the expected sample size to the minimum
achieved by previous feasible designs and continued the search over
$r_{1}$. Keeping $n$ fixed we searched over the range of $n_{1}$ to find
the optimal two-stage design for that maximum sample size $n$. The
search over $n$ ranged from a lower value of about $$
\bar{p}(1-\bar{p})\left[\frac{z_{1-\alpha}+z_{1-\beta}}{p_{1}-p_{0}}\right]^{2}
$$ where $\vec{p}=\left(p_{0}+p_{1}\right) / 2$. We checked below this
starting point to ensure that we had determined the smallest maximum
sample size $n$ for which there was a nontrivial
$\left(n_{1}, n_{2}>0\right)$ two-stage design that satisfied the error
probability constraints. The enumeration procedure searched upwards from
this minimum value of $n$ until it was clear that the optimum had been
determined. The minimum expected sample size for fixed $n$ is not a
unimodal function of $n$ because of discreteness of the underlying
binomial distributions. Nevertheless, eventually as $n$ increased the
value of the local minima increased and it was clear that a global
minimum had been found.

|     | `ph2simon(pu, pa, ep1, ep2, nmax=100)`                             |
|-----|--------------------------------------------------------------------|
| pu  | unacceptable response rate                                         |
| pa  | response rate that is desirable                                    |
| ep1 | threshold for the probability of declaring drug desirable under p0 |
| ep2 | threshold for the probability of rejecting the drug under p1       |

```{r Simon-Two-Stages-Design, echo=T, fig.align="center", out.width = '70%',fig.cap="Figure: Simon’s 2-Stage Design"}
knitr::include_graphics("./02_Plots/Simon_twoStage.PNG")

## `ph2simon(pu, pa, ep1, ep2, nmax=100)`
library("clinfun")
Simon <- ph2simon(0.2, 0.35, 0.05, 0.05, nmax=150)
Simon
plot(Simon)
```

### Jonckheere-Terptsra (JT) trend test

In some safety and efficacy studies, it is of interest to determine if
an increase in the dose yields an increase (or decrease) in the
response. The statistical analysis for such a situation is called a
dose-response or trend analysis. We want to see a trend here, not just a
difference in groups. Typically, patients in a dose-response study are
randomized to K + 1 treatment groups (a placebo dose and K increasing
doses of the drug). The response variables of interest may be binary,
ordinal, or continuous (in some circumstances, the response variable may
be a time-to-event variable). In some instances, trend tests can be
sensitive and reveal a mild trend where pair-wise comparisons would not
be able to find significant differences and not be as helpful.

> 在一些安全性和功效研究中，确定剂量增加是否会导致反应增加（或减少）是很有意义的。
> 针对这种情况的统计分析称为剂量响应或趋势分析。
> 我们希望在这里看到一种趋势，而不仅仅是群体上的差异。
> 通常，剂量反应研究中的患者被随机分为K +
> 1个治疗组（安慰剂剂量和K递增剂量的药物）。
> 感兴趣的响应变量可以是二进制，有序或连续的（在某些情况下，响应变量可以是事件发生时间的变量）。
> 在某些情况下，趋势测试可能很敏感，并显示出轻微的趋势，在这种趋势下，成对比较将无法发现明显的差异，并且没有太大的帮助。

For the sake of illustration, suppose that the response is continuous
and that we want to determine if there is a trend in the K + 1
population means.

> 为了说明起见，假设响应是连续的，并且我们要确定K +
> 1总体均值中是否存在趋势。

A one-sided hypothesis testing framework for investigating an increasing
trend is $$H_{0}: \mu_{0}=\mu_{1}=\cdots=\mu_{K}$$ versus
$$H_{1}: \mu_{0} \leq \mu_{1} \leq \cdots \leq \mu_{K}$$ with at least
one strict inequality} A one-sided hypothesis testing framework for
investigating a decreasing trend is
$$H_{0}: \mu_{0}=\mu_{1}=\cdots=\mu_{K}$$ versus
$$H_{1}: \mu_{0} \geq \mu_{1} \geq \cdots \geq \mu_{K}$$ with at least
one strict inequality} A two-sided hypothesis testing framework for
investigating a trend is $$H_{0}: \mu_{0}=\mu_{1}=\cdots=\mu_{K}$$
versus $$H_{1}: \mu_{0} \leq \mu_{1} \leq \cdots \leq \mu_{K}$$ or
$$\mu_{0} \geq \mu_{1} \geq \cdots \geq \mu_{K}$$ with at least one
strict inequality}

**Jonckheere-Terptsra (JT) trend test**

For a continuous response, an appropriate test is the
Jonckheere-Terptsra (JT) trend test that was developed in the 1950s. The
JT trend test is based on a sum of Mann-Whitney-Wilcoxon tests :

$$JT=\sum_{k=0}^{K-1}\sum_{k'=1}^{K}MWW_{kk'}$$ where $M W W_{, kk'}$ is
the Mann-Whitney-Wilcoxon test for comparing group $\mathrm{k}$ to group
$k^{\prime}, 0 \leq k<k^{\prime} \leq K$. Essentially, each of the pairs
of groups is compared against one another and then summed up. In this
way this test looks for trends.

As an example of how the JT statistic is constructed, suppose there are
four dose groups in a study (**placebo, low dose, mid-dose, and high
dose**). Then the JT trend test is the sum of six Mann-Whitney-Wilcoxon
test statistics.

Next, we assume that the $K+1$ groups have a homogeneous population
variance, $\sigma^{2}$. The population variance is estimated by the
pooled sample variance, $s^{2}$, and it has d degrees of freedom: $$
s^{2}=\frac{1}{d} \sum_{k=0}^{K} \sum_{i=1}^{n_{k}}\left(Y_{k i}-\bar{Y}_{k}\right)^{2}, d=\sum_{k=0}^{K}\left(n_{k}-1\right)
$$ Letting $c_{k}=2 k-K, k=0,1, \ldots, K$, the numerator reduces to $$
\sum_{k=0}^{K} c_{k} \bar{Y}_{k}
$$ Then the trend statistic is: $$
T=\left(\sum_{k=0}^{K} c_{k} \bar{Y}_{k}\right) /\left(\sqrt{s^{2} \sum_{k=0}^{K} \frac{c_{k}^{2}}{n_{k}^{2}}}\right)
$$

The T trend statistic can be constructed by using the CONTRAST statement
in SAS PROC GLM.

The JT trend test works well for binary and ordinal data, as well as
being available for continuous data. Another trend test for binary data
is the Cochran-Armitage (CA) trend test. The difference between the JT
and CA trend tests is that for the latter test, the actual dose levels
can be specified. In other words, instead of designating the dose levels
as low, mid, or high, the actual numerical dose levels can be used in
the CA trend test, such as 20 mg, 60, 180 mg.

> JT趋势测试适用于二进制和有序数据，也可用于连续数据。
> 二进制数据的另一种趋势测试是Cochran-Armitage（CA）趋势测试。
> JT和CA趋势测试之间的区别在于，对于后者的测试，可以指定实际剂量水平。
> 换句话说，代替将剂量水平指定为低，中或高，可以在CA趋势测试中使用实际的数字剂量水平，例如20
> mg，60、180 mg。

    *** Constructing JT trend tests;
    proc format;
    value groupfmt 0='Placebo' 1='20 mg' 2='60 mg' 3='180 mg';
    value reactfmt 0='F' 1='S';
    run;
    data 
    contin;
    input group subject response;
    cards;
    0 01 27
    0 02 28
    0 03 27
    0 04 31
    0 05 34
    0 06 32
    1 01 31
    1 02 35
    1 03 34
    1 04 32
    1 05 31
    1 06 33
    2 01 32
    2 02 33
    2 03 30
    2 04 34
    2 05 37
    2 06 36
    3 01 40
    3 02 39
    3 03 41
    3 04 38
    3 05 42
    3 06 43
    ;
    run;
    proc glm 
    data=contin;
    class group;
    model response=group;
    contrast 'Trend Test' group -1.5 -0.5 0.5 1.5;
    title "Parametric Trend Test for Continuous Data";
    run;
    proc freq 
    data=contin;
    tables group*response/jt;
    title "Jonckheere-Terpstra Trend Test for Continuous Data";
    run;
    data 
    binary;
    set contin;
    if group=0 then dose=0;
    if group=1 then dose=20;
    if group=2 then dose=60;
    if group=3 then dose=180;
    if response<32 then react=0;
    if response>=32 then react=1;
    format react reactfmt.;
    run;
    proc freq 
    data=binary;
    tables react*group/jt trend;
    exact jt trend;
    title "Jonckheere-Terpstra and Cochran-Armitage Trend Tests for Binary Data";
    title2 "Ordinal Scores";
    run;
    proc freq 
    data=binary;
    tables react*dose/jt trend;
    exact jt trend;
    title "Jonckheere-Terpstra and Cochran-Armitage Trend Tests for Binary Data";
    title2 "Dose Scores";
    run;

```{r JT Sample Size,echo = T,message = FALSE, error = FALSE, warning = FALSE}
library(clinfun)
set.seed(1234)
g <- rep(1:5, rep(10,5))
x <- rnorm(50)
jonckheere.test(x+0.3*g, g)

x[1:2] <- mean(x[1:2]) # tied data
jonckheere.test(x+0.3*g, g)
```

### Cochran-Armitage (CA) trend test

Perform a Cochran Armitage test for trend in binomial proportions across
the levels of a single variable. This test is appropriate only when one
variable has two levels and the other variable is ordinal. The two-level
variable represents the response, and the other represents an
explanatory variable with ordered levels. The null hypothesis is the
hypothesis of no trend, which means that the binomial proportion is the
same for all levels of the explanatory variable.

> 单个变量水平上的二项式比例趋势执行Cochran Armitage测试。
> 仅当一个变量具有两个级别而另一个变量为序数时，才适合使用此测试。
> 两级变量代表响应，另一级代表有序等级的解释变量。
> 零假设是没有趋势的假设，这意味着对于解释变量的所有级别，二项式比例都是相同的。

```{r CA-trend-test ,echo = T,message = FALSE, error = FALSE, warning = FALSE}
library("DescTools")
dose <- matrix(c(10,9,10,7, 0,1,0,3), byrow=TRUE, nrow=2, dimnames=list(resp=0:1, dose=0:3))
Desc(dose)
CochranArmitageTest(dose, "increasing")
CochranArmitageTest(dose)
CochranArmitageTest(dose, "decreasing")

### Test independence using permutation test
library("coin")
lungtumor <- data.frame(dose = rep(c(0, 1, 2), c(40, 50, 48)),
                        tumor = c(rep(c(0, 1), c(38, 2)),
                                  rep(c(0, 1), c(43, 7)),
                                  rep(c(0, 1), c(33, 15))))
independence_test(tumor ~ dose, data = lungtumor, teststat = "quad")


## Test propotion 
tab <- table(lungtumor$dose, lungtumor$tumor)
CochranArmitageTest(tab)
## similar to
prop.trend.test(tab[,1], apply(tab,1, sum))
```

### MCP-Mod

> 传统上，剂量反应研究的设计和分析分为两种策略：一种基于多重比较程序（MCP），另一种基于建模。
> 然而，这些方法具有其缺点。 Bretz等。
> （2005年）提出了一种用于剂量寻找研究的方法，称为MCP-Mod，将MCP原理与建模技术相结合。
> 他们的方法为剂量估算提供了建模的灵活性，同时保留了对与MCP相关的错误指定进行建模的鲁棒性。preserving
> the robustness to model misspecification associated with MCP.

MCP-Mod (Multiple Comparisons Procedure - Modelling) is an increasingly
popular statistical methodology. It can generate superior statistical
evidence from Phase II trials with regards to dose selection. The FDA &
EMA both recently approved this as fit-for-purpose (FFP). MCP-Mod is a
two-step approach for analyzing Phase II dose-finding data, targeting
two of the main Phase II objectives:

> MCP-Mod（多重比较程序-建模）是一种越来越流行的统计方法。
> 在剂量选择方面，它可以从II期试验中获得更好的统计证据。
> FDA和EMA最近都批准此为适用目的（FFP）。是用于分析II期剂量查找数据的两步方法，目标是II期的两个主要目标

-   Establish that the drug works as intended 确定该药物可按预期工作
-   Determine the appropriate doses for Phase III testing
    确定用于III期测试的合适剂量

+---+-------------------------------------------------------------------+
| M | Robust but restricted to selected doses as nominal variable       |
| C | 功能强大，但仅限于所选剂量作为标称变量                            |
| P |                                                                   |
+===+===================================================================+
| M | Flexible quantitative approach but reliant on model choice        |
| o | 灵活的定量方法，但依赖于模型选择                                  |
| d |                                                                   |
+---+-------------------------------------------------------------------+
| M | Design Stage: Select candidate models & generate optimal tests    |
| C | 选择候选模型并生成最佳测试 MCP Stage: Select best model(s) w/     |
| P | appropriate contrasts but control FWER                            |
| - | 选择具有适当对比度的最佳模型，但控制FWER Mod Stage: Model using   |
| M | best model and find target dose(s) of interest                    |
| o | 使用最佳模型进行建模并找到感兴趣的目标剂量                        |
| d |                                                                   |
+---+-------------------------------------------------------------------+

The strength of MCP-Mod lies in providing flexibility in characterizing
the expected dose-response curve by allowing multiple models to be
evaluated at the same time while still giving results that are efficient
and control the error rates.

> MCP-Mod的优势在于，通过允许同时评估多个模型，同时仍然提供有效的结果并控制错误率，可灵活地表征预期的剂量反应曲线。

MCP-Mod过程包含5个步骤，但分为两个不同的阶段。

-   The first step (MCP-step) is used to assess the presence of a dose
    response signal using a trend test deducted from a set of
    pre-specified candidate models.
    第一步（MCP步骤）用于使用从一组预先指定的候选模型中扣除的趋势测试来评估剂量响应信号的存在。

    -   Define a suitable study population to represent the underlying
        true dose-response shape.
        定义合适的研究人群以代表潜在的真实剂量反应形状。

    -   Pre-Specify the candidate dose response models based on
        available information. These are based on assessment of relevant
        metrics such as type I error rate, power to detect a significant
        dose-response shape, and the power to find the minimal effective
        dose. 根据可用信息预先指定候选剂量反应模型。
        这些是基于对相关指标的评估，例如I型错误率，检测出显着剂量反应形状的功效以及找到最小有效剂量的功效

    -   Dose determination and sample size calculation to achieve
        targeted performance characteristics.
        剂量确定和样本量计算可实现目标性能特征。

-   The second step (Mod-step) relies on parametric modeling or model
    averaging to find the "optimal' dose for confirmatory trials.
    第二步（修改步骤）依赖于参数化建模或模型平均，以找到用于验证性试验的"最佳"剂量。

    -   Later, a candidate model is selected using model selection
        criteria like Akaike Information Criterion (AIC) or Bayesian
        Information Criterion (BIC) or averaging.
        使用模型选择标准（如Akaike信息准则（AIC）或贝叶斯信息准则（BIC））或平均来选择候选模型。

    -   Dose-response and target dose estimation based on selected
        models. (Mod part of MCP-Mod).
        基于所选模型的剂量反应和目标剂量估计。

### Two Stage Phase II Design for Response and Toxicity

Phase II designs are often used to determine whether a new procedure or
treatment is likely to meet a basic level of efficacy to warrant further
development or evaluation. Phase IIa designs are focussed on the
proof-of-concept part of Phase II trials. They aim to show the potential
efficacy and safety of a proposed treatment. Two-stage designs are
common to allow for flexibility to stop trials early for futility as
Phase II is the most common failure point in drug evaluation.

> II期设计通常用于确定新程序或治疗是否有可能满足基本的疗效水平，以保证进一步的开发或评估。
> IIa期设计的重点是II期试验的概念验证部分。他们的目的是表明拟议疗法的潜在疗效和安全性。由于II期是药物评估中最常见的失败点，因此通常采用两阶段设计，以便灵活地提前终止试验，因为徒劳无功。

The method outlined in Bryant and Day (1995). As mentioned, often
evaluation of toxicity is listed as a primary objective in Phase IIa
trials. The Bryant and Day design is a two stage phase IIa design with a
coprimary endpoint which allows one to evaluate both the efficacy and
the toxicity of the drug or treatment within a single design.

> 遵循Bryant and
> Day（1995）中概述的方法。如前所述，在IIa期试验中，经常将毒性评估列为主要目标。
> Bryant和Day设计是具有共同主要终点的IIa阶段两阶段设计，该设计使人们可以在单个设计中评估药物或治疗的功效和毒性。

Phase IIa methods like Simon's Design looking for evidence of "response"
and will stop early if no signal. Phase IIb changed significantly by
combining robust MCP with modelling rather than separating these
objectives

## Trials Design (Phase III)

### Non-inferiority and Equivalence Three-armed trial

Non-inferiority testing is a common hypothesis test in the development
of generic medicine and medical devices. The most common design compares
the proposed non-inferior treatment to the standard treatment alone but
this leaves uncertain if the treatment effect is the same as from
previous studies. This "assay sensitivity" problem can be resolved by
using a three-arm trial which includes placebo alongside the new and
reference treatments for direct comparison.

> 非劣势性检验是仿制药和医疗器械开发中常见的假设检验。
> 最常见的设计将建议的非劣效治疗与标准治疗进行了比较，但是这些治疗效果是否与以前的研究相同，尚不确定。
> 可以通过三臂试验解决该"测定敏感性"问题，该试验包括安慰剂以及新药和参考药，以进行直接比较。

> 三臂NI试验可以同时测试参考相对于安慰剂的优越性，以及实验治疗相对于参考的NI的优越性。由于两样本非劣效试验中不包含安慰剂臂,无法确定阳性对照药的有效性,带来了诸如阳性对照药的测定灵敏度及稳定性无法确证等问题。因此,由于外部确证性,非劣效试验要求达到很高的质量。在伦理学条件允许下,增加安慰剂臂以达到内部确证不失为一个好的选择。包含安慰剂臂的三臂非劣效试验既能评价试验药是否非劣效于阳性对照药,又能评价试验药是否优效于安慰剂。

Design method of the three-arm non-inferiority trial

-   以固定值为非劣效界值的传统的检验方法
-   以阳性对照效应的一部分为非劣效界值的将检验整合的Pigeot法。(相同样本含量时,Pigeot法的检验效能更高,充分利用了所有样本量的信息,提高了检验效率,降低了临床试验的成本)

### Pigeot Method

有文献推荐充分利用所加的安慰剂组的信息，将△定义为阳性药效应(阳性药疗效与安慰剂疗效的差)的一部分，即对于计量资料
$$\Delta=f \cdot\left(\mu_{R}-\mu_{P}\right), f \geqslant-1$$
美国FDA推荐，为一1／2作为确定非劣效界值的一种方法。Pigeot等人哺1对于非劣效界值的确定正是基于这一方法，非劣效的假设检验由传统的
$$\mathrm{H}_{0}: \mu_{E}-\mu_{R} \leqslant \Delta, \mathrm{H}{1}: \mu{\varepsilon}-\mu_{R}>\Delta$$
转化为:
$$\mathrm{H}{0}: \mu{E}-\mu{R} \leqslant f\left(\mu{R}-\mu{P}\right) \text { vs } \mathrm{H}{1}: \mu{E}-\mu{R}>f\left(\mu{R}-\mu{P}\right)$$
其中 $E, R$ 和 $P$ 分别代表试验药、阳性对照药和安 时剂,
$\mu_{E}, \mu_{R}$ 和 $\mu_{P}$ 分别为试验组、阳性对照组 和安慰
剂组的总体均数。令 $f=\theta-1, \theta \in[0, \infty)$, $$
\mathrm{H}_{0}: \mu_{\mathrm{E}}-\mu_{\mathrm{P}} \leqslant \theta\left(\mu_{R}-\mu_{P}\right) \mathrm{vs} \mathrm{H}_{1}: \mu_{E}-\mu_{P}>\theta\left(\mu_{R}-\mu_{P}\right)
$$

## Sample Size Calculation

### **Chi-Square Test**

The sample size calculation for Stage 2 is based on the assumption that
the proportion of patients who have reoccurrence of active disease at
week 16 is 80% for ranibizumab and 45% for AGN-150998. The assumption
for ranibizumab is based on the results from the National Eye Institute
sponsored study that compared the effects of ranibizumab and bevacizumab
in patients with exudative AMD (CATT Research Group, 2011). With 50
patients per treatment group the study will have at least 95% power to
detect a statistical significant difference at week 16 between the
treatment groups for a 2-sided chi-square test at alpha level of 0.05.
Further, assuming a constant hazard ratio of 0.371 (AGN-150998 vs.
ranibizumab) for the reoccurrence of active disease during the 16 week
period, the survival analysis using a log rank test has at least a 95%
power to detect a statistical difference between treatment groups at an
alpha level of 0.05 (survival in 2 groups followed for fixed time).

> 第 2 阶段的样本量计算基于这样的假设，即在第 16
> 周时活动性疾病复发的患者比例对于雷珠单抗为 80%，对于 AGN-150998 为
> 45%。
> 雷珠单抗的假设基于国家眼科研究所赞助的研究结果，该研究比较了雷珠单抗和贝伐单抗对渗出性
> AMD 患者的影响（CATT 研究组，2011 年）。 对于每个治疗组 50
> 名患者，该研究将具有至少 95% 的功效来检测治疗组之间在第 16 周的 α
> 水平为 0.05 的 2 边卡方检验的统计学显着差异。 此外，假设 16
> 周期间活动性疾病复发的恒定风险比为 0.371（AGN-150998
> 与雷珠单抗），使用对数秩检验的生存分析具有至少 95%
> 的功效来检测两者之间的统计差异 α 水平为 0.05 的治疗组（2
> 组的存活率在固定时间之后）。

### Fisher's Exact Test

+-------+--------------------------------------------------------------+
| P     |                                                              |
| aram  |                                                              |
| eter  |                                                              |
+=======+==============================================================+
| p1    | response rate of standard treatment                          |
+-------+--------------------------------------------------------------+
| p2    | response rate of experimental treatment                      |
+-------+--------------------------------------------------------------+
| d     | difference = p2-p1                                           |
+-------+--------------------------------------------------------------+
| pcon  | control group probability                                    |
| trol  |                                                              |
+-------+--------------------------------------------------------------+
| n1    | sample size for the standard treatment group                 |
+-------+--------------------------------------------------------------+
| n2    | sample size for the standard treatment group                 |
+-------+--------------------------------------------------------------+
| ncon  | control group sample size                                    |
| trol  |                                                              |
+-------+--------------------------------------------------------------+
| n     | case group sample size                                       |
| case  |                                                              |
+-------+--------------------------------------------------------------+
| r     | treatments are randomized in 1:r ratio (default r=1)         |
+-------+--------------------------------------------------------------+
| npm   | the sample size program searches for sample sizes in a range |
|       | (+/- npm) to get the exact power                             |
+-------+--------------------------------------------------------------+
| mmax  | the maximum group size for which exact power is calculated   |
+-------+--------------------------------------------------------------+
| n     | total number of subjects                                     |
+-------+--------------------------------------------------------------+
| OR    | odds-ratio                                                   |
+-------+--------------------------------------------------------------+

```{r Fisher Sample Size,echo = T,message = FALSE, error = FALSE, warning = FALSE}
library(clinfun)

### fe.ssize return a 2x3 matrix with CPS and Fisher’s exact sample sizes with power.
p1=0.15
p2=0.07
fe.ssize(p1, p2, alpha=0.05, power=0.8, r=1, npm=5, mmax=1000)


### CPS.ssize returns Casagrande, Pike, Smith sample size which is a very close to the exact. Use this for small differences p2-p1 (hence large sample sizes) to get the result instantaneously.
CPS.ssize(p1, p2, alpha=0.05, power=0.8, r=1)

### fe.mdor return a 3x2 matrix with Schlesselman, CPS and Fisher’s exact minimum detectable odds ratios and the corresponding power.
fe.mdor(ncase=120, ncontrol=120, pcontrol=0.15, alpha=0.05, power=0.8)
```

### T-Test

**Reference: 002.011CSP_Acti-INSP-001_v2 3_29 Sep 14_285_clean final
incl. signatures (1)**

The sample size was calculated using following assumptions: One sided
test, alpha=0,025 and a power of 80%. A clinical relevant reduction of 1
to 2 days should be proved (exact parameter for sample size calculation:
1.5 days) if existent. The standard deviation was taken from Hayden et
al. 1997. The standard deviation of time to alleviation of clinical
(major) symptoms in 6 placebo groups varied from 2.2 to 3.1 days in that
trial. The present sample size calculation is based on a common standard
deviation of 3 taking into account that the early and late randomized
patients may present differing standard deviations varying between those
placebo values. Using these parameters 64 patients per group have been
computed for a t-test and 69 for the Wilcoxon signed rank test. Thus
both groups should contain 70 evaluable patients. Keeping in mind that
there will be a loss of randomized patients not available for analysis a
total of 200 patients will be randomized (100 for each group in the
primary comparison).

> 使用以下假设计算样本量：单面检验，α=0,025 和 80%
> 的功效。如果存在，应证明临床相关减少 1 到 2
> 天（样本量计算的确切参数：1.5 天）。标准偏差取自 Hayden 等人。 1997.
> 在该试验中，6 个安慰剂组临床（主要）症状缓解时间的标准偏差从 2.2 天到
> 3.1 天不等。目前的样本量计算基于 3
> 的共同标准偏差，考虑到早期和晚期随机化患者可能呈现不同的标准偏差，这些标准偏差在这些安慰剂值之间有所不同。使用这些参数计算了每组
> 64 名患者的 t 检验和 69 名威尔科克森符号秩检验。因此，两组都应包含 70
> 名可评估的患者。请记住，将丢失不可用于分析的随机化患者，总共 200
> 名患者将被随机化（主要比较中每组 100 名）。

## Data Analysis Methods in CIP

### Statistical Analysis Plan

**Reference: Prot_1.pdf**

The statistical and analytical plans presented below summarize the more
complete plans to be detailed in the statistical analysis plan (SAP). A
change to the data analysis methods described in the protocol will
require a protocol amendment only if it alters a principal feature of
the protocol. The SAP was finalized prior to first patient visit. Any
changes to the methods described in the final SAP will be described and
justified in the clinical study report.

> 下面列出的统计和分析计划总结了将在统计分析计划 (SAP)
> 中详述的更完整的计划。
> 协议中描述的数据分析方法的更改只有在改变协议的主要特征时才需要修改协议。
> SAP 在第一次患者就诊之前完成。 对最终 SAP
> 中描述的方法的任何更改都将在临床研究报告中进行描述和证明。

A statistical analysis plan (SAP) must be written and finalized before
study closure, i.e., before database closure and unblinding of the
randomization code. The SAP must provide full details of the analyses,
the data displays, and the algorithms to be used for data derivations.

> 统计分析计划 (SAP)
> 必须在研究结束之前编写并最终确定，即在数据库关闭和随机化代码揭盲之前。
> SAP 必须提供分析、数据显示和用于数据推导的算法的完整细节。

### General Considerations

-   **Randomization and Blinding**

-   **Adjustments for Covariates**

    -   \*Example\*\*: This is a phase 3 study. Stratified analyses will
        include adjustment for the stratification factors as recorded at
        randomization (described in Section 9.3.1.1). Covariates may be
        considered for adjustment in exploratory regression analyses

-   **Handling of Dropouts and Missing Data**

    -   *Survival Example*: Missing data will not be imputed, with the
        exception of AE start dates while calculating duration of
        events. Patients with missing values of a variable other than
        the time-to-event endpoints (PFS and OS) will be excluded from
        the analysis of that endpoint. Censoring rules will be applied
        to the estimation of the distribution of the time-to-event
        endpoints (see Sections 9.2.1 and 9.2.2.3).
        除了计算事件持续时间时的 AE 开始日期外，不会估算缺失的数据。
        除了事件发生时间终点（PFS 和
        OS）之外的变量缺失值的患者将从该终点的分析中排除。
        审查规则将应用于估计事件发生时间端点的分布

-   **Data Transformations and Derivations**

    -   The date of progression will be the earliest of all radiologic
        scan dates for the given disease assessment. No other data
        transformation is planned for the primary or secondary efficacy
        endpoints.

-   **Analysis Sets**

-   **Examination of Subgroups**

    -   As exploratory analyses, subgroup analyses may be conducted for
        selected endpoints. Detailed methodology will be provided in the
        SAP.

### Analysis Sets

#### Full-Analysis-Set (FAS)

The Full-Analysis-Set should include all randomized trial participants.
They will be analyzed as randomized according to the Intention-To-Treat
(ITT) principle. Basically, this implies evaluating all trial subjects
within their allocated treatment group, regardless of whether they
changed the treatment group, refused or discontinued the therapy, or
other violations of the protocol occurred. The accurate definition of
the Full-Analysis-Set is described in the study protocol or in the
statistical analysis plan in compliance with ICH guideline E9.
Imputation techniques may be required to substitute missing values of
important variables. The applied imputation methods should be defined in
the study protocol or statistical analysis plan.

It is possible to define the FAS by means of a modified ITT (mITT)
principle. The mITT population is a subset of the FAS population and
allows exclusion of randomized subjects in a justified way (e.g.
patients deemed ineligible after randomization and patients who never
started treatment or received less than a specified minimum amount of
the intended intervention).

#### Per-Protocol-Set (PPS)

The Per-Protocol-Set is defined as the group of trial subjects, in which
no (major/critical) protocol deviations occurred, which were treated
according to the protocol and all examinations required to evaluate the
study's objectives were completed. The definition of the PPS therefore
is highly dependent on the conditions of a specific trial. The PPS is a
subset of the FAS. Subjects who have been treated and reported to a
certain degree of compliance with the protocol in all essential aspects
of the trial may be analyzed in the PPS. This should be discussed and
described in the statistical analysis plan. The detailed reasons for
excluding subjects from the PPS should be fully defined. In blinded
studies this should happen prior to unblinding.

#### Safety-Evaluation-Set (SES)

The Safety-Evaluation-Set generally consists of all enrolled subjects
who received study treatment at least once. The Safety-Evaluation-Set
should be defined in the study protocol or in the statistical analysis
plan and should be used as the primary analysis set for all safety
evaluations.

#### Examples

-   *Example ACT-128800*

    -   Safety set: This analysis set includes all randomized patients
        who received at least one dose of the study drug.
    -   Modified intent-to-treat set (mITT): This analysis set includes
        all randomized patients who received at least one dose of the
        study drug and had at least one post-baseline MRI examination.
    -   Per-protocol set: This analysis set includes all patients in the
        mITT set meeting the criteria for evaluable patients, defined as
        patients presenting with RRMS, with a baseline MRI (or at least
        a screening MRI), and at least one post-baseline MRI examination
        between Week 12 and the end of study treatment, and considered
        as sufficiently treated with the study drug (≥ 80% study drug
        intake without any interruption longer than 14 consecutive days)
        from study drug initiation to the date of the last available MRI
        examination.

-   *Example 002.011CSP_Acti-INSP-001_v2 3_29 Sep 14_285_clean final
    incl. signatures (1)*

    -   The primary efficacy analysis set will be the modified intent to
        treat (MITT) population of all subjects who received at least
        one dose of study drug (or an inhalation of placebo) and who had
        influenza infection confirmed by RT-PCR.

    -   The per protocol (PP) analysis set will include all subjects
        from the MITT population who had at least 13 inhalations of
        LASAG and had no major protocol deviations (identified prior to
        database lock and unblinding).

    -   The safety analysis set (SA) will include all subjects
        randomized in the trial who received at least one inhalation.
        Treatment groups for the SA will be defined by real treatments
        of patients.

        主要疗效分析集将是所有接受至少一剂研究药物（或吸入安慰剂）且经
        RT-PCR 确认感染流感的所有受试者的改良意向治疗 (MITT) 人群。
        每个协议 (PP) 分析集将包括来自 MITT
        人群的所有受试者，他们至少吸入了 13 次 LASAG
        并且没有重大的协议偏差（在数据库锁定和揭盲之前确定）。
        安全性分析集 (SA) 将包括试验中随机接受至少一次吸入的所有受试者。
        SA 的治疗组将由患者的实际治疗定义。

### Patient Disposition

**Reference: Prot_1.pdf**

An accounting of study patients by disposition will be tabulated by
treatment group. The number of patients in each analysis population will
be summarized by treatment group. Patients who discontinue study
treatment and patients who withdraw from the study will be summarized by
treatment and reason for discontinuation or withdrawal and listed

> 按处置对研究患者的统计将按治疗组制成表格。
> 每个分析群体中的患者数量将按治疗组进行汇总。
> 中止研究治疗的患者和退出研究的患者将按治疗和中止或退出原因汇总并列出

### Patient Characteristics

**Reference: Prot_1.pdf**

Demographics, other baseline characteristics, and concomitant
medications will be summarized by treatment group and listed.

Previous and concomitant medications will be coded according to the WHO
drug code and the Anatomical Therapeutic Chemical (ATC) Classification
System. They will be summarized by type (e.g., previous, concomitant,
for AE) by tabulating the number and percentages of patients having
received each treatment.

### Treatment Compliance

**Reference: Prot_1.pdf**

The dose administered at each cycle for each treatment agent will be
assessed and dose intensity will be summarized. Details will be provided
in the SAP

### Descriptive/Explorative Analysis

The secondary analysis will be based on the MITT, all secondary tests
are of exploratory character only. The following secondary analyses will
be performed

> 二次分析将基于 MITT，所有二次测试仅具有探索性。 将进行以下二次分析

**Responders Analysis**

Responders are defined as patients who meet prespecified criteria in
percent change in average pain intensity score (≥ 30% and in 10%
increments up to 100%). The proportions of these responders will be
analyzed by week using Pearson's chi square or Fisher's exact test as
appropriate. The cumulative proportions of responders will be presented
in a continuous scale through weeks 4, 8, and 12.

\> 反应者被定义为在平均疼痛强度评分的百分比变化（≥ 30% 和以 10%
的增量增加到 100%）方面符合预先指定标准的患者。
这些响应者的比例将按周使用 Pearson 卡方或 Fisher 精确检验进行分析。
响应者的累积比例将在第 4、8 和 12 周连续显示。

**Reference: Prot_1.pdf**

Quality of life total and subscale scores will be summarized with
descriptive statistics by treatment group and visit using the ITT
analysis set. In addition, change from baseline will be tabulated by
treatment group and visit. Descriptive summaries of individual items may
also be presented. Additional statistical modeling for MRU and PRO
measures may be performed separately in post hoc analyses

> 生活质量总分和子量表分数将使用 ITT
> 分析集通过治疗组和访问的描述性统计数据进行总结。
> 此外，将从基线的变化按治疗组和访问制表。
> 还可以呈现单个项目的描述性摘要。 MRU 和 PRO
> 测量的附加统计建模可以在事后分析中单独执行

**Reference: Prot_2.pdf**

Prior to formal modeling, exploratory methods will be employed to assess
data quality, preliminary evidence of associations and to detect the
presence of outlying values and potential influence points. Means,
standard deviations, medians, and ranges will be computed for continuous
variables, and sample probability mass functions computed for
categorical factors. Histograms, scatter plots, and box plots will be
used to assess skew and examine assumptions (such as normality)
underlying statistical models. Baseline characteristics for the four
randomized subcohorts will be compared using ANOVA for continuous
variables and Fisher's exact tests for categorical variables. Where
appropriate, log or power transformations of outcome variables will be
employed to enhance conformity with assumptions (e.g. normality in
outcomes and/or linearity in associations between outcomes and
covariates). Exploratory graphical assessment of the strength of
association between covariates and outcome variables will be obtained
via scatterplot smoothing using Generalized Additive Models. A
preliminary assessment of the quantity and pattern of missing data will
also be performed.

> 在正式建模之前，将采用探索性方法来评估数据质量、关联的初步证据并检测外围值和潜在影响点的存在。将为连续变量计算均值、标准差、中位数和范围，并为分类因子计算样本概率质量函数。直方图、散点图和箱线图将用于评估偏斜和检查统计模型基础的假设（例如正态性）。四个随机子队列的基线特征将使用连续变量的
> ANOVA 和分类变量的 Fisher
> 精确检验进行比较。在适当的情况下，将采用结果变量的对数或幂变换来增强与假设的一致性（例如结果的正态性和/或结果与协变量之间关联的线性）。协变量和结果变量之间的关联强度的探索性图形评估将通过散点图平滑使用广义加性模型获得。还将对缺失数据的数量和模式进行初步评估。

**Reference: 002.011CSP_Acti-INSP-001_v2 3_29 Sep 14_285_clean final
incl. signatures (1)**

Each item reported in the eCRF will be analyzed in a descriptive manner
with number of units, mean, standard deviation, min, max, median and
quartiles in case of numeric values and counts and percentages in case
of classified items. These descriptive statistics will be reported
separately for both treatment groups.

> eCRF
> 中报告的每个项目将以描述方式进行分析，包括单位数、平均值、标准偏差、最小值、最大值、中位数和四分位数（如果是数值）以及计数和百分比（如果是分类项目）。
> 将针对两个治疗组分别报告这些描述性统计数据。

### Efficacy Survival Analyses

**Reference: Prot_1.pdf**

Kaplan-Meier methods will be used to assess PFS. The stratified log-rank
test without adjustments for covariates will be used in the primary
evaluation of PFS differences between the experimental arm and the
standard-of-care arm in the ITT analysis set using a one-sided, α =
0.025 level test. All events entered in the database at the time of
analysis that have been source data-verified will be included in the
analysis of PFS, even if there are more than the prespecified number of
events. Kaplan-Meier Curves depicting PFS in the 2 arms will be
generated. Additionally, median PFS and probability of PFS from 3 months
to the end of the follow-up period will be reported at 3-month
intervals. The two-sided 95% confidence intervals (CI) for the median
and 3-month intervals will be calculated using the complementary log-log
transformation method (Collett 1994). Detailed methodology is provided
in the SAP.

> Kaplan-Meier 方法将用于评估 PFS。
> 未对协变量进行调整的分层对数秩检验将用于使用单边 α = 0.025 水平检验对
> ITT 分析集中实验组和标准护理组之间的 PFS 差异进行初步评估。
> 在分析时输入到数据库中且经过源数据验证的所有事件都将包含在 PFS
> 分析中，即使事件数量超过预先指定的数量。 将生成描述 2 个臂中 PFS 的
> Kaplan-Meier 曲线。 此外，将每隔 3 个月报告一次从 3
> 个月到随访期结束的中位 PFS 和 PFS 概率。 中位数和 3 个月间隔的两侧 95%
> 置信区间 (CI) 将使用互补对数-对数转换方法 (Collett 1994) 计算。 SAP
> 中提供了详细的方法论。

ORR and CR rate will be summarized by treatment group using the ITT
analysis set. An exact two-sided 95% confidence interval using the
Clopper-Pearson method (Clopper 1934) will be calculated.

> ORR 和 CR 率将使用 ITT 分析集按治疗组进行汇总。 将使用 Clopper-Pearson
> 方法 (Clopper 1934) 计算精确的两侧 95% 置信区间。

OS will be analyzed using Kaplan-Meier methodology and Kaplan-Meier
plots will be provided by treatment group using the ITT analysis set.
The median OS and its two-sided 95% CI using the complementary log-log
transformation method (Collett 1994) will be calculated by treatment
group

> OS 将使用 Kaplan-Meier 方法进行分析，Kaplan-Meier 图将由治疗组使用 ITT
> 分析集提供。 使用互补对数转换方法 (Collett 1994) 将按治疗组计算中位 OS
> 及其两侧 95% CI

### Efficacy ANOVA Analyses

**Example 1 BOTOX**

The primary efficacy analysis will be a comparison of placebo and 200 U
BOTOX at the week 12 post treatment visit B, using the change from
baseline in the total IPSS score. This will be done by using an analysis
of variance model with treatment, baseline IPSS ("\<=21 or \>21) and
adjuvant BPH therapy usage (use or no use) as the main effects in the
model (type III sum of squares will be used). Adjusted (least-squares)
means will be obtained from the model and 2-sided 95% confidence
intervals for the difference in least-squares means between 200 U BOTOX
and placebo will be constructed from the model.

> 主要疗效分析将是在治疗访问 B 后第 12 周时比较安慰剂和 200 U
> BOTOX，使用总 IPSS
> 评分相对于基线的变化。这将通过使用方差分析模型来完成，其中治疗、基线
> IPSS（"\<=21 或 \>21）和辅助 BPH
> 治疗使用（使用或不使用）作为模型中的主要影响（III
> 型平方和将将从模型中获得调整后的（最小二乘法）均值，并从模型中构建 200
> U BOTOX 和安慰剂之间最小二乘法均值差异的 2 边 95% 置信区间。

The hypotheses to compare placebo and 200 U BOTOX dose are:

\* Primary null hypothesis - at the primary timepoint, the difference in
mean change from baseline in total IPSS score between placebo and 200 U
BOTOX is zero; ie, the effectiveness of placebo is identical to 200 U
BOTOX, using the mITT and ITT populations.

\* Primary alternative hypothesis - at the primary timepoint the
difference in mean change from baseline in total IPSS between placebo
and 200 U BOTOX is not equal to zero; ie, the effectiveness of placebo
is not equal to the effectiveness of 200 U BOTOX, using the mITT and ITT
populations.

**Example 2**

Subjects who meet the eligibility criteria will be randomly assigned to
one of four treatment groups based on a stratified randomization
schedule developed by the biostatistician, using the permuted blocks
strategy with randomly varying blocks of size 4 and 8. Stratification
will be by diabetes status.
符合资格标准的受试者将根据生物统计学家制定的分层随机化时间表随机分配到四个治疗组之一，使用大小为
4 和 8 的随机变化块的置换块策略。分层将按糖尿病状态进行。

-   Group A: Placebo injections weekly; 0.8 g/kg/day protein
-   Group B: Placebo injections weekly; 1.3 g/kg/day protein
-   Group C: Testosterone enanthate 100 mg intramuscularly weekly; 0.8 g
    • kg • day protein
-   Group D: Testosterone enanthate 100 mg intramuscularly weekly; 1.3 g
    • kg • day protein

The primary analysis of lean body mass will be performed in two parts.
Our primary analytical strategy is to use mixed-effects regression
analysis to assess 3 and 6 month outcomes simultaneously with baseline
total body lean mass considered as a covariate, as is appropriate for
between-group comparisons of randomized subcohorts, and 6-month
differences between arms will be estimated via a treatment contrast and
corresponding 95% confidence interval. We will also use a two-way ANOVA
to compare change from baseline to 6-month across the four randomized
subcohorts. We expect general agreement between estimates arising from
Parts I and II, but owing to its use of all data, that from mixed
effects regression analysis will be considered the principal estimate of
treatment effect. Though the primary aim of the analysis will be to
estimate treatment effects at 6-months, a linear trend in change with
time will not be assumed, and the potential for differential mean
trajectories in treatment effects over the entire duration of follow-up
will be assessed via stratification and the use of statistical
interaction terms. Unless otherwise noted, all comparisons will assume
an allowed type-I error probability of 0.05.

> 瘦体重的主要分析将分两部分进行。我们的主要分析策略是使用混合效应回归分析来评估
> 3 个月和 6
> 个月的结果，同时将基线总瘦体重视为协变量，这适用于随机子队列的组间比较，以及两组之间的
> 6 个月差异将通过治疗对比和相应的 95%
> 置信区间进行估计。我们还将使用双向方差分析来比较四个随机子队列从基线到
> 6 个月的变化。我们预计第 I 部分和第 II
> 部分得出的估计值之间普遍一致，但由于它使用了所有数据，混合效应回归分析的数据将被视为治疗效果的主要估计值。虽然分析的主要目的是估计
> 6
> 个月时的治疗效果，但不会假设随时间变化的线性趋势，并且在整个随访期间治疗效果的差异平均轨迹的潜力将是通过分层和使用统计交互术语进行评估。除非另有说明，所有比较均假设允许的
> I 类错误概率为 0.05。

Multiple Comparisons: We recognize that a number of hypotheses will be
tested, which will increase the likelihood of committing a type 1 error.
We are aware of many different approaches that can be used to adjust for
multiple comparisons. A two -sided, 5% level of significance will be
used for each pre-specified hypothesis and magnitude of effect size will
be carefully evaluated for clinical significance. For exploratory
hypotheses, we will adjust the p value by using the Boneferroni's
correction. It is still possible that we will find statistical
significance in some instances when the differences are of little
clinical significance. In such cases, the clinical importance of
findings -- whether the magnitude of treatment effect meets or exceeds
the minimal clinically important difference in the outcome - will be
highlighted in the interpretation of results.

> 多重比较：我们认识到将测试许多假设，这将增加犯第 1 类错误的可能性。
> 我们知道有许多不同的方法可用于调整多重比较。
> 对于每个预先指定的假设，将使用两侧 5%
> 的显着性水平，并且将仔细评估效应大小的临床显着性。
> 对于探索性假设，我们将使用 Boneferroni 校正来调整 p 值。
> 当差异几乎没有临床意义时，我们仍有可能在某些情况下发现统计显着性。
> 在这种情况下，结果的临床重要性------治疗效果的大小是否达到或超过结果的最小临床重要差异------将在结果的解释中得到强调。

**Example 3**

The primary efficacy variable is the change from Baseline in atrophic
lesion area in the study eye. The primary analysis will use the mITT
population and will be based on an Analysis of Covariance (ANCOVA) model
that includes the treatment group and region as the factors and the
baseline lesion area as the covariate. The least-squares means (LS
means) for change from baseline will be calculated for each group.
Statistical test for the between-group difference (Brimo DDS versus
Sham) in LS means and the construction of the corresponding 2-sided 95%
confidence intervals will be done using the same ANCOVA model. If
warranted, data transformation will be applied to the atrophic lesion
area (such as the square root transformation), and the final statistical
analysis for the change from baseline will be based on the transformed
data.

> 主要功效变量是研究眼中萎缩性病变区域相对于基线的变化。 主要分析将使用
> mITT 群体，并将基于协方差分析 (ANCOVA)
> 模型，该模型包括治疗组和区域作为因素以及基线病变区域作为协变量。
> 将为每组计算从基线变化的最小二乘均值（LS 均值）。 LS
> 均值的组间差异（Brimo DDS 与 Sham）的统计检验以及相应的 2 边 95%
> 置信区间的构建将使用相同的 ANCOVA 模型进行。
> 如果有必要，将对萎缩病变区域进行数据转换（如平方根转换），最终的基线变化统计分析将基于转换后的数据。

**Example 4**

The primary efficacy analysis will be based on the mITT population.
Missing average pain intensity scores (ie, less than 4 out of 7 daily
scores) at each week will be imputed using the LOCF method. The primary
efficacy analysis will be performed on the change from baseline of
average pain intensity scores at each week. This will be analyzed using
the analysis of covariance (ANCOVA) main effects model, with treatment
as a factor, and the baseline pain intensity and baseline area of
spontaneous pain as the covariates. The least square means will be
obtained from the model, and 2-sided 90% confidence interval of the
difference in least square means will be constructed. A 95% confidence
interval for the mean, as well as graph over time, will be provided for
each treatment. No adjustment for multiple testing will be made.

\> 主要功效分析将基于 mITT 人群。 每周缺失的平均疼痛强度评分（即，少于 7
个每日评分中的 4 个）将使用 LOCF 方法进行估算。
主要功效分析将针对每周平均疼痛强度评分从基线的变化进行。
这将使用协方差分析 (ANCOVA)
主效应模型进行分析，以治疗为因素，以及基线疼痛强度和自发性疼痛的基线面积作为协变量。
将从模型中获得最小二乘均值，并构建最小二乘均值差异的 2 边 90% 置信区间。
将为每个处理提供平均值的 95% 置信区间以及随时间变化的图表。
不会对多次测试进行调整。

### Efficacy GLM Dose-Finding Study

The primary endpoint of this dose-finding study is the cumulative number
of new gadolinium-enhancing lesions per patient on T1-weighted MRI scans
at Weeks 12, 16, 20, and 24.

> 主要终点是在第 12、16、20 和 24 周的 T1 加权 MRI
> 扫描中，每位患者的新钆增强病变的累积数量。

The generalized linear model, with a log link function [Littell 2002],
applied in the study for the primary analysis can be described as
follows: $$
\mu_{\mathrm{i}}=\exp \left(\beta_{\mathrm{i}}\right)
$$ $\mu_{\mathrm{i}}$ expected value of $\mathrm{y}_{\mathrm{i}}$, the
observed number of new gadolinium-enhancing lesions recorded on
$\mathrm{T}_{1}$-weighted MRI scans at Weeks $12,16,20$, and 24 after
study drug initiation of treatment group i $\beta_{i}$ the treatment
effect.

More specifically, the comparisons of each of the active dose groups
with placebo on the primary endpoint are carried out by means of a
negative binomial model with the treatment arm as a four-level
classification explanatory variable, testing individual comparisons of
each of the active treatments and placebo.

The negative binomial distribution is introduced due to the nature of
the data and to reflect the uncertainty about the true rates at which
the number of new gadolinium-enhancing lesions occur for individual
patients [Sormani 1999].

> 更具体地说，每个活性剂量组与安慰剂在主要终点上的比较是通过负二项式模型进行的，治疗组作为四级分类解释变量，测试每个活性治疗的个体比较和安慰剂。
> 引入负二项式分布是由于数据的性质，并反映了个体患者发生新钆增强病变数量的真实比率的不确定性
> [Sormani 1999]。

More specifically the probability of observing $y_{i}$ lesions for each
patient in the $i$-th treatment group at Weeks $12,16,20$, and 24 is
negative binomial with: $$
\operatorname{Pr}\left(\mathrm{y}_{\mathrm{i}} ; \mu_{\mathrm{i}}, \theta\right)=\frac{\Gamma\left(y_{i}+\theta\right)}{\Gamma(\theta) \cdot y_{i} !} \cdot \frac{\theta^{\vartheta} \cdot \mu^{y_{i}}}{(\theta+\mu)^{\left(\theta+y_{i}\right)}}
$$ This distribution has $E(y)=\mu_{i}$ and
$\operatorname{Var}(y)=\left(\mu_{i}+\mu_{i}^{2} / \theta\right)$.

**Hypotheses and statistical inference**

The global null hypothesis is that none of the three active treatment
groups differs from the placebo group for the mean cumulative number of
new gadolinium-enhancing lesions. The alternative hypothesis is that at
least one of the active treatment groups differs from the placebo group.

> 全局无效假设是，三个活性治疗组中没有一个与安慰剂组在新钆增强病变的平均累积数量方面存在差异。
> 另一种假设是，至少有一个活性治疗组不同于安慰剂组。

The global null hypothesis is expressed as a family of null hypothesis
H0i, defined as follows: $$
\begin{array}{l}
\mathrm{H}_{01}: \mu_{1}=\mu_{\text {placebo }} \\
\mathrm{H}_{02}: \mu_{2}=\mu_{\text {placebo }} \\
\mathrm{H}_{03}: \mu_{3}=\mu_{\text {placebo }}
\end{array}
$$ Where $\mu_{\mathrm{i}}$ (with $\mathrm{i}=1,2,3$ ) corresponds to
the mean number of new gadolinium-enhancing lesions per patient on
$\mathrm{T}_{1}$-weighted MRI scans at Weeks $12,16,20$, and 24 for each
of the three active doses and $\mu_{\text {placebo }}$ is the mean
number for the placebo group.

The Bonferroni-Holm's procedure [Holm 1979] is adopted to control the
global type I error set equal to $\alpha=0.05$ two-sided. This stepwise
(step down) procedure is based on ordered $\mathrm{p}$-values, and the
corresponding hypotheses are rejected one at a time. The smallest
p-value will be compared to the two-sided nominal significance level
$0.0167$.

The power of this study to detect a reduction of $50 \%$ of the
cumulative number of new gadolinium-enhancing lesions in at least one of
the active dose groups is set equal to $90 \%$. (i.e., the study-wise
type II error of accepting all three null hypotheses when they are false
is set equal to $0.10$ ).

The study has $90 \%$ power to detect a reduction of $50 \%$ in the
cumulative number of new gadolinium-enhancing lesions in at least one of
the ACT-128800 groups, as compared with the placebo group (i.e., a
reduction from 8 to 4 lesions.

The primary efficacy endpoint is summarized by the treatment group
showing mean, median, standard deviation, standard error, quartiles,
minimum and maximum, and 95% two-sided confidence limits of the mean and
median.

In addition, least-square estimates of treatment mean differences with
the corresponding 95% two-sided confidence limits from the negative
binomial regression model are presented.

### Safety Analyses

#### Extent of Exposure

Duration of treatment, number of cycles, total dose and dose intensity
will be summarized by treatment arm using the safety analysis set. Dose
modifications will also be summarized. Details will be provided in the
SAP

#### Adverse Events

Adverse events will be defined as treatment-emergent if they are newly
occurring or worsen following treatment with XXX. The incidence of all
AEs, treatment-emergent AEs, and treatment-related AEs will be tabulated
by treatment group using the safety analysis set. AEs will be classified
by system organ class and preferred term using the Medical Dictionary
for Regulatory Activities (MedDRA).

AEs will be listed and summarized by treatment group, MedDRA preferred
term, severity, and relationship to study drug using the safety analysis
set. In the event of multiple occurrences of the same AE with the same
preferred term in one patient, the AE will be counted once as the
occurrence. The incidence of AEs will be tabulated by preferred term and
treatment group. AEs leading to premature discontinuation of study drug
or withdrawal from the study will be summarized and listed in the same
manner.

> 如果不良事件是新发生的或在 XXX
> 治疗后恶化，则将定义为治疗中出现的不良事件。 所有 AE、治疗出现的 AE
> 和治疗相关 AE 的发生率将使用安全性分析集按治疗组制成表格。 AE
> 将使用管理活动医学词典 (MedDRA) 按系统器官类别和首选术语进行分类。

> AE 将使用安全性分析集按治疗组、MedDRA
> 首选术语、严重程度和与研究药物的关系列出和总结。
> 如果在一名患者中多次出现具有相同首选术语的相同 AE，则该 AE
> 将被计为一次。 AE 的发生率将按首选术语和治疗组制成表格。
> 导致过早停止研究药物或退出研究的 AE 将以相同的方式进行总结和列出。

#### Deaths and Serious Adverse Events

Serious adverse events will be listed and summarized in the same manner
as all AEs. Adverse events with a fatal outcome will be listed.

#### Clinical Laboratory Results

Summary statistics for actual values and for change from baseline will
be tabulated as appropriate for laboratory results by treatment group
and scheduled visit using the safety analysis set. Patients with
laboratory values outside of the normal reference range at any
postbaseline assessment will be listed by treatment group.

> 实际值和从基线变化的汇总统计将根据实验室结果按治疗组和使用安全性分析集安排的访问适当地制成表格。
> 在任何基线后评估中实验室值超出正常参考范围的患者将按治疗组列出。

### Pharmacokinetic and Pharmacodynamic Analyses

**Reference: Prot_1.pdf**

Antibody drug-conjugate (brentuximab vedotin) and unconjugated drug
(MMAE) levels in serum or plasma will be summarized with descriptive
statistics at each PK sampling time point. Any additional PK and PK/PD
analyses may be described in a separate analysis plan and presented in a
separate report.

> 血清或血浆中的抗体药物偶联物 (brentuximab vedotin) 和未偶联药物 (MMAE)
> 水平将在每个 PK 采样时间点用描述性统计数据进行总结。 任何额外的 PK 和
> PK/PD 分析都可以在单独的分析计划中描述并在单独的报告中呈现。

**Reference: AGN-150998**

Serum AGN-150998 concentrations will be summarized by descriptive
statistics (mean, standard deviation, coefficient of variation, etc.)
using SAS \$\^{\\circledR}\$. Pharmacokinetic parameters including
\$C\_{\\max }, T\_{\\max }, T\_{1 / 2}\$, and \$A U C\_{0-t}\$ will be
calculated from individual patient concentration/time profiles using
standard model independent techniques, if applicable. Descriptive
statistics will be computed for the PK parameters. Plasma concentrations
may be examined in conjunction with safety and/or pharmacodynamic data
for correlations.

> 血清 AGN-150998 浓度将使用 SAS®
> 通过描述性统计（平均值、标准偏差、变异系数等）进行汇总。
> 如果适用，药代动力学参数包括 Cmax、Tmax、T1/2 和 AUC0-t
> 将使用标准模型独立技术从个体患者浓度/时间曲线计算。 将为 PK
> 参数计算描述性统计数据。
> 可以结合安全性和/或药效学数据来检查血浆浓度的相关性

**Reference: Protocol 214868-007 Amendment 3**

The plasma AGN-214868 concentrations will be summarized for each dose by
descriptive statistics using SAS®. Population pharmacokinetic analysis
for pooled plasma AGN-214868 concentrations may be estimated using
NONMEM® (Beal et al, 2008). Concentration data from previously completed
AGN-214868 clinical studies may be included to enrich the data prior to
population pharmacokinetic analysis. Population pharmacokinetic
parameters to be estimated include apparent clearance (CL), apparent
volume of distribution, and absorption rate constant (Ka). Potential
influences by demographic variables and by dose on the pharmacokinetic
parameters will be investigated. In addition, the interpatient
variability of these parameters may be determined. Once the modeling
process is complete, patient-specific drug exposure, including Cmax and
AUC, may be estimated using the posterior conditional estimation
approach (POSTHOC). Systemic AGN-214868 exposure may be correlated to
safety and efficacy variables over time using exploratory quantitative
techniques.

\> 将使用 SAS® 通过描述性统计总结每个剂量的血浆 AGN-214868 浓度。可使用
NONMEM® (Beal 等人，2008) 估计混合血浆 AGN-214868
浓度的群体药代动力学分析。可以包括之前完成的 AGN-214868
临床研究的浓度数据，以在群体药代动力学分析之前丰富数据。要估计的群体药代动力学参数包括表观清除率
(CL)、表观分布容积和吸收速率常数
(Ka)。将研究人口统计学变量和剂量对药代动力学参数的潜在影响。此外，可以确定这些参数的患者间变异性。建模过程完成后，可以使用后验条件估计方法
(POSTHOC) 估计患者特定的药物暴露，包括 Cmax 和 AUC。系统性 AGN-214868
暴露可能与使用探索性定量技术随时间推移的安全性和有效性变量相关。

### Immunogenicity Data Analyses

**Reference: 214868-007 Amd 3.pdf**

The immunogenicity (binding antibodies against AGN-214868, neutralizing
antibodies, and antibodies against the nociceptin variant ligand domain)
results will be summarized as a tabulation of reactive, negative, or
inconclusive results for each dose. Quantitative relationships between
immunogenicity findings and AGN-214868 pharmacokinetic, efficacy, and/or
safety variables may be explored using NONMEM.

> 免疫原性（针对 AGN-214868
> 的结合抗体、中和抗体和针对伤害感受素变体配体结构域的抗体）结果将总结为每个剂量的反应性、阴性或不确定结果的表格。
> 可以使用 NONMEM 探索免疫原性发现与 AGN-214868
> 药代动力学、功效和/或安全性变量之间的定量关系。
