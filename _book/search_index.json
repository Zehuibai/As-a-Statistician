[["parametric-test.html", "Chapter 11 Parametric Test 11.1 Binomial test 11.2 Fishers Exact Test 11.3 McNemars test 11.4 CochranMantelHaenszel Test 11.5 Correlation Test 11.6 Two Sample T-Test 11.7 Normality test", " Chapter 11 Parametric Test Under the null hypothesis of no difference, the differences should be rather small. Of course, the size of the difference would depend on such factors as the sample sizes involved, the precision of our light meter, and the memories of our patients. Even after taking all of these factors into account, there will still be observed differences, and we will need to quantify the magnitude of these. The magnitude of the difference is expressed as the probability that such a difference could have occurred by chance alone under the null hypothesis. This probability is called the p-value. The p-value is a measure of how unusual the observed outcome would be if all the conditions of the null hypothesis were valid. The p-value is also known as the significance level, or statistical significance.   pp p Statistical significance is the probability that such an outcome could have occurred by chance alone, under the null hypothesis. In this case, a small p-value suggests that perhaps the null hypothesis is not the correct explanation for the observed data. Notice that the p-value is not the probability that the null hypothesis is true. This is a common misconception. The p-value is a measure of how tolerant we may be of unusual outcomes. This tolerance will vary depending on the circumstances. p pp p p  Power is the probability of correctly rejecting the null hypothesis when the alternative is true. p.05.05 201 : p true  11.1 Binomial test 11.1.1 Mathematical Formula The Hzpothesis is \\[{\\displaystyle H_{0}:\\pi =\\pi _{0}}\\] For Large samples we have \\[{\\displaystyle Z={\\frac {k-n\\pi }{\\sqrt {n\\pi (1-\\pi )}}}}\\] The continuity correction is an adjustment that is made when a discrete distribution is approximated by a continuous distribution: \\[{\\displaystyle Z={\\frac {k-n\\pi \\pm {\\frac {1}{2}}}{\\sqrt {n\\pi (1-\\pi )}}}}\\] 11.1.2 R implementation Package binom can provide different binomial CI and Test such as exact - Pearson-Klopper method. See also binom.test. asymptotic - the text-book definition for confidence limits on a single proportion using the Central Limit Theorem. wilson - Wilson method. prop.test - equivalent to prop.test(x = x, n = n, conf.level = conf.level)$conf.int. bayes - see binom.bayes. logit - see binom.logit. cloglog - see binom.cloglog. probit - see binom.probit. profile - see binom.profile. Function Description binom.bayes Binomial confidence intervals using Bayesian inference betabeta pbetaxpp | xBetax + prior.shape1n-x +prior.shape2)priorityJeffreyspriorBeta0.50.5  x +0.5/n + 1 binom.logit Binomial confidence intervals using the logit parameterization binom.probit Binomial confidence intervals using the probit parameterization binom.cloglog cloglog The complementary-log-log link function says that \\[\\eta(x) = \\log(-\\log(1-\\pi_x))=\\mathbf{x}\\beta\\] binom.lrt Binomial confidence intervals using the lrt likelihood  likelihood ratio test (LRT) MLE binom.profile Binomial confidence intervals using the profile likelihood .profile likelihood binom.sim Simulates confidence intervals for binomial data binom.confint Binomial confidence intervals binom.coverage Probability coverage for binomial confidence intervals binom.plot Coverage plots for binomial confidence intervals binom.length Expected length for binomial confidence intervals binom.power Power curves for binomial parameterizations cloglog.sample.size Power and sample size for a binomial proportion using the cloglog parameterization cloglog.sample.size Power and sample size for a binomial proportion using the cloglog parameterization library(binom) binom.test(3,4,0.99,alternative = &quot;less&quot;) library(pwr) pwr.p.test(ES.h(3/4,0.99),n = 42,alternative = &quot;less&quot;) 11.1.3 SAS Implementation See more ODS Table Names ODS Table Name Description Statement Option BinomialCLs Binomial confidence limits TABLES BINOMIAL(CL=) BinomialEquivTest Binomial equivalence test TABLES BINOMIAL(EQUIV) BinomialNoninf Binomial noninferiority test TABLES BINOMIAL(NONINF) BinomialTest Binomial proportion test TABLES BINOMIAL CMH Cochran-Mantel-Haenszel test TABLES CMH ChiSq Chi-square tests TABLES CHISQ EqualKappaTests Tests for equal kappas TABLES AGREE EqualOddsRatios Tests for equal odds ratios EXACT EQOR GammaTest Gamma test TEST GAMMA LRChiSq Likelihood ratio chi-square exact test EXACT LRCHI MHChiSq Mantel-Haenszel chi-square exact test EXACT MHCHI OneWayChiSq One-way chi-square test TABLES CHISQ PearsonCorr Pearson correlation TEST PCORR 11.2 Fishers Exact Test Fishers exact test is particularly appropriate when dealing with small samples. Comparing to the contingency chi-square test, Fishers exact test is to exaclty calculate the p-value rather than being based on an asymptotic approximation. 11.2.1 Introduction Hypotheses The hypotheses of the Fishers exact test are the same than for the Chi-square test, that is: \\(H_0\\): the variables are independent, there is no relationship between the two categorical variables. Knowing the value of one variable does not help to predict the value of the other variable \\(H_1\\): the variables are dependent, there is a relationship between the two categorical variables. Knowing the value of one variable helps to predict the value of the other variable Studying a b a + b Non-studying c d c + d Column Total a + c b + d a + b + c + d (=n) \\[{\\displaystyle p={\\frac {\\displaystyle {{a+b} \\choose {a}}\\displaystyle {{c+d} \\choose {c}}}{\\displaystyle {{n} \\choose {a+c}}}}={\\frac {\\displaystyle {{a+b} \\choose {b}}\\displaystyle {{c+d} \\choose {d}}}{\\displaystyle {{n} \\choose {b+d}}}}={\\frac {(a+b)!~(c+d)!~(a+c)!~(b+d)!}{a!~~b!~~c!~~d!~~n!}}}\\] 11.2.2 SAS implementation https://www.pharmasug.org/proceedings/2012/PO/PharmaSUG-2012-PO05.pdf *** 0) Prepare example data; data EXAMPLE; do ID = 1 to 50; GROUP = &quot;A&quot;; RESULT =&quot;negative&quot;; output; end; do ID = 51 to 100; GROUP = &quot;B&quot;; RESULT =&quot;negative&quot;; output; end; RUN; *** 1) Define a format for the variable for which the statistical test should be conducted with PROC FREQ (Note: A dummy format is sufficient if the variable of interest is a character variable); proc format; value $RESULT_F &quot;positive&quot;=&quot;positive&quot; &quot;negative&quot;=&quot;negative&quot;; run; *** 2) Count frequencies for variable of interest (Note: It is essential to use PRELOADFMT and PRINTMISS in order to have all possible values of the variable of interest in the output datasset); proc tabulate data=EXAMPLE out=FREQUENCIES; class GROUP RESULT / preloadfmt; * PRELOADFMT loads the format of class variables if available; table GROUP*RESULT*(n) / printmiss; * (n) requests only frequencies and PRINTMISS requests entries also for values of the variable of interest which do not occur; format RESULT $RESULT_F.; * Assign format if it has not been done before; run; *** 3) The count for values which not occurred has to be set from missing to 0; data FREQUENCIES_mod; set FREQUENCIES (where=(RESULT ne &quot;&quot;)); * Delete frequency of missing values for the variable of interest ; if N eq . then N = 0; * Convert missing to 0; run; *** 4) Execute statistical test; proc sort data=FREQUENCIES_mod; by GROUP; run; proc freq data=FREQUENCIES_mod; by GROUP; * Analysis by group; weight N/zeros; * Indicate that the input dataset already contains summary data (WEIGHT option) and indicate that entries with frequency 0 should be included (ZEROS option); tables RESULT / binomial(cl=wald exact LEVEL=&quot;positive&quot;) alpha=0.05; exact binomial; output out=OUTPUT binomial; RUN; 11.2.3 R implementation dat &lt;- data.frame( &quot;smoke_no&quot; = c(7, 0), &quot;smoke_yes&quot; = c(2, 5), row.names = c(&quot;Athlete&quot;, &quot;Non-athlete&quot;), stringsAsFactors = FALSE ) colnames(dat) &lt;- c(&quot;Non-smoker&quot;, &quot;Smoker&quot;) dat ## Non-smoker Smoker ## Athlete 7 2 ## Non-athlete 0 5 ## Expected frequencies chisq.test(dat)$expected ## Non-smoker Smoker ## Athlete 4.5 4.5 ## Non-athlete 2.5 2.5 ## Fishers exact test fisher.test(dat) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: dat ## p-value = 0.02098 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 1.449481 Inf ## sample estimates: ## odds ratio ## Inf 11.3 McNemars test 11.3.1 introduction Simar to the contigency test, McNemars test can be used to analyze categorical data in survey and questionnarie. But when the data are dependent, McNemars test is more appropiate. t is applied to 2 × 2 contingency tables with a dichotomous trait, with matched pairs of subjects, to determine whether the row and column marginal frequencies are equal (that is, whether there is marginal homogeneity). The test is applied to a \\(2 \\times 2\\) contingency table, which tabulates the outcomes of two tests on a sample of \\(N\\) subjects, as follows. \\[ \\begin{tabular}{|c|c|c|c|} \\hline &amp; Test 2 positive &amp; Test 2 negative &amp; Row total \\\\ \\hline Test 1 positive &amp; $a$ &amp; $b$ &amp; $a+b$ \\\\ \\hline Test 1 negative &amp; $c$ &amp; $d$ &amp; $c+d$ \\\\ \\hline Column total &amp; $a+c$ &amp; $b+d$ &amp; $N$ \\\\ \\hline \\end{tabular} \\] The null hypothesis of marginal homogeneity states that the two marginal probabilities for each outcome are the same, i.e. \\(p_{a}+p_{b}=p_{a}+p_{c}\\) and \\(p_{c}+p_{d}=p_{b}+p_{d}\\) The null and alternative hypotheses are \\(H_{0}: p_{b}=p_{c}\\) \\(H_{1}: p_{b} \\neq p_{c}\\) The McNemar test statistic is: \\[ \\chi^{2}=\\frac{(b-c)^{2}}{b+c} \\] Under the null hypothesis, with a sufficiently large number of discordants (cells b and c), \\(\\chi^{2}\\) has a chi-squared distribution with 1 degree of freedom. If the \\(\\chi^{2}\\) result is significant, this provides sufficient evidence to reject the null hypothesis, in favour of the alternative hypothesis that \\(p_{b} \\neq p_{c}\\), which would mean that the marginal proportions are significantly different from each other. 11.3.2 SAS Implementation proc freq data=athelete; title &quot;McNemar&#39;s test for Paired Samples&quot;; tables treatX*treatY /agree expected norow nocol nopercent; run; 11.3.3 R Implementation set.seed(150) data &lt;- data.frame(before = sample(c(&quot;Positive&quot;, &quot;Positive&quot;, &quot;Positive&quot;, &quot;Positive&quot;, &quot;Negative&quot;), 300, replace = TRUE), after = sample(c(&quot;Positive&quot;, &quot;Positive&quot;, &quot;Positive&quot;, &quot;Positive&quot;, &quot;Negative&quot;), 300, replace = TRUE)) ### contingency table table(data$before, data$after) ## ## Negative Positive ## Negative 13 49 ## Positive 55 183 mcnemar.test(table(data$before, data$after)) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: table(data$before, data$after) ## McNemar&#39;s chi-squared = 0.24038, df = 1, p-value = 0.6239 11.4 CochranMantelHaenszel Test McNemarCMH Treatment No treatment Row total Title Case Ai Bi N1i Controls Ci Di N2i Column total M1i M2i Ti The common odds-ratio of the K contingency tables is defined as: \\[{\\displaystyle R={{\\sum _{i=1}^{K}{{A_{i}D_{i}} \\over T_{i}}} \\over {\\sum _{i=1}^{K}{{B_{i}C_{i}} \\over T_{i}}}},}\\] The null hypothesis is that there is no association between the treatment and the outcome. More precisely, the null hypothesis is: \\(H_0\\): \\(R = 1\\) \\(H_1\\): \\(R \\neq 1\\) The test statistic is: \\[{\\displaystyle \\xi _{CMH}={[{\\sum _{i=1}^{K}(A_{i}-{N_{1i}M_{1i} \\over T_{i}})]^{2}} \\over {\\sum _{i=1}^{K}{N_{1i}N_{2i}M_{1i}M_{2i} \\over T_{i}^{2}(T_{i}-1)}}}.}\\] 11.4.1 R implementation library(vcd) mytable &lt;- xtabs(~Treatment+Improved+Sex, data=Arthritis) mantelhaen.test(mytable) 11.5 Correlation Test 11.5.1 Pearson correlation The correlation is calculated as \\[r = \\frac{\\sum{(x-m_x)(y-m_y)}}{\\sqrt{\\sum{(x-m_x)^2}\\sum{(y-m_y)^2}}}\\] The p-value (significance level) of the correlation can be determined: by using the correlation coefficient table for the degrees of freedom : df=n2, where nn is the number of observations in x and y variables. or by calculating the t value as follow: \\[t = \\frac{r}{\\sqrt{1-r^2}}\\sqrt{n-2}\\] 11.5.2 Spearman correlation \\[rho = \\frac{\\sum(x&#39; - m_{x&#39;})(y&#39;_i - m_{y&#39;})}{\\sqrt{\\sum(x&#39; - m_{x&#39;})^2 \\sum(y&#39; - m_{y&#39;})^2}}\\] where \\(x&#39; = rank(x_)\\) and \\(y&#39; = rank(y)\\) 11.5.3 Kendall correlation Begin by ordering the pairs by the \\(x\\) values. If \\(x\\) and \\(y\\) are correlated, then they would have the same relative rank orders. Now, for each \\(y_{i}\\), count the number of \\(y_{j}&gt;y_{i}\\) (concordant pairs (\\(n_{c}\\))) and the number of \\(y_{j}&lt;y_{i}\\) (discordant pairs (\\(n_{d}\\))). \\(n\\) is the size of \\(x\\) and \\(y\\) \\[t a u=\\frac{n_{c}-n_{d}}{\\frac{1}{2} n(n-1)}\\]  (0) cor.test()PearsonSpearmanKendall. xyalternative( two.sidelessgreater)method(pearson kendallspearman)0alternative= less0alternative=greater pcor(u,s) cor(x, y, method = c(&quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;)) cor.test(x, y, method=c(&quot;pearson&quot;, &quot;kendall&quot;, &quot;spearman&quot;)) 11.6 Two Sample T-Test 11.6.1 Inreoduction Assumptions Two sample t-test assumes that There is one continuous dependent variable and one categorical independent variable (with 2 levels); The two samples are independent; The two samples follow normal distributions, and can be done with Normality check. When the assumptions are not met, other methods are possible based on the two samples: Two dependent samples and follow Normal distribution, suggest Paired T-test; Two independent samples and does not follow Normal distribution, suggest WMW test; Two dependent samples and does not follow Normal distribution, suggest Signed Rank test; Two-sample t-test for unpaired data \\[\\mathrm{H}_{0}: \\mu_{1}=\\mu_{2}\\] \\[\\mathrm{H}_{\\mathrm{a}}: \\mu_{1} \\neq \\mu_{2}\\] Test Statistic: \\[T=\\frac{\\bar{Y}_{1}-\\bar{Y}_{2}}{\\sqrt{s_{1}^{2} / N_{1}+s_{2}^{2} / N_{2}}}\\] where \\(N_{1}\\) and \\(N_{2}\\) are the sample sizes, \\(\\bar{Y}_{1}\\) and \\(\\bar{Y}_{2}\\) are the sample means, and \\(s_{1}^{2}\\) and \\(s_{2}^{2}\\) are the sample variances. If equal variances are assumed, then the formula reduces to: \\[ T=\\frac{\\bar{Y}_{1}-\\bar{Y}_{2}}{s_{p} \\sqrt{1 / N_{1}+1 / N_{2}}} \\] where \\[ s_{p}^{2}=\\frac{\\left(N_{1}-1\\right) s_{1}^{2}+\\left(N_{2}-1\\right) s_{2}^{2}}{N_{1}+N_{2}-2} \\] Reject the null hypothesis that the two means are equal if \\[ |T|&gt;t_{1-\\alpha / 2, v} \\] where \\(t_{1-\\alpha / 2, v}\\) is the critical value of the \\(\\underline{\\underline{d} \\text { dstribution with }} v\\) degrees of freedom where \\[ v=\\frac{\\left(s_{1}^{2} / N_{1}+s_{2}^{2} / N_{2}\\right)^{2}}{\\left(s_{1}^{2} / N_{1}\\right)^{2} /\\left(N_{1}-1\\right)+\\left(s_{2}^{2} / N_{2}\\right)^{2} /\\left(N_{2}-1\\right)} \\] If equal variances are assumed, then \\(v=N_{1}+N_{2}-2\\) Paired Samples t Test The test statistic for the Paired Samples t Test, denoted \\(t\\), follows the same formula as the one sample \\(t \\mathrm{te}\\) \\[ t=\\frac{\\bar{x}_{\\mathrm{diff}}-0}{s_{\\bar{x}}} \\] where \\[ s_{\\bar{x}}=\\frac{s_{\\mathrm{diff}}}{\\sqrt{n}} \\] where \\(\\bar{x}_{\\text {diff }}=\\) Sample mean of the differences \\(n=\\) Sample size (i.e., number of observations) \\(s_{\\text {diff }}=\\) Sample standard deviation of the differences \\(s_{\\bar{x}}=\\) Estimated standard error of the mean \\((s / \\operatorname{sqrt}(n))\\) 11.6.2 SAS implementation roc ttest data=read sides=2 alpha=0.05 h0=0; title &quot;Two sample t-test example&quot;; class method; var grade; run; 11.6.3 R implementation ## One Sample t-test t.test(X, mu= 1, alternative=&quot;two.sided&quot;, conf.level=0.95)$conf.int ## Two Sample t-test t.test(A, B,var.equal=TRUE, paired=TRUE) ## Gauß Test (Bekannt Variance) mu0 &lt;- 0 alpha &lt;- 0.05 # (zweiseitig): sigma &lt;- 1 unten &lt;- qnorm(alpha/2,mean=mu0,sd=(sigma)/(sqrt(n))) oben &lt;- qnorm(1-alpha/2,mean=mu0,sd=(sigma)/(sqrt(n))) ## T Test (Unbekannt Variance) mu1 &lt;- 1 tcr &lt;- qt(p=1-alpha, df=n-1) ncp1 &lt;- abs(mu1-mu0)*sqrt(n)/sigma power &lt;- 1-pt(q=tcr, df=n-1, ncp=ncp1) 11.7 Normality test Checking the assumptionof Normality is necessary for many statistical methods. For example two sample t test or ANOVA. In this section we introduce some common ways to access normality: the normal probability plot and test statistics. The normal probabiltiy plot, QQplot creates quantile-quantile plots and compares ordered variable values with quantiles of a specific theoretical distribution. If the data distribution matches the theoretical distribution, the points on the plot form a linear pattern. In SAS, there are four test statistics for detecting the presence of non-normality, namely, the Shapiro-Wilk (Shapiro &amp; Wilk, 1965), the Kolmogorov-Smirnov test, Cramer von Mises test, and the Anderson-Darling test. Details and discussions are given below. For example, in the two sample t test example , the assumption is the variables are normal. 11.7.1 SAS implementation proc univariate data=read normal; qqplot grade /Normal(mu=est sigma=est color=red l=1); by method; run; 11.7.2 R implementation Shapiro-Wilk Test shapiro.test(X2) "]]
