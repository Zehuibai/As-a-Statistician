<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 30 Bayesian Theory | As a Statistician</title>
  <meta name="description" content="This book involves different statistical principles and methods, including the application of SAS and R, and aims to accumulate personal statistical knowledge." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 30 Bayesian Theory | As a Statistician" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book involves different statistical principles and methods, including the application of SAS and R, and aims to accumulate personal statistical knowledge." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 30 Bayesian Theory | As a Statistician" />
  
  <meta name="twitter:description" content="This book involves different statistical principles and methods, including the application of SAS and R, and aims to accumulate personal statistical knowledge." />
  

<meta name="author" content="Zehui Bai" />


<meta name="date" content="2022-09-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regularization-penalized-regression.html"/>
<link rel="next" href="smoothing.html"/>
<script src="libs/header-attrs-2.14/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/d3-3.5.17/d3.min.js"></script>
<link href="libs/markmap-0.3.3/view.mindmap.css" rel="stylesheet" />
<script src="libs/markmap-0.3.3/view.mindmap.js"></script>
<script src="libs/markmap-0.3.3/plugins/parsemd.min.js"></script>
<script src="libs/markmap-binding-1.2.3/markmap.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">As a Statistician</a></li>

<li class="divider"></li>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="data-management-in-sas.html#data-management-in-sas" id="toc-data-management-in-sas"><span class="toc-section-number">2</span> Data Management in SAS</a>
<ul>
<li><a href="data-management-in-sas.html#input-data-into-sas" id="toc-input-data-into-sas"><span class="toc-section-number">2.1</span> Input data into SAS</a>
<ul>
<li><a href="data-management-in-sas.html#native-datasets-input" id="toc-native-datasets-input"><span class="toc-section-number">2.1.1</span> Native datasets input</a></li>
<li><a href="data-management-in-sas.html#reading-free-formatted-data-instream" id="toc-reading-free-formatted-data-instream"><span class="toc-section-number">2.1.2</span> Reading free formatted data instream</a></li>
<li><a href="data-management-in-sas.html#reading-fixed-formatted-data-instream" id="toc-reading-fixed-formatted-data-instream"><span class="toc-section-number">2.1.3</span> Reading fixed formatted data instream</a></li>
<li><a href="data-management-in-sas.html#infile-reading-fixed-formatted-data-from-an-external-file" id="toc-infile-reading-fixed-formatted-data-from-an-external-file"><span class="toc-section-number">2.1.4</span> INFILE: Reading fixed formatted data from an external file</a></li>
<li><a href="data-management-in-sas.html#write-the-sas-file" id="toc-write-the-sas-file"><span class="toc-section-number">2.1.5</span> Write the SAS File</a></li>
<li><a href="data-management-in-sas.html#import-csv-data" id="toc-import-csv-data"><span class="toc-section-number">2.1.6</span> Import csv data</a></li>
<li><a href="data-management-in-sas.html#import" id="toc-import"><span class="toc-section-number">2.1.7</span> %Import</a></li>
<li><a href="data-management-in-sas.html#url" id="toc-url"><span class="toc-section-number">2.1.8</span> URL</a></li>
<li><a href="data-management-in-sas.html#infile-read-multiple-raw-data-files" id="toc-infile-read-multiple-raw-data-files"><span class="toc-section-number">2.1.9</span> Infile Read multiple raw data files</a></li>
<li><a href="data-management-in-sas.html#generate-automatic-file-name" id="toc-generate-automatic-file-name"><span class="toc-section-number">2.1.10</span> Generate automatic file name</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#format-the-variables" id="toc-format-the-variables"><span class="toc-section-number">2.2</span> Format the variables</a>
<ul>
<li><a href="data-management-in-sas.html#proc-format" id="toc-proc-format"><span class="toc-section-number">2.2.1</span> Proc format</a></li>
<li><a href="data-management-in-sas.html#copy-and-combine-sas-format-libraries" id="toc-copy-and-combine-sas-format-libraries"><span class="toc-section-number">2.2.2</span> Copy and combine SAS format libraries</a></li>
<li><a href="data-management-in-sas.html#build-a-format-from-a-dataset" id="toc-build-a-format-from-a-dataset"><span class="toc-section-number">2.2.3</span> Build a format from a dataset</a></li>
<li><a href="data-management-in-sas.html#output-format-as-datasets" id="toc-output-format-as-datasets"><span class="toc-section-number">2.2.4</span> Output format as datasets</a></li>
<li><a href="data-management-in-sas.html#delete-the-format" id="toc-delete-the-format"><span class="toc-section-number">2.2.5</span> Delete the format</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#array" id="toc-array"><span class="toc-section-number">2.3</span> Array</a>
<ul>
<li><a href="data-management-in-sas.html#defining" id="toc-defining"><span class="toc-section-number">2.3.1</span> Defining</a></li>
<li><a href="data-management-in-sas.html#format-multiple-variables" id="toc-format-multiple-variables"><span class="toc-section-number">2.3.2</span> Format multiple variables</a></li>
<li><a href="data-management-in-sas.html#arrays" id="toc-arrays"><span class="toc-section-number">2.3.3</span> 2*2 arrays</a></li>
<li><a href="data-management-in-sas.html#dynamic-element-list-using-macro-variables" id="toc-dynamic-element-list-using-macro-variables"><span class="toc-section-number">2.3.4</span> Dynamic Element List using Macro Variables</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#retain" id="toc-retain"><span class="toc-section-number">2.4</span> Retain</a>
<ul>
<li><a href="data-management-in-sas.html#generate-serial-number" id="toc-generate-serial-number"><span class="toc-section-number">2.4.1</span> Generate Serial Number</a></li>
<li><a href="data-management-in-sas.html#change-from-basilne" id="toc-change-from-basilne"><span class="toc-section-number">2.4.2</span> Change from Basilne</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#data-utilities" id="toc-data-utilities"><span class="toc-section-number">2.5</span> Data utilities</a>
<ul>
<li><a href="data-management-in-sas.html#scan" id="toc-scan"><span class="toc-section-number">2.5.1</span> %Scan</a></li>
<li><a href="data-management-in-sas.html#eval-and-syseval" id="toc-eval-and-syseval"><span class="toc-section-number">2.5.2</span> %eval and %syseval</a></li>
<li><a href="data-management-in-sas.html#macro-variable-status" id="toc-macro-variable-status"><span class="toc-section-number">2.5.3</span> Macro variable status</a></li>
<li><a href="data-management-in-sas.html#sysfunc" id="toc-sysfunc"><span class="toc-section-number">2.5.4</span> %SYSFUNC</a></li>
<li><a href="data-management-in-sas.html#quoting-function" id="toc-quoting-function"><span class="toc-section-number">2.5.5</span> Quoting Function</a></li>
<li><a href="data-management-in-sas.html#call-symput" id="toc-call-symput"><span class="toc-section-number">2.5.6</span> Call Symput</a></li>
<li><a href="data-management-in-sas.html#call-execute" id="toc-call-execute"><span class="toc-section-number">2.5.7</span> Call Execute</a></li>
<li><a href="data-management-in-sas.html#sysfunc-get-the-observations" id="toc-sysfunc-get-the-observations"><span class="toc-section-number">2.5.8</span> %sysfunc get the observations</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#clean-up" id="toc-clean-up"><span class="toc-section-number">2.6</span> Clean Up</a>
<ul>
<li><a href="data-management-in-sas.html#basic-setting" id="toc-basic-setting"><span class="toc-section-number">2.6.1</span> Basic setting</a></li>
<li><a href="data-management-in-sas.html#delete-datasets" id="toc-delete-datasets"><span class="toc-section-number">2.6.2</span> Delete datasets</a></li>
<li><a href="data-management-in-sas.html#deleting-formats" id="toc-deleting-formats"><span class="toc-section-number">2.6.3</span> Deleting Formats</a></li>
<li><a href="data-management-in-sas.html#remove-assigned-formats" id="toc-remove-assigned-formats"><span class="toc-section-number">2.6.4</span> Remove assigned formats</a></li>
<li><a href="data-management-in-sas.html#delete-macro-variables" id="toc-delete-macro-variables"><span class="toc-section-number">2.6.5</span> Delete macro variables</a></li>
<li><a href="data-management-in-sas.html#delete-macro" id="toc-delete-macro"><span class="toc-section-number">2.6.6</span> Delete Macro</a></li>
</ul></li>
</ul></li>
<li><a href="data-management-in-r.html#data-management-in-r" id="toc-data-management-in-r"><span class="toc-section-number">3</span> Data Management in R</a>
<ul>
<li><a href="data-management-in-r.html#basic-data-management" id="toc-basic-data-management"><span class="toc-section-number">3.1</span> Basic data management</a>
<ul>
<li><a href="data-management-in-r.html#apply-family" id="toc-apply-family"><span class="toc-section-number">3.1.1</span> apply family</a></li>
</ul></li>
<li><a href="data-management-in-r.html#importimput" id="toc-importimput"><span class="toc-section-number">3.2</span> import/imput</a>
<ul>
<li><a href="data-management-in-r.html#package-readr" id="toc-package-readr"><span class="toc-section-number">3.2.1</span> Package readr</a></li>
<li><a href="data-management-in-sas.html#import-csv-data" id="toc-import-csv-data"><span class="toc-section-number">3.2.2</span> Import csv data</a></li>
<li><a href="data-management-in-r.html#import-txt-data" id="toc-import-txt-data"><span class="toc-section-number">3.2.3</span> Import txt data</a></li>
<li><a href="data-management-in-r.html#import-excel-data" id="toc-import-excel-data"><span class="toc-section-number">3.2.4</span> Import excel data</a></li>
<li><a href="data-management-in-r.html#import-stata-data" id="toc-import-stata-data"><span class="toc-section-number">3.2.5</span> Import stata data</a></li>
<li><a href="data-management-in-r.html#import-sas-data" id="toc-import-sas-data"><span class="toc-section-number">3.2.6</span> Import SAS data</a></li>
<li><a href="data-management-in-r.html#copy-from-clipboard" id="toc-copy-from-clipboard"><span class="toc-section-number">3.2.7</span> Copy from clipboard</a></li>
<li><a href="data-management-in-r.html#save-and-write-objective-in-r" id="toc-save-and-write-objective-in-r"><span class="toc-section-number">3.2.8</span> Save and write objective in R</a></li>
<li><a href="data-management-in-r.html#save-the-plot" id="toc-save-the-plot"><span class="toc-section-number">3.2.9</span> Save the plot</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-tidyr" id="toc-package-tidyr"><span class="toc-section-number">3.3</span> Package tidyr</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet" id="toc-cheat-sheet"><span class="toc-section-number">3.3.1</span> CHEAT SHEET</a></li>
<li><a href="data-management-in-r.html#pivoting" id="toc-pivoting"><span class="toc-section-number">3.3.2</span> Pivoting</a></li>
<li><a href="data-management-in-r.html#gather-and-spread" id="toc-gather-and-spread"><span class="toc-section-number">3.3.3</span> gather and spread</a></li>
<li><a href="data-management-in-r.html#separate-and-unite" id="toc-separate-and-unite"><span class="toc-section-number">3.3.4</span> separate and unite</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-dplyr" id="toc-package-dplyr"><span class="toc-section-number">3.4</span> Package dplyr</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-1" id="toc-cheat-sheet-1"><span class="toc-section-number">3.4.1</span> CHEAT SHEET</a></li>
<li><a href="data-management-in-r.html#across" id="toc-across"><span class="toc-section-number">3.4.2</span> across</a></li>
<li><a href="data-management-in-r.html#arrange" id="toc-arrange"><span class="toc-section-number">3.4.3</span> arrange</a></li>
<li><a href="data-management-in-r.html#coalesce" id="toc-coalesce"><span class="toc-section-number">3.4.4</span> coalesce</a></li>
<li><a href="data-management-in-r.html#filter" id="toc-filter"><span class="toc-section-number">3.4.5</span> filter</a></li>
<li><a href="data-management-in-r.html#if_else" id="toc-if_else"><span class="toc-section-number">3.4.6</span> if_else</a></li>
<li><a href="data-management-in-r.html#join" id="toc-join"><span class="toc-section-number">3.4.7</span> join</a></li>
<li><a href="data-management-in-r.html#mutate" id="toc-mutate"><span class="toc-section-number">3.4.8</span> mutate</a></li>
<li><a href="data-management-in-r.html#select" id="toc-select"><span class="toc-section-number">3.4.9</span> select</a></li>
<li><a href="data-management-in-r.html#summarise" id="toc-summarise"><span class="toc-section-number">3.4.10</span> summarise</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-stringr" id="toc-package-stringr"><span class="toc-section-number">3.5</span> Package stringr</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-2" id="toc-cheat-sheet-2"><span class="toc-section-number">3.5.1</span> CHEAT SHEET</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-forcats" id="toc-package-forcats"><span class="toc-section-number">3.6</span> Package forcats</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-3" id="toc-cheat-sheet-3"><span class="toc-section-number">3.6.1</span> CHEAT SHEET</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-lubridate" id="toc-package-lubridate"><span class="toc-section-number">3.7</span> Package lubridate</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-4" id="toc-cheat-sheet-4"><span class="toc-section-number">3.7.1</span> CHEAT SHEET</a></li>
</ul></li>
</ul></li>
<li><a href="ggplot2.html#ggplot2" id="toc-ggplot2"><span class="toc-section-number">4</span> ggplot2</a>
<ul>
<li><a href="ggplot2.html#parametric-rendering" id="toc-parametric-rendering"><span class="toc-section-number">4.1</span> Parametric Rendering</a>
<ul>
<li><a href="ggplot2.html#grammar" id="toc-grammar"><span class="toc-section-number">4.1.1</span> Grammar</a></li>
<li><a href="ggplot2.html#coordinate-system" id="toc-coordinate-system"><span class="toc-section-number">4.1.2</span> Coordinate system</a></li>
<li><a href="ggplot2.html#legend" id="toc-legend"><span class="toc-section-number">4.1.3</span> Legend</a></li>
<li><a href="ggplot2.html#geom" id="toc-geom"><span class="toc-section-number">4.1.4</span> geom</a></li>
<li><a href="ggplot2.html#position" id="toc-position"><span class="toc-section-number">4.1.5</span> position</a></li>
<li><a href="ggplot2.html#scale" id="toc-scale"><span class="toc-section-number">4.1.6</span> scale</a></li>
<li><a href="ggplot2.html#stat" id="toc-stat"><span class="toc-section-number">4.1.7</span> stat</a></li>
<li><a href="ggplot2.html#color" id="toc-color"><span class="toc-section-number">4.1.8</span> Color</a></li>
<li><a href="ggplot2.html#thema" id="toc-thema"><span class="toc-section-number">4.1.9</span> Thema</a></li>
<li><a href="ggplot2.html#saving-plots" id="toc-saving-plots"><span class="toc-section-number">4.1.10</span> Saving plots</a></li>
</ul></li>
<li><a href="ggplot2.html#scatter-plot" id="toc-scatter-plot"><span class="toc-section-number">4.2</span> Scatter plot</a>
<ul>
<li><a href="ggplot2.html#grouping-aesthetic" id="toc-grouping-aesthetic"><span class="toc-section-number">4.2.1</span> Grouping Aesthetic</a></li>
<li><a href="ggplot2.html#facet" id="toc-facet"><span class="toc-section-number">4.2.2</span> facet</a></li>
<li><a href="ggplot2.html#geom_smooth" id="toc-geom_smooth"><span class="toc-section-number">4.2.3</span> geom_smooth</a></li>
<li><a href="ggplot2.html#dot-plot" id="toc-dot-plot"><span class="toc-section-number">4.2.4</span> Dot Plot</a></li>
<li><a href="ggplot2.html#label-and-title" id="toc-label-and-title"><span class="toc-section-number">4.2.5</span> Label and Title</a></li>
<li><a href="ggplot2.html#residuals" id="toc-residuals"><span class="toc-section-number">4.2.6</span> Residuals</a></li>
<li><a href="ggplot2.html#encircling" id="toc-encircling"><span class="toc-section-number">4.2.7</span> Encircling</a></li>
<li><a href="ggplot2.html#dumbbell-plot" id="toc-dumbbell-plot"><span class="toc-section-number">4.2.8</span> Dumbbell Plot</a></li>
</ul></li>
<li><a href="ggplot2.html#histogram" id="toc-histogram"><span class="toc-section-number">4.3</span> Histogram</a>
<ul>
<li><a href="ggplot2.html#general-appearance" id="toc-general-appearance"><span class="toc-section-number">4.3.1</span> General appearance</a></li>
<li><a href="ggplot2.html#themes" id="toc-themes"><span class="toc-section-number">4.3.2</span> Themes</a></li>
<li><a href="ggplot2.html#geom_freqpoly" id="toc-geom_freqpoly"><span class="toc-section-number">4.3.3</span> geom_freqpoly()</a></li>
<li><a href="ggplot2.html#marginal-histogram-boxplot" id="toc-marginal-histogram-boxplot"><span class="toc-section-number">4.3.4</span> Marginal Histogram / Boxplot</a></li>
<li><a href="ggplot2.html#scales" id="toc-scales"><span class="toc-section-number">4.3.5</span> Scales</a></li>
</ul></li>
<li><a href="ggplot2.html#bar-plot" id="toc-bar-plot"><span class="toc-section-number">4.4</span> Bar plot</a>
<ul>
<li><a href="ggplot2.html#aesthetic" id="toc-aesthetic"><span class="toc-section-number">4.4.1</span> Aesthetic</a></li>
<li><a href="ggplot2.html#proportion" id="toc-proportion"><span class="toc-section-number">4.4.2</span> Proportion</a></li>
<li><a href="ggplot2.html#coord" id="toc-coord"><span class="toc-section-number">4.4.3</span> coord</a></li>
<li><a href="ggplot2.html#statidentity" id="toc-statidentity"><span class="toc-section-number">4.4.4</span> stat=“identity”</a></li>
<li><a href="ggplot2.html#ranking" id="toc-ranking"><span class="toc-section-number">4.4.5</span> Ranking</a></li>
<li><a href="ggplot2.html#means-and-error-bars" id="toc-means-and-error-bars"><span class="toc-section-number">4.4.6</span> Means and error bars</a></li>
<li><a href="ggplot2.html#waffle-chart" id="toc-waffle-chart"><span class="toc-section-number">4.4.7</span> Waffle Chart</a></li>
</ul></li>
<li><a href="ggplot2.html#box-plot" id="toc-box-plot"><span class="toc-section-number">4.5</span> Box plot</a>
<ul>
<li><a href="ggplot2.html#varwidth" id="toc-varwidth"><span class="toc-section-number">4.5.1</span> varwidth</a></li>
<li><a href="ggplot2.html#reorder" id="toc-reorder"><span class="toc-section-number">4.5.2</span> Reorder</a></li>
<li><a href="ggplot2.html#fill" id="toc-fill"><span class="toc-section-number">4.5.3</span> Fill</a></li>
<li><a href="ggplot2.html#statidentity-1" id="toc-statidentity-1"><span class="toc-section-number">4.5.4</span> stat=“identity”</a></li>
<li><a href="ggplot2.html#dot-box-plot" id="toc-dot-box-plot"><span class="toc-section-number">4.5.5</span> Dot + Box Plot</a></li>
<li><a href="ggplot2.html#violin-plot" id="toc-violin-plot"><span class="toc-section-number">4.5.6</span> Violin Plot</a></li>
</ul></li>
<li><a href="ggplot2.html#other-rendering" id="toc-other-rendering"><span class="toc-section-number">4.6</span> Other rendering</a>
<ul>
<li><a href="ggplot2.html#annotation" id="toc-annotation"><span class="toc-section-number">4.6.1</span> Annotation</a></li>
<li><a href="ggplot2.html#text-ggtext" id="toc-text-ggtext"><span class="toc-section-number">4.6.2</span> Text: ggtext</a></li>
<li><a href="ggplot2.html#text-ggrepel" id="toc-text-ggrepel"><span class="toc-section-number">4.6.3</span> Text: ggrepel</a></li>
<li><a href="ggplot2.html#arrage-gridextra" id="toc-arrage-gridextra"><span class="toc-section-number">4.6.4</span> Arrage: gridExtra</a></li>
<li><a href="ggplot2.html#interactive-charts-plotly" id="toc-interactive-charts-plotly"><span class="toc-section-number">4.6.5</span> Interactive charts: plotly</a></li>
</ul></li>
<li><a href="ggplot2.html#diagrammer" id="toc-diagrammer"><span class="toc-section-number">4.7</span> DiagrammeR</a>
<ul>
<li><a href="ggplot2.html#basic-flowchart-using-grviz" id="toc-basic-flowchart-using-grviz"><span class="toc-section-number">4.7.1</span> Basic flowchart using <code>grViz</code></a></li>
<li><a href="ggplot2.html#graphviz-attributes" id="toc-graphviz-attributes"><span class="toc-section-number">4.7.2</span> Graphviz Attributes</a></li>
<li><a href="ggplot2.html#gantt-chart" id="toc-gantt-chart"><span class="toc-section-number">4.7.3</span> Gantt chart</a></li>
</ul></li>
<li><a href="ggplot2.html#ggstatsplot" id="toc-ggstatsplot"><span class="toc-section-number">4.8</span> ggstatsplot</a>
<ul>
<li><a href="ggplot2.html#ggbetweenstats" id="toc-ggbetweenstats"><span class="toc-section-number">4.8.1</span> ggbetweenstats</a></li>
</ul></li>
</ul></li>
<li><a href="descriptive-statistics-in-r.html#descriptive-statistics-in-r" id="toc-descriptive-statistics-in-r"><span class="toc-section-number">5</span> Descriptive Statistics in R</a>
<ul>
<li><a href="descriptive-statistics-in-r.html#package-pape" id="toc-package-pape"><span class="toc-section-number">5.1</span> Package pape</a></li>
<li><a href="descriptive-statistics-in-r.html#package-summarytools" id="toc-package-summarytools"><span class="toc-section-number">5.2</span> Package summarytools</a></li>
<li><a href="descriptive-statistics-in-r.html#package-comparegroups" id="toc-package-comparegroups"><span class="toc-section-number">5.3</span> Package compareGroups</a></li>
<li><a href="descriptive-statistics-in-r.html#package-sjplot-for-models-summary" id="toc-package-sjplot-for-models-summary"><span class="toc-section-number">5.4</span> Package sjPlot for Models Summary</a>
<ul>
<li><a href="descriptive-statistics-in-r.html#tab_model-and-options" id="toc-tab_model-and-options"><span class="toc-section-number">5.4.1</span> tab_model and options</a></li>
<li><a href="descriptive-statistics-in-r.html#mixed-models" id="toc-mixed-models"><span class="toc-section-number">5.4.2</span> Mixed Models</a></li>
<li><a href="descriptive-statistics-in-r.html#plot_model" id="toc-plot_model"><span class="toc-section-number">5.4.3</span> plot_model</a></li>
</ul></li>
<li><a href="descriptive-statistics-in-r.html#package-kableextra" id="toc-package-kableextra"><span class="toc-section-number">5.5</span> Package kableExtra</a>
<ul>
<li><a href="descriptive-statistics-in-r.html#kable_styling" id="toc-kable_styling"><span class="toc-section-number">5.5.1</span> kable_styling</a></li>
<li><a href="descriptive-statistics-in-r.html#columnrow-specification" id="toc-columnrow-specification"><span class="toc-section-number">5.5.2</span> Column/Row Specification</a></li>
<li><a href="descriptive-statistics-in-r.html#grouping-columnsrows" id="toc-grouping-columnsrows"><span class="toc-section-number">5.5.3</span> Grouping columns/rows</a></li>
<li><a href="descriptive-statistics-in-r.html#add-footnote" id="toc-add-footnote"><span class="toc-section-number">5.5.4</span> Add Footnote</a></li>
</ul></li>
</ul></li>
<li><a href="parametric-test.html#parametric-test" id="toc-parametric-test"><span class="toc-section-number">6</span> Parametric Test</a>
<ul>
<li><a href="parametric-test.html#binomial-test" id="toc-binomial-test"><span class="toc-section-number">6.1</span> Binomial test</a>
<ul>
<li><a href="parametric-test.html#mathematical-formula" id="toc-mathematical-formula"><span class="toc-section-number">6.1.1</span> Mathematical Formula</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">6.1.2</span> R implementation</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">6.1.3</span> SAS Implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#fishers-exact-test" id="toc-fishers-exact-test"><span class="toc-section-number">6.2</span> Fisher’s Exact Test</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">6.2.1</span> Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">6.2.2</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">6.2.3</span> R implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#sensitivity-and-specificity" id="toc-sensitivity-and-specificity"><span class="toc-section-number">6.3</span> Sensitivity and specificity</a></li>
<li><a href="parametric-test.html#mcnemars-test" id="toc-mcnemars-test"><span class="toc-section-number">6.4</span> McNemar’s test</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">6.4.1</span> introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-2" id="toc-sas-implementation-2"><span class="toc-section-number">6.4.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-2" id="toc-r-implementation-2"><span class="toc-section-number">6.4.3</span> R Implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#cochranmantelhaenszel-test" id="toc-cochranmantelhaenszel-test"><span class="toc-section-number">6.5</span> Cochran–Mantel–Haenszel Test</a>
<ul>
<li><a href="parametric-test.html#r-implementation-3" id="toc-r-implementation-3"><span class="toc-section-number">6.5.1</span> R implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#correlation-test" id="toc-correlation-test"><span class="toc-section-number">6.6</span> Correlation Test</a>
<ul>
<li><a href="parametric-test.html#pearson-correlation" id="toc-pearson-correlation"><span class="toc-section-number">6.6.1</span> Pearson correlation</a></li>
<li><a href="parametric-test.html#spearman-correlation" id="toc-spearman-correlation"><span class="toc-section-number">6.6.2</span> Spearman correlation</a></li>
<li><a href="parametric-test.html#kendall-correlation" id="toc-kendall-correlation"><span class="toc-section-number">6.6.3</span> Kendall correlation</a></li>
</ul></li>
<li><a href="parametric-test.html#two-sample-t-test" id="toc-two-sample-t-test"><span class="toc-section-number">6.7</span> Two Sample T-Test</a>
<ul>
<li><a href="parametric-test.html#inreoduction" id="toc-inreoduction"><span class="toc-section-number">6.7.1</span> Inreoduction</a></li>
<li><a href="parametric-test.html#sas-implementation-3" id="toc-sas-implementation-3"><span class="toc-section-number">6.7.2</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-4" id="toc-r-implementation-4"><span class="toc-section-number">6.7.3</span> R implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#normality-test" id="toc-normality-test"><span class="toc-section-number">6.8</span> Normality test</a>
<ul>
<li><a href="parametric-test.html#sas-implementation-4" id="toc-sas-implementation-4"><span class="toc-section-number">6.8.1</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-5" id="toc-r-implementation-5"><span class="toc-section-number">6.8.2</span> R implementation</a></li>
</ul></li>
</ul></li>
<li><a href="non-parametric-test.html#non-parametric-test" id="toc-non-parametric-test"><span class="toc-section-number">7</span> Non-Parametric Test</a>
<ul>
<li><a href="non-parametric-test.html#two-samples-hypotheses-testing" id="toc-two-samples-hypotheses-testing"><span class="toc-section-number">7.1</span> Two Samples Hypotheses Testing</a>
<ul>
<li><a href="non-parametric-test.html#sign-test-for-location-parameter-for-matched-paired-samples" id="toc-sign-test-for-location-parameter-for-matched-paired-samples"><span class="toc-section-number">7.1.1</span> Sign Test for Location Parameter for Matched Paired Samples</a></li>
<li><a href="non-parametric-test.html#wilcoxon-signed-rank-test-for-location-parameter-for-matched" id="toc-wilcoxon-signed-rank-test-for-location-parameter-for-matched"><span class="toc-section-number">7.1.2</span> Wilcoxon Signed-Rank Test for Location Parameter for Matched</a></li>
<li><a href="non-parametric-test.html#wilcoxon-rank-sum-test-for-location-parameter-for-two-independent-samples" id="toc-wilcoxon-rank-sum-test-for-location-parameter-for-two-independent-samples"><span class="toc-section-number">7.1.3</span> Wilcoxon Rank-Sum Test for Location Parameter for Two Independent Samples</a></li>
<li><a href="non-parametric-test.html#ansari-bradley-test-for-scale-parameter-for-two-independent-samples" id="toc-ansari-bradley-test-for-scale-parameter-for-two-independent-samples"><span class="toc-section-number">7.1.4</span> Ansari-Bradley Test for Scale Parameter for Two Independent Samples</a></li>
<li><a href="non-parametric-test.html#kolmogorov-smirnov-test-for-equality-of-distributions" id="toc-kolmogorov-smirnov-test-for-equality-of-distributions"><span class="toc-section-number">7.1.5</span> Kolmogorov-Smirnov Test for Equality of Distributions</a></li>
</ul></li>
<li><a href="non-parametric-test.html#several-samples-hypotheses-testing" id="toc-several-samples-hypotheses-testing"><span class="toc-section-number">7.2</span> Several Samples Hypotheses Testing</a>
<ul>
<li><a href="non-parametric-test.html#friedman-rank-test-for-location-parameter-for-several-dependent-samples" id="toc-friedman-rank-test-for-location-parameter-for-several-dependent-samples"><span class="toc-section-number">7.2.1</span> Friedman Rank Test for Location Parameter for Several Dependent Samples</a></li>
<li><a href="non-parametric-test.html#kruskal-wallis-h-test-for-location-parameter" id="toc-kruskal-wallis-h-test-for-location-parameter"><span class="toc-section-number">7.2.2</span> Kruskal-Wallis H-Test for Location Parameter</a></li>
</ul></li>
<li><a href="non-parametric-test.html#tests-for-categorical-data" id="toc-tests-for-categorical-data"><span class="toc-section-number">7.3</span> Tests for Categorical Data</a>
<ul>
<li><a href="non-parametric-test.html#spearman-rank-correlation-coefficient-test" id="toc-spearman-rank-correlation-coefficient-test"><span class="toc-section-number">7.3.1</span> Spearman Rank Correlation Coefficient Test</a></li>
<li><a href="non-parametric-test.html#fisher-exact-test" id="toc-fisher-exact-test"><span class="toc-section-number">7.3.2</span> Fisher Exact Test</a></li>
</ul></li>
<li><a href="non-parametric-test.html#permutation-test" id="toc-permutation-test"><span class="toc-section-number">7.4</span> Permutation test</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">7.4.1</span> Introduction</a></li>
<li><a href="non-parametric-test.html#package-coin" id="toc-package-coin"><span class="toc-section-number">7.4.2</span> Package: coin</a></li>
<li><a href="non-parametric-test.html#one-way-permutation-test-of-independence-for-ordinal-data" id="toc-one-way-permutation-test-of-independence-for-ordinal-data"><span class="toc-section-number">7.4.3</span> One-way Permutation Test of Independence for Ordinal Data</a></li>
<li><a href="non-parametric-test.html#one-way-permutation-test-of-symmetry-for-ordinal-data" id="toc-one-way-permutation-test-of-symmetry-for-ordinal-data"><span class="toc-section-number">7.4.4</span> One-way Permutation Test of Symmetry for Ordinal Data</a></li>
<li><a href="non-parametric-test.html#permutation-tests-for-medians-and-percentiles" id="toc-permutation-tests-for-medians-and-percentiles"><span class="toc-section-number">7.4.5</span> Permutation Tests for Medians and Percentiles</a></li>
</ul></li>
</ul></li>
<li><a href="sample-size-calculation.html#sample-size-calculation" id="toc-sample-size-calculation"><span class="toc-section-number">8</span> Sample Size Calculation</a>
<ul>
<li><a href="sample-size-calculation.html#distribution" id="toc-distribution"><span class="toc-section-number">8.1</span> Distribution</a>
<ul>
<li><a href="sample-size-calculation.html#quantile-function-in-sas" id="toc-quantile-function-in-sas"><span class="toc-section-number">8.1.1</span> Quantile Function in SAS</a></li>
<li><a href="sample-size-calculation.html#binomial-distribution" id="toc-binomial-distribution"><span class="toc-section-number">8.1.2</span> Binomial distribution</a></li>
<li><a href="sample-size-calculation.html#negative-binomial-distribution" id="toc-negative-binomial-distribution"><span class="toc-section-number">8.1.3</span> Negative binomial distribution</a></li>
<li><a href="sample-size-calculation.html#multinomial-distribution" id="toc-multinomial-distribution"><span class="toc-section-number">8.1.4</span> Multinomial distribution</a></li>
<li><a href="sample-size-calculation.html#normal-distribution" id="toc-normal-distribution"><span class="toc-section-number">8.1.5</span> Normal Distribution</a></li>
<li><a href="sample-size-calculation.html#multivariate-normal-distribution" id="toc-multivariate-normal-distribution"><span class="toc-section-number">8.1.6</span> Multivariate normal distribution</a></li>
<li><a href="sample-size-calculation.html#poisson-distribution" id="toc-poisson-distribution"><span class="toc-section-number">8.1.7</span> Poisson distribution</a></li>
<li><a href="sample-size-calculation.html#exponential-distribution" id="toc-exponential-distribution"><span class="toc-section-number">8.1.8</span> Exponential distribution</a></li>
<li><a href="sample-size-calculation.html#gamma-distribution" id="toc-gamma-distribution"><span class="toc-section-number">8.1.9</span> Gamma distribution</a></li>
<li><a href="sample-size-calculation.html#weibull-distribution" id="toc-weibull-distribution"><span class="toc-section-number">8.1.10</span> Weibull Distribution</a></li>
<li><a href="sample-size-calculation.html#chi-squared-distribution" id="toc-chi-squared-distribution"><span class="toc-section-number">8.1.11</span> Chi-Squared Distribution</a></li>
<li><a href="sample-size-calculation.html#beta-distribution" id="toc-beta-distribution"><span class="toc-section-number">8.1.12</span> Beta Distribution</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#binomial-ci" id="toc-binomial-ci"><span class="toc-section-number">8.2</span> Binomial CI</a>
<ul>
<li><a href="sample-size-calculation.html#point-estimates" id="toc-point-estimates"><span class="toc-section-number">8.2.1</span> Point Estimates</a></li>
<li><a href="sample-size-calculation.html#binomial-ci-for-small-samples" id="toc-binomial-ci-for-small-samples"><span class="toc-section-number">8.2.2</span> Binomial CI for Small Samples</a></li>
<li><a href="sample-size-calculation.html#r-packages" id="toc-r-packages"><span class="toc-section-number">8.2.3</span> R Packages</a></li>
<li><a href="sample-size-calculation.html#incidence-rate-ci" id="toc-incidence-rate-ci"><span class="toc-section-number">8.2.4</span> Incidence rate CI</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#test-1-sample-proportion" id="toc-test-1-sample-proportion"><span class="toc-section-number">8.3</span> Test 1-Sample Proportion</a></li>
<li><a href="sample-size-calculation.html#test-2-sample-proportions" id="toc-test-2-sample-proportions"><span class="toc-section-number">8.4</span> Test 2-Sample Proportions</a>
<ul>
<li><a href="sample-size-calculation.html#technical-details" id="toc-technical-details"><span class="toc-section-number">8.4.1</span> Technical details</a></li>
<li><a href="parametric-test.html#fishers-exact-test" id="toc-fishers-exact-test"><span class="toc-section-number">8.4.2</span> Fisher’s Exact Test</a></li>
<li><a href="sample-size-calculation.html#z-test-or-chi-square-test-pooled-and-unpooled" id="toc-z-test-or-chi-square-test-pooled-and-unpooled"><span class="toc-section-number">8.4.3</span> Z Test (or Chi-Square Test) (Pooled and Unpooled)</a></li>
<li><a href="sample-size-calculation.html#conditional-mantel-haenszel-test" id="toc-conditional-mantel-haenszel-test"><span class="toc-section-number">8.4.4</span> Conditional Mantel-Haenszel Test</a></li>
<li><a href="sample-size-calculation.html#paired-proportions-mcnemars-z-test" id="toc-paired-proportions-mcnemars-z-test"><span class="toc-section-number">8.4.5</span> Paired Proportions: McNemar’s Z-test</a></li>
<li><a href="sample-size-calculation.html#chi-square-test" id="toc-chi-square-test"><span class="toc-section-number">8.4.6</span> Chi-square test</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#test-means" id="toc-test-means"><span class="toc-section-number">8.5</span> Test Mean(s)</a>
<ul>
<li><a href="sample-size-calculation.html#one-sample-mean-2-sided-equality" id="toc-one-sample-mean-2-sided-equality"><span class="toc-section-number">8.5.1</span> One Sample Mean 2-Sided Equality</a></li>
<li><a href="sample-size-calculation.html#sample-mean-non-inferiority-or-superiority" id="toc-sample-mean-non-inferiority-or-superiority"><span class="toc-section-number">8.5.2</span> 1-Sample Mean Non-Inferiority or Superiority</a></li>
<li><a href="sample-size-calculation.html#sample-mean-equivalence" id="toc-sample-mean-equivalence"><span class="toc-section-number">8.5.3</span> 1-Sample Mean Equivalence</a></li>
<li><a href="sample-size-calculation.html#sample-means-2-sided-equality" id="toc-sample-means-2-sided-equality"><span class="toc-section-number">8.5.4</span> 2-Sample Means, 2-Sided Equality</a></li>
<li><a href="sample-size-calculation.html#sample-means-1-sided" id="toc-sample-means-1-sided"><span class="toc-section-number">8.5.5</span> 2-Sample Means, 1-Sided</a></li>
<li><a href="sample-size-calculation.html#sample-means-non-inferiority-or-superiority" id="toc-sample-means-non-inferiority-or-superiority"><span class="toc-section-number">8.5.6</span> 2-Sample Means Non-Inferiority or Superiority</a></li>
<li><a href="sample-size-calculation.html#sample-means-equivalence" id="toc-sample-means-equivalence"><span class="toc-section-number">8.5.7</span> 2-Sample Means Equivalence</a></li>
<li><a href="sample-size-calculation.html#t-test-using-pwr.t.test-or-pwr.t2n.test" id="toc-t-test-using-pwr.t.test-or-pwr.t2n.test"><span class="toc-section-number">8.5.8</span> T-Test using <code>pwr.t.test</code> or <code>pwr.t2n.test</code></a></li>
<li><a href="sample-size-calculation.html#test-k-means" id="toc-test-k-means"><span class="toc-section-number">8.5.9</span> Test k Means</a></li>
<li><a href="sample-size-calculation.html#anova-using-pwr.anova.test" id="toc-anova-using-pwr.anova.test"><span class="toc-section-number">8.5.10</span> Anova using <code>pwr.anova.test</code></a></li>
<li><a href="sample-size-calculation.html#average-bioequivalence" id="toc-average-bioequivalence"><span class="toc-section-number">8.5.11</span> Average Bioequivalence</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#other-methods" id="toc-other-methods"><span class="toc-section-number">8.6</span> Other Methods</a>
<ul>
<li><a href="sample-size-calculation.html#odds-ratio" id="toc-odds-ratio"><span class="toc-section-number">8.6.1</span> Odds Ratio</a></li>
<li><a href="sample-size-calculation.html#correlation" id="toc-correlation"><span class="toc-section-number">8.6.2</span> Correlation</a></li>
<li><a href="sample-size-calculation.html#correlated-binary-data-ophthalmologic-studies" id="toc-correlated-binary-data-ophthalmologic-studies"><span class="toc-section-number">8.6.3</span> Correlated Binary Data: Ophthalmologic Studies</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#multiple-test" id="toc-multiple-test"><span class="toc-section-number">8.7</span> Multiple test</a>
<ul>
<li><a href="sample-size-calculation.html#definitions-of-power" id="toc-definitions-of-power"><span class="toc-section-number">8.7.1</span> Definitions of Power</a></li>
<li><a href="sample-size-calculation.html#bonferroni-tests-individual-power" id="toc-bonferroni-tests-individual-power"><span class="toc-section-number">8.7.2</span> Bonferroni Tests (Individual Power)</a></li>
<li><a href="sample-size-calculation.html#tukeys-method-individual-power" id="toc-tukeys-method-individual-power"><span class="toc-section-number">8.7.3</span> Tukey’s method (Individual Power)</a></li>
<li><a href="sample-size-calculation.html#dunnetts-two-sided-tests-individual-power" id="toc-dunnetts-two-sided-tests-individual-power"><span class="toc-section-number">8.7.4</span> Dunnett’s Two-Sided Tests (Individual Power)</a></li>
<li><a href="sample-size-calculation.html#combined-power-simpower-and-plotsimpower" id="toc-combined-power-simpower-and-plotsimpower"><span class="toc-section-number">8.7.5</span> Combined Power %SimPower and %PlotSimPower</a></li>
<li><a href="sample-size-calculation.html#dunnett-set-up-close-tests-in-r" id="toc-dunnett-set-up-close-tests-in-r"><span class="toc-section-number">8.7.6</span> Dunnett Set up Close Tests in R</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#time-to-event-data" id="toc-time-to-event-data"><span class="toc-section-number">8.8</span> Time-To-Event Data</a>
<ul>
<li><a href="sample-size-calculation.html#cox-ph-2-sided-equality" id="toc-cox-ph-2-sided-equality"><span class="toc-section-number">8.8.1</span> Cox PH, 2-Sided Equality</a></li>
<li><a href="sample-size-calculation.html#log-rank-tests-for-competing-risks" id="toc-log-rank-tests-for-competing-risks"><span class="toc-section-number">8.8.2</span> Log-Rank Tests for Competing Risks</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#estimation-in-diagnostic-test" id="toc-estimation-in-diagnostic-test"><span class="toc-section-number">8.9</span> Estimation in diagnostic test</a>
<ul>
<li><a href="sample-size-calculation.html#adequate-sensitivityspecificity" id="toc-adequate-sensitivityspecificity"><span class="toc-section-number">8.9.1</span> Adequate sensitivity/specificity</a></li>
<li><a href="sample-size-calculation.html#testing-sensitivity-or-specificity" id="toc-testing-sensitivity-or-specificity"><span class="toc-section-number">8.9.2</span> Testing sensitivity (or specificity)</a></li>
<li><a href="sample-size-calculation.html#likelihood-ratio-estimation" id="toc-likelihood-ratio-estimation"><span class="toc-section-number">8.9.3</span> Likelihood ratio estimation</a></li>
<li><a href="sample-size-calculation.html#roc-index-of-accuracy" id="toc-roc-index-of-accuracy"><span class="toc-section-number">8.9.4</span> ROC index of accuracy</a></li>
</ul></li>
</ul></li>
<li><a href="anova.html#anova" id="toc-anova"><span class="toc-section-number">9</span> ANOVA</a>
<ul>
<li><a href="anova.html#unstructured-models" id="toc-unstructured-models"><span class="toc-section-number">9.1</span> Unstructured Models</a></li>
<li><a href="anova.html#balanced-one-way-analysis-of-variance-anova" id="toc-balanced-one-way-analysis-of-variance-anova"><span class="toc-section-number">9.2</span> Balanced One-Way Analysis-of-Variance (ANOVA)</a>
<ul>
<li><a href="anova.html#modeling-assumptions-and-basic-analysis" id="toc-modeling-assumptions-and-basic-analysis"><span class="toc-section-number">9.2.1</span> Modeling Assumptions and Basic Analysis</a></li>
<li><a href="anova.html#parameter-estimates" id="toc-parameter-estimates"><span class="toc-section-number">9.2.2</span> Parameter Estimates</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">9.2.3</span> R Implementation</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">9.2.4</span> SAS Implementation</a></li>
<li><a href="anova.html#model-diagnosis" id="toc-model-diagnosis"><span class="toc-section-number">9.2.5</span> Model Diagnosis</a></li>
</ul></li>
<li><a href="anova.html#unbalanced-one-way-anova-and-analysis-of-covariance-ancova" id="toc-unbalanced-one-way-anova-and-analysis-of-covariance-ancova"><span class="toc-section-number">9.3</span> Unbalanced One-Way ANOVA and Analysis-of-Covariance (ANCOVA)</a></li>
<li><a href="anova.html#two-ways-anova-test" id="toc-two-ways-anova-test"><span class="toc-section-number">9.4</span> Two-Ways ANOVA Test</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">9.4.1</span> Introduction</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">9.4.2</span> R implementation</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">9.4.3</span> SAS Implementation</a></li>
<li><a href="anova.html#unbalanced-design" id="toc-unbalanced-design"><span class="toc-section-number">9.4.4</span> Unbalanced design</a></li>
</ul></li>
<li><a href="anova.html#heteroscedastic-responses" id="toc-heteroscedastic-responses"><span class="toc-section-number">9.5</span> Heteroscedastic Responses</a></li>
<li><a href="anova.html#repeated-measures-anova-data" id="toc-repeated-measures-anova-data"><span class="toc-section-number">9.6</span> Repeated Measures ANOVA Data</a></li>
<li><a href="anova.html#multivariate-responses-with-normally-distributed-data" id="toc-multivariate-responses-with-normally-distributed-data"><span class="toc-section-number">9.7</span> Multivariate Responses with Normally Distributed Data</a></li>
<li><a href="anova.html#independent-observations-from-parametric-nonnormal-distributions" id="toc-independent-observations-from-parametric-nonnormal-distributions"><span class="toc-section-number">9.8</span> Independent Observations from Parametric Nonnormal Distributions</a></li>
<li><a href="anova.html#dependent-observations-from-parametric-nonnormal-distributions" id="toc-dependent-observations-from-parametric-nonnormal-distributions"><span class="toc-section-number">9.9</span> Dependent Observations from Parametric Nonnormal Distributions</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparison" id="toc-multiple-comparison"><span class="toc-section-number">10</span> Multiple-Comparison</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">10.1</span> Introduction</a>
<ul>
<li><a href="multiple-comparison.html#multiplicity-problem" id="toc-multiplicity-problem"><span class="toc-section-number">10.1.1</span> Multiplicity Problem</a></li>
<li><a href="multiple-comparison.html#error-rates" id="toc-error-rates"><span class="toc-section-number">10.1.2</span> Error Rates</a></li>
<li><a href="multiple-comparison.html#the-adjusted-p" id="toc-the-adjusted-p"><span class="toc-section-number">10.1.3</span> The adjusted P</a></li>
<li><a href="multiple-comparison.html#basic-statistical-concepts" id="toc-basic-statistical-concepts"><span class="toc-section-number">10.1.4</span> Basic Statistical Concepts</a></li>
<li><a href="multiple-comparison.html#functions-in-glht-package-in-r" id="toc-functions-in-glht-package-in-r"><span class="toc-section-number">10.1.5</span> Functions in glht package in R</a></li>
</ul></li>
<li><a href="multiple-comparison.html#bonferroni-and-šidák-methods" id="toc-bonferroni-and-šidák-methods"><span class="toc-section-number">10.2</span> Bonferroni and Šidák Methods</a>
<ul>
<li><a href="multiple-comparison.html#lsd-least-significance-difference" id="toc-lsd-least-significance-difference"><span class="toc-section-number">10.2.1</span> LSD (least significance difference)</a></li>
<li><a href="multiple-comparison.html#šidák" id="toc-šidák"><span class="toc-section-number">10.2.2</span> Šidák</a></li>
<li><a href="multiple-comparison.html#bonferroni" id="toc-bonferroni"><span class="toc-section-number">10.2.3</span> Bonferroni</a></li>
<li><a href="multiple-comparison.html#schweder-spjøtvoll-p-value-plot" id="toc-schweder-spjøtvoll-p-value-plot"><span class="toc-section-number">10.2.4</span> Schweder-Spjøtvoll p-Value Plot</a></li>
</ul></li>
<li><a href="multiple-comparison.html#mcp-among-treatment-means-in-the-one-way-balanced-anova" id="toc-mcp-among-treatment-means-in-the-one-way-balanced-anova"><span class="toc-section-number">10.3</span> MCP among Treatment Means in the One-Way Balanced ANOVA</a>
<ul>
<li><a href="multiple-comparison.html#ls-means" id="toc-ls-means"><span class="toc-section-number">10.3.1</span> LS-Means</a></li>
<li><a href="multiple-comparison.html#the-multivariate-t-distribution" id="toc-the-multivariate-t-distribution"><span class="toc-section-number">10.3.2</span> The Multivariate t Distribution</a></li>
<li><a href="multiple-comparison.html#calculating-the-critical-value-c_alpha" id="toc-calculating-the-critical-value-c_alpha"><span class="toc-section-number">10.3.3</span> Calculating the Critical Value <span class="math inline">\(c_{\alpha}\)</span></a></li>
<li><a href="multiple-comparison.html#all-pairwise-comparisons-and-studentized-range-distribution" id="toc-all-pairwise-comparisons-and-studentized-range-distribution"><span class="toc-section-number">10.3.4</span> All Pairwise Comparisons and Studentized Range Distribution</a></li>
<li><a href="multiple-comparison.html#tukeys-method-for-all-pairwise-comparisons" id="toc-tukeys-method-for-all-pairwise-comparisons"><span class="toc-section-number">10.3.5</span> Tukey’s Method for All Pairwise Comparisons</a></li>
<li><a href="multiple-comparison.html#displaying-pairwise-comparisons-graphically" id="toc-displaying-pairwise-comparisons-graphically"><span class="toc-section-number">10.3.6</span> Displaying Pairwise Comparisons Graphically</a></li>
<li><a href="multiple-comparison.html#dunnetts-two-sided-comparisons-with-a-control-and-dunnetts-two-sided-range-distribution" id="toc-dunnetts-two-sided-comparisons-with-a-control-and-dunnetts-two-sided-range-distribution"><span class="toc-section-number">10.3.7</span> Dunnett’s Two-Sided Comparisons with a Control and Dunnett’s Two-Sided Range Distribution</a></li>
<li><a href="multiple-comparison.html#dunnetts-one-sided-comparisons-with-a-control" id="toc-dunnetts-one-sided-comparisons-with-a-control"><span class="toc-section-number">10.3.8</span> Dunnett’s One-Sided Comparisons with a Control</a></li>
<li><a href="multiple-comparison.html#maximum-modulus-distribution-multiple-inferences-for-independent-estimates" id="toc-maximum-modulus-distribution-multiple-inferences-for-independent-estimates"><span class="toc-section-number">10.3.9</span> Maximum Modulus Distribution, Multiple Inferences for Independent Estimates</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparisons-among-treatment-means-in-the-one-way-unbalanced-anova" id="toc-multiple-comparisons-among-treatment-means-in-the-one-way-unbalanced-anova"><span class="toc-section-number">10.4</span> Multiple Comparisons among Treatment Means in the One-Way Unbalanced ANOVA</a>
<ul>
<li><a href="multiple-comparison.html#the-model-and-estimates" id="toc-the-model-and-estimates"><span class="toc-section-number">10.4.1</span> The Model and Estimates</a></li>
<li><a href="multiple-comparison.html#tukey-kramer-method" id="toc-tukey-kramer-method"><span class="toc-section-number">10.4.2</span> Tukey-Kramer Method</a></li>
<li><a href="multiple-comparison.html#alternative-simulation-based-method" id="toc-alternative-simulation-based-method"><span class="toc-section-number">10.4.3</span> Alternative Simulation-Based Method</a></li>
<li><a href="multiple-comparison.html#pairwise-comparisons-with-control" id="toc-pairwise-comparisons-with-control"><span class="toc-section-number">10.4.4</span> Pairwise Comparisons with Control</a></li>
<li><a href="multiple-comparison.html#comparisons-with-the-average-meananalysis-of-means-anom" id="toc-comparisons-with-the-average-meananalysis-of-means-anom"><span class="toc-section-number">10.4.5</span> Comparisons with the Average Mean–Analysis of Means (ANOM)</a></li>
</ul></li>
<li><a href="multiple-comparison.html#generalizations-for-the-analysis-of-covariance-ancova-model" id="toc-generalizations-for-the-analysis-of-covariance-ancova-model"><span class="toc-section-number">10.5</span> Generalizations for the Analysis of Covariance (ANCOVA) model</a>
<ul>
<li><a href="multiple-comparison.html#dunnett-hsu-factor-analytic-approximation" id="toc-dunnett-hsu-factor-analytic-approximation"><span class="toc-section-number">10.5.1</span> Dunnett-Hsu Factor Analytic Approximation</a></li>
<li><a href="multiple-comparison.html#hsu-nelson-simulation-based-approximation-cvadjust-method" id="toc-hsu-nelson-simulation-based-approximation-cvadjust-method"><span class="toc-section-number">10.5.2</span> Hsu-Nelson Simulation-Based Approximation: CVADJUST Method</a></li>
<li><a href="multiple-comparison.html#comparisons-in-ancova-models-with-interaction" id="toc-comparisons-in-ancova-models-with-interaction"><span class="toc-section-number">10.5.3</span> Comparisons in ANCOVA Models with Interaction</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-inferences-for-infinite-sets-of-parameters" id="toc-multiple-inferences-for-infinite-sets-of-parameters"><span class="toc-section-number">10.6</span> Multiple Inferences for Infinite Sets of Parameters</a>
<ul>
<li><a href="multiple-comparison.html#scheffés-method" id="toc-scheffés-method"><span class="toc-section-number">10.6.1</span> Scheffés Method</a></li>
<li><a href="multiple-comparison.html#finding-the-maximal-contrast" id="toc-finding-the-maximal-contrast"><span class="toc-section-number">10.6.2</span> Finding the Maximal Contrast</a></li>
<li><a href="multiple-comparison.html#working-hotelling-method" id="toc-working-hotelling-method"><span class="toc-section-number">10.6.3</span> Working-Hotelling method</a></li>
<li><a href="multiple-comparison.html#discrete-approximation-method" id="toc-discrete-approximation-method"><span class="toc-section-number">10.6.4</span> Discrete approximation method</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparisons-under-heteroscedasticity" id="toc-multiple-comparisons-under-heteroscedasticity"><span class="toc-section-number">10.7</span> Multiple Comparisons under Heteroscedasticity</a>
<ul>
<li><a href="multiple-comparison.html#introduction-of-heteroscedasticity" id="toc-introduction-of-heteroscedasticity"><span class="toc-section-number">10.7.1</span> Introduction of heteroscedasticity</a></li>
<li><a href="multiple-comparison.html#satterthwaite-approximation" id="toc-satterthwaite-approximation"><span class="toc-section-number">10.7.2</span> Satterthwaite Approximation</a></li>
<li><a href="multiple-comparison.html#maxt-method-under-heteroscedasticity" id="toc-maxt-method-under-heteroscedasticity"><span class="toc-section-number">10.7.3</span> MaxT Method under Heteroscedasticity</a></li>
<li><a href="multiple-comparison.html#minp-method-under-heteroscedasticity" id="toc-minp-method-under-heteroscedasticity"><span class="toc-section-number">10.7.4</span> MinP Method under Heteroscedasticity</a></li>
</ul></li>
<li><a href="multiple-comparison.html#closed-and-stepwise-testing-methods" id="toc-closed-and-stepwise-testing-methods"><span class="toc-section-number">10.8</span> Closed and Stepwise Testing Methods</a>
<ul>
<li><a href="multiple-comparison.html#closed-family-of-hypotheses" id="toc-closed-family-of-hypotheses"><span class="toc-section-number">10.8.1</span> Closed Family of Hypotheses</a></li>
<li><a href="multiple-comparison.html#bonferroni-holm-method" id="toc-bonferroni-holm-method"><span class="toc-section-number">10.8.2</span> Bonferroni-Holm Method</a></li>
<li><a href="multiple-comparison.html#šidák-holm-method" id="toc-šidák-holm-method"><span class="toc-section-number">10.8.3</span> Šidák-Holm Method</a></li>
<li><a href="multiple-comparison.html#closed-fisher-combination-method" id="toc-closed-fisher-combination-method"><span class="toc-section-number">10.8.4</span> Closed Fisher Combination Method</a></li>
<li><a href="multiple-comparison.html#simes-hommel-method" id="toc-simes-hommel-method"><span class="toc-section-number">10.8.5</span> Simes-Hommel Method</a></li>
<li><a href="multiple-comparison.html#hochbergs-ok-step-up" id="toc-hochbergs-ok-step-up"><span class="toc-section-number">10.8.6</span> Hochberg’s O(k) Step-Up</a></li>
<li><a href="multiple-comparison.html#sequential-testing-with-fixed-sequences" id="toc-sequential-testing-with-fixed-sequences"><span class="toc-section-number">10.8.7</span> Sequential Testing with Fixed Sequences</a></li>
<li><a href="multiple-comparison.html#sequential-testing-using-gatekeeping-methods" id="toc-sequential-testing-using-gatekeeping-methods"><span class="toc-section-number">10.8.8</span> Sequential Testing Using Gatekeeping Methods</a></li>
</ul></li>
<li><a href="multiple-comparison.html#closed-testing-of-pairwise-comparisons-and-general-contrasts" id="toc-closed-testing-of-pairwise-comparisons-and-general-contrasts"><span class="toc-section-number">10.9</span> Closed Testing of Pairwise Comparisons and General Contrasts</a>
<ul>
<li><a href="multiple-comparison.html#incorporating-logical-constraints" id="toc-incorporating-logical-constraints"><span class="toc-section-number">10.9.1</span> Incorporating Logical Constraints</a></li>
<li><a href="multiple-comparison.html#shaffers-method" id="toc-shaffers-method"><span class="toc-section-number">10.9.2</span> Shaffer’s Method</a></li>
<li><a href="multiple-comparison.html#extended-shaffer-royen-method" id="toc-extended-shaffer-royen-method"><span class="toc-section-number">10.9.3</span> Extended Shaffer-Royen Method</a></li>
<li><a href="multiple-comparison.html#step-down-dunnett-test" id="toc-step-down-dunnett-test"><span class="toc-section-number">10.9.4</span> Step-down Dunnett test</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparisons-with-binary-data" id="toc-multiple-comparisons-with-binary-data"><span class="toc-section-number">10.10</span> Multiple Comparisons with Binary Data</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">10.10.1</span> Introduction</a></li>
<li><a href="multiple-comparison.html#multivariate-two-sample-binary-outcomes" id="toc-multivariate-two-sample-binary-outcomes"><span class="toc-section-number">10.10.2</span> Multivariate Two-Sample Binary Outcomes</a></li>
</ul></li>
</ul></li>
<li><a href="correlation-and-regression.html#correlation-and-regression" id="toc-correlation-and-regression"><span class="toc-section-number">11</span> Correlation and Regression</a>
<ul>
<li><a href="sample-size-calculation.html#correlation" id="toc-correlation"><span class="toc-section-number">11.1</span> Correlation</a>
<ul>
<li><a href="correlation-and-regression.html#pearson-correlation-coefficient" id="toc-pearson-correlation-coefficient"><span class="toc-section-number">11.1.1</span> Pearson correlation coefficient</a></li>
<li><a href="correlation-and-regression.html#spearmans-rank-correlation-coefficient" id="toc-spearmans-rank-correlation-coefficient"><span class="toc-section-number">11.1.2</span> Spearman’s rank correlation coefficient</a></li>
<li><a href="correlation-and-regression.html#kendall-rank-correlation-coefficient" id="toc-kendall-rank-correlation-coefficient"><span class="toc-section-number">11.1.3</span> Kendall rank correlation coefficient</a></li>
<li><a href="correlation-and-regression.html#intraclass-correlation" id="toc-intraclass-correlation"><span class="toc-section-number">11.1.4</span> Intraclass correlation</a></li>
<li><a href="correlation-and-regression.html#visualize-the-correlation-in-r" id="toc-visualize-the-correlation-in-r"><span class="toc-section-number">11.1.5</span> Visualize the correlation in R</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#ordinary-least-squares-ols" id="toc-ordinary-least-squares-ols"><span class="toc-section-number">11.2</span> Ordinary least squares (OLS)</a>
<ul>
<li><a href="correlation-and-regression.html#assumpions" id="toc-assumpions"><span class="toc-section-number">11.2.1</span> Assumpions</a></li>
<li><a href="correlation-and-regression.html#interpretation" id="toc-interpretation"><span class="toc-section-number">11.2.2</span> Interpretation</a></li>
<li><a href="correlation-and-regression.html#matrix-solution" id="toc-matrix-solution"><span class="toc-section-number">11.2.3</span> Matrix Solution</a></li>
<li><a href="correlation-and-regression.html#gauss-markov-theorem" id="toc-gauss-markov-theorem"><span class="toc-section-number">11.2.4</span> Gauss-Markov Theorem</a></li>
<li><a href="correlation-and-regression.html#limitation" id="toc-limitation"><span class="toc-section-number">11.2.5</span> limitation</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#model-statistics" id="toc-model-statistics"><span class="toc-section-number">11.3</span> Model Statistics</a>
<ul>
<li><a href="correlation-and-regression.html#residuals-standard-error" id="toc-residuals-standard-error"><span class="toc-section-number">11.3.1</span> Residuals Standard Error</a></li>
<li><a href="correlation-and-regression.html#r-squared-and-adjusted-r-squared" id="toc-r-squared-and-adjusted-r-squared"><span class="toc-section-number">11.3.2</span> R-Squared and Adjusted R-Squared</a></li>
<li><a href="correlation-and-regression.html#t-statistic" id="toc-t-statistic"><span class="toc-section-number">11.3.3</span> T Statistic</a></li>
<li><a href="correlation-and-regression.html#f-statistic" id="toc-f-statistic"><span class="toc-section-number">11.3.4</span> F Statistic</a></li>
<li><a href="correlation-and-regression.html#confidence-intervals" id="toc-confidence-intervals"><span class="toc-section-number">11.3.5</span> Confidence Intervals</a></li>
<li><a href="correlation-and-regression.html#likelihood-ratio-test" id="toc-likelihood-ratio-test"><span class="toc-section-number">11.3.6</span> Likelihood-ratio test</a></li>
<li><a href="correlation-and-regression.html#accuracy" id="toc-accuracy"><span class="toc-section-number">11.3.7</span> Accuracy</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#model-diagnostics" id="toc-model-diagnostics"><span class="toc-section-number">11.4</span> Model Diagnostics</a>
<ul>
<li><a href="correlation-and-regression.html#checking-error-assumptions" id="toc-checking-error-assumptions"><span class="toc-section-number">11.4.1</span> Checking Error Assumptions</a></li>
<li><a href="correlation-and-regression.html#finding-unusual-observations" id="toc-finding-unusual-observations"><span class="toc-section-number">11.4.2</span> Finding Unusual Observations</a></li>
<li><a href="correlation-and-regression.html#checking-the-structure-of-the-model" id="toc-checking-the-structure-of-the-model"><span class="toc-section-number">11.4.3</span> Checking the Structure of the Model</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#sas-implementation-proc-reg" id="toc-sas-implementation-proc-reg"><span class="toc-section-number">11.5</span> SAS implementation Proc Reg</a>
<ul>
<li><a href="correlation-and-regression.html#options" id="toc-options"><span class="toc-section-number">11.5.1</span> Options</a></li>
<li><a href="correlation-and-regression.html#diagnose" id="toc-diagnose"><span class="toc-section-number">11.5.2</span> Diagnose</a></li>
</ul></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">11.6</span> R implementation</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#advanced-linear-regression" id="toc-advanced-linear-regression"><span class="toc-section-number">12</span> Advanced Linear Regression</a>
<ul>
<li><a href="advanced-linear-regression.html#model-selection" id="toc-model-selection"><span class="toc-section-number">12.1</span> Model Selection</a>
<ul>
<li><a href="advanced-linear-regression.html#selection-methods" id="toc-selection-methods"><span class="toc-section-number">12.1.1</span> Selection Methods</a></li>
<li><a href="advanced-linear-regression.html#selection-criteria" id="toc-selection-criteria"><span class="toc-section-number">12.1.2</span> Selection Criteria</a></li>
<li><a href="advanced-linear-regression.html#k--fold-cross-validation" id="toc-k--fold-cross-validation"><span class="toc-section-number">12.1.3</span> k- Fold Cross validation</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#practical-difficulties-using-ols" id="toc-practical-difficulties-using-ols"><span class="toc-section-number">12.2</span> Practical Difficulties using OLS</a></li>
<li><a href="advanced-linear-regression.html#skewness" id="toc-skewness"><span class="toc-section-number">12.3</span> Skewness</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">12.3.1</span> Introduction</a></li>
<li><a href="advanced-linear-regression.html#baisc-transformation" id="toc-baisc-transformation"><span class="toc-section-number">12.3.2</span> Baisc Transformation</a></li>
<li><a href="advanced-linear-regression.html#box-cox-power-transformation" id="toc-box-cox-power-transformation"><span class="toc-section-number">12.3.3</span> Box-Cox Power Transformation</a></li>
</ul></li>
<li><a href="ggplot2.html#scale" id="toc-scale"><span class="toc-section-number">12.4</span> Scale</a></li>
<li><a href="advanced-linear-regression.html#interaction" id="toc-interaction"><span class="toc-section-number">12.5</span> Interaction</a>
<ul>
<li><a href="advanced-linear-regression.html#simple-slopes-analysis" id="toc-simple-slopes-analysis"><span class="toc-section-number">12.5.1</span> Simple slopes analysis</a></li>
<li><a href="advanced-linear-regression.html#plotting-interactions" id="toc-plotting-interactions"><span class="toc-section-number">12.5.2</span> Plotting Interactions</a></li>
<li><a href="advanced-linear-regression.html#check-linearity-assumption" id="toc-check-linearity-assumption"><span class="toc-section-number">12.5.3</span> Check linearity assumption</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#collinearity" id="toc-collinearity"><span class="toc-section-number">12.6</span> Collinearity</a></li>
<li><a href="advanced-linear-regression.html#problems-with-the-error" id="toc-problems-with-the-error"><span class="toc-section-number">12.7</span> Problems with the Error</a>
<ul>
<li><a href="advanced-linear-regression.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">12.7.1</span> Generalized Least Squares</a></li>
<li><a href="advanced-linear-regression.html#weighted-least-squares" id="toc-weighted-least-squares"><span class="toc-section-number">12.7.2</span> Weighted Least Squares</a></li>
<li><a href="advanced-linear-regression.html#robust-regression" id="toc-robust-regression"><span class="toc-section-number">12.7.3</span> Robust Regression</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#shrinkage-methods" id="toc-shrinkage-methods"><span class="toc-section-number">12.8</span> Shrinkage Methods</a>
<ul>
<li><a href="advanced-linear-regression.html#principal-components-analzsis" id="toc-principal-components-analzsis"><span class="toc-section-number">12.8.1</span> Principal Components Analzsis</a></li>
<li><a href="advanced-linear-regression.html#partial-least-squares" id="toc-partial-least-squares"><span class="toc-section-number">12.8.2</span> Partial Least Squares</a></li>
<li><a href="advanced-linear-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">12.8.3</span> Ridge Regression</a></li>
</ul></li>
</ul></li>
<li><a href="logistic-regression.html#logistic-regression" id="toc-logistic-regression"><span class="toc-section-number">13</span> Logistic Regression</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">13.1</span> Introduction</a>
<ul>
<li><a href="logistic-regression.html#violation-of-assumptions-of-ordinary-least-squares-ols" id="toc-violation-of-assumptions-of-ordinary-least-squares-ols"><span class="toc-section-number">13.1.1</span> Violation of assumptions of Ordinary least squares (OLS)</a></li>
<li><a href="logistic-regression.html#more-fundamental-problem-outside-01" id="toc-more-fundamental-problem-outside-01"><span class="toc-section-number">13.1.2</span> More fundamental problem outside [0,1]</a></li>
<li><a href="logistic-regression.html#logistic-regression-model" id="toc-logistic-regression-model"><span class="toc-section-number">13.1.3</span> Logistic Regression Model</a></li>
<li><a href="logistic-regression.html#estimation-of-the-logistic-model" id="toc-estimation-of-the-logistic-model"><span class="toc-section-number">13.1.4</span> Estimation of the Logistic Model</a></li>
<li><a href="logistic-regression.html#convergence-problems" id="toc-convergence-problems"><span class="toc-section-number">13.1.5</span> Convergence Problems</a></li>
<li><a href="logistic-regression.html#use-exact-methods." id="toc-use-exact-methods."><span class="toc-section-number">13.1.6</span> Use exact methods.</a></li>
<li><a href="logistic-regression.html#use-penalized-likelihood" id="toc-use-penalized-likelihood"><span class="toc-section-number">13.1.7</span> Use penalized likelihood</a></li>
</ul></li>
<li><a href="logistic-regression.html#logit-modell" id="toc-logit-modell"><span class="toc-section-number">13.2</span> Logit Modell</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">13.2.1</span> Introduction</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">13.2.2</span> R Implementation</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">13.2.3</span> SAS Implementation</a></li>
<li><a href="logistic-regression.html#multicollinearity" id="toc-multicollinearity"><span class="toc-section-number">13.2.4</span> Multicollinearity</a></li>
<li><a href="logistic-regression.html#goodness-of-fit-statistics-pearson-deviance" id="toc-goodness-of-fit-statistics-pearson-deviance"><span class="toc-section-number">13.2.5</span> Goodness-of-Fit Statistics Pearson deviance</a></li>
<li><a href="logistic-regression.html#hosmer-and-lemeshow-goodness-of-fit-test" id="toc-hosmer-and-lemeshow-goodness-of-fit-test"><span class="toc-section-number">13.2.6</span> Hosmer and Lemeshow Goodness-of-Fit Test</a></li>
<li><a href="logistic-regression.html#statistics-measuring-predictive-power-r2" id="toc-statistics-measuring-predictive-power-r2"><span class="toc-section-number">13.2.7</span> Statistics Measuring Predictive Power <span class="math inline">\(R^2\)</span></a></li>
<li><a href="logistic-regression.html#roc-curves" id="toc-roc-curves"><span class="toc-section-number">13.2.8</span> ROC Curves</a></li>
<li><a href="logistic-regression.html#predicted-values-residuals-and-influence-statistics" id="toc-predicted-values-residuals-and-influence-statistics"><span class="toc-section-number">13.2.9</span> Predicted Values, Residuals, and Influence Statistics</a></li>
<li><a href="logistic-regression.html#unobserved-heterogeneity" id="toc-unobserved-heterogeneity"><span class="toc-section-number">13.2.10</span> Unobserved Heterogeneity</a></li>
</ul></li>
<li><a href="logistic-regression.html#illustration-in-sas" id="toc-illustration-in-sas"><span class="toc-section-number">13.3</span> Illustration in SAS</a>
<ul>
<li><a href="logistic-regression.html#effects-of-predictor-variables" id="toc-effects-of-predictor-variables"><span class="toc-section-number">13.3.1</span> Effects of Predictor Variables</a></li>
<li><a href="logistic-regression.html#odds-ratio-plot" id="toc-odds-ratio-plot"><span class="toc-section-number">13.3.2</span> Odds ratio plot</a></li>
</ul></li>
<li><a href="logistic-regression.html#probit-modell" id="toc-probit-modell"><span class="toc-section-number">13.4</span> Probit Modell</a>
<ul>
<li><a href="logistic-regression.html#introduction-2" id="toc-introduction-2"><span class="toc-section-number">13.4.1</span> Introduction</a></li>
<li><a href="logistic-regression.html#r-implemetation" id="toc-r-implemetation"><span class="toc-section-number">13.4.2</span> R Implemetation</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">13.4.3</span> SAS Implementation</a></li>
</ul></li>
<li><a href="logistic-regression.html#complementary-log-log-modell" id="toc-complementary-log-log-modell"><span class="toc-section-number">13.5</span> Complementary log-log-Modell</a>
<ul>
<li><a href="logistic-regression.html#r-implemetation-1" id="toc-r-implemetation-1"><span class="toc-section-number">13.5.1</span> R Implemetation</a></li>
</ul></li>
<li><a href="logistic-regression.html#multicategory-logit-models" id="toc-multicategory-logit-models"><span class="toc-section-number">13.6</span> Multicategory Logit Models</a>
<ul>
<li><a href="logistic-regression.html#multinomialverteilung" id="toc-multinomialverteilung"><span class="toc-section-number">13.6.1</span> Multinomialverteilung</a></li>
<li><a href="logistic-regression.html#nominal-response" id="toc-nominal-response"><span class="toc-section-number">13.6.2</span> Nominal Response</a></li>
<li><a href="logistic-regression.html#ordinal-response-cumulative-logit-model" id="toc-ordinal-response-cumulative-logit-model"><span class="toc-section-number">13.6.3</span> Ordinal Response: Cumulative Logit Model</a></li>
</ul></li>
<li><a href="logistic-regression.html#adjacent-categories-model" id="toc-adjacent-categories-model"><span class="toc-section-number">13.7</span> Adjacent Categories Model</a></li>
<li><a href="logistic-regression.html#continuation-ratio-model" id="toc-continuation-ratio-model"><span class="toc-section-number">13.8</span> Continuation Ratio Model</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#advanced-logistic-regression" id="toc-advanced-logistic-regression"><span class="toc-section-number">14</span> Advanced Logistic Regression</a>
<ul>
<li><a href="advanced-logistic-regression.html#logit-analysis-of-contingency-tables" id="toc-logit-analysis-of-contingency-tables"><span class="toc-section-number">14.1</span> Logit Analysis of Contingency Tables</a>
<ul>
<li><a href="advanced-logistic-regression.html#two-way-table" id="toc-two-way-table"><span class="toc-section-number">14.1.1</span> Two-Way Table</a></li>
<li><a href="advanced-logistic-regression.html#three-way-table" id="toc-three-way-table"><span class="toc-section-number">14.1.2</span> Three-Way Table</a></li>
<li><a href="advanced-logistic-regression.html#four-way-table" id="toc-four-way-table"><span class="toc-section-number">14.1.3</span> Four-Way Table</a></li>
<li><a href="advanced-logistic-regression.html#overdispersion" id="toc-overdispersion"><span class="toc-section-number">14.1.4</span> Overdispersion</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#loglinear-analysis-of-contingency-tables" id="toc-loglinear-analysis-of-contingency-tables"><span class="toc-section-number">14.2</span> Loglinear Analysis of Contingency Tables</a>
<ul>
<li><a href="advanced-logistic-regression.html#two-way-table-1" id="toc-two-way-table-1"><span class="toc-section-number">14.2.1</span> Two-way Table</a></li>
<li><a href="advanced-logistic-regression.html#problem-of-zeros" id="toc-problem-of-zeros"><span class="toc-section-number">14.2.2</span> Problem of Zeros</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#discrete-choice-analysis" id="toc-discrete-choice-analysis"><span class="toc-section-number">14.3</span> Discrete Choice Analysis</a>
<ul>
<li><a href="advanced-logistic-regression.html#logistic-strata" id="toc-logistic-strata"><span class="toc-section-number">14.3.1</span> Logistic Strata</a></li>
<li><a href="advanced-logistic-regression.html#conditional-logit-model" id="toc-conditional-logit-model"><span class="toc-section-number">14.3.2</span> Conditional logit model</a></li>
<li><a href="advanced-logistic-regression.html#ranked-data" id="toc-ranked-data"><span class="toc-section-number">14.3.3</span> Ranked Data</a></li>
<li><a href="advanced-logistic-regression.html#heteroscedastic-extreme-value-hev-model" id="toc-heteroscedastic-extreme-value-hev-model"><span class="toc-section-number">14.3.4</span> Heteroscedastic extreme value (HEV) Model</a></li>
<li><a href="advanced-logistic-regression.html#nested-logit-model" id="toc-nested-logit-model"><span class="toc-section-number">14.3.5</span> Nested logit model</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#longitudinal-and-other-clustered-data" id="toc-longitudinal-and-other-clustered-data"><span class="toc-section-number">14.4</span> Longitudinal and Other Clustered Data</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">14.4.1</span> Introduction</a></li>
<li><a href="advanced-logistic-regression.html#robust-standard-errors" id="toc-robust-standard-errors"><span class="toc-section-number">14.4.2</span> Robust Standard Errors</a></li>
<li><a href="advanced-logistic-regression.html#gee-estimation-with-proc-genmod" id="toc-gee-estimation-with-proc-genmod"><span class="toc-section-number">14.4.3</span> GEE Estimation with PROC GENMOD</a></li>
<li><a href="advanced-logistic-regression.html#mixed-models-with-proc-glimmix" id="toc-mixed-models-with-proc-glimmix"><span class="toc-section-number">14.4.4</span> Mixed Models with PROC GLIMMIX</a></li>
<li><a href="advanced-logistic-regression.html#fixed-effects-with-conditional-logistic-regression" id="toc-fixed-effects-with-conditional-logistic-regression"><span class="toc-section-number">14.4.5</span> Fixed-Effects with Conditional Logistic Regression</a></li>
<li><a href="advanced-logistic-regression.html#hybrid-method" id="toc-hybrid-method"><span class="toc-section-number">14.4.6</span> Hybrid Method</a></li>
</ul></li>
</ul></li>
<li><a href="count-data-regression.html#count-data-regression" id="toc-count-data-regression"><span class="toc-section-number">15</span> Count Data Regression</a>
<ul>
<li><a href="count-data-regression.html#introduction-of-count-data-regression" id="toc-introduction-of-count-data-regression"><span class="toc-section-number">15.1</span> Introduction of Count Data Regression</a></li>
<li><a href="count-data-regression.html#poisson-regression" id="toc-poisson-regression"><span class="toc-section-number">15.2</span> Poisson regression</a>
<ul>
<li><a href="count-data-regression.html#model" id="toc-model"><span class="toc-section-number">15.2.1</span> Model</a></li>
<li><a href="count-data-regression.html#interpretation-of-estimated-coefficients" id="toc-interpretation-of-estimated-coefficients"><span class="toc-section-number">15.2.2</span> Interpretation of Estimated Coefficients</a></li>
<li><a href="advanced-logistic-regression.html#overdispersion" id="toc-overdispersion"><span class="toc-section-number">15.2.3</span> Overdispersion</a></li>
<li><a href="count-data-regression.html#adjustment-for-varying-time-spans" id="toc-adjustment-for-varying-time-spans"><span class="toc-section-number">15.2.4</span> Adjustment for Varying Time Spans</a></li>
<li><a href="count-data-regression.html#sas-implementation-using-proc-genmod" id="toc-sas-implementation-using-proc-genmod"><span class="toc-section-number">15.2.5</span> SAS implementation using PROC GENMOD</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">15.2.6</span> R implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#negative-binomial-regression" id="toc-negative-binomial-regression"><span class="toc-section-number">15.3</span> Negative Binomial Regression</a>
<ul>
<li><a href="count-data-regression.html#model-1" id="toc-model-1"><span class="toc-section-number">15.3.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">15.3.2</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">15.3.3</span> R implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#zero-truncated-poisson-regression-model" id="toc-zero-truncated-poisson-regression-model"><span class="toc-section-number">15.4</span> Zero-truncated Poisson Regression Model</a>
<ul>
<li><a href="count-data-regression.html#model-2" id="toc-model-2"><span class="toc-section-number">15.4.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">15.4.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-2" id="toc-r-implementation-2"><span class="toc-section-number">15.4.3</span> R implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#zero-insflated-model" id="toc-zero-insflated-model"><span class="toc-section-number">15.5</span> Zero-Insflated Model</a>
<ul>
<li><a href="count-data-regression.html#model-3" id="toc-model-3"><span class="toc-section-number">15.5.1</span> Model</a></li>
<li><a href="count-data-regression.html#interpretation-of-estimated-coefficients-1" id="toc-interpretation-of-estimated-coefficients-1"><span class="toc-section-number">15.5.2</span> Interpretation of Estimated Coefficients</a></li>
<li><a href="parametric-test.html#sas-implementation-2" id="toc-sas-implementation-2"><span class="toc-section-number">15.5.3</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-3" id="toc-r-implementation-3"><span class="toc-section-number">15.5.4</span> R Implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#hurdle-models" id="toc-hurdle-models"><span class="toc-section-number">15.6</span> Hurdle models</a>
<ul>
<li><a href="count-data-regression.html#model-4" id="toc-model-4"><span class="toc-section-number">15.6.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation-3" id="toc-sas-implementation-3"><span class="toc-section-number">15.6.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-4" id="toc-r-implementation-4"><span class="toc-section-number">15.6.3</span> R Implementation</a></li>
</ul></li>
</ul></li>
<li><a href="proportion-response-regression.html#proportion-response-regression" id="toc-proportion-response-regression"><span class="toc-section-number">16</span> Proportion Response Regression</a>
<ul>
<li><a href="proportion-response-regression.html#beta-regression" id="toc-beta-regression"><span class="toc-section-number">16.1</span> Beta Regression</a>
<ul>
<li><a href="count-data-regression.html#model" id="toc-model"><span class="toc-section-number">16.1.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">16.1.2</span> SAS Implementation</a></li>
<li><a href="proportion-response-regression.html#r-implementation-betareg" id="toc-r-implementation-betareg"><span class="toc-section-number">16.1.3</span> R Implementation “betareg”</a></li>
</ul></li>
<li><a href="proportion-response-regression.html#zero-inflated-beta-regression" id="toc-zero-inflated-beta-regression"><span class="toc-section-number">16.2</span> Zero-inflated Beta Regression</a></li>
<li><a href="proportion-response-regression.html#one-inflated-beta-regression" id="toc-one-inflated-beta-regression"><span class="toc-section-number">16.3</span> One-inflated Beta Regression</a></li>
<li><a href="proportion-response-regression.html#zero-one-inflated-beta-regression" id="toc-zero-one-inflated-beta-regression"><span class="toc-section-number">16.4</span> Zero-one-inflated Beta Regression</a></li>
</ul></li>
<li><a href="survival-analysis.html#survival-analysis" id="toc-survival-analysis"><span class="toc-section-number">17</span> Survival Analysis</a>
<ul>
<li><a href="survival-analysis.html#preliminary" id="toc-preliminary"><span class="toc-section-number">17.1</span> Preliminary</a>
<ul>
<li><a href="survival-analysis.html#probability-density-function" id="toc-probability-density-function"><span class="toc-section-number">17.1.1</span> Probability density function</a></li>
<li><a href="survival-analysis.html#cumulative-distribution-function" id="toc-cumulative-distribution-function"><span class="toc-section-number">17.1.2</span> Cumulative distribution function</a></li>
<li><a href="survival-analysis.html#survival-function" id="toc-survival-function"><span class="toc-section-number">17.1.3</span> Survival function</a></li>
<li><a href="survival-analysis.html#hazard-function" id="toc-hazard-function"><span class="toc-section-number">17.1.4</span> Hazard function</a></li>
<li><a href="survival-analysis.html#cumulative-hazard-function" id="toc-cumulative-hazard-function"><span class="toc-section-number">17.1.5</span> Cumulative hazard function</a></li>
<li><a href="survival-analysis.html#mean-residual-life" id="toc-mean-residual-life"><span class="toc-section-number">17.1.6</span> Mean Residual Life</a></li>
<li><a href="survival-analysis.html#relation-between-functions" id="toc-relation-between-functions"><span class="toc-section-number">17.1.7</span> Relation between functions</a></li>
</ul></li>
<li><a href="survival-analysis.html#kaplan-meier-estimator" id="toc-kaplan-meier-estimator"><span class="toc-section-number">17.2</span> Kaplan-Meier estimator</a>
<ul>
<li><a href="survival-analysis.html#km-introduction" id="toc-km-introduction"><span class="toc-section-number">17.2.1</span> KM Introduction</a></li>
<li><a href="survival-analysis.html#nelson-aalen-estimator-of-the-cumulative-hazard-function" id="toc-nelson-aalen-estimator-of-the-cumulative-hazard-function"><span class="toc-section-number">17.2.2</span> Nelson-Aalen estimator of the cumulative hazard function</a></li>
<li><a href="survival-analysis.html#survival-curve-in-sas" id="toc-survival-curve-in-sas"><span class="toc-section-number">17.2.3</span> Survival curve in SAS</a></li>
<li><a href="survival-analysis.html#km-survival-plots-in-sas" id="toc-km-survival-plots-in-sas"><span class="toc-section-number">17.2.4</span> KM Survival Plots in SAS</a></li>
<li><a href="survival-analysis.html#convert-personal-level-to-personal-period-in-r" id="toc-convert-personal-level-to-personal-period-in-r"><span class="toc-section-number">17.2.5</span> Convert Personal-level to Personal-period in R</a></li>
<li><a href="survival-analysis.html#package-survfit-in-r" id="toc-package-survfit-in-r"><span class="toc-section-number">17.2.6</span> Package survfit in R</a></li>
<li><a href="survival-analysis.html#km-survival-plots-in-r" id="toc-km-survival-plots-in-r"><span class="toc-section-number">17.2.7</span> KM Survival Plots in R</a></li>
</ul></li>
<li><a href="survival-analysis.html#compare-the-survival-function" id="toc-compare-the-survival-function"><span class="toc-section-number">17.3</span> Compare the survival function</a>
<ul>
<li><a href="survival-analysis.html#tests-of-equality-of-the-survival-function" id="toc-tests-of-equality-of-the-survival-function"><span class="toc-section-number">17.3.1</span> Tests of equality of the survival function</a></li>
<li><a href="survival-analysis.html#other-nonparametric-tests-for-strata-statement" id="toc-other-nonparametric-tests-for-strata-statement"><span class="toc-section-number">17.3.2</span> Other nonparametric tests for STRATA statement</a></li>
<li><a href="survival-analysis.html#multiple-comparisons" id="toc-multiple-comparisons"><span class="toc-section-number">17.3.3</span> Multiple comparisons</a></li>
<li><a href="survival-analysis.html#comparing-survival-functions-using-log-rank-hr" id="toc-comparing-survival-functions-using-log-rank-hr"><span class="toc-section-number">17.3.4</span> Comparing survival functions using Log-Rank HR</a></li>
<li><a href="survival-analysis.html#mantel-haenszel-hr" id="toc-mantel-haenszel-hr"><span class="toc-section-number">17.3.5</span> Mantel-Haenszel HR</a></li>
<li><a href="survival-analysis.html#analysis-of-covariance-adjustment" id="toc-analysis-of-covariance-adjustment"><span class="toc-section-number">17.3.6</span> Analysis-of-covariance (Adjustment)</a></li>
</ul></li>
<li><a href="survival-analysis.html#accelerated-failure-time-aft-model" id="toc-accelerated-failure-time-aft-model"><span class="toc-section-number">17.4</span> Accelerated failure time (AFT) model</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">17.4.1</span> Introduction</a></li>
<li><a href="survival-analysis.html#proc-lifereg" id="toc-proc-lifereg"><span class="toc-section-number">17.4.2</span> PROC LIFEREG</a></li>
<li><a href="survival-analysis.html#residuum-distribution" id="toc-residuum-distribution"><span class="toc-section-number">17.4.3</span> Residuum distribution</a></li>
<li><a href="survival-analysis.html#exponential-model" id="toc-exponential-model"><span class="toc-section-number">17.4.4</span> Exponential Model</a></li>
<li><a href="survival-analysis.html#weibull-model" id="toc-weibull-model"><span class="toc-section-number">17.4.5</span> Weibull Model</a></li>
<li><a href="survival-analysis.html#log-normal-model" id="toc-log-normal-model"><span class="toc-section-number">17.4.6</span> Log-Normal Model</a></li>
<li><a href="survival-analysis.html#log-logistic-model" id="toc-log-logistic-model"><span class="toc-section-number">17.4.7</span> Log-Logistic Model</a></li>
<li><a href="survival-analysis.html#fit-statistics-for-model-comparsion" id="toc-fit-statistics-for-model-comparsion"><span class="toc-section-number">17.4.8</span> Fit statistics for model comparsion</a></li>
<li><a href="survival-analysis.html#graphical-method-for-distinguishing-different-distributions-in-sas" id="toc-graphical-method-for-distinguishing-different-distributions-in-sas"><span class="toc-section-number">17.4.9</span> Graphical method for distinguishing different distributions in SAS</a></li>
<li><a href="survival-analysis.html#prediction-and-hazard-function" id="toc-prediction-and-hazard-function"><span class="toc-section-number">17.4.10</span> Prediction and hazard function</a></li>
<li><a href="survival-analysis.html#left-censoring-and-interval-censoring" id="toc-left-censoring-and-interval-censoring"><span class="toc-section-number">17.4.11</span> Left Censoring and Interval Censoring</a></li>
</ul></li>
<li><a href="survival-analysis.html#cox-proportional-hazards-model" id="toc-cox-proportional-hazards-model"><span class="toc-section-number">17.5</span> Cox Proportional Hazards Model</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">17.5.1</span> Introduction</a></li>
<li><a href="survival-analysis.html#parameter-estimate" id="toc-parameter-estimate"><span class="toc-section-number">17.5.2</span> Parameter estimate</a></li>
<li><a href="survival-analysis.html#parameter-test" id="toc-parameter-test"><span class="toc-section-number">17.5.3</span> Parameter test</a></li>
<li><a href="survival-analysis.html#graphs-of-the-survival-and-baseline-hazard-function-in-sas" id="toc-graphs-of-the-survival-and-baseline-hazard-function-in-sas"><span class="toc-section-number">17.5.4</span> Graphs of the survival and baseline hazard function in SAS</a></li>
<li><a href="survival-analysis.html#check-proportional-hazards" id="toc-check-proportional-hazards"><span class="toc-section-number">17.5.5</span> Check proportional hazards</a></li>
<li><a href="survival-analysis.html#dealing-with-nonproportionality" id="toc-dealing-with-nonproportionality"><span class="toc-section-number">17.5.6</span> Dealing with nonproportionality</a></li>
<li><a href="correlation-and-regression.html#model-diagnostics" id="toc-model-diagnostics"><span class="toc-section-number">17.5.7</span> Model Diagnostics</a></li>
</ul></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#advanced-survival-analysis" id="toc-advanced-survival-analysis"><span class="toc-section-number">18</span> Advanced Survival Analysis</a>
<ul>
<li><a href="advanced-survival-analysis.html#tied-or-discrete-data" id="toc-tied-or-discrete-data"><span class="toc-section-number">18.1</span> Tied or Discrete Data</a>
<ul>
<li><a href="advanced-survival-analysis.html#introduction-of-tie" id="toc-introduction-of-tie"><span class="toc-section-number">18.1.1</span> Introduction of Tie</a></li>
<li><a href="advanced-survival-analysis.html#discrete-time" id="toc-discrete-time"><span class="toc-section-number">18.1.2</span> Discrete time</a></li>
<li><a href="advanced-survival-analysis.html#notation-and-definitions" id="toc-notation-and-definitions"><span class="toc-section-number">18.1.3</span> Notation and Definitions</a></li>
<li><a href="advanced-survival-analysis.html#discrete-cox-regression" id="toc-discrete-cox-regression"><span class="toc-section-number">18.1.4</span> Discrete Cox Regression</a></li>
<li><a href="advanced-survival-analysis.html#discrete-time-regression-models" id="toc-discrete-time-regression-models"><span class="toc-section-number">18.1.5</span> Discrete-Time Regression Models</a></li>
<li><a href="advanced-survival-analysis.html#the-glm-framework-and-person-period-data" id="toc-the-glm-framework-and-person-period-data"><span class="toc-section-number">18.1.6</span> The GLM Framework and Person-Period Data</a></li>
<li><a href="advanced-survival-analysis.html#discrete-time-survival-analysis-in-r" id="toc-discrete-time-survival-analysis-in-r"><span class="toc-section-number">18.1.7</span> Discrete-Time Survival Analysis in R</a></li>
<li><a href="advanced-survival-analysis.html#discrete-cause-specific-hazards-model" id="toc-discrete-cause-specific-hazards-model"><span class="toc-section-number">18.1.8</span> Discrete Cause-Specific Hazards Model</a></li>
<li><a href="advanced-survival-analysis.html#discrete-subdistribution-hazard-model" id="toc-discrete-subdistribution-hazard-model"><span class="toc-section-number">18.1.9</span> Discrete Subdistribution Hazard Model</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#time-dependent-covariates" id="toc-time-dependent-covariates"><span class="toc-section-number">18.2</span> Time-dependent covariates</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">18.2.1</span> Introduction</a></li>
<li><a href="advanced-survival-analysis.html#programming-method" id="toc-programming-method"><span class="toc-section-number">18.2.2</span> Programming method</a></li>
<li><a href="advanced-survival-analysis.html#counting-method" id="toc-counting-method"><span class="toc-section-number">18.2.3</span> Counting method</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#additive-hazards-regression-model" id="toc-additive-hazards-regression-model"><span class="toc-section-number">18.3</span> Additive Hazards Regression Model</a>
<ul>
<li><a href="advanced-survival-analysis.html#preview" id="toc-preview"><span class="toc-section-number">18.3.1</span> Preview</a></li>
<li><a href="advanced-survival-analysis.html#lin-and-yings-additive-hazards-model" id="toc-lin-and-yings-additive-hazards-model"><span class="toc-section-number">18.3.2</span> Lin and Ying’s additive hazards model</a></li>
<li><a href="advanced-survival-analysis.html#aalens-additive-hazards-model" id="toc-aalens-additive-hazards-model"><span class="toc-section-number">18.3.3</span> Aalen’s Additive Hazards Model</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#competing-risk" id="toc-competing-risk"><span class="toc-section-number">18.4</span> Competing Risk</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">18.4.1</span> Introduction</a></li>
<li><a href="advanced-survival-analysis.html#type-specific-hazards" id="toc-type-specific-hazards"><span class="toc-section-number">18.4.2</span> Type-specific hazards</a></li>
<li><a href="advanced-survival-analysis.html#covariate-effects-via-cox-model" id="toc-covariate-effects-via-cox-model"><span class="toc-section-number">18.4.3</span> Covariate effects via COX model</a></li>
<li><a href="advanced-survival-analysis.html#cumulative-incidence-function-cif" id="toc-cumulative-incidence-function-cif"><span class="toc-section-number">18.4.4</span> Cumulative incidence function (CIF)</a></li>
<li><a href="advanced-survival-analysis.html#subdistribution-hazard-function" id="toc-subdistribution-hazard-function"><span class="toc-section-number">18.4.5</span> Subdistribution hazard function</a></li>
<li><a href="advanced-survival-analysis.html#cause-specific-hazard-function" id="toc-cause-specific-hazard-function"><span class="toc-section-number">18.4.6</span> Cause-specific hazard function</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#clustered-events" id="toc-clustered-events"><span class="toc-section-number">18.5</span> Clustered Events</a>
<ul>
<li><a href="advanced-survival-analysis.html#introduction-4" id="toc-introduction-4"><span class="toc-section-number">18.5.1</span> Introduction</a></li>
<li><a href="advanced-survival-analysis.html#proportional-hazards-model-which-adopts-a-marginal" id="toc-proportional-hazards-model-which-adopts-a-marginal"><span class="toc-section-number">18.5.2</span> Proportional hazards model which adopts a marginal</a></li>
<li><a href="advanced-survival-analysis.html#frailty-model" id="toc-frailty-model"><span class="toc-section-number">18.5.3</span> Frailty model</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#non-proportional-hazards-in-survival-analysis" id="toc-non-proportional-hazards-in-survival-analysis"><span class="toc-section-number">18.6</span> Non-proportional hazards in Survival Analysis</a>
<ul>
<li><a href="advanced-survival-analysis.html#weighted-piecewise-log-rank-test" id="toc-weighted-piecewise-log-rank-test"><span class="toc-section-number">18.6.1</span> Weighted Piecewise Log-Rank Test</a></li>
<li><a href="advanced-survival-analysis.html#restricted-mean-survival-time-difference" id="toc-restricted-mean-survival-time-difference"><span class="toc-section-number">18.6.2</span> Restricted Mean Survival Time Difference</a></li>
<li><a href="advanced-survival-analysis.html#maximum-combination-test" id="toc-maximum-combination-test"><span class="toc-section-number">18.6.3</span> Maximum Combination Test</a></li>
</ul></li>
</ul></li>
<li><a href="mixed-model.html#mixed-model" id="toc-mixed-model"><span class="toc-section-number">19</span> Mixed Model</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">19.1</span> Introduction</a>
<ul>
<li><a href="mixed-model.html#correlated-response-data" id="toc-correlated-response-data"><span class="toc-section-number">19.1.1</span> Correlated response data</a></li>
<li><a href="mixed-model.html#hierarchical-and-marginal-model" id="toc-hierarchical-and-marginal-model"><span class="toc-section-number">19.1.2</span> Hierarchical and Marginal model</a></li>
<li><a href="mixed-model.html#mle-in-marginal-model" id="toc-mle-in-marginal-model"><span class="toc-section-number">19.1.3</span> MLE in Marginal model</a></li>
<li><a href="mixed-model.html#reml-in-marginal-model" id="toc-reml-in-marginal-model"><span class="toc-section-number">19.1.4</span> REML in Marginal model</a></li>
<li><a href="mixed-model.html#variance-correction" id="toc-variance-correction"><span class="toc-section-number">19.1.5</span> Variance correction</a></li>
<li><a href="mixed-model.html#hypothesis-tests" id="toc-hypothesis-tests"><span class="toc-section-number">19.1.6</span> Hypothesis tests</a></li>
<li><a href="mixed-model.html#residual-structure" id="toc-residual-structure"><span class="toc-section-number">19.1.7</span> Residual Structure</a></li>
<li><a href="mixed-model.html#converge-problems" id="toc-converge-problems"><span class="toc-section-number">19.1.8</span> Converge problems</a></li>
<li><a href="mixed-model.html#preface-of-linear-mixed-model" id="toc-preface-of-linear-mixed-model"><span class="toc-section-number">19.1.9</span> Preface of linear mixed model</a></li>
</ul></li>
<li><a href="mixed-model.html#random-slope-and-intercept-model" id="toc-random-slope-and-intercept-model"><span class="toc-section-number">19.2</span> Random Slope and Intercept Model</a>
<ul>
<li><a href="mixed-model.html#model-introduction" id="toc-model-introduction"><span class="toc-section-number">19.2.1</span> Model Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">19.2.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">19.2.3</span> R Implementation</a></li>
</ul></li>
<li><a href="mixed-model.html#covariance-structure" id="toc-covariance-structure"><span class="toc-section-number">19.3</span> Covariance Structure</a>
<ul>
<li><a href="mixed-model.html#model-introduction-1" id="toc-model-introduction-1"><span class="toc-section-number">19.3.1</span> Model Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">19.3.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">19.3.3</span> R Implementation</a></li>
</ul></li>
<li><a href="mixed-model.html#hierarchical-regression-model-for-normal-response" id="toc-hierarchical-regression-model-for-normal-response"><span class="toc-section-number">19.4</span> Hierarchical Regression Model for Normal Response</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">19.4.1</span> Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-2" id="toc-sas-implementation-2"><span class="toc-section-number">19.4.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-2" id="toc-r-implementation-2"><span class="toc-section-number">19.4.3</span> R Implementation</a></li>
</ul></li>
<li><a href="mixed-model.html#generalized-estimating-equation" id="toc-generalized-estimating-equation"><span class="toc-section-number">19.5</span> Generalized Estimating Equation</a>
<ul>
<li><a href="mixed-model.html#introduction-of-gee" id="toc-introduction-of-gee"><span class="toc-section-number">19.5.1</span> Introduction of GEE</a></li>
<li><a href="parametric-test.html#sas-implementation-3" id="toc-sas-implementation-3"><span class="toc-section-number">19.5.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-3" id="toc-r-implementation-3"><span class="toc-section-number">19.5.3</span> R Implementation</a></li>
</ul></li>
</ul></li>
<li><a href="glmm-and-gam.html#glmm-and-gam" id="toc-glmm-and-gam"><span class="toc-section-number">20</span> GLMM and GAM</a>
<ul>
<li><a href="glmm-and-gam.html#genaralised-linear-model" id="toc-genaralised-linear-model"><span class="toc-section-number">20.1</span> Genaralised linear model</a>
<ul>
<li><a href="glmm-and-gam.html#review" id="toc-review"><span class="toc-section-number">20.1.1</span> Review</a></li>
<li><a href="glmm-and-gam.html#exponential-families" id="toc-exponential-families"><span class="toc-section-number">20.1.2</span> Exponential Families</a></li>
<li><a href="glmm-and-gam.html#testing-linear-hypotheses" id="toc-testing-linear-hypotheses"><span class="toc-section-number">20.1.3</span> Testing linear Hypotheses</a></li>
<li><a href="glmm-and-gam.html#maximum-likelihood-estimation-in-glm" id="toc-maximum-likelihood-estimation-in-glm"><span class="toc-section-number">20.1.4</span> Maximum Likelihood Estimation in GLM</a></li>
<li><a href="glmm-and-gam.html#irls-algorithm-for-estimating-glm" id="toc-irls-algorithm-for-estimating-glm"><span class="toc-section-number">20.1.5</span> IRLS Algorithm for Estimating GLM</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#generalized-linear-mixed-model" id="toc-generalized-linear-mixed-model"><span class="toc-section-number">20.2</span> Generalized Linear Mixed Model</a>
<ul>
<li><a href="glmm-and-gam.html#backgroud" id="toc-backgroud"><span class="toc-section-number">20.2.1</span> Backgroud</a></li>
<li><a href="glmm-and-gam.html#lmm-to-glmm" id="toc-lmm-to-glmm"><span class="toc-section-number">20.2.2</span> LMM to GLMM</a></li>
<li><a href="glmm-and-gam.html#link-functions-and-families" id="toc-link-functions-and-families"><span class="toc-section-number">20.2.3</span> Link Functions and Families</a></li>
<li><a href="glmm-and-gam.html#parameter-estimation" id="toc-parameter-estimation"><span class="toc-section-number">20.2.4</span> Parameter estimation</a></li>
<li><a href="glmm-and-gam.html#logistic-model-with-fixed-and-random-effectss" id="toc-logistic-model-with-fixed-and-random-effectss"><span class="toc-section-number">20.2.5</span> logistic model with fixed and random effectss</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#generalized-additive-models" id="toc-generalized-additive-models"><span class="toc-section-number">20.3</span> Generalized Additive Models</a>
<ul>
<li><a href="glmm-and-gam.html#concept" id="toc-concept"><span class="toc-section-number">20.3.1</span> Concept</a></li>
</ul></li>
</ul></li>
<li><a href="missing-data.html#missing-data" id="toc-missing-data"><span class="toc-section-number">21</span> Missing Data</a>
<ul>
<li><a href="missing-data.html#missing-mechanisms" id="toc-missing-mechanisms"><span class="toc-section-number">21.1</span> Missing mechanisms</a></li>
<li><a href="missing-data.html#compatibility-and-congeniality" id="toc-compatibility-and-congeniality"><span class="toc-section-number">21.2</span> Compatibility and Congeniality</a></li>
<li><a href="missing-data.html#single-imputation" id="toc-single-imputation"><span class="toc-section-number">21.3</span> Single imputation</a></li>
<li><a href="missing-data.html#multiple-imputation" id="toc-multiple-imputation"><span class="toc-section-number">21.4</span> Multiple imputation</a>
<ul>
<li><a href="missing-data.html#joint-modeling-jm" id="toc-joint-modeling-jm"><span class="toc-section-number">21.4.1</span> Joint Modeling (JM)</a></li>
<li><a href="missing-data.html#multiple-imputation-by-fully-conditional-specification-mice" id="toc-multiple-imputation-by-fully-conditional-specification-mice"><span class="toc-section-number">21.4.2</span> Multiple Imputation by Fully Conditional Specification (MICE)</a></li>
</ul></li>
<li><a href="missing-data.html#bayesian-linear-regression" id="toc-bayesian-linear-regression"><span class="toc-section-number">21.5</span> Bayesian linear regression</a></li>
<li><a href="missing-data.html#predictive-mean-matching" id="toc-predictive-mean-matching"><span class="toc-section-number">21.6</span> Predictive Mean Matching</a></li>
<li><a href="missing-data.html#mice-using-random-forest" id="toc-mice-using-random-forest"><span class="toc-section-number">21.7</span> MICE using random forest</a></li>
</ul></li>
<li><a href="meta-analysis.html#meta-analysis" id="toc-meta-analysis"><span class="toc-section-number">22</span> Meta Analysis</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">22.1</span> Introduction</a>
<ul>
<li><a href="meta-analysis.html#meta-analysis-for-different-data" id="toc-meta-analysis-for-different-data"><span class="toc-section-number">22.1.1</span> meta-analysis for different data</a></li>
</ul></li>
<li><a href="meta-analysis.html#fixed-effect-model-for-continuous-outcomes" id="toc-fixed-effect-model-for-continuous-outcomes"><span class="toc-section-number">22.2</span> Fixed Effect Model for Continuous Outcomes</a>
<ul>
<li><a href="meta-analysis.html#effect-measures" id="toc-effect-measures"><span class="toc-section-number">22.2.1</span> Effect Measures</a></li>
<li><a href="meta-analysis.html#standardized-mean-difference" id="toc-standardized-mean-difference"><span class="toc-section-number">22.2.2</span> Standardized Mean Difference</a></li>
<li><a href="meta-analysis.html#inverse-variance-weighted-average-method" id="toc-inverse-variance-weighted-average-method"><span class="toc-section-number">22.2.3</span> Inverse variance-weighted average method</a></li>
<li><a href="meta-analysis.html#generic-inverse-variance-meta-analysis-metagen" id="toc-generic-inverse-variance-meta-analysis-metagen"><span class="toc-section-number">22.2.4</span> Generic inverse variance meta-analysis <code>metagen</code></a></li>
<li><a href="meta-analysis.html#weighted-sum-of-z-scores" id="toc-weighted-sum-of-z-scores"><span class="toc-section-number">22.2.5</span> Weighted Sum of Z-Scores</a></li>
</ul></li>
<li><a href="meta-analysis.html#random-effects-model-for-continuous-outcomes" id="toc-random-effects-model-for-continuous-outcomes"><span class="toc-section-number">22.3</span> Random Effects Model for Continuous Outcomes</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">22.3.1</span> Introduction</a></li>
<li><a href="meta-analysis.html#implementation" id="toc-implementation"><span class="toc-section-number">22.3.2</span> Implementation</a></li>
<li><a href="meta-analysis.html#hartung-knapp-adjustment" id="toc-hartung-knapp-adjustment"><span class="toc-section-number">22.3.3</span> Hartung-Knapp Adjustment</a></li>
</ul></li>
<li><a href="meta-analysis.html#meta-regression" id="toc-meta-regression"><span class="toc-section-number">22.4</span> Meta-Regression</a></li>
<li><a href="meta-analysis.html#meta-analysis-with-binary-outcomes" id="toc-meta-analysis-with-binary-outcomes"><span class="toc-section-number">22.5</span> Meta-Analysis with Binary Outcomes</a>
<ul>
<li><a href="meta-analysis.html#effect-measures-1" id="toc-effect-measures-1"><span class="toc-section-number">22.5.1</span> Effect Measures</a></li>
<li><a href="meta-analysis.html#implementation-1" id="toc-implementation-1"><span class="toc-section-number">22.5.2</span> Implementation</a></li>
<li><a href="meta-analysis.html#estimation-in-sparse-data---continuity-correction" id="toc-estimation-in-sparse-data---continuity-correction"><span class="toc-section-number">22.5.3</span> Estimation in Sparse Data - Continuity correction</a></li>
<li><a href="meta-analysis.html#peto-odds-ratio" id="toc-peto-odds-ratio"><span class="toc-section-number">22.5.4</span> Peto Odds Ratio</a></li>
<li><a href="meta-analysis.html#fixed-effect-model-inverse-variance-method" id="toc-fixed-effect-model-inverse-variance-method"><span class="toc-section-number">22.5.5</span> Fixed Effect Model: Inverse Variance Method</a></li>
<li><a href="meta-analysis.html#fixed-effect-model-mantelhaenszel-method" id="toc-fixed-effect-model-mantelhaenszel-method"><span class="toc-section-number">22.5.6</span> Fixed Effect Model: Mantel–Haenszel Method</a></li>
<li><a href="meta-analysis.html#random-effects-model" id="toc-random-effects-model"><span class="toc-section-number">22.5.7</span> Random Effects Model</a></li>
</ul></li>
</ul></li>
<li><a href="time-series-analysis.html#time-series-analysis" id="toc-time-series-analysis"><span class="toc-section-number">23</span> Time Series Analysis</a>
<ul>
<li><a href="time-series-analysis.html#fundational-concepts" id="toc-fundational-concepts"><span class="toc-section-number">23.1</span> Fundational Concepts</a>
<ul>
<li><a href="time-series-analysis.html#means-variances-and-covariances" id="toc-means-variances-and-covariances"><span class="toc-section-number">23.1.1</span> Means, Variances, and Covariances</a></li>
<li><a href="time-series-analysis.html#properties-of-covariance" id="toc-properties-of-covariance"><span class="toc-section-number">23.1.2</span> Properties of covariance</a></li>
<li><a href="time-series-analysis.html#properties-of-expectation" id="toc-properties-of-expectation"><span class="toc-section-number">23.1.3</span> Properties of Expectation</a></li>
<li><a href="time-series-analysis.html#properties-of-variance" id="toc-properties-of-variance"><span class="toc-section-number">23.1.4</span> Properties of Variance</a></li>
<li><a href="time-series-analysis.html#the-random-walk" id="toc-the-random-walk"><span class="toc-section-number">23.1.5</span> The Random Walk</a></li>
<li><a href="time-series-analysis.html#a-moving-average" id="toc-a-moving-average"><span class="toc-section-number">23.1.6</span> A Moving Average</a></li>
<li><a href="time-series-analysis.html#strictly-stationarity" id="toc-strictly-stationarity"><span class="toc-section-number">23.1.7</span> Strictly Stationarity</a></li>
<li><a href="time-series-analysis.html#weakly-or-second-order-stationary" id="toc-weakly-or-second-order-stationary"><span class="toc-section-number">23.1.8</span> Weakly (or second-order) stationary</a></li>
<li><a href="time-series-analysis.html#white-noise" id="toc-white-noise"><span class="toc-section-number">23.1.9</span> White Noise</a></li>
<li><a href="time-series-analysis.html#deterministic-versus-stochastic-trends" id="toc-deterministic-versus-stochastic-trends"><span class="toc-section-number">23.1.10</span> Deterministic Versus Stochastic Trends</a></li>
</ul></li>
<li><a href="time-series-analysis.html#arma-models" id="toc-arma-models"><span class="toc-section-number">23.2</span> ARMA models</a>
<ul>
<li><a href="time-series-analysis.html#general-linear-processes" id="toc-general-linear-processes"><span class="toc-section-number">23.2.1</span> General Linear Processes</a></li>
<li><a href="time-series-analysis.html#moving-average-processes" id="toc-moving-average-processes"><span class="toc-section-number">23.2.2</span> Moving Average Processes</a></li>
<li><a href="time-series-analysis.html#autoregressive-processes" id="toc-autoregressive-processes"><span class="toc-section-number">23.2.3</span> Autoregressive Processes</a></li>
<li><a href="time-series-analysis.html#the-mixed-autoregressive-moving-average-model" id="toc-the-mixed-autoregressive-moving-average-model"><span class="toc-section-number">23.2.4</span> The Mixed Autoregressive Moving Average Model</a></li>
<li><a href="time-series-analysis.html#invertibility" id="toc-invertibility"><span class="toc-section-number">23.2.5</span> Invertibility</a></li>
<li><a href="time-series-analysis.html#fit-the-ar-model-in-r" id="toc-fit-the-ar-model-in-r"><span class="toc-section-number">23.2.6</span> Fit the AR model in R</a></li>
<li><a href="time-series-analysis.html#fit-the-ma-model-in-r" id="toc-fit-the-ma-model-in-r"><span class="toc-section-number">23.2.7</span> Fit the MA model in R</a></li>
</ul></li>
<li><a href="time-series-analysis.html#arima-models" id="toc-arima-models"><span class="toc-section-number">23.3</span> ARIMA Models</a>
<ul>
<li><a href="time-series-analysis.html#stationarity-through-differencing" id="toc-stationarity-through-differencing"><span class="toc-section-number">23.3.1</span> Stationarity Through Differencing</a></li>
<li><a href="time-series-analysis.html#arima-integrated-autoregressive-moving-average-model" id="toc-arima-integrated-autoregressive-moving-average-model"><span class="toc-section-number">23.3.2</span> ARIMA: Integrated autoregressive moving average model</a></li>
<li><a href="time-series-analysis.html#ima11-model" id="toc-ima11-model"><span class="toc-section-number">23.3.3</span> IMA(1,1) Model</a></li>
<li><a href="time-series-analysis.html#ari11-model" id="toc-ari11-model"><span class="toc-section-number">23.3.4</span> ARI(1,1) Model</a></li>
</ul></li>
<li><a href="time-series-analysis.html#time-series-graphics" id="toc-time-series-graphics"><span class="toc-section-number">23.4</span> Time series graphics</a>
<ul>
<li><a href="time-series-analysis.html#time-plots" id="toc-time-plots"><span class="toc-section-number">23.4.1</span> Time plots</a></li>
<li><a href="time-series-analysis.html#seasonal-plots" id="toc-seasonal-plots"><span class="toc-section-number">23.4.2</span> Seasonal plots</a></li>
<li><a href="time-series-analysis.html#scatterplots-matrices" id="toc-scatterplots-matrices"><span class="toc-section-number">23.4.3</span> Scatterplots matrices</a></li>
<li><a href="time-series-analysis.html#lag-plots" id="toc-lag-plots"><span class="toc-section-number">23.4.4</span> Lag plots</a></li>
<li><a href="time-series-analysis.html#autocorrelation" id="toc-autocorrelation"><span class="toc-section-number">23.4.5</span> Autocorrelation</a></li>
<li><a href="time-series-analysis.html#white-noise-1" id="toc-white-noise-1"><span class="toc-section-number">23.4.6</span> White noise</a></li>
</ul></li>
</ul></li>
<li><a href="clinic-trail-design.html#clinic-trail-design" id="toc-clinic-trail-design"><span class="toc-section-number">24</span> Clinic Trail Design</a>
<ul>
<li><a href="clinic-trail-design.html#regulation" id="toc-regulation"><span class="toc-section-number">24.1</span> Regulation</a></li>
<li><a href="clinic-trail-design.html#randomization" id="toc-randomization"><span class="toc-section-number">24.2</span> Randomization</a>
<ul>
<li><a href="clinic-trail-design.html#simple-randomization" id="toc-simple-randomization"><span class="toc-section-number">24.2.1</span> Simple randomization</a></li>
<li><a href="clinic-trail-design.html#block-randomization" id="toc-block-randomization"><span class="toc-section-number">24.2.2</span> Block randomization</a></li>
<li><a href="clinic-trail-design.html#stratified-randomization" id="toc-stratified-randomization"><span class="toc-section-number">24.2.3</span> Stratified randomization</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#phase-i-trials-design" id="toc-phase-i-trials-design"><span class="toc-section-number">24.3</span> Phase I Trials Design</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">24.3.1</span> Introduction</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#pharmacokinetic-analysis-pk-package" id="toc-pharmacokinetic-analysis-pk-package"><span class="toc-section-number">24.4</span> Pharmacokinetic Analysis (PK package）</a>
<ul>
<li><a href="clinic-trail-design.html#auc" id="toc-auc"><span class="toc-section-number">24.4.1</span> AUC</a></li>
<li><a href="clinic-trail-design.html#auc-in-complete-data-design" id="toc-auc-in-complete-data-design"><span class="toc-section-number">24.4.2</span> AUC in complete data design</a></li>
<li><a href="clinic-trail-design.html#auc-in-repeated-complete-data-design" id="toc-auc-in-repeated-complete-data-design"><span class="toc-section-number">24.4.3</span> AUC in repeated complete data design</a></li>
<li><a href="clinic-trail-design.html#bioequivalence-between-aucs" id="toc-bioequivalence-between-aucs"><span class="toc-section-number">24.4.4</span> Bioequivalence between AUCs</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-biexponential-model" id="toc-two-phase-half-life-estimation-by-biexponential-model"><span class="toc-section-number">24.4.5</span> Two-phase half-life estimation by biexponential model</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-linear-fitting" id="toc-two-phase-half-life-estimation-by-linear-fitting"><span class="toc-section-number">24.4.6</span> Two-phase half-life estimation by linear fitting</a></li>
<li><a href="clinic-trail-design.html#estimation-of-various-pk-parameters" id="toc-estimation-of-various-pk-parameters"><span class="toc-section-number">24.4.7</span> Estimation of various PK parameters</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#phase-ii-trials-design" id="toc-phase-ii-trials-design"><span class="toc-section-number">24.5</span> Phase II Trials Design</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">24.5.1</span> Introduction</a></li>
<li><a href="clinic-trail-design.html#gehans-design" id="toc-gehans-design"><span class="toc-section-number">24.5.2</span> Gehan’s design</a></li>
<li><a href="clinic-trail-design.html#flemings-two-stage-design" id="toc-flemings-two-stage-design"><span class="toc-section-number">24.5.3</span> Fleming’s Two-Stage design</a></li>
<li><a href="clinic-trail-design.html#simons-2-stage-design" id="toc-simons-2-stage-design"><span class="toc-section-number">24.5.4</span> Simon’s 2-Stage Design</a></li>
<li><a href="clinic-trail-design.html#jonckheere-terptsra-jt-trend-test" id="toc-jonckheere-terptsra-jt-trend-test"><span class="toc-section-number">24.5.5</span> Jonckheere-Terptsra (JT) trend test</a></li>
<li><a href="clinic-trail-design.html#cochran-armitage-ca-trend-test" id="toc-cochran-armitage-ca-trend-test"><span class="toc-section-number">24.5.6</span> Cochran-Armitage (CA) trend test</a></li>
<li><a href="clinic-trail-design.html#mcp-mod" id="toc-mcp-mod"><span class="toc-section-number">24.5.7</span> MCP-Mod</a></li>
<li><a href="clinic-trail-design.html#two-stage-phase-ii-design-for-response-and-toxicity" id="toc-two-stage-phase-ii-design-for-response-and-toxicity"><span class="toc-section-number">24.5.8</span> Two Stage Phase II Design for Response and Toxicity</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#phase-iii-trials-design" id="toc-phase-iii-trials-design"><span class="toc-section-number">24.6</span> Phase III Trials Design</a>
<ul>
<li><a href="clinic-trail-design.html#non-inferiority-and-equivalence-three-armed-trial" id="toc-non-inferiority-and-equivalence-three-armed-trial"><span class="toc-section-number">24.6.1</span> Non-inferiority and Equivalence Three-armed trial</a></li>
<li><a href="clinic-trail-design.html#pigeot-method" id="toc-pigeot-method"><span class="toc-section-number">24.6.2</span> Pigeot Method</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#medical-devices-postmarketing-surveillance-pms" id="toc-medical-devices-postmarketing-surveillance-pms"><span class="toc-section-number">24.7</span> Medical Devices Postmarketing Surveillance (PMS)</a>
<ul>
<li><a href="clinic-trail-design.html#phase-iv-and-pms" id="toc-phase-iv-and-pms"><span class="toc-section-number">24.7.1</span> Phase IV and PMS</a></li>
</ul></li>
</ul></li>
<li><a href="group-sequential-design.html#group-sequential-design" id="toc-group-sequential-design"><span class="toc-section-number">25</span> Group Sequential Design</a>
<ul>
<li><a href="group-sequential-design.html#classical-designs-without-futility-stopping" id="toc-classical-designs-without-futility-stopping"><span class="toc-section-number">25.1</span> Classical Designs without futility stopping</a>
<ul>
<li><a href="group-sequential-design.html#pocock-method" id="toc-pocock-method"><span class="toc-section-number">25.1.1</span> Pocock Method</a></li>
<li><a href="group-sequential-design.html#obrien-fleming-method" id="toc-obrien-fleming-method"><span class="toc-section-number">25.1.2</span> O’Brien &amp; Fleming Method</a></li>
<li><a href="group-sequential-design.html#wang-tsiatis-method" id="toc-wang-tsiatis-method"><span class="toc-section-number">25.1.3</span> Wang &amp; Tsiatis Method</a></li>
<li><a href="group-sequential-design.html#rejection-bounds-and-local-p-values" id="toc-rejection-bounds-and-local-p-values"><span class="toc-section-number">25.1.4</span> Rejection bounds and Local p-values</a></li>
<li><a href="group-sequential-design.html#power-and-sample-size" id="toc-power-and-sample-size"><span class="toc-section-number">25.1.5</span> Power and Sample size</a></li>
</ul></li>
<li><a href="group-sequential-design.html#classical-designs-with-binding-futility-stopping" id="toc-classical-designs-with-binding-futility-stopping"><span class="toc-section-number">25.2</span> Classical Designs with binding futility stopping</a>
<ul>
<li><a href="group-sequential-design.html#symmetric-designs" id="toc-symmetric-designs"><span class="toc-section-number">25.2.1</span> Symmetric designs</a></li>
<li><a href="group-sequential-design.html#one-sided-designs" id="toc-one-sided-designs"><span class="toc-section-number">25.2.2</span> One-Sided Designs</a></li>
</ul></li>
<li><a href="group-sequential-design.html#alpha-spending-function-approach" id="toc-alpha-spending-function-approach"><span class="toc-section-number">25.3</span> Alpha Spending Function Approach</a></li>
<li><a href="group-sequential-design.html#r-implementation-using-rpact" id="toc-r-implementation-using-rpact"><span class="toc-section-number">25.4</span> R Implementation using rpact</a>
<ul>
<li><a href="group-sequential-design.html#basic-functions" id="toc-basic-functions"><span class="toc-section-number">25.4.1</span> Basic Functions</a></li>
<li><a href="group-sequential-design.html#getdesigngroupsequential-defining-efficacy-boundaries" id="toc-getdesigngroupsequential-defining-efficacy-boundaries"><span class="toc-section-number">25.4.2</span> <code>getDesignGroupSequential</code> defining efficacy boundaries</a></li>
</ul></li>
<li><a href="group-sequential-design.html#sample-size" id="toc-sample-size"><span class="toc-section-number">25.5</span> Sample Size</a>
<ul>
<li><a href="group-sequential-design.html#sample-sizes-for-different-types-of-endpoints-without-ia" id="toc-sample-sizes-for-different-types-of-endpoints-without-ia"><span class="toc-section-number">25.5.1</span> Sample Sizes for Different Types of Endpoints without IA</a></li>
<li><a href="group-sequential-design.html#two-groups-continuous-endpoint-without-ia" id="toc-two-groups-continuous-endpoint-without-ia"><span class="toc-section-number">25.5.2</span> Two groups continuous endpoint (without IA)</a></li>
<li><a href="group-sequential-design.html#two-groups-binary-endpoint-without-ia" id="toc-two-groups-binary-endpoint-without-ia"><span class="toc-section-number">25.5.3</span> Two groups binary endpoint (without IA)</a></li>
<li><a href="group-sequential-design.html#group-sequential-designs-for-conti-and-binary" id="toc-group-sequential-designs-for-conti-and-binary"><span class="toc-section-number">25.5.4</span> Group-sequential designs for conti and binary</a></li>
<li><a href="group-sequential-design.html#survival-endpoint" id="toc-survival-endpoint"><span class="toc-section-number">25.5.5</span> Survival endpoint</a></li>
</ul></li>
</ul></li>
<li><a href="adaptive-designs.html#adaptive-designs" id="toc-adaptive-designs"><span class="toc-section-number">26</span> Adaptive designs</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">26.1</span> Introduction</a>
<ul>
<li><a href="adaptive-designs.html#early-termination-due-to-futility" id="toc-early-termination-due-to-futility"><span class="toc-section-number">26.1.1</span> Early termination due to futility</a></li>
<li><a href="adaptive-designs.html#early-termination-due-to-efficacy" id="toc-early-termination-due-to-efficacy"><span class="toc-section-number">26.1.2</span> Early termination due to efficacy</a></li>
<li><a href="adaptive-designs.html#sample-size-reassessment" id="toc-sample-size-reassessment"><span class="toc-section-number">26.1.3</span> Sample size reassessment</a></li>
<li><a href="adaptive-designs.html#change-or-modification-of-the-primary-endpoint" id="toc-change-or-modification-of-the-primary-endpoint"><span class="toc-section-number">26.1.4</span> Change or modification of the primary endpoint</a></li>
<li><a href="adaptive-designs.html#discontinuing-treatment-arms" id="toc-discontinuing-treatment-arms"><span class="toc-section-number">26.1.5</span> Discontinuing treatment arms</a></li>
<li><a href="adaptive-designs.html#switching-between-superiority-and-non-inferiority" id="toc-switching-between-superiority-and-non-inferiority"><span class="toc-section-number">26.1.6</span> Switching between superiority and non-inferiority</a></li>
<li><a href="adaptive-designs.html#selection-of-the-patient-population" id="toc-selection-of-the-patient-population"><span class="toc-section-number">26.1.7</span> Selection of the patient population</a></li>
</ul></li>
<li><a href="adaptive-designs.html#general-theory" id="toc-general-theory"><span class="toc-section-number">26.2</span> General Theory</a>
<ul>
<li><a href="adaptive-designs.html#stopping-boundary" id="toc-stopping-boundary"><span class="toc-section-number">26.2.1</span> Stopping Boundary</a></li>
<li><a href="adaptive-designs.html#power-and-adjusted-p-value" id="toc-power-and-adjusted-p-value"><span class="toc-section-number">26.2.2</span> Power and Adjusted p-value</a></li>
<li><a href="adaptive-designs.html#stopping-probabilities-design-evaluation" id="toc-stopping-probabilities-design-evaluation"><span class="toc-section-number">26.2.3</span> Stopping Probabilities (Design Evaluation)</a></li>
<li><a href="adaptive-designs.html#expected-duration-of-an-adaptive-trial-design-evaluation" id="toc-expected-duration-of-an-adaptive-trial-design-evaluation"><span class="toc-section-number">26.2.4</span> Expected Duration of an Adaptive Trial (Design Evaluation)</a></li>
<li><a href="adaptive-designs.html#expected-sample-sizes-design-evaluation" id="toc-expected-sample-sizes-design-evaluation"><span class="toc-section-number">26.2.5</span> Expected Sample Sizes (Design Evaluation)</a></li>
<li><a href="adaptive-designs.html#conditional-power-and-futility-index" id="toc-conditional-power-and-futility-index"><span class="toc-section-number">26.2.6</span> Conditional Power and futility index</a></li>
</ul></li>
<li><a href="adaptive-designs.html#methods" id="toc-methods"><span class="toc-section-number">26.3</span> Methods</a>
<ul>
<li><a href="adaptive-designs.html#four-inroduction" id="toc-four-inroduction"><span class="toc-section-number">26.3.1</span> Four Inroduction</a></li>
<li><a href="adaptive-designs.html#sample-size-re-estimation" id="toc-sample-size-re-estimation"><span class="toc-section-number">26.3.2</span> Sample size re-estimation</a></li>
<li><a href="adaptive-designs.html#additional-considerations" id="toc-additional-considerations"><span class="toc-section-number">26.3.3</span> Additional Considerations</a></li>
</ul></li>
<li><a href="adaptive-designs.html#combination-of-p-values" id="toc-combination-of-p-values"><span class="toc-section-number">26.4</span> Combination of p-values</a>
<ul>
<li><a href="adaptive-designs.html#method-based-on-individual-p-values" id="toc-method-based-on-individual-p-values"><span class="toc-section-number">26.4.1</span> Method Based on Individual p-values</a></li>
<li><a href="adaptive-designs.html#method-based-on-the-sum-of-p-values" id="toc-method-based-on-the-sum-of-p-values"><span class="toc-section-number">26.4.2</span> Method Based on the Sum of p-values</a></li>
<li><a href="adaptive-designs.html#method-with-product-of-p-values" id="toc-method-with-product-of-p-values"><span class="toc-section-number">26.4.3</span> Method with Product of p-values</a></li>
<li><a href="adaptive-designs.html#r-implementing" id="toc-r-implementing"><span class="toc-section-number">26.4.4</span> R Implementing</a></li>
</ul></li>
<li><a href="adaptive-designs.html#inverse-normal-combination-function" id="toc-inverse-normal-combination-function"><span class="toc-section-number">26.5</span> Inverse normal combination function</a>
<ul>
<li><a href="adaptive-designs.html#method-with-linear-combination-of-z-scores" id="toc-method-with-linear-combination-of-z-scores"><span class="toc-section-number">26.5.1</span> Method with Linear Combination of z-Scores</a></li>
<li><a href="adaptive-designs.html#weighted-inverse-normal-method" id="toc-weighted-inverse-normal-method"><span class="toc-section-number">26.5.2</span> Weighted inverse normal method</a></li>
</ul></li>
<li><a href="adaptive-designs.html#conditional-error-function-method-cefm-and-conditional-power" id="toc-conditional-error-function-method-cefm-and-conditional-power"><span class="toc-section-number">26.6</span> Conditional Error Function Method (CEFM) and Conditional Power</a>
<ul>
<li><a href="adaptive-designs.html#proschanhunsberger-method" id="toc-proschanhunsberger-method"><span class="toc-section-number">26.6.1</span> Proschan–Hunsberger Method</a></li>
<li><a href="adaptive-designs.html#denne-method" id="toc-denne-method"><span class="toc-section-number">26.6.2</span> Denne Method</a></li>
</ul></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#pk-and-pd-analysis" id="toc-pk-and-pd-analysis"><span class="toc-section-number">27</span> PK and PD Analysis</a>
<ul>
<li><a href="pk-and-pd-analysis.html#pharmacokinetic-concepts" id="toc-pharmacokinetic-concepts"><span class="toc-section-number">27.1</span> Pharmacokinetic Concepts</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">27.1.1</span> Introduction</a></li>
<li><a href="pk-and-pd-analysis.html#pk-analysis-package-in-r" id="toc-pk-analysis-package-in-r"><span class="toc-section-number">27.1.2</span> PK Analysis Package in R</a></li>
<li><a href="pk-and-pd-analysis.html#one-compartment-models-intravenous-bolus-administration" id="toc-one-compartment-models-intravenous-bolus-administration"><span class="toc-section-number">27.1.3</span> One-Compartment Models-Intravenous bolus administration</a></li>
<li><a href="pk-and-pd-analysis.html#one-compartment-models-constant-rate-infusion" id="toc-one-compartment-models-constant-rate-infusion"><span class="toc-section-number">27.1.4</span> One-Compartment Models-Constant rate infusion</a></li>
<li><a href="pk-and-pd-analysis.html#integration-of-clearance-and-volume" id="toc-integration-of-clearance-and-volume"><span class="toc-section-number">27.1.5</span> Integration of clearance and volume</a></li>
<li><a href="pk-and-pd-analysis.html#one-compartment-models-extravascular-administration" id="toc-one-compartment-models-extravascular-administration"><span class="toc-section-number">27.1.6</span> One-Compartment Models-Extravascular administration</a></li>
<li><a href="pk-and-pd-analysis.html#plasma-and-urine-data" id="toc-plasma-and-urine-data"><span class="toc-section-number">27.1.7</span> Plasma and Urine Data</a></li>
<li><a href="pk-and-pd-analysis.html#multi-compartment-catenary-and-mammillary-models" id="toc-multi-compartment-catenary-and-mammillary-models"><span class="toc-section-number">27.1.8</span> Multi-Compartment-Catenary and mammillary models</a></li>
<li><a href="pk-and-pd-analysis.html#two-compartment-model-intravenous-bolus-administration" id="toc-two-compartment-model-intravenous-bolus-administration"><span class="toc-section-number">27.1.9</span> Two-compartment model-Intravenous bolus administration</a></li>
<li><a href="pk-and-pd-analysis.html#two-compartment-model-constant-rate-infusion" id="toc-two-compartment-model-constant-rate-infusion"><span class="toc-section-number">27.1.10</span> Two-compartment model-Constant rate infusion</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#non-compartmental-analysis-nca" id="toc-non-compartmental-analysis-nca"><span class="toc-section-number">27.2</span> Non-Compartmental Analysis (NCA)</a>
<ul>
<li><a href="pk-and-pd-analysis.html#nca-vs-regression-analysis" id="toc-nca-vs-regression-analysis"><span class="toc-section-number">27.2.1</span> NCA vs regression analysis</a></li>
<li><a href="pk-and-pd-analysis.html#computational-methods---linear-trapezoidal-rule" id="toc-computational-methods---linear-trapezoidal-rule"><span class="toc-section-number">27.2.2</span> Computational methods - Linear trapezoidal rule</a></li>
<li><a href="pk-and-pd-analysis.html#computational-methods---log-linear-trapezoidal-rule" id="toc-computational-methods---log-linear-trapezoidal-rule"><span class="toc-section-number">27.2.3</span> Computational methods - Log-linear trapezoidal rule</a></li>
<li><a href="pk-and-pd-analysis.html#pertinent-pharmacokinetic-estimates" id="toc-pertinent-pharmacokinetic-estimates"><span class="toc-section-number">27.2.4</span> Pertinent pharmacokinetic estimates</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#calculation-pk-package" id="toc-calculation-pk-package"><span class="toc-section-number">27.3</span> Calculation (PK package）</a>
<ul>
<li><a href="clinic-trail-design.html#auc" id="toc-auc"><span class="toc-section-number">27.3.1</span> AUC</a></li>
<li><a href="clinic-trail-design.html#auc-in-complete-data-design" id="toc-auc-in-complete-data-design"><span class="toc-section-number">27.3.2</span> AUC in complete data design</a></li>
<li><a href="clinic-trail-design.html#auc-in-repeated-complete-data-design" id="toc-auc-in-repeated-complete-data-design"><span class="toc-section-number">27.3.3</span> AUC in repeated complete data design</a></li>
<li><a href="clinic-trail-design.html#bioequivalence-between-aucs" id="toc-bioequivalence-between-aucs"><span class="toc-section-number">27.3.4</span> Bioequivalence between AUCs</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-biexponential-model" id="toc-two-phase-half-life-estimation-by-biexponential-model"><span class="toc-section-number">27.3.5</span> Two-phase half-life estimation by biexponential model</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-linear-fitting" id="toc-two-phase-half-life-estimation-by-linear-fitting"><span class="toc-section-number">27.3.6</span> Two-phase half-life estimation by linear fitting</a></li>
<li><a href="clinic-trail-design.html#estimation-of-various-pk-parameters" id="toc-estimation-of-various-pk-parameters"><span class="toc-section-number">27.3.7</span> Estimation of various PK parameters</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#pharmacodynamic-concepts" id="toc-pharmacodynamic-concepts"><span class="toc-section-number">27.4</span> Pharmacodynamic Concepts</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">27.4.1</span> Introduction</a></li>
<li><a href="pk-and-pd-analysis.html#response" id="toc-response"><span class="toc-section-number">27.4.2</span> Response</a></li>
<li><a href="pk-and-pd-analysis.html#law-of-mass-action" id="toc-law-of-mass-action"><span class="toc-section-number">27.4.3</span> Law of Mass Action</a></li>
<li><a href="pk-and-pd-analysis.html#pharmacodynamic-models" id="toc-pharmacodynamic-models"><span class="toc-section-number">27.4.4</span> Pharmacodynamic Models</a></li>
<li><a href="pk-and-pd-analysis.html#interaction-models" id="toc-interaction-models"><span class="toc-section-number">27.4.5</span> Interaction Models</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#pk-and-pd-data-transfer" id="toc-pk-and-pd-data-transfer"><span class="toc-section-number">27.5</span> PK and PD data transfer</a>
<ul>
<li><a href="pk-and-pd-analysis.html#adpp-specification" id="toc-adpp-specification"><span class="toc-section-number">27.5.1</span> ADPP Specification</a></li>
<li><a href="pk-and-pd-analysis.html#adpp" id="toc-adpp"><span class="toc-section-number">27.5.2</span> ADPP</a></li>
<li><a href="pk-and-pd-analysis.html#adpc-specification" id="toc-adpc-specification"><span class="toc-section-number">27.5.3</span> ADPC Specification</a></li>
<li><a href="pk-and-pd-analysis.html#adpc" id="toc-adpc"><span class="toc-section-number">27.5.4</span> ADPC</a></li>
</ul></li>
</ul></li>
<li><a href="cdisc.html#cdisc" id="toc-cdisc"><span class="toc-section-number">28</span> CDISC</a>
<ul>
<li><a href="cdisc.html#study-data-tabulation-model-sdtm" id="toc-study-data-tabulation-model-sdtm"><span class="toc-section-number">28.1</span> Study Data Tabulation Model (SDTM)</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">28.1.1</span> Introduction</a></li>
<li><a href="cdisc.html#model-concepts-and-terms" id="toc-model-concepts-and-terms"><span class="toc-section-number">28.1.2</span> Model Concepts and Terms</a></li>
<li><a href="cdisc.html#sdtm-domains" id="toc-sdtm-domains"><span class="toc-section-number">28.1.3</span> SDTM Domains</a></li>
<li><a href="cdisc.html#sdtm-define.xml" id="toc-sdtm-define.xml"><span class="toc-section-number">28.1.4</span> SDTM Define.xml</a></li>
<li><a href="cdisc.html#extract-transform-load-etl" id="toc-extract-transform-load-etl"><span class="toc-section-number">28.1.5</span> Extract-Transform-Load (ETL)</a></li>
<li><a href="cdisc.html#example-building-dm-sdtm-datasets" id="toc-example-building-dm-sdtm-datasets"><span class="toc-section-number">28.1.6</span> Example Building DM SDTM Datasets</a></li>
</ul></li>
<li><a href="cdisc.html#sdtm-sas-macro" id="toc-sdtm-sas-macro"><span class="toc-section-number">28.2</span> SDTM SAS Macro</a>
<ul>
<li><a href="cdisc.html#make_define" id="toc-make_define"><span class="toc-section-number">28.2.1</span> ％make_define</a></li>
<li><a href="cdisc.html#make_codelist_formats" id="toc-make_codelist_formats"><span class="toc-section-number">28.2.2</span> %make_codelist_formats</a></li>
<li><a href="cdisc.html#make_empty_dataset" id="toc-make_empty_dataset"><span class="toc-section-number">28.2.3</span> %make_empty_dataset</a></li>
<li><a href="cdisc.html#make_dtc_date" id="toc-make_dtc_date"><span class="toc-section-number">28.2.4</span> %make_dtc_date</a></li>
<li><a href="cdisc.html#make_sdtm_dy" id="toc-make_sdtm_dy"><span class="toc-section-number">28.2.5</span> %make_sdtm_dy</a></li>
<li><a href="cdisc.html#make_sort_order" id="toc-make_sort_order"><span class="toc-section-number">28.2.6</span> %make_sort_order</a></li>
<li><a href="cdisc.html#create_stdm_domains" id="toc-create_stdm_domains"><span class="toc-section-number">28.2.7</span> %Create_STDM_Domains</a></li>
<li><a href="cdisc.html#detectduplicates" id="toc-detectduplicates"><span class="toc-section-number">28.2.8</span> %DetectDuplicates</a></li>
<li><a href="cdisc.html#changedvarnum" id="toc-changedvarnum"><span class="toc-section-number">28.2.9</span> %ChangedVarNum</a></li>
<li><a href="cdisc.html#changedlabels" id="toc-changedlabels"><span class="toc-section-number">28.2.10</span> %ChangedLabels</a></li>
</ul></li>
<li><a href="cdisc.html#analysis-data-model-adam" id="toc-analysis-data-model-adam"><span class="toc-section-number">28.3</span> Analysis Data Model (ADaM)</a>
<ul>
<li><a href="cdisc.html#compare-with-sdtm" id="toc-compare-with-sdtm"><span class="toc-section-number">28.3.1</span> Compare with SDTM</a></li>
<li><a href="cdisc.html#types-of-adam-metadata" id="toc-types-of-adam-metadata"><span class="toc-section-number">28.3.2</span> 4 types of ADaM metadata</a></li>
<li><a href="cdisc.html#subject-level-analysis-dataset-adsl" id="toc-subject-level-analysis-dataset-adsl"><span class="toc-section-number">28.3.3</span> Subject-Level Analysis Dataset (ADSL)</a></li>
<li><a href="cdisc.html#the-basic-data-structure-bds" id="toc-the-basic-data-structure-bds"><span class="toc-section-number">28.3.4</span> The Basic Data Structure (BDS)</a></li>
<li><a href="cdisc.html#example-building-adsl-datasets" id="toc-example-building-adsl-datasets"><span class="toc-section-number">28.3.5</span> Example Building ADSL Datasets</a></li>
<li><a href="cdisc.html#example-building-adam-basic-data-structure-bds-datasets" id="toc-example-building-adam-basic-data-structure-bds-datasets"><span class="toc-section-number">28.3.6</span> Example Building ADaM Basic Data Structure (BDS) Datasets</a></li>
<li><a href="cdisc.html#example-building-adae-adverse-event-analysis-datasets-datasets" id="toc-example-building-adae-adverse-event-analysis-datasets-datasets"><span class="toc-section-number">28.3.7</span> Example Building ADAE – Adverse Event Analysis Datasets Datasets</a></li>
</ul></li>
<li><a href="cdisc.html#adam-sas-macro" id="toc-adam-sas-macro"><span class="toc-section-number">28.4</span> ADaM SAS Macro</a>
<ul>
<li><a href="cdisc.html#make_define-1" id="toc-make_define-1"><span class="toc-section-number">28.4.1</span> %make_define</a></li>
<li><a href="cdisc.html#create_adam_dataset" id="toc-create_adam_dataset"><span class="toc-section-number">28.4.2</span> %create_adam_dataset</a></li>
<li><a href="cdisc.html#make_empty_dataset-1" id="toc-make_empty_dataset-1"><span class="toc-section-number">28.4.3</span> %make_empty_dataset</a></li>
<li><a href="cdisc.html#dtc2dt" id="toc-dtc2dt"><span class="toc-section-number">28.4.4</span> %DTC2DT</a></li>
<li><a href="cdisc.html#imputed_date" id="toc-imputed_date"><span class="toc-section-number">28.4.5</span> %imputed_date</a></li>
<li><a href="cdisc.html#mergsupp" id="toc-mergsupp"><span class="toc-section-number">28.4.6</span> %mergsupp</a></li>
</ul></li>
<li><a href="cdisc.html#project-example-mediwound1" id="toc-project-example-mediwound1"><span class="toc-section-number">28.5</span> Project Example MEDIWOUND1</a>
<ul>
<li><a href="cdisc.html#study-design" id="toc-study-design"><span class="toc-section-number">28.5.1</span> Study Design</a></li>
<li><a href="cdisc.html#primary-objective" id="toc-primary-objective"><span class="toc-section-number">28.5.2</span> Primary Objective</a></li>
<li><a href="cdisc.html#statistical-analysis" id="toc-statistical-analysis"><span class="toc-section-number">28.5.3</span> Statistical Analysis</a></li>
<li><a href="cdisc.html#cdisc-programming" id="toc-cdisc-programming"><span class="toc-section-number">28.5.4</span> CDISC Programming</a></li>
</ul></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#regularization-penalized-regression" id="toc-regularization-penalized-regression"><span class="toc-section-number">29</span> Regularization Penalized Regression</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">29.1</span> Introduction</a>
<ul>
<li><a href="regularization-penalized-regression.html#motivation" id="toc-motivation"><span class="toc-section-number">29.1.1</span> Motivation</a></li>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">29.1.2</span> Data preparation</a></li>
<li><a href="regularization-penalized-regression.html#best-subset-regression" id="toc-best-subset-regression"><span class="toc-section-number">29.1.3</span> Best subset regression</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">29.2</span> Ridge Regression</a>
<ul>
<li><a href="regularization-penalized-regression.html#modeling" id="toc-modeling"><span class="toc-section-number">29.2.1</span> Modeling</a></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#lasso-regression" id="toc-lasso-regression"><span class="toc-section-number">29.3</span> Lasso Regression</a>
<ul>
<li><a href="regularization-penalized-regression.html#modelling" id="toc-modelling"><span class="toc-section-number">29.3.1</span> Modelling</a></li>
<li><a href="regularization-penalized-regression.html#glmnet-cross-validation" id="toc-glmnet-cross-validation"><span class="toc-section-number">29.3.2</span> glmnet cross validation</a></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#elasticnet" id="toc-elasticnet"><span class="toc-section-number">29.4</span> ElasticNet</a>
<ul>
<li><a href="regularization-penalized-regression.html#modelling-1" id="toc-modelling-1"><span class="toc-section-number">29.4.1</span> Modelling</a></li>
<li><a href="regularization-penalized-regression.html#classification" id="toc-classification"><span class="toc-section-number">29.4.2</span> Classification</a></li>
</ul></li>
</ul></li>
<li><a href="bayesian-theory.html#bayesian-theory" id="toc-bayesian-theory"><span class="toc-section-number">30</span> Bayesian Theory</a>
<ul>
<li><a href="bayesian-theory.html#introduction-of-bayesian" id="toc-introduction-of-bayesian"><span class="toc-section-number">30.1</span> Introduction of Bayesian</a>
<ul>
<li><a href="bayesian-theory.html#frequency-and-bayesian" id="toc-frequency-and-bayesian"><span class="toc-section-number">30.1.1</span> Frequency and Bayesian</a></li>
<li><a href="bayesian-theory.html#bayesian-and-classical-methods" id="toc-bayesian-and-classical-methods"><span class="toc-section-number">30.1.2</span> Bayesian and classical methods</a></li>
<li><a href="bayesian-theory.html#bayes-rule" id="toc-bayes-rule"><span class="toc-section-number">30.1.3</span> Bayes’ Rule</a></li>
<li><a href="bayesian-theory.html#bootstrap" id="toc-bootstrap"><span class="toc-section-number">30.1.4</span> Bootstrap</a></li>
<li><a href="bayesian-theory.html#posterior-distribution" id="toc-posterior-distribution"><span class="toc-section-number">30.1.5</span> Posterior Distribution</a></li>
<li><a href="bayesian-theory.html#bayesian-credible-intervals" id="toc-bayesian-credible-intervals"><span class="toc-section-number">30.1.6</span> Bayesian Credible Intervals</a></li>
</ul></li>
<li><a href="anova.html#parameter-estimates" id="toc-parameter-estimates"><span class="toc-section-number">30.2</span> Parameter estimates</a>
<ul>
<li><a href="bayesian-theory.html#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation"><span class="toc-section-number">30.2.1</span> Maximum likelihood estimation</a></li>
<li><a href="bayesian-theory.html#maximum-a-posteriori-estimation" id="toc-maximum-a-posteriori-estimation"><span class="toc-section-number">30.2.2</span> Maximum a posteriori estimation</a></li>
<li><a href="bayesian-theory.html#bayesian-model" id="toc-bayesian-model"><span class="toc-section-number">30.2.3</span> Bayesian Model</a></li>
</ul></li>
<li><a href="bayesian-theory.html#prior-distributions" id="toc-prior-distributions"><span class="toc-section-number">30.3</span> Prior Distributions</a>
<ul>
<li><a href="bayesian-theory.html#conjugate-prior-distributions" id="toc-conjugate-prior-distributions"><span class="toc-section-number">30.3.1</span> Conjugate Prior Distributions</a></li>
<li><a href="bayesian-theory.html#non-informativ-priors" id="toc-non-informativ-priors"><span class="toc-section-number">30.3.2</span> Non-informativ Priors</a></li>
</ul></li>
<li><a href="bayesian-theory.html#mcmc" id="toc-mcmc"><span class="toc-section-number">30.4</span> MCMC</a>
<ul>
<li><a href="bayesian-theory.html#monte-carlo-simulation" id="toc-monte-carlo-simulation"><span class="toc-section-number">30.4.1</span> Monte Carlo Simulation</a></li>
<li><a href="bayesian-theory.html#概率分布采样" id="toc-概率分布采样"><span class="toc-section-number">30.4.2</span> 概率分布采样</a></li>
<li><a href="bayesian-theory.html#接受-拒绝采样" id="toc-接受-拒绝采样"><span class="toc-section-number">30.4.3</span> 接受-拒绝采样</a></li>
<li><a href="bayesian-theory.html#markov-chain" id="toc-markov-chain"><span class="toc-section-number">30.4.4</span> Markov Chain</a></li>
<li><a href="bayesian-theory.html#马尔科夫链的收敛性质" id="toc-马尔科夫链的收敛性质"><span class="toc-section-number">30.4.5</span> 马尔科夫链的收敛性质</a></li>
<li><a href="bayesian-theory.html#基于马尔科夫链采样" id="toc-基于马尔科夫链采样"><span class="toc-section-number">30.4.6</span> 基于马尔科夫链采样</a></li>
<li><a href="bayesian-theory.html#mcmc采样" id="toc-mcmc采样"><span class="toc-section-number">30.4.7</span> MCMC采样</a></li>
<li><a href="bayesian-theory.html#m-h采样" id="toc-m-h采样"><span class="toc-section-number">30.4.8</span> M-H采样</a></li>
<li><a href="bayesian-theory.html#gibbs采样" id="toc-gibbs采样"><span class="toc-section-number">30.4.9</span> Gibbs采样</a></li>
</ul></li>
<li><a href="bayesian-theory.html#regression-and-variable-selection" id="toc-regression-and-variable-selection"><span class="toc-section-number">30.5</span> Regression and Variable Selection</a>
<ul>
<li><a href="bayesian-theory.html#classical-least-squares-estimator" id="toc-classical-least-squares-estimator"><span class="toc-section-number">30.5.1</span> Classical Least Squares Estimator</a></li>
<li><a href="bayesian-theory.html#the-jeffreys-prior-analysis" id="toc-the-jeffreys-prior-analysis"><span class="toc-section-number">30.5.2</span> The Jeffreys Prior Analysis</a></li>
<li><a href="bayesian-theory.html#zellners-g-prior-analysis" id="toc-zellners-g-prior-analysis"><span class="toc-section-number">30.5.3</span> Zellner’s G-prior analysis</a></li>
</ul></li>
<li><a href="missing-data.html#bayesian-linear-regression" id="toc-bayesian-linear-regression"><span class="toc-section-number">30.6</span> Bayesian linear regression</a></li>
<li><a href="bayesian-theory.html#item-response-theory" id="toc-item-response-theory"><span class="toc-section-number">30.7</span> Item Response Theory</a>
<ul>
<li><a href="bayesian-theory.html#item-response-theory-1" id="toc-item-response-theory-1"><span class="toc-section-number">30.7.1</span> Item response theory</a></li>
<li><a href="bayesian-theory.html#em-algorithm" id="toc-em-algorithm"><span class="toc-section-number">30.7.2</span> EM algorithm</a></li>
<li><a href="bayesian-theory.html#mcmc-algorithm" id="toc-mcmc-algorithm"><span class="toc-section-number">30.7.3</span> MCMC algorithm</a></li>
<li><a href="bayesian-theory.html#unidimensional-irt-models" id="toc-unidimensional-irt-models"><span class="toc-section-number">30.7.4</span> Unidimensional IRT Models</a></li>
</ul></li>
</ul></li>
<li><a href="smoothing.html#smoothing" id="toc-smoothing"><span class="toc-section-number">31</span> Smoothing</a>
<ul>
<li><a href="smoothing.html#smoothing-1" id="toc-smoothing-1"><span class="toc-section-number">31.1</span> Smoothing</a>
<ul>
<li><a href="smoothing.html#bin-smoothing" id="toc-bin-smoothing"><span class="toc-section-number">31.1.1</span> Bin smoothing</a></li>
<li><a href="smoothing.html#kernels" id="toc-kernels"><span class="toc-section-number">31.1.2</span> Kernels</a></li>
<li><a href="smoothing.html#local-weighted-regression-loess" id="toc-local-weighted-regression-loess"><span class="toc-section-number">31.1.3</span> Local weighted regression (loess)</a></li>
</ul></li>
<li><a href="smoothing.html#loess-regression" id="toc-loess-regression"><span class="toc-section-number">31.2</span> Loess Regression</a></li>
</ul></li>
<li><a href="knn.html#knn" id="toc-knn"><span class="toc-section-number">32</span> KNN</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">32.1</span> Introduction</a>
<ul>
<li><a href="knn.html#idee" id="toc-idee"><span class="toc-section-number">32.1.1</span> Idee</a></li>
<li><a href="knn.html#加权最近邻法" id="toc-加权最近邻法"><span class="toc-section-number">32.1.2</span> 加权最近邻法</a></li>
<li><a href="knn.html#knn算法三要素" id="toc-knn算法三要素"><span class="toc-section-number">32.1.3</span> KNN算法三要素</a></li>
<li><a href="knn.html#优缺点" id="toc-优缺点"><span class="toc-section-number">32.1.4</span> 优缺点</a></li>
</ul></li>
<li><a href="knn.html#knn算法的实现方式" id="toc-knn算法的实现方式"><span class="toc-section-number">32.2</span> KNN算法的实现方式</a>
<ul>
<li><a href="knn.html#brute-force" id="toc-brute-force"><span class="toc-section-number">32.2.1</span> Brute-force</a></li>
<li><a href="knn.html#kd树实现" id="toc-kd树实现"><span class="toc-section-number">32.2.2</span> KD树实现</a></li>
<li><a href="knn.html#球树实现" id="toc-球树实现"><span class="toc-section-number">32.2.3</span> 球树实现</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">32.3</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">32.3.1</span> Data Preparation</a></li>
<li><a href="knn.html#knn-modelling" id="toc-knn-modelling"><span class="toc-section-number">32.3.2</span> KNN Modelling</a></li>
<li><a href="knn.html#加权最近邻法-1" id="toc-加权最近邻法-1"><span class="toc-section-number">32.3.3</span> 加权最近邻法</a></li>
<li><a href="knn.html#over-training" id="toc-over-training"><span class="toc-section-number">32.3.4</span> Over-training</a></li>
</ul></li>
</ul></li>
<li><a href="svm.html#svm" id="toc-svm"><span class="toc-section-number">33</span> SVM</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">33.1</span> Introduction</a>
<ul>
<li><a href="svm.html#perceptron" id="toc-perceptron"><span class="toc-section-number">33.1.1</span> Perceptron</a></li>
<li><a href="svm.html#函数间隔与几何间隔" id="toc-函数间隔与几何间隔"><span class="toc-section-number">33.1.2</span> 函数间隔与几何间隔</a></li>
<li><a href="svm.html#svm支持向量" id="toc-svm支持向量"><span class="toc-section-number">33.1.3</span> SVM支持向量</a></li>
<li><a href="svm.html#svm模型目标函数与优化" id="toc-svm模型目标函数与优化"><span class="toc-section-number">33.1.4</span> SVM模型目标函数与优化</a></li>
<li><a href="svm.html#线性可分svm的算法过程" id="toc-线性可分svm的算法过程"><span class="toc-section-number">33.1.5</span> 线性可分SVM的算法过程</a></li>
<li><a href="svm.html#线性svm的软间隔最大化" id="toc-线性svm的软间隔最大化"><span class="toc-section-number">33.1.6</span> 线性SVM的软间隔最大化</a></li>
<li><a href="svm.html#线性不可分支持向量机与核函数" id="toc-线性不可分支持向量机与核函数"><span class="toc-section-number">33.1.7</span> 线性不可分支持向量机与核函数</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">33.2</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">33.2.1</span> Data Preparation</a></li>
<li><a href="svm.html#svm-modelling" id="toc-svm-modelling"><span class="toc-section-number">33.2.2</span> SVM Modelling</a></li>
<li><a href="advanced-linear-regression.html#model-selection" id="toc-model-selection"><span class="toc-section-number">33.2.3</span> Model Selection</a></li>
<li><a href="svm.html#character-selection" id="toc-character-selection"><span class="toc-section-number">33.2.4</span> Character selection</a></li>
</ul></li>
</ul></li>
<li><a href="tree-models.html#tree-models" id="toc-tree-models"><span class="toc-section-number">34</span> Tree models</a>
<ul>
<li><a href="tree-models.html#decision-tree-model" id="toc-decision-tree-model"><span class="toc-section-number">34.1</span> Decision Tree Model</a>
<ul>
<li><a href="tree-models.html#decision-tree-algorithm" id="toc-decision-tree-algorithm"><span class="toc-section-number">34.1.1</span> Decision tree algorithm</a></li>
<li><a href="tree-models.html#id3-algorithm" id="toc-id3-algorithm"><span class="toc-section-number">34.1.2</span> ID3 Algorithm</a></li>
<li><a href="tree-models.html#c4.5-algorithm" id="toc-c4.5-algorithm"><span class="toc-section-number">34.1.3</span> C4.5 Algorithm</a></li>
<li><a href="tree-models.html#cart-algorithm" id="toc-cart-algorithm"><span class="toc-section-number">34.1.4</span> CART Algorithm</a></li>
<li><a href="tree-models.html#pruning" id="toc-pruning"><span class="toc-section-number">34.1.5</span> Pruning</a></li>
<li><a href="tree-models.html#package-rpart" id="toc-package-rpart"><span class="toc-section-number">34.1.6</span> Package ‘rpart’</a></li>
</ul></li>
<li><a href="tree-models.html#random-forest" id="toc-random-forest"><span class="toc-section-number">34.2</span> Random Forest</a>
<ul>
<li><a href="tree-models.html#bootstrap-bagging" id="toc-bootstrap-bagging"><span class="toc-section-number">34.2.1</span> Bootstrap (Bagging)</a></li>
<li><a href="tree-models.html#bagging算法流程" id="toc-bagging算法流程"><span class="toc-section-number">34.2.2</span> bagging算法流程</a></li>
<li><a href="tree-models.html#random-forest-algorithm" id="toc-random-forest-algorithm"><span class="toc-section-number">34.2.3</span> Random Forest Algorithm</a></li>
<li><a href="tree-models.html#random-forest-promotion" id="toc-random-forest-promotion"><span class="toc-section-number">34.2.4</span> Random forest promotion</a></li>
<li><a href="tree-models.html#package-randomforest" id="toc-package-randomforest"><span class="toc-section-number">34.2.5</span> Package ‘randomForest’</a></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#modelling" id="toc-modelling"><span class="toc-section-number">34.3</span> Modelling</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">34.3.1</span> Data preparation</a></li>
<li><a href="tree-models.html#regression-tree-1" id="toc-regression-tree-1"><span class="toc-section-number">34.3.2</span> Regression tree</a></li>
<li><a href="tree-models.html#classification-tree-1" id="toc-classification-tree-1"><span class="toc-section-number">34.3.3</span> Classification tree</a></li>
<li><a href="tree-models.html#random-forest-for-regression" id="toc-random-forest-for-regression"><span class="toc-section-number">34.3.4</span> Random forest for regression</a></li>
<li><a href="tree-models.html#random-forest-for-classification" id="toc-random-forest-for-classification"><span class="toc-section-number">34.3.5</span> Random forest for classification</a></li>
<li><a href="tree-models.html#皮玛印第安人糖尿病数据集" id="toc-皮玛印第安人糖尿病数据集"><span class="toc-section-number">34.3.6</span> 皮玛印第安人糖尿病数据集</a></li>
<li><a href="tree-models.html#使用随机森林进行特征选择" id="toc-使用随机森林进行特征选择"><span class="toc-section-number">34.3.7</span> 使用随机森林进行特征选择</a></li>
</ul></li>
<li><a href="tree-models.html#gradient-boosting" id="toc-gradient-boosting"><span class="toc-section-number">34.4</span> Gradient Boosting</a></li>
<li><a href="tree-models.html#gradient-descent" id="toc-gradient-descent"><span class="toc-section-number">34.5</span> Gradient Descent</a>
<ul>
<li><a href="tree-models.html#gradient" id="toc-gradient"><span class="toc-section-number">34.5.1</span> Gradient</a></li>
<li><a href="tree-models.html#gradient-descent-1" id="toc-gradient-descent-1"><span class="toc-section-number">34.5.2</span> Gradient Descent</a></li>
<li><a href="tree-models.html#gradient-descent-algorithm" id="toc-gradient-descent-algorithm"><span class="toc-section-number">34.5.3</span> Gradient Descent Algorithm</a></li>
<li><a href="tree-models.html#gradient-descent-familiy" id="toc-gradient-descent-familiy"><span class="toc-section-number">34.5.4</span> Gradient Descent Familiy</a></li>
<li><a href="tree-models.html#gbdt分类算法" id="toc-gbdt分类算法"><span class="toc-section-number">34.5.5</span> GBDT分类算法</a></li>
<li><a href="tree-models.html#package-gbm" id="toc-package-gbm"><span class="toc-section-number">34.5.6</span> Package ‘gbm’</a></li>
<li><a href="tree-models.html#极限梯度提升分类" id="toc-极限梯度提升分类"><span class="toc-section-number">34.5.7</span> 极限梯度提升——分类</a></li>
</ul></li>
<li><a href="tree-models.html#cubist-model" id="toc-cubist-model"><span class="toc-section-number">34.6</span> Cubist Model</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">34.6.1</span> Introduction</a></li>
<li><a href="tree-models.html#application-data-preparation" id="toc-application-data-preparation"><span class="toc-section-number">34.6.2</span> Application Data Preparation</a></li>
<li><a href="tree-models.html#fit-continious-outcome" id="toc-fit-continious-outcome"><span class="toc-section-number">34.6.3</span> Fit Continious Outcome</a></li>
<li><a href="tree-models.html#variable-importance" id="toc-variable-importance"><span class="toc-section-number">34.6.4</span> Variable Importance</a></li>
<li><a href="tree-models.html#summary-display" id="toc-summary-display"><span class="toc-section-number">34.6.5</span> Summary display</a></li>
<li><a href="tree-models.html#specific-parts" id="toc-specific-parts"><span class="toc-section-number">34.6.6</span> specific parts</a></li>
<li><a href="tree-models.html#ensembles-by-committees" id="toc-ensembles-by-committees"><span class="toc-section-number">34.6.7</span> Ensembles By Committees</a></li>
<li><a href="tree-models.html#nearestneighbors-adjustmemt" id="toc-nearestneighbors-adjustmemt"><span class="toc-section-number">34.6.8</span> Nearest–neighbors Adjustmemt</a></li>
<li><a href="tree-models.html#optimize-parameters" id="toc-optimize-parameters"><span class="toc-section-number">34.6.9</span> Optimize parameters</a></li>
<li><a href="tree-models.html#logistic-cv" id="toc-logistic-cv"><span class="toc-section-number">34.6.10</span> Logistic CV</a></li>
</ul></li>
</ul></li>
<li><a href="pca.html#pca" id="toc-pca"><span class="toc-section-number">35</span> PCA</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">35.1</span> Introduction</a>
<ul>
<li><a href="pca.html#component" id="toc-component"><span class="toc-section-number">35.1.1</span> Component</a></li>
<li><a href="pca.html#pca算法" id="toc-pca算法"><span class="toc-section-number">35.1.2</span> PCA算法</a></li>
<li><a href="pca.html#主成分旋转" id="toc-主成分旋转"><span class="toc-section-number">35.1.3</span> 主成分旋转</a></li>
<li><a href="pca.html#kernelized-pca" id="toc-kernelized-pca"><span class="toc-section-number">35.1.4</span> Kernelized PCA</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">35.2</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">35.2.1</span> Data preparation</a></li>
<li><a href="regularization-penalized-regression.html#modeling" id="toc-modeling"><span class="toc-section-number">35.2.2</span> Modeling</a></li>
</ul></li>
</ul></li>
<li><a href="cluster-analysis.html#cluster-analysis" id="toc-cluster-analysis"><span class="toc-section-number">36</span> Cluster Analysis</a>
<ul>
<li><a href="cluster-analysis.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">36.1</span> Hierarchical Clustering</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">36.1.1</span> Introduction</a></li>
<li><a href="cluster-analysis.html#hierarchical-clustering-algorithms" id="toc-hierarchical-clustering-algorithms"><span class="toc-section-number">36.1.2</span> Hierarchical clustering algorithms</a></li>
<li><a href="cluster-analysis.html#measure-the-dissimilarity-between-two-clusters-of-observations" id="toc-measure-the-dissimilarity-between-two-clusters-of-observations"><span class="toc-section-number">36.1.3</span> Measure the dissimilarity between two clusters of observations</a></li>
</ul></li>
<li><a href="cluster-analysis.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">36.2</span> K-means Clustering</a>
<ul>
<li><a href="cluster-analysis.html#algorithm" id="toc-algorithm"><span class="toc-section-number">36.2.1</span> Algorithm</a></li>
<li><a href="cluster-analysis.html#k-means" id="toc-k-means"><span class="toc-section-number">36.2.2</span> K-Means++</a></li>
<li><a href="cluster-analysis.html#elkan-k-means" id="toc-elkan-k-means"><span class="toc-section-number">36.2.3</span> elkan K-Means</a></li>
<li><a href="cluster-analysis.html#mini-batch-k-means" id="toc-mini-batch-k-means"><span class="toc-section-number">36.2.4</span> Mini Batch K-Means</a></li>
</ul></li>
<li><a href="cluster-analysis.html#gowers-coefficient-and-pam" id="toc-gowers-coefficient-and-pam"><span class="toc-section-number">36.3</span> Gower’s coefficient and PAM</a>
<ul>
<li><a href="cluster-analysis.html#gowers-coefficient" id="toc-gowers-coefficient"><span class="toc-section-number">36.3.1</span> Gower’s coefficient</a></li>
<li><a href="cluster-analysis.html#不同数据类型的相异度计算-距离法" id="toc-不同数据类型的相异度计算-距离法"><span class="toc-section-number">36.3.2</span> 不同数据类型的相异度计算 (距离法)</a></li>
<li><a href="cluster-analysis.html#pam" id="toc-pam"><span class="toc-section-number">36.3.3</span> PAM</a></li>
</ul></li>
<li><a href="cluster-analysis.html#birch-clustering" id="toc-birch-clustering"><span class="toc-section-number">36.4</span> BIRCH Clustering</a>
<ul>
<li><a href="cluster-analysis.html#birch-introduction" id="toc-birch-introduction"><span class="toc-section-number">36.4.1</span> BIRCH Introduction</a></li>
<li><a href="cluster-analysis.html#聚类特征cf与聚类特征树cf-tree" id="toc-聚类特征cf与聚类特征树cf-tree"><span class="toc-section-number">36.4.2</span> 聚类特征CF与聚类特征树CF Tree</a></li>
<li><a href="cluster-analysis.html#cf-tree的生成" id="toc-cf-tree的生成"><span class="toc-section-number">36.4.3</span> CF Tree的生成</a></li>
<li><a href="cluster-analysis.html#birch算法" id="toc-birch算法"><span class="toc-section-number">36.4.4</span> BIRCH算法</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">36.5</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">36.5.1</span> Data preparation</a></li>
<li><a href="cluster-analysis.html#hierarchical-clustering-1" id="toc-hierarchical-clustering-1"><span class="toc-section-number">36.5.2</span> Hierarchical Clustering</a></li>
<li><a href="cluster-analysis.html#k-means-clustering-1" id="toc-k-means-clustering-1"><span class="toc-section-number">36.5.3</span> K-means Clustering</a></li>
<li><a href="cluster-analysis.html#gowers-coefficient-and-pam-1" id="toc-gowers-coefficient-and-pam-1"><span class="toc-section-number">36.5.4</span> Gower’s coefficient and PAM</a></li>
</ul></li>
</ul></li>
<li><a href="linear-discriminant-analysis-lda.html#linear-discriminant-analysis-lda" id="toc-linear-discriminant-analysis-lda"><span class="toc-section-number">37</span> linear discriminant analysis (LDA)</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">37.1</span> Introduction</a>
<ul>
<li><a href="linear-discriminant-analysis-lda.html#naive-bayes" id="toc-naive-bayes"><span class="toc-section-number">37.1.1</span> Naive Bayes</a></li>
<li><a href="linear-discriminant-analysis-lda.html#controlling-prevalence" id="toc-controlling-prevalence"><span class="toc-section-number">37.1.2</span> Controlling prevalence</a></li>
<li><a href="linear-discriminant-analysis-lda.html#qda" id="toc-qda"><span class="toc-section-number">37.1.3</span> QDA</a></li>
<li><a href="linear-discriminant-analysis-lda.html#lda" id="toc-lda"><span class="toc-section-number">37.1.4</span> LDA</a></li>
</ul></li>
<li><a href="linear-discriminant-analysis-lda.html#discriminant-analysis-algorithm" id="toc-discriminant-analysis-algorithm"><span class="toc-section-number">37.2</span> Discriminant analysis algorithm</a>
<ul>
<li><a href="knn.html#idee" id="toc-idee"><span class="toc-section-number">37.2.1</span> Idee</a></li>
<li><a href="linear-discriminant-analysis-lda.html#瑞利商rayleigh-quotient" id="toc-瑞利商rayleigh-quotient"><span class="toc-section-number">37.2.2</span> 瑞利商（Rayleigh quotient）</a></li>
<li><a href="linear-discriminant-analysis-lda.html#广义瑞利商-genralized-rayleigh-quotient" id="toc-广义瑞利商-genralized-rayleigh-quotient"><span class="toc-section-number">37.2.3</span> 广义瑞利商 genralized Rayleigh quotient</a></li>
<li><a href="linear-discriminant-analysis-lda.html#lda算法流程" id="toc-lda算法流程"><span class="toc-section-number">37.2.4</span> LDA算法流程</a></li>
<li><a href="linear-discriminant-analysis-lda.html#lda-application" id="toc-lda-application"><span class="toc-section-number">37.2.5</span> LDA Application</a></li>
<li><a href="linear-discriminant-analysis-lda.html#qda-1" id="toc-qda-1"><span class="toc-section-number">37.2.6</span> QDA</a></li>
</ul></li>
</ul></li>
<li><a href="neural-network.html#neural-network" id="toc-neural-network"><span class="toc-section-number">38</span> Neural Network</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">38.1</span> Introduction</a></li>
<li><a href="neural-network.html#反向传播方法进行训练的前馈神经网络" id="toc-反向传播方法进行训练的前馈神经网络"><span class="toc-section-number">38.2</span> 反向传播方法进行训练的前馈神经网络</a></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">38.3</span> Application</a>
<ul>
<li><a href="neural-network.html#数据准备" id="toc-数据准备"><span class="toc-section-number">38.3.1</span> 数据准备</a></li>
<li><a href="neural-network.html#模型构建" id="toc-模型构建"><span class="toc-section-number">38.3.2</span> 模型构建</a></li>
</ul></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">As a Statistician</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayesian-theory" class="section level1" number="30">
<h1><span class="header-section-number">Chapter 30</span> Bayesian Theory</h1>
<div id="htmlwidget-0d57c0ff2a7c68ca3570" style="width:672px;height:480px;" class="markmap html-widget"></div>
<script type="application/json" data-for="htmlwidget-0d57c0ff2a7c68ca3570">{"x":{"data":"# \n## Bayesian Theory\n### Introduction of Bayesian\n#### Frequency and Bayesian\n#### Bayesian and classical methods \n#### Bayes' Rule\n#### Bootstrap\n#### Posterior Distribution\n#### Bayesian Credible Intervals\n### Parameter estimates\n#### Maximum likelihood estimation\n#### Maximum a posteriori estimation\n#### Bayesian Model\n##### Full-Bayesian\n### Prior Distributions\n#### Conjugate Prior Distributions\n#### Non-informativ Priors\n##### Jeffreys Prior\n##### Reference Prior\n### MCMC\n#### Monte Carlo Simulation\n#### 概率分布采样\n#### 接受-拒绝采样\n#### Markov Chain\n#### 马尔科夫链的收敛性质\n#### 基于马尔科夫链采样\n#### MCMC采样\n##### 马尔科夫链的细致平稳条件\n##### 总结下MCMC的采样过程\n#### M-H采样\n#### Gibbs采样\n##### 二维Gibbs采样\n### Regression and Variable Selection\n#### Classical Least Squares Estimator\n#### The Jeffreys Prior Analysis\n#### Zellner’s G-prior analysis \n### Bayesian linear regression\n### Item Response Theory\n#### Item response theory\n#### EM algorithm  \n#### MCMC algorithm\n#### Unidimensional IRT Models ","options":{"preset":"colorful","autoFit":true}},"evals":[],"jsHooks":[]}</script>
<div id="introduction-of-bayesian" class="section level2" number="30.1">
<h2><span class="header-section-number">30.1</span> Introduction of Bayesian</h2>
<div id="frequency-and-bayesian" class="section level3" number="30.1.1">
<h3><span class="header-section-number">30.1.1</span> Frequency and Bayesian</h3>
<ul>
<li>A set of random samples, the frequency school believes that the
overall parameters are constant, and the samples are obtained
randomly;</li>
<li>The Bayesian school believes that the <strong>overall parameters</strong> are
random, and the sample obtained is constant. The Bayesian school
does not care much about the correct parameters, but needs to obtain
the <strong>posterior</strong> by adding the <strong>acquired data to the prior
knowledge</strong></li>
</ul>
<p>一组随机样本，频率学派认为总体的参数是不变的，样本是随机获取的；
而贝叶斯学派认为总体参数是随机的，而获样本是不变的.</p>
<ul>
<li>如果总体参数固定，那么随机获得的样本就是理想实体的不完美映射。相应的，如果获得了这些样本证据
,利用极大似然法，推断出获得这些样本最有可能的参数。</li>
<li>贝叶斯不关心正确的参数到底是多少，而是需要通过获取的数据加上先验知识得出后验
概率进行统计推断</li>
</ul>
<p>The posterior distribution summarises our uncertainty over the value of
a parameter. If the distribution is narrower, then this indicates that
we have greater confidence in our estimates of the parameter’s value.
More narrow posterior distributions can be obtained by collecting more
data.</p>
<ul>
<li>先验是一种概率分布，描述了我们在收集和分析数据之前对假设的信念。</li>
<li>在贝叶斯推理中，我们对该假设的分析后信念为后验。 后验概率分布
<span class="math display">\[\mathrm{P}(\theta | \text{data})\]</span>是贝叶斯推理的主要目标。
后验分布总结了我们对参数值的不确定性。如果分布范围更窄，则表明我们对参数值的估计更有信心。通过收集更多数据可以获得更窄的后验分布。后验分布还用于预测实验的未来结果和模型测试。</li>
</ul>
</div>
<div id="bayesian-and-classical-methods" class="section level3" number="30.1.2">
<h3><span class="header-section-number">30.1.2</span> Bayesian and classical methods</h3>
<p>Advantages of Bayesian analysis over classical analysis of clinical trials include the ability to incorporate prior information regarding treatment efficacies into the analysis; the ability to make multiple unscheduled inspections of accumulating data without increasing the error rate of the study; and the ability to calculate the probability that one treatment is more effective than another.</p>
<blockquote>
<p>贝叶斯分析相对于临床试验的经典分析的优势包括能够将有关治疗效果的先前信息纳入分析；在不增加研究错误率的情况下对累积数据进行多次计划外检查的能力；以及计算一种治疗比另一种治疗更有效的概率的能力。</p>
</blockquote>
<p>Bayesian and classical methods differ in the way data are used to reach conclusions. Bayesian analysis is conditional on the observed data; it is concerned with the probability that a conclusion or hypothesis is true given the available data. Classical inference is not conditional on the observed data; rather, it is concerned with the behavior of a statistical procedure over an infinite number of repetitions considering all data that might have been observed, given a hypothesis. Bayesians deal with the probabilities of hypotheses, given a data set, whereas frequentists deal with the probabilities of data sets, given a hypothesis.</p>
<blockquote>
<p>贝叶斯方法和经典方法在使用数据得出结论的方式上有所不同。贝叶斯分析以观察到的数据为条件；它与给定可用数据的结论或假设为真的概率有关。经典推理不以观察到的数据为条件；相反，它关注的是统计过程在无限次重复中的行为，考虑到所有可能已经观察到的数据，给定一个假设。贝叶斯主义者在给定数据集的情况下处理假设的概率，而频率论者在给定假设的情况下处理数据集的概率。</p>
</blockquote>
<p>Classical hypothesis testing hangs on a double negative and entails five possible steps: definition of null and alternate hypotheses, calculating a P value, and accepting or rejecting the null hypothesis.</p>
<blockquote>
<p>经典假设检验基于双重否定，需要五个可能的步骤：定义零假设和替代假设，计算 P 值，以及接受或拒绝零假设。</p>
</blockquote>
<p>The most fundamental is that classical hypothesis testing does not provide the information that the clinician or investigator desires, namely, the probability that the alternate hypothesis, or any other hypothesis, is true.</p>
<blockquote>
<p>不幸的是，可能有许多与原始假设不同的替代假设，如果它们被提出，这些假设可能已经被接受。例如，在一项比较两种治疗下生存率的研究中，零假设可能是 A 和 B 的生存率相等，而一个明确的替代假设可能是 A 的生存率比 B 的生存率至少高 10%。另一种假设可能是 A 的存活率仅高出 5%，而三分之一的假设可能是 A 的存活率仅高出 1%。如果我们拒绝原假设，我们默认接受最初提出的替代假设；不可能使用经典假设检验来确定可能提出的哪些可能的替代假设最接近事实。尽管样本量和功效计算可能有助于选择一个现实的替代方案：假设，但它们不能提供两个这样的替代方案的相对优点的指示。尽管经典的统计分析已经取得了高度的实际成功，但它也存在一些似乎无法克服的长期问题。最基本的一点是，经典假设检验不提供临床医生或研究人员想要的信息，即替代假设或任何其他假设为真的概率。</p>
</blockquote>
<p>A related problem in classical hypothesis testing is that peeking at the data as they accumulate affects the analysis.</p>
<blockquote>
<p>经典假设检验中的一个相关问题是，在数据积累时偷看数据会影响分析。考虑一项比较两种药物 A 和 B 的研究，发现 60 名患者中有 24 名（40%）对药物 A 有阳性反应，61 名患者中有 13 名（21%）对药物 B 有阳性反应。经典分析通过双尾 Fisher 精确检验得出的这些结果中的 P = .031，从而得出药物 A 与显着更大的阳性反应相关的结论。假设研究人员在较早的时候分析了结果，当时 30 名患者中有 12 名（40%）对药物 A 有反应，30 名患者中的严重（23%）对药物 B 有反应。这里的双尾 P 值为 0.267，所以他们继续在试验中招募新患者，因为他们认为有利于药物 A 的趋势是真实的，尽管它没有统计学意义。 （如果他们获得了显着的 P 值，他们会在这一点停止并发表。）因为最终分析是第二次观察，研究人员必须将显着性的 a 水平调整为 0.029（通过 Pocock 方法）以保持整个试验的总体 a 为 0.05。 7现在最终数据不显着，药物和反应之间没有关联的零假设未被拒绝。在经典统计学中，随着数据的积累而观察数据，如果结果足够令人信服则停止试验，这可以改变对最终数据集的解释。这个事实对大多数研究人员来说是违反直觉的。对于贝叶斯来说，这是荒谬的。</p>
</blockquote>
<p>Bayes’ theorem allows one to calculate the probability that a particular hypothesis regarding treatment efficacies is true, based on an observed set of data and our estimates (before we knew the data) of the probabilities that various hypotheses were true. These probability estimates, made before observing the data, are called the prior probabilities. In determining the prior probabilities, we should incorporate all available information regarding the efficacies of the control and test treatments. If the information is vague, unreliable, or biased, as in the case in which only anecdotal reports of the efficacy of the test treatment are available, then this uncertainty regarding the accuracy of the prior information can be incorporated quantitatively into the analysis.</p>
<blockquote>
<p>贝叶斯定理允许人们根据一组观察到的数据和我们对各种假设为真的概率的估计（在我们知道数据之前）来计算关于治疗效果的特定假设为真的概率。在观察数据之前做出的这些概率估计称为先验概率。在确定先验概率时，我们应该结合所有关于控制和测试治疗效果的可用信息。如果信息是模糊的、不可靠的或有偏见的，例如只有关于测试治疗效果的轶事报告，那么这种关于先前信息准确性的不确定性可以定量地纳入分析中。</p>
</blockquote>
<p>A Bayesian analysis entails four basic steps: definition of knowledge prior to the study, acquisition of the data, revision of the prior information to form posterior estimates, and interpretation of the resulting posterior estimates.</p>
<blockquote>
<p>贝叶斯分析需要四个基本步骤：在研究之前定义知识、获取数据、修改先验信息以形成后验估计，以及解释所得的后验估计。</p>
</blockquote>
<p>A Bayesian analysis proceeds as follows:</p>
<ul>
<li>First, define prior knowledge. Information regarding the likely efficacy of the treatments and the uncertainty in this prior information may be obtained from the medical literature, pilot studies, or recognized experts in the clinical area in which the trial is to be conducted. It is important that the experts represent a range of points of view, so that the uncertainty in their estimates is appreciated. This information is expressed mathematically as a probability distribution. Frequently, it is useful to assume that very little prior knowledge exists to avoid biasing the results if the available information is unreliable. In most practical situations, the particular form of the prior information has little influence on the final conclusion because it is overwhelmed by the weight of experimental evidence. This practical point prevents one from unduly influencing the trial resuh by using an overly optimistic or pessimistic set of prior estimates.</li>
<li>Second, acquire the data. Unlike a classical trial, the number of patients to be enrolled in the trial or the timing of the interim analyses do not need to be predetermined. Other considerations, such as the rate of patient recruitment or funding constraints, can be used to determine the number and timing of the data analyses.</li>
<li>Third, revise the prior estimates. The data obtained from the trial are used with Bayes’ theorem to revise the prior estimates of treatment efficacy and create “posterior” estimates. These posterior estimates will have a narrower range of uncertainty; reflecting the additional information now available.</li>
<li>Fourth, interpret the posterior estimates. The posterior estimates contain the information from both the prior estimates and the experimental observations. They allow the calculation of the probability that the efficacy of the control or test treatments, or the difference in efficacy, falls into a given range.</li>
</ul>
<blockquote>
<ul>
<li>首先，定义先验知识。有关治疗的可能疗效和该先前信息的不确定性的信息可以从医学文献、试点研究或将要进行试验的临床领域的公认专家获得。专家代表一系列观点很重要，这样他们的估计中的不确定性才能得到重视。该信息在数学上表示为概率分布。通常，假设存在非常少的先验知识以避免在可用信息不可靠时对结果产生偏差是有用的。在大多数实际情况下，先验信息的特定形式对最终结论的影响很小，因为它被实验证据的权重所压倒。这一点可以防止人们通过使用一组过于乐观或悲观的先前估计来过度影响试验结果。</li>
<li>其次，获取数据。与经典试验不同，参加试验的患者人数或中期分析的时间不需要预先确定。其他考虑因素，例如患者招募率或资金限制，可用于确定数据分析的数量和时间。</li>
<li>第三，修正先前的估计。从试验中获得的数据与贝叶斯定理一起使用，以修正先前的治疗效果估计并创建“后验”估计。这些后验估计的不确定性范围更窄；反映现在可用的附加信息。</li>
<li>第四，解释后验估计。后验估计包含来自先前估计和实验观察的信息。它们允许计算对照或测试治疗的功效或功效差异落入给定范围的概率。</li>
</ul>
</blockquote>
<p>阴性和阳性试验结果之间没有任意的分界点。这与经典假设检验形成对比，其中 0.049 的 P 值可能被认为是正的，而 0.051 的 P 值可能被认为是负的。与经典分析不同，贝叶斯分析给出了假设为真的概率。例如，贝叶斯分析可以支持这样的陈述，</p>
<p>Based on our prior information regarding the treatment’s efficacy and on the data observed in this trial, there is an 87% probability that the treatment increases survival by 10% or more over the placebo.”</p>
<blockquote>
<p>“根据我们先前关于治疗效果的信息和在本试验中观察到的数据，治疗有 87% 的可能性使生存率比安慰剂提高 10% 或更多。”</p>
</blockquote>
<p>这比经典陈述“治疗被证明与增加生存率具有统计学意义相关，P 值小于 0.052”更具临床相关性，因为人们可以从后验估计中计算出感兴趣变量所在的概率在任何特定范围内，很容易找到变量具有给定发生概率（通常为 95% 或 99%）的最小范围。这样的区间可以解释为 95% 或 99% 的“置信区间”。虽然在经典分析中也可以计算置信区间，但经典置信区间的解释略有不同。因此，贝叶斯置信区间称为概率区间，而经典区间简称为“置信区间”。贝叶斯概率区间实际上具有包含感兴趣变量的真实值的规定概率，而经典 confid ence 间隔可能不会。</p>
</div>
<div id="bayes-rule" class="section level3" number="30.1.3">
<h3><span class="header-section-number">30.1.3</span> Bayes’ Rule</h3>
<p><span class="math display">\[
\overbrace{p(\theta/D)}^{Posterior}=\frac{\overbrace{p(D/\theta)}^{Likelihood}.\overbrace{p(\theta)}^{Prior}}{\underbrace{p(D)}_{Evidence}}
\]</span></p>
<p><span class="math display">\[
P(H\mid E)={\frac {P(E\mid H)\cdot P(H)}{P(E)}}
\]</span></p>
<p><span class="math inline">\(P(H)\)</span> 先验概率，是在观察到当前数据E之前，假设概率H的估计.
边缘概率（又称先验概率）：某个事件发生的概率。边缘概率是这样得到的：在联合概率中，把最终结果中那
些不需要的事件通过合并成它们的全概率，而消去它们（对离散随机变量用求和得全概率，对连续随机变量用
积分得全概率），这称为边缘化（marginalization），比如A的边缘概率表示为P(A)，B的边缘概率表示为P(B)。</p>
<p><span class="math display">\[\textstyle P(H\mid E)\]</span>
后验概率：事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，
读作”在B条件下<strong>A</strong>的概率”,。The posterior distribution summarises our
uncertainty over the value of a parameter. If the distribution is
narrower, then this indicates that we have greater confidence in our
estimates of the parameter’s value. More narrow posterior distributions
can be obtained by collecting more data.</p>
<ul>
<li>The posterior probability is the probability of the parameters
<span class="math inline">\(\theta\)</span> given the evidence <span class="math inline">\(X: p(\theta \mid X)\)</span></li>
<li>It contrasts with the likelihood function, which is the probability
of the evidence given the parameters: <span class="math inline">\(p(X \mid \theta)\)</span></li>
</ul>
<p><span class="math display">\[\textstyle P(E\mid H)\]</span>
贝叶斯方法的核心就是通过先验知识不断更新后验概率密度来分析参数的可能性分布，如果继续进行实验
，之前的后验概率密度就变成了先验知识，这样最终就会越来越接近参数的真实分布。需要注意的是，一
般来讲如果当前的样本量比先验知识的样本量大很多，那么先验知识就可以忽略不计。</p>
</div>
<div id="bootstrap" class="section level3" number="30.1.4">
<h3><span class="header-section-number">30.1.4</span> Bootstrap</h3>
<p>Bootstrap
是一种用小样本来估计大样本的统计方法，斯坦福统计系主任的Bradley
Efron在70年代提出。
中心思想是通过从样本中重抽样（resample），构建某个估计的置信区间。抽象的说，通过样本得到的估
计并没有榨干样本中的信息，bootstrap利用重抽样，把剩余价值发挥在了构建置信区间上。</p>
<ul>
<li>首先，Bootstrap通过重抽样，可以避免了Cross-Validation造成的样本减少问题</li>
<li>其次，Bootstrap也可以用于创造数据的随机性。比如，我们所熟知的随机森林算法第一步就是从原始训
练数据集中，应用bootstrap方法有放回地随机抽取k个新的自助样本集，并由此构建k棵分类回归树。</li>
</ul>
<p><strong>Bootstrap VS Monte Carlo</strong></p>
<ul>
<li>Bootstrap是对现有的数据，不断再随机取小的样本，对每个小样处理数据,得到estimator.从而来了解
estimator 的variation or distribution.</li>
<li>Monte Carlo
是用一个algorithm,依次输出数组，然后对这些数组处理，得到想要的结果。数组之间的
关系由algorithm来决定。Monte Carlo 的概念更广泛。Bootstrap
其实是一种Monte Carlo. {从某种意义上，Mente
Carlo是一种计算积分的方法，期望，方差等等都是在概率空间的积分，先采样，
再加和。一般用在两个地方，一是在closed
form拿不到的情况下来做的，二是空间维度非常高，因为 Mente
Carlo的收敛阶依赖于采样点的个数（半阶收敛）而和空间维数没有关系，在特别高维的问题中计算
积分，Mente Carlo甚至成为了唯一可行的方法。}</li>
</ul>
</div>
<div id="posterior-distribution" class="section level3" number="30.1.5">
<h3><span class="header-section-number">30.1.5</span> Posterior Distribution</h3>
<p>Given an independent and identically distributed (later abbreviated as
iid) sample <span class="math inline">\(\mathscr{D}_{n}=\left(x_{1}, \ldots, x_{n}\right)\)</span> from a
density <span class="math inline">\(f(x \mid \theta)\)</span>, depending upon an unknown parameter
<span class="math inline">\(\theta \in \Theta\)</span>, for instance the mean <span class="math inline">\(\mu\)</span> of the benchmark normal
distribution, the associated likelihood function is <span class="math display">\[
\ell\left(\theta \mid \mathscr{D}_{n}\right)=\prod_{i=1}^{n} f\left(x_{i} \mid \theta\right)
\]</span> This function of <span class="math inline">\(\theta\)</span> is a fundamental entity for the analysis of
the information provided about <span class="math inline">\(\theta\)</span> by the sample <span class="math inline">\(\mathscr{D}_{n}\)</span>,
and Bayesian analysis relies on (2.1) to draw its inference on <span class="math inline">\(\theta\)</span>.
For instance, when <span class="math inline">\(\mathscr{D}_{n}\)</span> is a normal
<span class="math inline">\(\mathscr{N}\left(\mu, \sigma^{2}\right)\)</span> sample of size <span class="math inline">\(n\)</span> and
<span class="math inline">\(\theta=\left(\mu, \sigma^{2}\right)\)</span>, we get</p>
<p><span class="math display">\[
\begin{array}{l}
\ell\left(\theta \mid \mathscr{D}_{n}\right)=\prod_{i=1}^{n} \exp \left\{-\left(x_{i}-\mu\right)^{2} / 2 \sigma^{2}\right\} / \sqrt{2 \pi} \sigma\\
\propto \exp \left\{-\sum_{i=1}\left(x_{i}-\mu\right)^{2} / 2 \sigma^{2}\right\} / \sigma^{n} \\
\propto \exp \left\{-\left(n \mu^{2}-2 n \bar{x} \mu+\sum_{i=1} x_{i}^{2}\right) / 2 \sigma^{2}\right\} / \sigma^{n} \\
\propto \exp \left\{-\left[n(\mu-\bar{x})^{2}+s^{2}\right] / 2 \sigma^{2}\right\} / \sigma^{n}
\end{array}
\]</span></p>
<p>where <span class="math inline">\(\bar{x}\)</span> denotes the empirical mean and where <span class="math inline">\(s^{2}\)</span> is the sum
<span class="math inline">\(\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}\)</span>. This shows in particular
that <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(s^{2}\)</span> are sufficient statistics.</p>
<p>The major input of the Bayesian approach, compared with a traditional
likelihood approach, is that it modifies the likelihood function into a
posterior distribution, which is a valid probability distribution on
<span class="math inline">\(\Theta\)</span> defined by the classical Bayes’ formula (or theorem) <span class="math display">\[
\pi\left(\theta \mid \mathscr{D}_{n}\right)=\frac{\ell\left(\theta \mid \mathscr{D}_{n}\right) \pi(\theta)}{\int \ell\left(\theta \mid \mathscr{D}_{n}\right) \pi(\theta) \mathrm{d} \theta}
\]</span> The factor <span class="math inline">\(\pi(\theta)\)</span> is called the prior and it obviously has to
be chosen to start the analysis.</p>
</div>
<div id="bayesian-credible-intervals" class="section level3" number="30.1.6">
<h3><span class="header-section-number">30.1.6</span> Bayesian Credible Intervals</h3>
<p>Bayesian approach is a complete inferential approach. Therefore, it
covers confidence evaluation, testing, prediction, model checking, and
point estimation. As with everything else, the derivation of the
confidence intervals (or confidence regions in more general settings) is
based on the posterior distribution
<span class="math inline">\(\pi\left(\theta \mid \mathscr{D}_{n}\right) .\)</span> Since the Bayesian
approach processes <span class="math inline">\(\theta\)</span> as a random variable, a natural definition
of a confidence region on <span class="math inline">\(\theta\)</span> is to determine
<span class="math inline">\(C\left(\mathscr{D}_{n}\right)\)</span> such that <span class="math display">\[
\pi\left(\theta \in C\left(\mathscr{D}_{n}\right) \mid \mathscr{D}_{n}\right)=1-\alpha
\]</span> where <span class="math inline">\(\alpha\)</span> is a predetermined level such as <span class="math inline">\(0.05\)</span></p>
<p>The important difference with a traditional perspective is that the
integration is done over the parameter space, rather than over the
observation space. The quantity <span class="math inline">\(1-\alpha\)</span> thus corresponds to the
probability that a random <span class="math inline">\(\theta\)</span> belongs to this set
<span class="math inline">\(C\left(\mathscr{D}_{n}\right)\)</span>, rather than to the probability that the
random set contains the “true” value of <span class="math inline">\(\theta\)</span>. Given this drift in
the interpretation of a confidence set (rather called a credible set by
Bayesians), the determination of the best credible set turns out to be
easier than in the classical sense: indeed, this set simply corresponds
to the values of <span class="math inline">\(\theta\)</span> with the highest posterior values, <span class="math display">\[
C\left(\mathscr{D}_{n}\right)=\left\{\theta ; \pi\left(\theta \mid \mathscr{D}_{n}\right) \geq k_{\alpha}\right\}
\]</span> where <span class="math inline">\(k_{\alpha}\)</span> is determined by the coverage constraint. This
region is called the highest posterior density <span class="math inline">\((\mathrm{HPD})\)</span> region.</p>
<!-- 贝叶斯方法是一种完全推理方法。因此，它涵盖了置信度评估、测试、预测、模型检查和点估计。与传统视角的重要区别在于，积分是在参数空间上完成的，而不是在观察空间上完成的。因此，数量 $1-\alpha$ 对应于随机 $\theta$ 属于该集合 $C\left(\mathscr{D}_{n}\right)$ 的概率，而不是随机 set 包含 $\theta$ 的“真”值。 鉴于置信集（贝叶斯学派称为可信集）的解释存在这种偏差，确定最佳可信集比传统意义上更容易：事实上，这个集合只是对应 到具有最高后验值的 $\theta$ 的值，该区域称为最高后验密度 $(\mathrm{HPD})$ 区域。 -->
</div>
</div>
<div id="parameter-estimates" class="section level2" number="30.2">
<h2><span class="header-section-number">30.2</span> Parameter estimates</h2>
<p>想要确定数据对应的概率密度分布，就需要确定两个东西：概率密度函数的形式和概率密度函数的参数。</p>
<ul>
<li>有时可能知道的是概率密度函数的形式(高斯、瑞利等等)，但是不知道具体的参数，例如均值或者方差；</li>
<li>有时候可能不知道概率密度的类型，但是知道一些估计的参数，比如均值和方差。</li>
</ul>
<p>在一个基础模型之下我们需要去一估计些未知的参数（比如在linear regression,
需要去计算<strong>W这个向量</strong>),
但在贝叶斯模型下我们需要去计算的是<strong>W的分布（而不是W的点估计</strong>)，用其分布直接计算对y的预测值p(y|x,D)，所以我们需要去需要整合W，也就是说我们把<strong>所有可能的W向量都会去考虑</strong>.这也为什么贝叶斯模型通常棘手的。所以我们需要用<strong>MCMC</strong>，不是直接用优化的方法。</p>
<p>在贝叶斯模型之下， 随着我们观察到越来越多的数据，
我们会对<strong>W向量的分布会有更清晰的推断</strong>，这其实就是<strong>posterior
inference</strong>. 我们比较三种预测</p>
<ol style="list-style-type: decimal">
<li>Maximum likelihood estimation (ML) (point estimation)</li>
<li>Maximum a posteriori estimation（MAP) (point estimation)</li>
<li>Bayesian Model (distribution estimation)</li>
</ol>
<div id="maximum-likelihood-estimation" class="section level3" number="30.2.1">
<h3><span class="header-section-number">30.2.1</span> Maximum likelihood estimation</h3>
<p>极大似然估计是最简单的point estimation, 也就是我们需要去计算P(D|W),
从而找到最优化的W. 它的缺点就是数据比较少的时候往往过度拟合</p>
<p>基本的假设</p>
<ul>
<li>第一：假设M个类别的数据子集的概率密度函数形式一样，只是参数的取值不同；</li>
<li>第二：假设类别i中的数据和类别j中的数据是相互独立抽样的，即类别j的参数仅仅根据类别j的数据就可以估计出来，类别i的数据并不能影响类别j的参数估计，反之亦然；</li>
<li>第三：每个类别内的样本之间具有统计独立性，即每个类别内的样本之间是<strong>独立同分布</strong>
(iid) 的。</li>
</ul>
<p>设x1,x2,…,xN 是从概率密度函数p(x;θ)
中随机抽取的样本，那么就可以得到联合概率密度函数 p(X;θ)，</p>
<p><span class="math display">\[
p(X;\theta)\equiv p(x_1,x_2,...,x_N;\theta)=\prod_{k=1}^Np(x_k;\theta)
\]</span></p>
<p>此时，就可以使用最大似然估计(Maximum Likelihood,ML)来估计参数θ：</p>
<p><span class="math display">\[
\hat{\theta}_{ML}=arg\max_{\theta}\prod_{k=1}^Np(x_k;\theta)
\]</span></p>
<p>为了得到最大值，<span class="math display">\[\theta^{\text{ML}}\]</span>
必须满足的必要条件是,似然函数对θ的梯度必须为0，即：</p>
<p><span class="math display">\[
\frac{\partial \prod_{k=1}^Np(x_k;\theta)}{\partial\theta}=0
\]</span></p>
<p>一般我们取其对数形式：</p>
<p><span class="math display">\[
L(\theta)\equiv ln\prod_{k=1}^Np(x_k;\theta)
\]</span></p>
<p><span class="math display">\[
\frac{\partial L(\theta)}{\partial \theta}=\sum_{k=1}^N  \frac{\partial ln p(x_k;\theta)}{\partial \theta}=\sum_{k=1}^N\frac{1}{p(x_k;\theta)} \frac{\partial p(x_k;\theta)}{\partial \theta}=0
\]</span></p>
<p>极大似然估计有两个非常重要的性质：使得极大似然估计的成为了非常简单而且实用的参数估计方法。这里假设<span class="math display">\[θ_0\]</span>是密度函数p(x;θ)
中未知参数的准确值。</p>
<ul>
<li>渐进无偏</li>
<li>渐进一致性， 有了这两个性质，</li>
</ul>
<p>极大似然估计是渐进无偏的，即：<span class="math display">\[\lim_{N \to \infty}E[\hat{\theta}_{ML}]=\theta_0\]</span>,
也就是说，这里认为估计值**
θ^ML本身是一个随机变量<strong>（因为不同的样本集合X会得到不同的 θ^ML），
那么其</strong>均值就是未知参数的真实值**，这就是渐进无偏。</p>
<p>极大似然估计是渐进一致的，即：<span class="math display">\[\lim_{N \to \infty}prob\{ \lVert \hat{\theta}_{ML}- \theta_0 \rVert \leqslant \epsilon\} = 1\]</span>,这个公式还可以表示为:
<span class="math display">\[\lim_{N \to \infty} E \lVert \hat{\theta}_{ML}- \theta_0 \rVert^2 = 0\]</span>,
对于一个估计器而言，一致性是非常重要的，因为存在满足无偏性，但是不满足一致性的情况，比如，θ<sup>ML</sup>
在 θ-0-周围震荡。如果不满足一致性，那么就会出现很大的方差.
以上两个性质，都是在渐进的前提下（<span class="math display">\[N \to \infty\]</span>）才能讨论的，即只有N足够大时，上面两个性质才能成立.</p>
</div>
<div id="maximum-a-posteriori-estimation" class="section level3" number="30.2.2">
<h3><span class="header-section-number">30.2.2</span> Maximum a posteriori estimation</h3>
<p>在最大似然估计中，将θ看做是未知的参数，说的通俗一点，<strong>最大似然估计是θ的函数</strong>，其求解过程就是找到使得最大似然函数最大的那个参数θ。
<strong>从最大后验估计开始，将参数θ看成一个随机变量</strong>，并在已知样本集{x1,x2,…,xN}的条件下，估计参数θ。</p>
<ul>
<li>在<strong>最大似然估计中，参数θ是一个定值，只是这个值未知</strong>，最大似然函数是θ的函数，这里θ
是没有概率意义的。</li>
<li>在最大后验估计中，<strong>θ是有概率意义的，θ有自己的分布</strong>，而这个分布函数，需要<strong>通过已有的样本集合X得到</strong>，即最大后验估计需要计算的是
<strong>p(θ|X)</strong>. Maximum a posteriori estimation (MAP).
他是在ML的基础上加了prior,
也就是假定了一些P(θ)的分布根据贝叶斯理论：</li>
</ul>
<p><span class="math display">\[
p(\theta|X)=\frac{p(\theta)p(X|\theta)}{p(X)}
\]</span></p>
<p>这就是参数θ关于已有数据集合X的后验概率，<strong>要使得这个后验概率最大，和极大似然估计一样，这里需要对后验概率函数求导</strong>。由于分子中的p(X)相对于θ是独立的，随意可以直接忽略掉p(X)。</p>
<p><span class="math display">\[
\hat{\theta}_{MAP}=arg\max_{\theta}p(\theta|X)=arg\max_{\theta}p(\theta)p(X|\theta)
\]</span></p>
<p>为了得到参数θ，和ML一样，需要对p(θ|X)求梯度，并使其等于0：</p>
<p><span class="math display">\[
\frac{p(\theta|X)}{\partial\theta}=\frac{p(\theta)p(X|\theta）}{\partial\theta}=0
\]</span></p>
<p>这里<strong>p(X|θ)和极大似然估计中的似然函数p(X;θ)</strong>
是一样的，只是记法不一样。MAP和ML的区别是：MAP是在ML的基础上加上了p(θ).</p>
<p>在MAP中，p(θ)称为θ的先验，假设其服从均匀分布，即对于所有θ取值，p(θ)都是同一个常量，则MAP和ML会得到相同的结果。当然了，如果p(θ)的方差非常的小，也就是说，<strong>p(θ)是近似均匀分布的话，MAP和ML的结果自然也会非常的相似</strong>。</p>
<p><strong>MAP and MLE</strong></p>
<p>The similarity of maximum a posteriori estimator (MAP) <span class="math display">\[
\hat{\theta}=\arg \max _{\theta} \pi\left(\theta \mid \mathscr{D}_{n}\right)=\arg \max _{\theta} \pi(\theta) \ell\left(\theta \mid \mathscr{D}_{n}\right)
\]</span> with the maximum likelihood estimator (MLE): The influence of the
prior distribution <span class="math inline">\(\pi(\theta)\)</span> on the estimate progressively
disappears as the number of observations <span class="math inline">\(n\)</span> increases, and the MAP
estimator often recovers the asymptotic properties of the MLE.</p>
<p>For normaldata, since the posterior distribution on <span class="math inline">\(\sigma^{-2}\)</span> is a
<span class="math inline">\(\mathscr{G}(32,1.82)\)</span> distribution, the posterior expectation of
<span class="math inline">\(\sigma^{-2}\)</span> given Illingworth’s experimental data is
<span class="math inline">\(32 / 1.82=17.53\)</span>. The posterior expectation of <span class="math inline">\(\sigma^{2}\)</span> requires a
supplementary effort in order to derive the mean of an inverse gamma
distribution (see Exercise 2.2), namely <span class="math display">\[
\mathbb{E}^{\pi}\left[\sigma^{2} \mid \mathscr{D}_{n}\right]=1.82 /(33-1)=0.057
\]</span></p>
<p>Similarly, the MAP estimate is given here by <span class="math display">\[
\arg \max _{\theta} \pi\left(\sigma^{2} \mid \mathscr{D}_{n}\right)=1.82 /(33+1)=0.054
\]</span> These values therefore reinforce our observation that the
Michelson-Morley precision is not appropriate for the Illingworth
experiment, which is much more precise indeed.</p>
</div>
<div id="bayesian-model" class="section level3" number="30.2.3">
<h3><span class="header-section-number">30.2.3</span> Bayesian Model</h3>
<p>MAP的一些limitation 贝叶斯可以帮我们解决.
贝叶斯的特点就是<strong>考虑整个X的分布</strong>，而不是<strong>通过已有的样本集合X得到得到的θ的</strong>分布函数。
所以自然而然也就是防止overfitting.</p>
<p>防止标号混淆，这里定义已有的样本集合为D，而不是之前的X。
样本集合D中的样本都是从一个
固定但是未知的概率密度函数p(x)中独立抽取出来的，要求根据这些样本估计x的概率分布，<strong>记为p(x|D)</strong>，并且使得p(x|D)尽量的接近p(x)，这就是贝叶斯估计的核心问题。在这里我们是计算x的分布，而不是x的一个最优化的值！</p>
<p>虽然p(x)是未知的，但是前面提到过，一个密度分布的两个要素为：形式和参数，
我们可以假设p(x)的形式已知，但是参数θ的取值未知。这里就有了贝叶斯估计的第一个重要元素<strong>p(x|θ)</strong>,
这是一个条件概率密度函数，准确的说，是一个类条件概率密度函数.
p(x|θ)的形式是已知的，只是参数θ的取值未知。由于这里的x可以看成一个测试样本，
所以这个条件密度函数，从本质上讲，是θ在点 x 处的似然估计。</p>
<p>由于参数θ的取值未知，且，我们将θ看成一个随机变量，那么，在观察到具体的训练样本之前，
关于θ的全部知识，可以用一个先验概率密度函数p(θ)来表示，对于训练样本的观察，
使得我们能够把这个先验概率密度转化成为后验概率密度函数p(θ|D)，
根据后验概率密度相关的论述知道，我们希望p(θ|D)在θ的真实值附近有非常显著的尖峰。
这里的这个后验概率密度<strong>p(θ|D)</strong>，就是贝叶斯估计的第二个主要元素。</p>
<p>现在，将贝叶斯估计核心问题p(x|D)，和贝叶斯估计的两个重要元素：p(x|θ)、p(θ|D)联系起来</p>
<p><span class="math display">\[
p(x|D)=\int p(x,\theta|D) d\theta=\int p(x|\theta,D)p(\theta|D)d\theta
\]</span></p>
<ul>
<li>x 是测试样本</li>
<li>D 是训练集，x和D的选取是独立进行的, 因此，p(x|θ,D)可以写成p(x|θ),
所以，贝叶斯估计的核心问题就是下面这个公式：</li>
</ul>
<p><span class="math display">\[
p(x|D)=\int p(x|\theta)p(\theta|D)d\theta
\]</span></p>
<ul>
<li><p>p(x|D) 根据这些样D本估计x的概率分布</p></li>
<li><p>p(x|θ) 假设p(x)的形式已知，但是参数θ的取值未知,
p(x|θ)的形式是已知的，只是参数θ的取值未知, 这里p(x|θ)</p>
<p>是θ关于测试样本x这一个点的似然估计</p></li>
<li><p>p(θ|D)
在观察到具体的训练样本之前，关于θ的全部知识，可以用一个先验概率密度函数p(θ)来表示，对于训练样本的观察，使得我们能够把这个先验概率密度转化成为后验概率密度函数p(θ|D)
(p(θ|D)是θ在已有样本集合上的后验概率)</p></li>
</ul>
<p><span class="math display">\[
p(\theta|D)=\frac{p(D|\theta)p(\theta)}{p(D)}=\frac{p(D|\theta)p(\theta)}{\int p(D|\theta)p(\theta)d\theta}
\]</span></p>
<p><span class="math display">\[
p(D|\theta)=\prod_{k=1}^N p(x_k|\theta)
\]</span></p>
<div id="full-bayesian" class="section level4" number="30.2.3.1">
<h4><span class="header-section-number">30.2.3.1</span> Full-Bayesian</h4>
<p>与最大似然估计，最大后验估计（MAP）不同之处在于它得到的是测试数据在整个空间上的一个概率分布，而不单纯是一个点估计。它的精髓就在于这个<strong>加权积分：考虑到了参数的所有情况，并且加以不同的权重（后验分布的值）</strong>，自然就避免了过拟合。此外，很多情况下比起单纯的点估计，我们更需要一个分布来获得更多的信息</p>
<ul>
<li>Step 1:
用训练数据得到似然函数likelihood，再加上一个先验分布prior，得到一个后验分布posterior.</li>
<li>Step 2:
对于一个新的测试数据x，用之前得到的posterior作为权重在整个参数空间里计算一个加权积分，得到一个预测分布。</li>
</ul>
<p>在实际中，除了少数情况（比如先验和似然函数都是高斯分布），那个后验分布的形式一般都很复杂，第二步里的积分是积不出来的。这时候就要采取一些近似方法，近似方法又分为两大类：</p>
<ul>
<li>简化复杂的后验分布，然后就能算出积分的解析形式了。具体方法有变分推断，Laplace近似等。这类方法的特点是人算起来困难，机器跑起来快。</li>
<li>用采样的方法搞定后验分布。具体方法有Gibbs采样，HMC采样等。这类方法反过来了，人算起来简单，但是机器跑起来慢。采样方法还有一个好处，就是精度算得比谁都高</li>
</ul>
</div>
</div>
</div>
<div id="prior-distributions" class="section level2" number="30.3">
<h2><span class="header-section-number">30.3</span> Prior Distributions</h2>
<div id="conjugate-prior-distributions" class="section level3" number="30.3.1">
<h3><span class="header-section-number">30.3.1</span> Conjugate Prior Distributions</h3>
<!-- 先验分布的选择是贝叶斯统计中的一个重要问题。当有关数据或模型的先验信息可用时，它可以（并且必须）用于构建先验. 然而，在许多情况下，由于缺乏可靠的先验信息，先验分布的选择非常微妙，必须选择默认解决方案。由于先验分布的选择  对结果推断有相当大的影响，因此必须非常小心地进行此推断步骤。从计算的角度来看，先验分布最方便的选择是模拟先验内的似然结构。 -->
<!-- 在最有利的情况下，先验和后验保持在同一个参数化族中。这种先验称为共轭。对于大多数常见的家庭，包括正态分布，都存在这样的先验。 由于共轭先验使得先验密度和后验密度属于同一参数族，因此使用观察归结为先验参数的更新。为了避免混淆，模型参数的先验分布中涉及的参数通常称为超参数。 （它们本身可以与先验分布相关联，然后称为超先验。） -->
<p>An important feature of conjugate priors is that one has a priori to
select two hyperparameters, e.g., a mean and a variance in the normal
case. On the one hand, this is an advantage when using a conjugate
prior, namely that one has to select only a few parameters to determine
the prior distribution. On the other hand, this is a drawback in that
the information known a priori on <span class="math inline">\(\mu\)</span> may be either insufficient to
determine both parameters or incompatible with the structure imposed by
conjugacy.</p>
<!-- 共轭先验的一个重要特征是可以先验地选择两个超参数，例如正常情况下的均值和方差。一方面，这是使用共轭先验时的优势，即只需要选择几个参数来确定先验分布。另一方面，这是一个缺点，因为在 μ 上先验已知的信息可能不足以确定两个参数或与共轭强加的结构不兼容. -->
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="02_Plots/Conjugate.PNG" alt="Conjugate priors for the most common statistical families" width="342" />
<p class="caption">
Figure 30.1: Conjugate priors for the most common statistical families
</p>
</div>
</div>
<div id="non-informativ-priors" class="section level3" number="30.3.2">
<h3><span class="header-section-number">30.3.2</span> Non-informativ Priors</h3>
<p>确定先验主要有<strong>四个方向:</strong></p>
<ol style="list-style-type: decimal">
<li>无信息先验分布</li>
<li>共轭先验分布</li>
<li>经验Bayes方法</li>
<li>专家验定先验分布</li>
</ol>
<p>通常在贝叶斯分析中，我们需要指定一个先验，但事实在很多前提下，我们是不知道其先验的，这时我们就可以采用无信息先验分布来进行分析计算。</p>
<div id="jeffreys-prior" class="section level4" number="30.3.2.1">
<h4><span class="header-section-number">30.3.2.1</span> Jeffreys Prior</h4>
<ul>
<li>Jeffreys在他的书里提出了Jeffreys 先验，
其最主要性质就是不变性（invariant），即先验的形式不随着参数形式变化而变化。</li>
<li>较好地解决了无信息先验中的一个矛盾：若对参数θ选用均匀分布，则其函数g(θ)往往不是均匀分布。</li>
<li>采用Fisher信息阵的平方根作为θ的无信息先验分布</li>
</ul>
</div>
<div id="reference-prior" class="section level4" number="30.3.2.2">
<h4><span class="header-section-number">30.3.2.2</span> Reference Prior</h4>
<ul>
<li>Reference prior解决了Jeffreys prior在多元情况下的一些问题</li>
<li>Reference
prior是在极大样本下使得先验分布和后验分布的Kullback–Leibler
divergence最大的reference prior。
先验分布和后验分布的Kullback–Leibler</li>
<li>divergence可以被理解成这两个分布之间的信息差，而这个信息差显然来自于样本的信息，使得这个信息差最大就说明后验分布主要体现的是样本的信息，reference
prior对我们得到的信息几乎没有影响。所以这种先验分布可以叫做noninformative
prior。</li>
</ul>
</div>
</div>
</div>
<div id="mcmc" class="section level2" number="30.4">
<h2><span class="header-section-number">30.4</span> MCMC</h2>
<p>MCMC由两个MC组成，即蒙特卡罗方法（Monte Carlo
Simulation，简称MC）和马尔科夫链（Markov Chain ，也简称MC）</p>
<div id="monte-carlo-simulation" class="section level3" number="30.4.1">
<h3><span class="header-section-number">30.4.1</span> Monte Carlo Simulation</h3>
<p>蒙特卡罗原来是一个赌场的名称，用它作为名字大概是因为蒙特卡罗方法是一种随机模拟的方法，这很像赌博场里面的扔骰子的过程。最早的蒙特卡罗方法都是为了求解一些不太好求解的求和或者积分问题。比如积分：
<span class="math display">\[\theta = \int_a^b f(x)dx\]</span></p>
<p>如果我们可以得到x在[a,b]的概率分布函数p(x)，那么我们的定积分求和可以这样进行：</p>
<p><span class="math display">\[
\theta = \int_a^b f(x)dx =  \int_a^b \frac{f(x)}{p(x)}p(x)dx \approx \frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{p(x_i)}
\]</span></p>
<p>最右边的这个形式就是蒙特卡罗方法的一般形式。当然这里是连续函数形式的蒙特卡罗方法，但是在离散时一样成立。假设x在[a,b]之间是均匀分布的时候，
<span class="math inline">\(p(x_i) = 1/(b-a)\)</span>，带入我们有概率分布的蒙特卡罗积分的上式，可以得到：</p>
<p><span class="math display">\[
\frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(x_i)}{1/(b-a)} = \frac{b-a}{n}\sum\limits_{i=0}^{n-1}f(x_i)
\]</span></p>
</div>
<div id="概率分布采样" class="section level3" number="30.4.2">
<h3><span class="header-section-number">30.4.2</span> 概率分布采样</h3>
<p>蒙特卡罗方法的<strong>关键是得到x的概率分布</strong>。如果求出了x的概率分布，我们可以基于概率分布去采样基于这个概率分布的n个x的样本集，带入蒙特卡罗求和的式子即可求解。</p>
<p>还有一个关键的问题需要解决，即<strong>如何基于概率分布去采样基于这个概率分布的n个x的样本集</strong>。</p>
<p>对于常见的均匀分布uniform(0,1)是非常容易采样样本的，一般通过线性同余发生器可以很方便的生成(0,1)之间的伪随机数样本。而其他常见的概率分布，无论是离散的分布还是连续的分布，它们的样本都可以通过uniform(0,1)的样本转换而得。</p>
<ul>
<li>比如二维正态分布的样本<span class="math display">\[(Z_1,Z_2)\]</span>
可以通过通过独立采样得到的uniform(0,1)样本对<span class="math display">\[(X_1,X_2)\]</span>通过如下的式子转换而得：</li>
</ul>
<p><span class="math display">\[
Z_1 = \sqrt{-2 ln X_1}cos(2\pi X_2)
\]</span></p>
<p><span class="math display">\[
Z_2 = \sqrt{-2 ln X_1}sin(2\pi X_2)
\]</span></p>
<ul>
<li>其他一些常见的连续分布，比如t分布，F分布，Beta分布，Gamma分布等，都可以通过类似的方式从uniform(0,1)得到的采样样本转化得到。</li>
</ul>
</div>
<div id="接受-拒绝采样" class="section level3" number="30.4.3">
<h3><span class="header-section-number">30.4.3</span> 接受-拒绝采样</h3>
<p>对于概率分布不是常见的分布，一个可行的办法是采用接受-拒绝采样来得到该分布的样本。既然
p(x) 太复杂在程序中没法直接采样，那么我<strong>设定一个程序可采样的分布 q(x)</strong>
比如高斯分布，然后按照一定的方法<strong>拒绝某些样本，以达到接近 p(x)
分布的目的</strong>，其中<strong>q(x)叫做 proposal distribution</strong>。</p>
<p>具体采用过程如下，设定一个方便采样的常用概率分布函数 q(x)，以及一个常量
k，使得 p(x) 总在 kq(x)
的下方。如上图。首先，采样得到q(x)的一个样本z0，采样方法如第三节。然后，从均匀分布
<span class="math display">\[(0, kq(z_0))\]</span> 中采样得到一个值u.
如果u落在了上图中的灰色区域，则拒绝这次抽样，否则接受这个样本z0。重复以上过程得到n个接受的样本z0,z1,…zn−1,则最后的蒙特卡罗方法求解结果为：</p>
<p><span class="math display">\[
\frac{1}{n}\sum\limits_{i=0}^{n-1}\frac{f(z_i)}{p(z_i)}
\]</span></p>
</div>
<div id="markov-chain" class="section level3" number="30.4.4">
<h3><span class="header-section-number">30.4.4</span> Markov Chain</h3>
<p>马尔科夫链定义本身比较简单，它假设某一时刻状态转移的概率只依赖于它的前一个状态。如果用精确的数学定义来描述，则假设我们的序列状态是
<span class="math display">\[...X_{t-2}, X_{t-1}, X_{t},  X_{t+1},...\]</span>
那么我们的在时刻Xt+1的状态的条件概率仅仅依赖于时刻Xt，即：</p>
<p><span class="math display">\[
P(X_{t+1} |...X_{t-2}, X_{t-1}, X_{t} ) = P(X_{t+1} | X_{t})
\]</span></p>
<p>既然某一时刻状态转移的概率只依赖于它的前一个状态，那么我们只要能求出系统中任意两个状态之间的转换概率，这个马尔科夫链的模型就定了。</p>
<p><img src="02_Plots/MCMC1.PNG" width="416" /></p>
<p>例如马尔科夫链是表示股市模型的，共有三种状态：牛市（Bull market）,
熊市（Bear market）和横盘（Stagnant
market）。每一个状态都以一定的概率转化到下一个状态。比如，牛市以0.025的概率转化到横盘的状态。这个状态概率转化图可以以矩阵的形式表示。如果我们定义矩阵阵P某一位置<span class="math display">\[P(i,j)\]</span>的值为
<span class="math display">\[P(j|i)\]</span> 即从状态i转化到状态j的概率，并定义牛市为状态0， 熊市为状态1,
横盘为状态2. 这样我们得到了马尔科夫链模型的状态转移矩阵为：</p>
<p><span class="math display">\[
P=\left( \begin{array}{ccc} 0.9&amp;0.075&amp;0.025 \\ 0.15&amp;0.8&amp; 0.05 \\ 0.25&amp;0.25&amp;0.5 \end{array} \right)
\]</span></p>
<p>尽管这次采用了不同初始概率分布，最终状态的概率分布趋于同一个稳定的概率分布[0.625
0.3125 0.0625]，
也就是说我们的<strong>马尔科夫链模型的状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关</strong>。也就是说，如果我们得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则我们可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本。</p>
</div>
<div id="马尔科夫链的收敛性质" class="section level3" number="30.4.5">
<h3><span class="header-section-number">30.4.5</span> 马尔科夫链的收敛性质</h3>
<p>如果一个非周期的马尔科夫链有状态转移矩阵P,
并且它的任何两个状态是连通的，那么 <span class="math inline">\(\lim_{n \to \infty}P_{ij}^n\)</span>
与i无关，我们有： 1. <span class="math inline">\(\lim_{n \to \infty}P_{ij}^n = \pi(j)\)</span> 2.
<span class="math inline">\(\lim_{n \to \infty}P^n = \left( \begin{array}{ccc} \pi(1)&amp;\pi(2)&amp;\ldots&amp;\pi(j)&amp;\ldots \\ \pi(1)&amp;\pi(2)&amp;\ldots&amp;\pi(j)&amp;\ldots \\ \ldots&amp;\ldots&amp;\ldots&amp;\ldots&amp;\ldots \\ \pi(1)&amp;\pi(2)&amp;\ldots&amp;\pi(j)&amp;\ldots \\ \ldots&amp;\ldots&amp;\ldots&amp;\ldots&amp;\ldots \end{array} \right)\)</span>
3. <span class="math inline">\(\pi(j) = \sum\limits_{i=0}^{\infty}\pi(i)P_{ij}\)</span> 4. <span class="math inline">\(\pi\)</span>是方程的
<span class="math inline">\(\pi P = \pi\)</span>$ 唯一非负解，其中：
<span class="math inline">\(\pi = [\pi(1),\pi(2),...,\pi(j),...]\;\; \sum\limits_{i=0}^{\infty}\pi(i) = 1\)</span></p>
<p>上面的性质中需要解释的有：</p>
<ol style="list-style-type: decimal">
<li>非周期的马尔科夫链：这个主要是指马尔科夫链的状态转化不是循环的，如果是循环的则永远不会收敛。幸运的是我们遇到的马尔科夫链一般都是非周期性的。用数学方式表述则是：对于任意某一状态i，d为集合
<span class="math inline">\(\{n \mid n \geq 1,P_{ii}^n&gt;0 \}\)</span> 的最大公约数，如果 d=1d=1
，则该状态为非周期的</li>
<li>任何两个状态是连通的：这个指的是从任意一个状态可以通过有限步到达其他的任意一个状态，不会出现条件概率一直为0导致不可达的情况。</li>
<li>马尔科夫链的状态数可以是有限的，也可以是无限的。因此可以用于连续概率分布和离散概率分布。</li>
<li><span class="math inline">\(\pi\)</span>通常称为马尔科夫链的平稳分布。</li>
</ol>
</div>
<div id="基于马尔科夫链采样" class="section level3" number="30.4.6">
<h3><span class="header-section-number">30.4.6</span> 基于马尔科夫链采样</h3>
<p>如果我们得到了某个平稳分布所对应的马尔科夫链状态转移矩阵，我们就很容易采用出这个平稳分布的样本集。假设我们任意初始的概率分布是
<span class="math inline">\(\pi_0(x)\)</span> ,
经过第一轮马尔科夫链状态转移后的概率分布是<span class="math inline">\(\pi_1(x)\)</span>，。。。第i轮的概率分布是<span class="math inline">\(\pi_i(x)\)</span>。假设经过n轮后马尔科夫链收敛到我们的平稳分布<span class="math inline">\(\pi(x)\)</span>，即：</p>
<p><span class="math display">\[
\pi_n(x) = \pi_{n+1}(x) = \pi_{n+2}(x) =... = \pi(x)
\]</span></p>
<p>对于每个分布<span class="math inline">\(\pi_i(x)\)</span>，我们有：</p>
<p><span class="math display">\[
\pi_i(x) = \pi_{i-1}(x)P = \pi_{i-2}(x)P^2 = \pi_{0}(x)P^i
\]</span></p>
<p>现在我们可以开始采样了，首先，基于初始任意简单概率分布比如高斯分布π0(x)采样得到状态值x0，基于条件概率分布
<span class="math inline">\(P(x|x_0)\)</span>
采样状态值x1，一直进行下去，当状态转移进行到一定的次数时，比如到n次时，我们认为此时的采样集
<span class="math inline">\((x_n,x_{n+1},x_{n+2},...)\)</span>
即是符合我们的平稳分布的对应样本集，可以用来做蒙特卡罗模拟求和了。</p>
<p>总结下基于马尔科夫链的采样过程:</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>输入马尔科夫链状态转移矩阵 <span class="math display">\[P\]</span>, 设定状态转移次数间值 <span class="math inline">\(n_{1},\)</span>
需要的样本个数 <span class="math inline">\(n_{2}\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>从任意简单概率分布采样得到初始状态值 <span class="math inline">\(x_{0}\)</span></li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>for <span class="math inline">\(t=0\)</span> to <span class="math inline">\(n_{1}+n_{2}-1:\)</span> 从条件概率分布
<span class="math inline">\(P\left(x \mid x_{t}\right)\)</span> 中采样得到样本 <span class="math inline">\(x_{t+1}\)</span> 样本集
<span class="math inline">\(\left(x_{n_{1}}, x_{n_{1}+1}, \ldots, x_{n_{1}+n_{2}-1}\right)\)</span>
即为我们需要的平稳分布对应的样本集。</li>
</ol></li>
</ul>
<p>如果假定我们可以得到我们需要采样样本的平稳分布所对应的马尔科夫链状态转移矩阵，那么我们就可以用马尔科夫链采样得到我们需要的样本集，进而进行蒙特卡罗模拟。但是一个重要的问题是，随意给定一个平稳分布π,如何得到它所对应的马尔科夫链状态转移矩阵P呢？这是个大问题。我们绕了一圈似乎还是没有解决任意概率分布采样样本集的问题。幸运的是，MCMC采样通过迂回的方式解决了上面这个大问题.</p>
</div>
<div id="mcmc采样" class="section level3" number="30.4.7">
<h3><span class="header-section-number">30.4.7</span> MCMC采样</h3>
<div id="马尔科夫链的细致平稳条件" class="section level4" number="30.4.7.1">
<h4><span class="header-section-number">30.4.7.1</span> 马尔科夫链的细致平稳条件</h4>
<p>在解决从平稳分布π,
找到对应的马尔科夫链状态转移矩阵P之前，我们还需要先看看马尔科夫链的细致平稳条件》如果非周期马尔科夫链的状态转移矩阵P和概率分布π(x)对于所有的i,j满足：</p>
<p><span class="math display">\[
\pi(i)P(i,j) = \pi(j)P(j,i)
\]</span></p>
<p>则称概率分布π(x)是状态转移矩阵P的平稳分布。证明如下</p>
<p><span class="math display">\[
\sum\limits_{i=1}^{\infty}\pi(i)P(i,j)  = \sum\limits_{i=1}^{\infty} \pi(j)P(j,i) =  \pi(j)\sum\limits_{i=1}^{\infty} P(j,i) =  \pi(j)
\]</span></p>
<p>将上式用矩阵表示即为： <span class="math inline">\(\pi P = \pi\)</span></p>
<p>不过不幸的是，仅仅从细致平稳条件还是很难找到合适的矩阵P。比如我们的目标平稳分布是π(x),随机找一个马尔科夫链状态转移矩阵Q,它是很难满足细致平稳条件的，即：</p>
<p><span class="math display">\[
\pi(i)Q(i,j) \neq \pi(j)Q(j,i)
\]</span></p>
<p>可以对上式做一个改造，使细致平稳条件成立。方法是引入一个 <span class="math inline">\(\alpha(i,j)\)</span>
,使上式可以取等号，即：</p>
<p><span class="math display">\[
\pi(i)Q(i,j)\alpha(i,j) = \pi(j)Q(j,i)\alpha(j,i)
\]</span></p>
<p><span class="math display">\[\alpha(i,j)\]</span>满足下两式即可：</p>
<p><span class="math display">\[
\alpha(i,j) = \pi(j)Q(j,i)
\]</span></p>
<p><span class="math display">\[
\alpha(j,i) = \pi(i)Q(i,j)
\]</span></p>
<p>我们就得到了我们的分布π(x)对应的马尔科夫链状态转移矩阵P，满足：</p>
<p><span class="math display">\[
P(i,j) = Q(i,j)\alpha(i,j)
\]</span></p>
<p><span class="math inline">\(\alpha(i,j)\)</span>一般称之为<strong>接受率</strong>。取值在[0,1]之间，可以理解为一个概率值。即目标矩阵P可以通过任意一个马尔科夫链状态转移矩阵Q以一定的接受率获得</p>
</div>
<div id="总结下mcmc的采样过程" class="section level4" number="30.4.7.2">
<h4><span class="header-section-number">30.4.7.2</span> 总结下MCMC的采样过程</h4>
<ul>
<li><ol style="list-style-type: decimal">
<li>输入我们任意选定的马尔科夫链状态转移矩阵 <span class="math inline">\(Q,\)</span> 平稳分布 <span class="math inline">\(\pi(x),\)</span>
设定状态转移次数间值 <span class="math inline">\(n_{1},\)</span> 需要的样本个数 <span class="math inline">\(n_{2}\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>从任意简单概率分布采样得到初始状态值 <span class="math inline">\(x_{0}\)</span></li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>for <span class="math inline">\(t=0\)</span> to <span class="math inline">\(n_{1}+n_{2}-1\)</span> :</li>
</ol>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>从条件概率分布 <span class="math inline">\(Q\left(x \mid x_{t}\right)\)</span> 中采样得到样本
<span class="math inline">\(x_{*}\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>从均匀分布采样 <span class="math inline">\(u \sim\)</span>$ $<span class="math inline">\(uniform [0,1]\)</span></li>
</ol></li>
<li><ol start="3" style="list-style-type: lower-alpha">
<li>如果
<span class="math inline">\(u&lt;\alpha\left(x_{t}, x_{*}\right)=\pi\left(x_{*}\right) Q\left(x_{*}, x_{t}\right),\)</span>
则接受转移 <span class="math inline">\(x_{t} \rightarrow x_{*},\)</span> 即 <span class="math inline">\(x_{t+1}=x_{*}\)</span></li>
</ol></li>
<li><ol start="4" style="list-style-type: lower-alpha">
<li>否则不接受转移, 即 <span class="math inline">\(x_{t+1}=x_{t}\)</span></li>
</ol></li>
</ul></li>
</ul>
<p>样本集 <span class="math inline">\(\left(x_{n_{1}}, x_{n_{1}+1}, \ldots, x_{n_{1}+n_{2}-1}\right)\)</span>
即为我们需要的平稳分布对应的样本集。</p>
<p>但是这个采样算法还是比较难在实际中应用，问题在上面第三步的c步骤，由于
<span class="math inline">\(\alpha(x_t,x_{*})\)</span>可能非常的小，比如0.1，导致我们大部分的采样值都被拒绝转移，采样效率很低。有可能我们采样了上百万次马尔可夫链还没有收敛，也就是上面这个n1要非常非常的大，这让人难以接受，怎么办呢？这时就轮到我们的<strong>M-H采样</strong>出场了。</p>
</div>
</div>
<div id="m-h采样" class="section level3" number="30.4.8">
<h3><span class="header-section-number">30.4.8</span> M-H采样</h3>
<p>M-H采样是Metropolis-Hastings采样的简称，这个算法首先由Metropolis提出，被Hastings改进，因此被称之为Metropolis-Hastings采样或M-H采样.
M-H采样解决了我们上一节MCMC采样接受率过低的问题。</p>
<p>回到MCMC采样的细致平稳条件：
<span class="math inline">\(\pi(i)Q(i,j)\alpha(i,j) = \pi(j)Q(j,i)\alpha(j,i)\)</span></p>
<p>我们采样效率低的原因是 <span class="math inline">\(\alpha(i,j)\)</span>
太小了，比如为0.1，而<span class="math inline">\(\alpha(j,i)\)</span>为0.2。即：
<span class="math inline">\(\pi(i)Q(i,j)\times 0.1 = \pi(j)Q(j,i)\times 0.2\)</span> ,
这时我们可以看到，如果两边同时扩大五倍，接受率提高到了0.5，但是细致平稳条件却仍然是满足的，即：
<span class="math inline">\(\pi(i)Q(i,j)\times 0.5 = \pi(j)Q(j,i)\times 1\)</span>
这样我们的接受率可以做如下改进，即：</p>
<p><span class="math display">\[
\alpha(i,j) = min\{ \frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)},1\}
\]</span></p>
<p>通过这个微小的改造，我们就得到了可以在实际应用中使用的M-H采样算法过程如下：</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>输入我们任意选定的马尔科夫链状态转移矩阵 <span class="math inline">\(Q,\)</span> 平稳分布 <span class="math inline">\(\pi(x),\)</span>
设定状态转移次数间值 <span class="math inline">\(n_{1},\)</span> 需要的样本个数 <span class="math inline">\(n_{2}\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>从任意简单概率分布采样得到初始状态值 <span class="math inline">\(x_{0}\)</span></li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>for <span class="math inline">\(t=0\)</span> to <span class="math inline">\(n_{1}+n_{2}-1\)</span> :</li>
</ol>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>从条件概率分布 <span class="math inline">\(Q\left(x \mid x_{t}\right)\)</span> 中采样得到样本
<span class="math inline">\(x_{*}\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>从均匀分布采样 <span class="math inline">\(u \sim\)</span> uniform [0,1]</li>
</ol></li>
<li><ol start="3" style="list-style-type: lower-alpha">
<li>如果
<span class="math inline">\(u&lt;\alpha\left(x_{t}, x_{*}\right)=\min \left\{\frac{\pi(j) Q(j, i)}{\pi(i) Q(i, j)}, 1\right\},\)</span>
则接受转移 <span class="math inline">\(x_{t} \rightarrow x_{*},\)</span> 即 <span class="math inline">\(x_{t+1}=x_{*}\)</span></li>
</ol></li>
<li><ol start="4" style="list-style-type: lower-alpha">
<li>否则不接受转移， 即 <span class="math inline">\(x_{t+1}=x_{t}\)</span></li>
</ol></li>
</ul></li>
</ul>
<p>样本集 <span class="math inline">\(\left(x_{n_{1}}, x_{n_{1}+1}, \ldots, x_{n_{1}+n_{2}-1}\right)\)</span>
即为我们需要的平稳分布对应的样本集。 很多时候,
我们选择的马尔科夫链状态转移矩阵Q如果是对称的, 即满足
<span class="math inline">\(Q(i, j)=Q(j, i)\)</span>,这时我们的接受率可以进一步简化为：</p>
<p><span class="math display">\[
\alpha(i, j)=\min \left\{\frac{\pi(j)}{\pi(i)}, 1\right\}
\]</span></p>
<p>M-H采样完整解决了使用蒙特卡罗方法需要的任意概率分布样本集的问题，因此在实际生产环境得到了广泛的应用.
但是在大数据时代，M-H采样面临着两大难题：</p>
<ol style="list-style-type: decimal">
<li>我们的数据特征非常的多，M-H采样由于接受率计算式<span class="math inline">\(\frac{\pi(j)Q(j,i)}{\pi(i)Q(i,j)}\)</span>的存在，在高维时需要的计算时间非常的可观，算法效率很低。同时<span class="math inline">\(\alpha(i,j)\)</span>一般小于1，有时候辛苦计算出来却被拒绝了。能不能做到不拒绝转移呢？</li>
<li>由于特征维度大，很多时候我们甚至很难求出目标的各特征维度联合分布，但是可以方便求出各个特征之间的条件概率分布。这时候我们能不能只有各维度之间条件概率分布的情况下方便的采样呢？</li>
</ol>
<p>Gibbs采样解决了上面两个问题</p>
</div>
<div id="gibbs采样" class="section level3" number="30.4.9">
<h3><span class="header-section-number">30.4.9</span> Gibbs采样</h3>
<p>M-H采样已经可以很好的解决蒙特卡罗方法需要的任意概率分布的样本集的问题。但是M-H采样有两个缺点：一是需要计算接受率，在高维时计算量大。并且由于接受率的原因导致算法收敛时间变长。二是有些高维数据，特征的条件概率分布好求，但是特征的联合分布不好求。因此需要一个好的方法来改进M-H采样</p>
<p>细致平稳条件：如果非周期马尔科夫链的状态转移矩阵P和概率分布π(x)对于所有的i,j满足：<span class="math inline">\(\pi(i)Q(i,j)\alpha(i,j) = \pi(j)Q(j,i)\alpha(j,i)\)</span>则称概率分布π(x)是状态转移矩阵P的平稳分布。现在我们换一个思路,
重新寻找合适的细致平稳条件</p>
<p>从二维的数据分布开始，假设<span class="math inline">\(\pi(x_1,x_2)\)</span>是一个二维联合数据分布，观察第一个特征维度相同的两个点<span class="math inline">\(A(x_1^{(1)},x_2^{(1)})\)</span>和<span class="math inline">\(B(x_1^{(1)},x_2^{(1)})\)</span>，容易发现下面两式成立：</p>
<p><span class="math display">\[
\pi(x_1^{(1)},x_2^{(1)}) \pi(x_2^{(2)} | x_1^{(1)}) = \pi(x_1^{(1)})\pi(x_2^{(1)}|x_1^{(1)}) \pi(x_2^{(2)} | x_1^{(1)})
\]</span></p>
<p><span class="math display">\[
\pi(x_1^{(1)},x_2^{(2)}) \pi(x_2^{(1)} | x_1^{(1)}) = \pi(x_1^{(1)}) \pi(x_2^{(2)} | x_1^{(1)})\pi(x_2^{(1)}|x_1^{(1)})
\]</span></p>
<p>由于两式的右边相等，因此我们有：</p>
<p><span class="math display">\[
\pi(x_1^{(1)},x_2^{(1)}) \pi(x_2^{(2)} | x_1^{(1)})  = \pi(x_1^{(1)},x_2^{(2)}) \pi(x_2^{(1)} | x_1^{(1)})
\]</span></p>
<p><span class="math display">\[
\pi(A) \pi(x_2^{(2)} | x_1^{(1)})  = \pi(B) \pi(x_2^{(1)} | x_1^{(1)})
\]</span></p>
<p>观察上式再观察细致平稳条件的公式, 我们发现在 <span class="math inline">\(x_{1}=x_{1}^{(1)}\)</span>
这条直线上, 如果用条件概率分布 <span class="math inline">\(\pi\left(x_{2} \mid x_{1}^{(1)}\right.)\)</span>
作为马尔科夫链的状态转移概率, 则任意两 个点之间的转移满足细致平稳条件!
同样的道理, 在在 <span class="math inline">\(x_{2}=x_{2}^{(1)}\)</span> 这条直线上, 如果用条件概率分布
<span class="math inline">\(\pi\left(x_{1} \mid x_{2}^{(1)}\right.)\)</span> 作为马尔科夫链的状态 转移概率,
则任意两个点之间的转移也满足细致平稳条件。那是因为假如有一点
<span class="math inline">\(C\left(x_{1}^{(2)}, x_{2}^{(1)}\right)\)</span>,我们可以得到:</p>
<p><span class="math display">\[
\pi(A) \pi\left(x_{1}^{(2)} \mid x_{2}^{(1)}\right)=\pi(C) \pi\left(x_{1}^{(1)} \mid x_{2}^{(1)}\right)
\]</span></p>
<p>基于上面的发现, 我们可以这样构造分布 <span class="math inline">\(\pi\left(x_{1}, x_{2}\right)\)</span>
的马尔可夫链对应的状态转移矩阵 <span class="math inline">\(P\)</span> :</p>
<p><span class="math display">\[
\begin{array}{c}
P(A \rightarrow B)=\pi\left(x_{2}^{(B)} \mid x_{1}^{(1)}\right) \text {  if  } x_{1}^{(A)}=x_{1}^{(B)}=x_{1}^{(1)} \\
P(A \rightarrow C)=\pi\left(x_{1}^{(C)} \mid x_{2}^{(1)}\right) \text {  if  } x_{2}^{(A)}=x_{2}^{(C)}=x_{2}^{(1)} \\
P(A \rightarrow D)=0 \text { else }
\end{array}
\]</span></p>
<p>有了上面这个状态转移矩阵，我们很容易验证平面上的任意两点E,F，满足细致平稳条件：</p>
<p><span class="math display">\[
\pi(E)P(E \to F)  = \pi(F)P(F \to E)
\]</span></p>
<div id="二维gibbs采样" class="section level4" number="30.4.9.1">
<h4><span class="header-section-number">30.4.9.1</span> 二维Gibbs采样</h4>
<p>利用状态转移矩阵，我们就得到了二维Gibbs采样，这个采样需要两个维度之间的条件概率。具体过程如下：</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>输入平稳分布 <span class="math inline">\(\pi\left(x_{1}, x_{2}\right),\)</span>
设定状态转移次数间值 <span class="math inline">\(n_{1},\)</span> 需要的样本个数 <span class="math inline">\(n_{2}\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>随机初始化初始状态值 <span class="math inline">\(x_{1}^{(0)}\)</span> 和 <span class="math inline">\(x_{2}^{(0)}\)</span></li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>for <span class="math inline">\(t=0\)</span> to <span class="math inline">\(n_{1}+n_{2}-1\)</span>:</li>
</ol>
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>从条件概率分布 <span class="math inline">\(P\left(x_{2} \mid x_{1}^{(t)}\right)\)</span>
中采样得到样本 <span class="math inline">\(x_{2}^{t+1}\)</span></li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>从条件概率分布 <span class="math inline">\(P\left(x_{1} \mid x_{2}^{(t+1)}\right)\)</span>
中采样得到样本 <span class="math inline">\(x_{1}^{t+1}\)</span></li>
</ol></li>
</ul></li>
</ul>
<p>样本集
<span class="math inline">\(\left\{\left(x_{1}^{\left(n_{1}\right)}, x_{2}^{\left(n_{1}\right)}\right),\left(x_{1}^{\left(n_{1}+1\right)}, x_{2}^{\left(n_{1}+1\right)}\right), \ldots,\left(x_{1}^{\left(n_{1}+n_{2}-1\right)}, x_{2}^{\left(n_{1}+n_{2}-1\right)}\right)\right\}\)</span>
即为我们需要的平稳分布对应的样本集。</p>
<p>整个采样过程中，我们通过轮换坐标轴, 采样的过程为：</p>
<p><span class="math display">\[
\left(x_{1}^{(1)}, x_{2}^{(1)}\right) \rightarrow\left(x_{1}^{(1)}, x_{2}^{(2)}\right) \rightarrow\left(x_{1}^{(2)}, x_{2}^{(2)}\right) \rightarrow \ldots \rightarrow\left(x_{1}^{\left(n_{1}+n_{2}-1\right)}, x_{2}^{\left(n_{1}+n_{2}-1\right)}\right)
\]</span></p>
<p>采样是在两个坐标轴上不停的轮换的。当然，坐标轴轮换不是必须的，我们也可以每次随机选择一个坐标轴进行采样。不过常用的Gibbs采样的实现都是基于坐标轴轮换的。由于Gibbs采样在高维特征时的优势，目前我们通常意义上的MCMC采样都是用的Gibbs采样。当然Gibbs采样是从M-H采样的基础上的进化而来的，同时Gibbs采样要求数据至少有两个维度，一维概率分布的采样是没法用Gibbs采样的,这时M-H采样仍然成立。有了Gibbs采样来获取概率分布的样本集，有了蒙特卡罗方法来用样本集模拟求和，他们一起就奠定了MCMC算法在大数据时代高维数据模拟求和时的作用。</p>
</div>
</div>
</div>
<div id="regression-and-variable-selection" class="section level2" number="30.5">
<h2><span class="header-section-number">30.5</span> Regression and Variable Selection</h2>
<div id="classical-least-squares-estimator" class="section level3" number="30.5.1">
<h3><span class="header-section-number">30.5.1</span> Classical Least Squares Estimator</h3>
<p>毛毛虫数据集是从 1973
年对松林毛虫的研究中提取的：它评估了一些森林聚落特征对毛毛虫群落发展的影响。响应变量是在
500
平方米（对应于毛虫的最后一列）面积内每棵树的平均毛虫巢数的对数变换。在 n
= 33 个区域上定义了 p = 8 个潜在的解释变量， x1 是海拔（米），x2
是坡度（度），x3 是该地区的松树数量，x4
是在中心采样的树的高度（米）区域，x5 是该区域的方向（从 1 如果向南则为
2，否则为 2），x6 是优势树的高度（以米为单位），x7 是植被层数，x8
是混合沉降指数（如果是从 1如果混合，则不混合为
2）。回归分析的目标是确定哪些解释变量对巢的数量有很大影响，以及这些影响如何相互重叠。</p>
<p>For caterpillar, where <span class="math inline">\(n=33\)</span> and <span class="math inline">\(p=8\)</span>, we thus assume that the
expected lognumber <span class="math inline">\(y_{i}\)</span> of caterpillar nests per tree over an area is
modeled as a linear combination of an intercept and eight predictor
variables <span class="math inline">\((i=1, \ldots, n)\)</span>, <span class="math display">\[
\mathbb{E}\left[y_{i} \mid \alpha, \boldsymbol{\beta}, \sigma^{2}\right]=\alpha+\sum_{j=1}^{8} \beta_{j} x_{i j}
\]</span></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="bayesian-theory.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayess)</span>
<span id="cb1-2"><a href="bayesian-theory.html#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Demo code https://rdrr.io/cran/bayess/f/</span></span>
<span id="cb1-3"><a href="bayesian-theory.html#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="bayesian-theory.html#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(caterpillar)</span>
<span id="cb1-5"><a href="bayesian-theory.html#cb1-5" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">log</span>(caterpillar<span class="sc">$</span>y)</span>
<span id="cb1-6"><a href="bayesian-theory.html#cb1-6" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">as.matrix</span>(caterpillar[,<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>])</span>
<span id="cb1-7"><a href="bayesian-theory.html#cb1-7" aria-hidden="true" tabindex="-1"></a>vnames<span class="ot">=</span><span class="fu">names</span>(caterpillar)</span>
<span id="cb1-8"><a href="bayesian-theory.html#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="bayesian-theory.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>),<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.2</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="fl">1.2</span>))</span>
<span id="cb1-10"><a href="bayesian-theory.html#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>) <span class="fu">plot</span>(X[,i],y,<span class="at">xlab=</span>vnames[i],<span class="at">pch=</span><span class="dv">19</span>, <span class="at">col=</span><span class="st">&quot;sienna4&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>)</span></code></pre></div>
<p><img src="bookdown-demo_files/figure-html/t%20caterpillar-1.png" width="672" /></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="bayesian-theory.html#cb2-1" aria-hidden="true" tabindex="-1"></a>S<span class="ot">=</span><span class="fu">readline</span>(<span class="at">prompt=</span><span class="st">&quot;Type  &lt;Return&gt;   to continue : &quot;</span>)</span></code></pre></div>
<pre><code>## Type  &lt;Return&gt;   to continue :</code></pre>
<p>The parameter <span class="math inline">\(\boldsymbol{\beta}\)</span> can obviously be estimated via
maximum likelihood estimation. In order to avoid non-identifiability and
uniqueness problems, we assume that
<span class="math inline">\(\left[\mathbf{1}_{n} \quad \mathbf{X}\right]\)</span> is of full
<span class="math inline">\(\operatorname{rank}\)</span>, that is,
<span class="math inline">\(\operatorname{rank}\left[\mathbf{1}_{n} \quad \mathbf{X}\right]=p+1\)</span>.
This also means that there is no redundant structure among the
explanatory variables. We suppose in addition that <span class="math inline">\(p+\)</span> <span class="math inline">\(1&lt;n\)</span> in order
to obtain well-defined estimates for all parameters.</p>
<!-- 通过最大似然估计来估计参数 β。 为了避免不可识别性和唯一性问题，我们假设[1n X]是满秩的，即秩[1n X] = p+1。 这也意味着解释变量之间没有冗余结构。我们另外假设 p + 1 < n 以获得所有参数的明确估计。 -->
<p>The likelihood
<span class="math inline">\(\ell\left(\alpha, \boldsymbol{\beta}, \sigma^{2} \mid \mathbf{y}\right)\)</span>
of the standard normal linear model is provided by the following matrix
representation: <span class="math display">\[
\frac{1}{\left(2 \pi \sigma^{2}\right)^{n / 2}} \exp \left\{-\frac{1}{2 \sigma^{2}}\left(\mathbf{y}-\alpha \mathbf{1}_{n}-\mathbf{X} \boldsymbol{\beta}\right)^{\mathrm{T}}\left(\mathbf{y}-\alpha \mathbf{1}_{n}-\mathbf{X} \boldsymbol{\beta}\right)\right\}
\]</span> The maximum likelihood estimators of <span class="math inline">\(\alpha\)</span> and
<span class="math inline">\(\boldsymbol{\beta}\)</span> are then the solution of the (least squares)
minimization problem <span class="math display">\[
\begin{array}{l}
\min _{\alpha, \boldsymbol{\beta}}\left(\mathbf{y}-\alpha \mathbf{1}_{n}-\mathbf{X} \boldsymbol{\beta}\right)^{\mathrm{T}}\left(\mathbf{y}-\alpha \mathbf{1}_{n}-\mathbf{X} \boldsymbol{\beta}\right) \\
\quad=\min _{\alpha, \boldsymbol{\beta}} \sum_{i=1}^{n}\left(y_{i}-\alpha-\beta_{1} x_{i 1}-\ldots-\beta_{p} x_{i p}\right)^{2}
\end{array}
\]</span> We get solutions <span class="math display">\[
\hat{\alpha}=\overline{\mathbf{y}}, \quad \hat{\boldsymbol{\beta}}=\left(\mathbf{X}^{\top} \mathbf{X}\right)^{-1} \mathbf{X}^{\top}(\mathbf{y}-\bar{y})
\]</span></p>
<p><strong>best linear unbiased estimator</strong></p>
<p>(see, e.g., Christensen, 2002) states that <span class="math inline">\((\hat{\alpha}, \hat{\beta})\)</span>
is the best linear unbiased estimator of <span class="math inline">\((\alpha, \beta)\)</span>. This means
that, for all <span class="math inline">\(a \in \mathbb{R}^{p+1}\)</span>, and with the abuse of notation
that, here, <span class="math inline">\((\hat{\alpha}, \hat{\beta})\)</span> represents a column vector, <span class="math display">\[
\mathbb{V}\left(a^{\top}(\hat{\alpha}, \hat{\beta}) \mid \alpha, \boldsymbol{\beta}, \sigma^{2}\right) \leq \mathbb{V}\left(a^{\top}(\tilde{\alpha}, \tilde{\beta}) \mid \alpha, \boldsymbol{\beta}, \sigma^{2}\right)
\]</span> for any unbiased linear estimator <span class="math inline">\((\tilde{\alpha}, \tilde{\beta})\)</span>
of <span class="math inline">\((\alpha, \beta)\)</span>.</p>
<p>An unbiased estimator of <span class="math inline">\(\sigma^{2}\)</span> is <span class="math display">\[
\hat{\sigma}^{2}=\frac{1}{n-p-1}\left(\mathbf{y}-\hat{\alpha} \mathbf{1}_{n}-\mathbf{X} \hat{\boldsymbol{\beta}}\right)^{\top}\left(\mathbf{y}-\hat{\alpha} \mathbf{1}_{n}-\mathbf{X} \hat{\boldsymbol{\beta}}\right)=\frac{s^{2}}{n-p-1}
\]</span> and <span class="math inline">\(\hat{\sigma}^{2}\left(\mathbf{X}^{\top} \mathbf{X}\right)^{-1}\)</span>
approximates the covariance matrix of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>. Note
that the MLE of <span class="math inline">\(\sigma^{2}\)</span> is <span class="math inline">\(\operatorname{not} \hat{\sigma}^{2}\)</span>
but <span class="math inline">\(\tilde{\sigma}^{2}=s^{2} / n\)</span></p>
<pre><code>X=scale(X)
summary(lm(y~X))
## S=readline(prompt=&quot;Type  &lt;Return&gt;   to continue : &quot;)</code></pre>
</div>
<div id="the-jeffreys-prior-analysis" class="section level3" number="30.5.2">
<h3><span class="header-section-number">30.5.2</span> The Jeffreys Prior Analysis</h3>
<!-- 仅考虑线性模型参数完全缺乏先验信息的情况，我们首先描述基于 Jeffreys 先验的非信息性解决方案   -->
<p>Considering only the case of a complete lack of prior information on the
parameters of the linear model, we first describe a noninformative
solution based on the Jeffreys prior. It is rather easy to show that the
Jeffreys prior in this case is <span class="math display">\[
\pi^{J}\left(\alpha, \boldsymbol{\beta}, \sigma^{2}\right) \propto \sigma^{-2}
\]</span> which is equivalent to a flat prior on
<span class="math inline">\(\left(\alpha, \boldsymbol{\beta}, \log \sigma^{2}\right)\)</span>.</p>
<p>We could deduce the following (conditional and marginal) posterior distributions</p>
<p><span class="math display">\[
\begin{aligned}
\alpha \mid \sigma^{2}, \mathbf{y} \sim \mathscr{N} &amp;\left(\hat{\alpha}, \sigma^{2} / n\right) \\
\boldsymbol{\beta} \mid \sigma^{2}, \mathbf{y} &amp; \sim \mathscr{N}_{p}\left(\hat{\boldsymbol{\beta}}, \sigma^{2}\left(\mathbf{X}^{\top} \mathbf{X}\right)^{-1}\right) \\
\sigma^{2} \mid \mathbf{y} &amp; \sim \mathscr{I} \mathscr{G}\left((n-p-1) / 2, s^{2} / 2\right)
\end{aligned}
\]</span></p>
<p>The corresponding Bayesian estimates of <span class="math inline">\(\alpha, \boldsymbol{\beta}\)</span> and <span class="math inline">\(\sigma^{2}\)</span> are thus given by
<span class="math display">\[
\mathbb{E}^{\pi}[\alpha \mid \mathbf{y}]=\hat{\alpha}, \quad \mathbb{E}^{\pi}[\boldsymbol{\beta} \mid \mathbf{y}]=\hat{\boldsymbol{\beta}} \quad \text { and } \quad \mathbb{E}^{\pi}\left[\sigma^{2} \mid \mathbf{y}\right]=\frac{s^{2}}{n-p-3}
\]</span>
respectively. Unsurprisingly, the Jeffreys prior estimate of <span class="math inline">\(\alpha\)</span> is the empirical mean. Further, the posterior expectation of <span class="math inline">\(\boldsymbol{\beta}\)</span> is the maximum likelihood estimate. Note also that the Jeffreys prior estimate of <span class="math inline">\(\sigma^{2}\)</span> is larger (and thus more pessimistic) than both the maximum likelihood estimate <span class="math inline">\(s^{2} / n\)</span> and the classical unbiased estimate <span class="math inline">\(s^{2} /(n-p-1)\)</span>.</p>
<p>不出所料，Jeffreys 对 <span class="math inline">\(\alpha\)</span> 的先验估计是经验平均值。 此外，<span class="math inline">\(\boldsymbol{\beta}\)</span> 的后验期望是最大似然估计。 另请注意，Jeffreys 对 <span class="math inline">\(\sigma^{2}\)</span> 的先验估计比最大似然估计 <span class="math inline">\(s^{2}/n\)</span> 和经典无偏估计 <span class="math inline">\(s^{2}\)</span> 更大（因此更悲观） <span class="math inline">\(/(np-1)\)</span>。</p>
</div>
<div id="zellners-g-prior-analysis" class="section level3" number="30.5.3">
<h3><span class="header-section-number">30.5.3</span> Zellner’s G-prior analysis</h3>
<p>Zellner提出的一种不同的非信息性方法，用于从贝叶斯角度处理线性回归。 这种方法是一种中间观点，其中一些关于 β 的先验信息可能可用，它被称为 Zellner 的 G-prior，“G”是 Zellner 在先验方差中使用的符号。</p>
<p><strong>Semi-noninformative Solution</strong></p>
<p>虑到线性回归模型的自然共轭先验具有严重的局限性，需要更精细的策略。 Zellner 的 G-prior 建模的核心思想是允许实验者引入（可能很弱）关于回归位置参数的信息，但绕过先验规范中最困难的方面，即先验相关结构的推导.这个结构在 Zellner 的提议中是固定的. Zellner 的 G-prior 因此被分解为 β 的（条件）高斯先验和 (α, σ2) 的inproper (Jeffreys) 先验。</p>
<p>We could deduce that, conditionally on <span class="math inline">\(\mathbf{y}, \mathbf{X}\)</span> and <span class="math inline">\(\sigma^{2}\)</span>, the parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> are independent and such that
<span class="math display">\[
\begin{array}{c}
\alpha \mid \sigma^{2}, \mathbf{y} \sim \mathscr{N}_{1}\left(\overline{\mathbf{y}}, \sigma^{2} / n\right) \\
\boldsymbol{\beta} \mid \mathbf{y}, \sigma^{2} \sim \mathscr{N}_{p}\left(\frac{g}{g+1}(\hat{\boldsymbol{\beta}}+\mathbf{X} \tilde{\boldsymbol{\beta}} / g), \frac{\sigma^{2} g}{g+1}\left\{\mathbf{X}^{\mathrm{T}} \mathbf{X}\right\}^{-1}\right)
\end{array}
\]</span>
where <span class="math inline">\(\hat{\boldsymbol{\beta}}=\left\{\mathbf{X}^{\mathrm{T}} \mathbf{X}\right\}^{-1} \mathbf{X}^{\mathrm{T}} \mathbf{y}\)</span> is the maximum likelihood (and least squares) estimator of <span class="math inline">\(\boldsymbol{\beta}\)</span>. The posterior independence between <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> is due to the fact that <span class="math inline">\(\mathbf{X}\)</span> is centered and that <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\boldsymbol{\beta}\)</span> are a priori independent.
Moreover, the posterior distribution of <span class="math inline">\(\sigma^{2}\)</span> is given by
<span class="math display">\[
\sigma^{2} \mid \mathbf{y} \sim I \mathscr{G}\left[(n-1) / 2, s^{2}+(\tilde{\boldsymbol{\beta}}-\hat{\boldsymbol{\beta}})^{\mathrm{T}} \mathbf{X}^{\mathrm{T}} \mathbf{X}(\tilde{\boldsymbol{\beta}}-\hat{\boldsymbol{\beta}}) /(g+1)\right]
\]</span>
where <span class="math inline">\(I \mathscr{G}(a, b)\)</span> is an inverse Gamma distribution with mean <span class="math inline">\(b /(a-1)\)</span> and where <span class="math inline">\(s^{2}=\left(\mathbf{y}-\overline{\mathbf{y}} \mathbf{1}_{n}-\mathbf{X} \hat{\boldsymbol{\beta}}\right)^{\mathrm{T}}\left(\mathbf{y}-\overline{\mathbf{y}} \mathbf{1}_{n}-\mathbf{X} \hat{\boldsymbol{\beta}}\right)\)</span> corresponds to the (classical) residual sum of squares.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="bayesian-theory.html#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(bayess)</span>
<span id="cb5-2"><a href="bayesian-theory.html#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Demo code https://rdrr.io/cran/bayess/f/</span></span>
<span id="cb5-3"><a href="bayesian-theory.html#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="bayesian-theory.html#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="do">## postmeancoeff posterior mean of the regression coefficients</span></span>
<span id="cb5-5"><a href="bayesian-theory.html#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="do">## postsqrtcoeff posterior standard deviation of the regression coefficients</span></span>
<span id="cb5-6"><a href="bayesian-theory.html#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="do">## log10bf log-Bayes factors against the full model</span></span>
<span id="cb5-7"><a href="bayesian-theory.html#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="do">## postmeansigma2 posterior mean of the variance of the model</span></span>
<span id="cb5-8"><a href="bayesian-theory.html#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="do">## postvarsigma2 posterior variance of the variance of the model</span></span>
<span id="cb5-9"><a href="bayesian-theory.html#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(faithful)</span>
<span id="cb5-10"><a href="bayesian-theory.html#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="fu">BayesReg</span>(faithful[,<span class="dv">1</span>],faithful[,<span class="dv">2</span>])</span></code></pre></div>
<pre><code>## 
##           PostMean PostStError Log10bf EvidAgaH0
## Intercept   3.4878      0.0304                  
## x1          1.0225      0.0303     Inf    (****)
## 
## 
## Posterior Mean of Sigma2: 0.2513
## Posterior StError of Sigma2: 0.3561</code></pre>
<pre><code>## $postmeancoeff
## [1] 3.487783 1.022509
## 
## $postsqrtcoeff
## [1] 0.03039825 0.03034252
## 
## $log10bf
##      [,1]
## [1,]  Inf
## 
## $postmeansigma2
## [1] 0.2513425
## 
## $postvarsigma2
## [1] 0.1268176</code></pre>
</div>
</div>
<div id="bayesian-linear-regression" class="section level2" number="30.6">
<h2><span class="header-section-number">30.6</span> Bayesian linear regression</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="bayesian-theory.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># suppressPackageStartupMessages(library(rstanarm))</span></span>
<span id="cb8-2"><a href="bayesian-theory.html#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># suppressPackageStartupMessages(library(bayestestR))</span></span>
<span id="cb8-3"><a href="bayesian-theory.html#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># suppressPackageStartupMessages(library(bayesplot))</span></span>
<span id="cb8-4"><a href="bayesian-theory.html#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># suppressPackageStartupMessages(library(insight))</span></span>
<span id="cb8-5"><a href="bayesian-theory.html#cb8-5" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb8-6"><a href="bayesian-theory.html#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="bayesian-theory.html#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="do">## use the BostonHousing data from mlbench package</span></span>
<span id="cb8-8"><a href="bayesian-theory.html#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlbench)</span>
<span id="cb8-9"><a href="bayesian-theory.html#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;BostonHousing&quot;</span>)</span>
<span id="cb8-10"><a href="bayesian-theory.html#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(BostonHousing)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    506 obs. of  14 variables:
##  $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
##  $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
##  $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
##  $ chas   : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 1 1 ...
##  $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
##  $ rm     : num  6.58 6.42 7.18 7 7.15 ...
##  $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
##  $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
##  $ rad    : num  1 2 2 3 3 3 5 5 5 5 ...
##  $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
##  $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
##  $ b      : num  397 397 393 395 397 ...
##  $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
##  $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="bayesian-theory.html#cb10-1" aria-hidden="true" tabindex="-1"></a>bost <span class="ot">&lt;-</span> BostonHousing[,<span class="fu">c</span>(<span class="st">&quot;medv&quot;</span>,<span class="st">&quot;age&quot;</span>,<span class="st">&quot;dis&quot;</span>,<span class="st">&quot;chas&quot;</span>)]</span>
<span id="cb10-2"><a href="bayesian-theory.html#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(bost)</span></code></pre></div>
<pre><code>##       medv            age              dis         chas   
##  Min.   : 5.00   Min.   :  2.90   Min.   : 1.130   0:471  
##  1st Qu.:17.02   1st Qu.: 45.02   1st Qu.: 2.100   1: 35  
##  Median :21.20   Median : 77.50   Median : 3.207          
##  Mean   :22.53   Mean   : 68.57   Mean   : 3.795          
##  3rd Qu.:25.00   3rd Qu.: 94.08   3rd Qu.: 5.188          
##  Max.   :50.00   Max.   :100.00   Max.   :12.127</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="bayesian-theory.html#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Classical linear regression model</span></span>
<span id="cb12-2"><a href="bayesian-theory.html#cb12-2" aria-hidden="true" tabindex="-1"></a>model_freq<span class="ot">&lt;-</span><span class="fu">lm</span>(medv<span class="sc">~</span>., <span class="at">data=</span>bost)</span>
<span id="cb12-3"><a href="bayesian-theory.html#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb12-4"><a href="bayesian-theory.html#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(model_freq)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   32.7      2.25      14.6   2.33e-40
## 2 age           -0.143    0.0198    -7.21  2.09e-12
## 3 dis           -0.246    0.265     -0.928 3.54e- 1
## 4 chas1          7.51     1.46       5.13  4.16e- 7</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="bayesian-theory.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## Bayesian regression</span></span>
<span id="cb14-2"><a href="bayesian-theory.html#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># library(rstanarm)</span></span>
<span id="cb14-3"><a href="bayesian-theory.html#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.r-bloggers.com/2020/04/bayesian-linear-regression/</span></span></code></pre></div>
</div>
<div id="item-response-theory" class="section level2" number="30.7">
<h2><span class="header-section-number">30.7</span> Item Response Theory</h2>
<div id="item-response-theory-1" class="section level3" number="30.7.1">
<h3><span class="header-section-number">30.7.1</span> Item response theory</h3>
<p>IRT (item response theory 项目反映理论) 楻型。IRT模型用来描述被试者能力和项目特性之间的关系。在现实生活中，由于 被试者的能力不能通过可观测的数据进行描述，所以IRT楛型用一个潛变量 <span class="math inline">\(\theta\)</span> 来表示，并考虑与项目相关的一组参数来分析正确回答 测试项目的概率。目前常见的IRT楛型有2-PL楻型和3-PL楻型。其具体表达式如下:</p>
<p><strong>two-parameter logistic (2-PL) Model</strong></p>
<p>2-PL楻型的表达式如下:
<span class="math display">\[
p_{i, j}\left(\theta_{i}\right)=\frac{1}{1+\exp \left[-D a_{j}\left(\theta_{i}-b_{j}\right)\right]}
\]</span>
其种 <span class="math inline">\(\theta_{i}\)</span> 是被试者能力的参数， <span class="math inline">\(a_{j}\)</span> 和 <span class="math inline">\(b_{j}\)</span> 分别代表的是题目的区分度参数和难度参数，D是为 <span class="math inline">\(1.7\)</span> 的常数。</p>
<p><strong>3-PL Model</strong></p>
<p>3-PL模型是在模型中引入了预测参数 <span class="math inline">\(c_{j}\)</span> ，该参数的含义是描述被试者在没有任何先验知识的情况下，回答正确某项目的概率。 常见的例子有学生在做选择题时，即使对该问题没有任何相关知识的获取，也有一定的概率答对该题目。
3-PL模型的表达式如下:
<span class="math display">\[
p_{i, j}\left(\theta_{i}\right)=c_{j}+\frac{1-c_{j}}{1+\exp \left[-D a_{j}\left(\theta_{i}-b_{j}\right)\right]}
\]</span>
<span class="math inline">\(c_{j}\)</span> 表示的是预测参数，其余的参数含义和2-PL模型中的一致。</p>
<p><strong>Assumptions</strong></p>
<p>IRT模型满足三条基本假设：</p>
<ol style="list-style-type: decimal">
<li>潜在单调性，IRT㮛型是连续严格单调的函数。</li>
<li>条件独立性，IRT模型认为给定 <span class="math inline">\(\theta_{i}\)</span> ，对于第 <span class="math inline">\(i\)</span> 个被试者， <span class="math inline">\(Y_{i, j}\)</span> 是独立的; 而对于不同的被试者，其各自的答莞 <span class="math inline">\(Y_{i}\)</span> 也是相互独 立的。</li>
<li>单维性假设，IRT模型认为某个测试的所有项目都是测量同一个潜在特质。</li>
</ol>
</div>
<div id="em-algorithm" class="section level3" number="30.7.2">
<h3><span class="header-section-number">30.7.2</span> EM algorithm</h3>
<p>极大似然估计是利用已知的样本结果，去反推最有可能（最大概率）导致这样结果的参数值，也就是在给定的观测变量下去估计参数值。然而现实中可能存在这样的问题，除了观测变量之外，还存在着未知的隐变量，因为变量未知，因此无法直接通过最大似然估计直接求参数值。EM算法是一种迭代算法，用于含有隐变量的概率模型的极大似然估计，或者说是极大后验概率估计。</p>
<p>引入一个例子来说明隐变量存在的问题。假设有3枚硬币，分别记作A，B，C。这些硬币正面出现的概率分别是π，p，q。我们的实验过程如下，先投掷硬币A，根据其结果选出硬币B和硬币C，正面选B，反面选C；然后投掷选出的硬币，此时出现正面记作1，出现反面记作0。在这个例子中我们观察到的变量只是B或者C的结果，而对A的结果并不知道，在这里A的结果也就是我们的隐变量。A的结果对最终的结果是有影响的，因此在估计参数时必须将A的结果考虑进去。</p>
<p>我们将观测变量表示为<span class="math inline">\(\mathrm{Y}=\left(\mathrm{Y}_{1}, \mathrm{Y}_{2}, \ldots, \mathrm{Y}_{\mathrm{n}}\right)\)</span>, 隐变量表示为<span class="math inline">\(\mathrm{Z}=\left(\mathrm{Z} 1, \mathrm{Z}_{2}, \ldots, \mathrm{Z}_{\mathrm{n}}\right)\)</span>, 则观测数据的似然函数可以表示为 <span class="math inline">\(P(Y \mid \theta)=\sum_{\mathrm{Z}} P(Z \mid \theta) P(Y \mid Z, \theta)\)</span></p>
<p>在这里 <span class="math inline">\(P(Y \mid \theta)\)</span> 是 <span class="math inline">\(P(Y, Z \mid \theta)\)</span> 的边缘概率，通过转换后可以表示成右边的形式，我们将其转换成对数形式，这样便于求联合概率
<span class="math display">\[
\begin{aligned}
L(\theta) &amp;=\log P(Y \mid \theta)=\log \sum_{Z} P(Y, Z \mid \theta) \\
&amp;=\log \left(\sum_{Z} P(Y \mid Z, \theta) P(Z \mid \theta)\right)
\end{aligned}
\]</span>
然而对于这样的式子直接根据极大化求 <span class="math inline">\(\theta\)</span> 的值是很困难的，因为这里还存在隐变量 <span class="math inline">\(\mathrm{Z}\)</span> ，在这里引入 <span class="math inline">\(\mathrm{EM}\)</span> 算法，通过迭代求解，假设 在第i 次迭代后 <span class="math inline">\(\theta\)</span> 的估计值为 <span class="math inline">\(\theta^{(i)}\)</span> 。我们希望新估计值能是 <span class="math inline">\(L(\theta)\)</span> 增加，通过迭代逐步的达到最大值。为此我们考豦第 <span class="math inline">\(+1\)</span> 步迭代后两者的 差:
<span class="math display">\[
L(\theta)-L\left(\theta^{(i)}\right)=\log \left(\sum_{Z} P(Y \mid Z, \theta) P(Z \mid \theta)\right)-\log P\left(Y \mid \theta^{(i)}\right)
\]</span>
利用Jensen不等式将上述式子展开并得到其下界（对数函数是凹函数）：
<span class="math display">\[
\begin{aligned}
L(\theta)-L\left(\theta^{(i)}\right) &amp;=\log \left(\sum_{Z} P\left(Y \mid Z, \theta^{(i)}\right) \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Y \mid Z, \theta^{(i)}\right)}\right)-\log P\left(Y \mid \theta^{(i)}\right) \\
&amp; \geqslant \sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right)}-\log P\left(Y \mid \theta^{(i)}\right) \\
&amp;=\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)}
\end{aligned}
\]</span>
<span class="math display">\[
B\left(\theta, \theta^{(i)}\right) \triangleq L\left(\theta^{(i)}\right)+\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)}
\]</span>
则有
<span class="math display">\[
L(\theta) \geqslant B\left(\theta, \theta^{(i)}\right)
\]</span>
在这里 <span class="math inline">\(B\left(\theta, \theta^{(i)}\right)\)</span> 是 <span class="math inline">\(L(\theta)\)</span> 的一个下界，而且由的表达式可知
<span class="math display">\[
L\left(\theta^{(i)}\right)=B\left(\theta^{(i)}, \theta^{(i)}\right)
\]</span></p>
<p>因此任何能使得 <span class="math inline">\(B\left(\theta, \theta^{(i)}\right)\)</span> 増大的 <span class="math inline">\(\theta\)</span> ，也能使得 <span class="math inline">\(L(\theta)\)</span> 增大。因此求 <span class="math inline">\(\theta\)</span> 值使得 <span class="math inline">\(B\left(\theta, \theta^{(i)}\right)\)</span> 增大就可以转变成求 <span class="math inline">\(\theta\)</span> 使得 <span class="math inline">\(L(\theta)\)</span> 增大，即求 <span class="math inline">\(\theta^{(i+1)}=\arg \max _{\theta} B\left(\theta, \theta^{(i)}\right)\)</span>
将上述式子展开可得 (在这里去掉常数项，因为常数项不会影响最终的结果)
<span class="math display">\[
\begin{aligned}
\theta^{(i+1)} &amp;=\arg \max _{\theta}\left(L\left(\theta^{(i)}\right)+\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log \frac{P(Y \mid Z, \theta) P(Z \mid \theta)}{P\left(Z \mid Y, \theta^{(i)}\right) P\left(Y \mid \theta^{(i)}\right)}\right) \\
&amp;=\arg \max _{\theta}\left(\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log (P(Y \mid Z, \theta) P(Z \mid \theta))\right) \\
&amp;=\arg \max _{\theta}\left(\sum_{Z} P\left(Z \mid Y, \theta^{(i)}\right) \log P(Y, Z \mid \theta)\right) \\
&amp;=\arg \max _{\theta} Q\left(\theta, \theta^{(i)}\right)
\end{aligned}
\]</span>
因此问题就演变成了求 <span class="math inline">\(Q\)</span> 函数的极大化。EM算法的整体思路就是初始化 <span class="math inline">\(\theta\)</span> 的值为 <span class="math inline">\(\theta^{(0)}\)</span> ，然后通过迭代去求得最终的 <span class="math inline">\(\theta\)</span> 值，迭代的终 条件应该是 <span class="math inline">\(L(\theta)\)</span> 的增加不明显 (具体可以设定一个增加值来控制) 。
下面的图可以形象的表示EM算法的迭代更新过程</p>
<p><img src="02_Plots/EMAlgorim.PNG" width="100%" style="display: block; margin: auto;" />
EM算法分为 E步和 M步</p>
<ul>
<li>E步：计算联合分布的条件概率期望。</li>
<li>M步：极大化对数似然函数的条件期望求解参数</li>
</ul>
<p>For 2-PL Model</p>
<ul>
<li>观测数据: 我们把被试者 <span class="math inline">\(i\)</span> 对项目 <span class="math inline">\(j\)</span> 的作答反映记为 <span class="math inline">\(y_{i, j}\)</span> ，又记向量 <span class="math inline">\(y_{i}=\left(y_{i 1}, y_{i 2}, \ldots \ldots, y_{i m}\right)\)</span> ，称为观测数据，其中 <span class="math inline">\(i=1,2, \ldots, N, j=1,2, \ldots, m\)</span> 。对于两级计分模型（在这里我们只考虑两级计分模型，即模型输出的结果只有二分类）， <span class="math inline">\(y_{i j}\)</span> 的取值有 0 和 1 ，分别表示被试者答错和答对题目。除了两级计分模型，还会有多级计分模型（即输出的结果为多分类）。</li>
<li>隐变量 (缺失数据) : 我们把每个被试者的潜在的不可观测的能力值称为缺失数据，记为 <span class="math inline">\(\theta=\left(\theta_{1}, \theta_{2}, \ldots \ldots, \theta_{N}\right) ，\)</span> 其中 <span class="math inline">\(\theta_{i}\)</span> 是被试者 <span class="math inline">\(i\)</span> 的暳在能力值。</li>
<li>完全数据: 完全数据对每一个被试者来说就是观宗数据加缺失数据，记作 <span class="math inline">\(\left[\left(y_{1}, \theta_{1}\right),\left(y_{2}, \theta_{2}\right), \ldots,\left(y_{N}, \theta_{N}\right)\right]\)</span> 。</li>
</ul>
<p>将EM算法应用到IRT模型中来，则E步和M步可以描述为：</p>
<ul>
<li>E步：即在给定缺失数据的分布，观察数据和参数初值时，求完全数据的对数似然函数的条件期望。</li>
<li>M步：即使用E步计算出的完全数据充分统计量的条件期望值，极大化完全数据的对数似然函数的条件期望求解参数的值。</li>
<li>不断的循环迭代E步和M步，直到参数估计收敛。</li>
</ul>
<p>在IRT模型当中，我们通常认为能力参数 <span class="math inline">\(\theta\)</span> 是连续随机变量，故可以取任意值。在EM算法估计参数的过程中，我们是能力参数 <span class="math inline">\(\theta\)</span> 为离散分布。能力值只能取 <span class="math inline">\(q_{1}, q_{2}, \ldots \ldots, q_{K}, \mathrm{~K}\)</span> 个值中的一个，且 <span class="math inline">\(P\left(\theta=q_{k}\right)=\pi_{k}\)</span> 。
在给定了反应矩阵 <span class="math inline">\(Y\)</span> 的情况下，假设项目参数 <span class="math inline">\(\Delta=\left[\delta_{1}, \ldots \ldots, \delta_{J}\right]\)</span> ，能力分布参数 <span class="math inline">\(\pi=\left(\Pi_{1}, \ldots \ldots, \Pi_{K}\right)\)</span> 。则E步中计 算的条件期望推到如下:
<span class="math display">\[
\begin{aligned}
Q\left(\Delta, \pi \mid \Delta^{(s)}, \pi^{(s)}\right) &amp;=\mathrm{E}_{Z_{\mathrm{mis}} \mid Z_{\mathrm{obs}}, \Delta^{(s)}, \pi^{(s)}}\left[\log L\left(\Delta, \pi \mid Z_{\mathrm{obs}}, Z_{\mathrm{mis}}\right)\right] \\
&amp;=\mathrm{E}_{\theta \mid Y, \Delta^{(s)}, \pi^{(s)}}[\log L(\Delta, \pi \mid Y, \theta)] \\
&amp;=\mathrm{E}_{\theta \mid Y, \Delta^{(s)}, \pi^{(s)}}\left[\log \prod_{i=1}^{N} f\left(\mathbf{y}_{i}, \theta_{i} \mid \Delta, \pi\right)\right] \\
&amp;=\sum_{i=1}^{N} \mathrm{E}_{\theta_{i} \mid \mathbf{y}_{i}, \Delta^{(s)}, \pi^{(s)}}\left[\log f\left(\mathbf{y}_{i}, \theta_{i} \mid \Delta, \pi\right)\right]
\end{aligned}
\]</span>
对上面的公式做一些转换表示为:
<span class="math display">\[
Q\left(\Delta, \pi \mid \Delta^{(s)}, \pi^{(s)}\right)=\phi(\Delta)+\psi(\pi)
\]</span>
其中 <span class="math inline">\(\phi(\Delta)\)</span> 和 <span class="math inline">\(\psi(\pi)\)</span> 的表达式如下:
<span class="math display">\[
\begin{array}{c}
\phi(\Delta)=\sum_{k=1}^{K} \sum_{j=1}^{J}\left\{\log \left[P\left(q_{k}, \delta_{j}\right)\right] r_{j k}^{(s)}+\log \left[Q\left(q_{k}, \delta_{j}\right)\right]\left(n_{k}^{(s)}-r_{j k}^{(s)}\right)\right\} \\
\end{array}
\]</span>
<span class="math display">\[
\psi(\pi)=\sum_{k=1}^{K} \log \left(\pi_{k}\right) n_{k}^{(s)}
\]</span></p>
<p>其中:
<span class="math display">\[
\begin{aligned}
n_{k}^{(s)} &amp;=\sum_{i=1}^{N} \frac{f\left(\mathbf{y}_{i} \mid q_{k}, \Delta^{(s)}\right) \pi_{k}^{(s)}}{\sum_{k^{\prime}=1}^{K} f\left(\mathbf{y}_{i} \mid q_{k^{\prime}}, \Delta^{(s)}\right) \pi_{k^{\prime}}^{(s)}} \\
r_{j k}^{(s)} &amp;=\sum_{i=1}^{N} \frac{y_{i j} f\left(\mathbf{y}_{i} \mid q_{k}, \Delta^{(s)}\right) \pi_{k}^{(s)}}{\sum_{k^{\prime}=1}^{K} f\left(\mathbf{y}_{i} \mid q_{k^{\prime}}, \Delta^{(s)}\right) \pi_{k^{\prime}}^{(s)}} \\
f\left(\mathbf{y}_{i} \mid q_{k}, \Delta^{(s)}\right) &amp;=\prod_{j=1}^{J} P\left(q_{k}, \delta_{j}^{(s)}\right)^{y_{i j}}\left[1-P\left(q_{k}, \delta_{j}^{(s)}\right)\right]^{1-y_{i j}}
\end{aligned}
\]</span>
在上面式子中的 <span class="math inline">\(n_{k}^{(s)}\)</span> 可以理解为在 <span class="math inline">\(N\)</span> 个被试者中能加水平为 <span class="math inline">\(q_{k}\)</span> 的被试数目的期望 (即能力为 <span class="math inline">\(q_{k}\)</span> 的被试者的个数)， <span class="math inline">\(r_{j k}^{(s)}\)</span> 可 以理解为在 <span class="math inline">\(N\)</span> 个被试者中具有能力水平 <span class="math inline">\(q_{k}\)</span> 的被试者答对第 <span class="math inline">\(j\)</span> 个项目的个数。 <span class="math inline">\(n_{k}^{(s)}\)</span> 和 <span class="math inline">\(r_{j k}^{(s)}\)</span> 都是人工数据。</p>
<p>应用EM算法的第 <span class="math inline">\(s\)</span> 步迭代中
E步: 利用第 <span class="math inline">\(s-1\)</span> 步得到的参数估计值 <span class="math inline">\(\Delta^{(s)}\)</span> 和 <span class="math inline">\(\pi_{k}^{(s)}\)</span> 计算 <span class="math inline">\(n_{k}^{(s)}\)</span> 和 <span class="math inline">\(r_{j k}^{(s)}\)</span> (首次迭代时初始化 <span class="math inline">\(\Delta^{(0)}\)</span> 和 <span class="math inline">\(\pi_{k}^{(0)}\)</span> 的值) 。
M步: 将E步计算出的 <span class="math inline">\(n_{k}^{(s)}\)</span> 和 <span class="math inline">\(r_{j k}^{(s)}\)</span> 代入到 <span class="math inline">\(\phi(\Delta)\)</span> 和 <span class="math inline">\(\psi(\pi)\)</span> 中，对两项分别极大化可得参数 <span class="math inline">\(\Delta\)</span> 和 <span class="math inline">\(\pi\)</span> 的估计值 <span class="math inline">\(\Delta^{(s+1)}\)</span> 和 <span class="math inline">\(\pi_{k}^{(s+1)}\)</span> 具体的求解如下:
<span class="math display">\[
\pi_{k}^{(s+1)}=\frac{n_{k}^{(s)}}{\sum_{k^{\prime}=1}^{K} n_{k^{\prime}}^{(s)}}
\]</span>
<span class="math inline">\(\pi_{k}^{(s+1)}\)</span> 的值可以直接用上述表达式求出
而对于 <span class="math inline">\(\Delta^{(s+1)}\)</span> 在这里要用牛顿-拉弗逊方法求解。</p>
<p>EM算法估计IRT模型的步骤如下:</p>
<ol style="list-style-type: decimal">
<li>E步:
首先确定 <span class="math inline">\(q_{k}\)</span> 和 <span class="math inline">\(\pi_{k}\)</span>; 用前一次迭代参数 <span class="math inline">\(\Delta^{(s)}\)</span> 和 <span class="math inline">\(\pi_{k}^{(s)}\)</span> 求出 <span class="math inline">\(n_{k}^{(s)}\)</span> 和 <span class="math inline">\(r_{j k}^{(s)}\)</span> 。</li>
<li>M步:
计算<span class="math inline">\(\delta_{j}^{(s+1)}\)</span>和<span class="math inline">\(\pi^{(s+1)}\)</span></li>
<li>重曷E步和M步直到项目参数收敛为止。</li>
</ol>
</div>
<div id="mcmc-algorithm" class="section level3" number="30.7.3">
<h3><span class="header-section-number">30.7.3</span> MCMC algorithm</h3>
<p>在MCMC算法中，为了在一个指定的分布上采样，根据马尔可夫过程，首先从任一状态出发，模拟马尔可夫过程，不断进行状态转移，最终收敛到平稳分布。用MCMC算法在这里估计参数，事实上就是建立一条参数的马尔科夫链，根据参数的状态转移矩阵来输出马尔科夫链上的样本，当马尔科夫链到一定长度时就会开始收敛于某一值。</p>
<p>首先来看看MCMC算法在 <span class="math inline">\(2-\mathrm{PL}\)</span> 模型上的参数估计步骤:
1) 取模型参数的先验分布: <span class="math inline">\(\theta N(0,1), \log (a) N(0,1), b N(0,1)\)</span> ，则初始化被试能力参数，项目参数的初始值 <span class="math inline">\(\theta_{0}=0, a_{0}=1, b_{0}=0\)</span> 。</p>
<ol start="2" style="list-style-type: decimal">
<li><p>根据项目参数初值 <span class="math inline">\(a_{0}, b_{0}\)</span> ，估计被试者的能力参数 <span class="math inline">\(\theta_{1}\)</span> 。
各被试的能力参数 <span class="math inline">\(\theta_{*}\)</span> 独立地从建议性分布 <span class="math inline">\(q_{\theta}\)</span> 中选取，我们去被试能力参数的建议分布为 <span class="math inline">\(\theta_{*} N\left(\theta_{0}, c_{\theta}^{2}\right)\)</span> 。其中一般 <span class="math inline">\(c_{\theta}=1.1\)</span> 。
计算从状态 <span class="math inline">\(\theta_{0}\)</span> 转移到状态 <span class="math inline">\(\theta_{1}\)</span> 的接受概率 <span class="math inline">\(a\left(\theta_{0}, \theta_{*}\right)=\min \left(1, R_{\theta}^{0}\right)\)</span> ，由它来决定是否发生状态的转移。
<span class="math display">\[
R_{\theta} 0=\frac{\left[\prod_{j} p_{i j}\left(\theta_{i}^{*}, a_{j}^{0}, b_{j}^{0}\right)^{x_{i j}}\left(1-p_{i j}\left(\theta_{i}^{*}, a_{j}^{0}, b_{j}^{0}\right)\right)^{1-x_{i j}}\right] \exp -\frac{1}{2 \sigma_{\theta}^{2}}\left(\theta_{i}^{*}\right)^{2}}{\left[\prod_{j} p_{i j}\left(\theta_{i}^{0}, a_{j}^{0}, b_{j}^{0}\right)^{x_{y_{y}}}\left(1-p_{i j}\left(\theta_{i}^{0}, a_{j}^{0}, b_{j}^{0}\right)\right)^{1-x_{y}}\right] \exp -\frac{1}{2 \sigma_{\theta}^{2}}\left(\theta_{i}^{0}\right)^{2}}
\]</span>
其中
<span class="math display">\[
p_{i j}\left(\theta_{i}, a_{j}^{0}, b_{j}^{0}\right)=\frac{1}{1+\exp \left[-1.7 a_{i}^{0}\left(\theta_{i}+b_{i}^{0}\right)\right]}
\]</span>
生成随机数 <span class="math inline">\(r_{1} U(0,1)\)</span> ，比较 <span class="math inline">\(r_{1}\)</span> 与接受概率 <span class="math inline">\(a\left(\theta_{0}, \theta_{*}\right)\)</span> 的大小，进行状态转移判断:
若 <span class="math inline">\(a\left(\theta_{0}, \theta_{*}\right) \geq r_{1}\)</span> ，则有 <span class="math inline">\(\theta_{1}=\theta_{*}\)</span> ；否则 <span class="math inline">\(\theta_{1}=\theta_{*}\)</span> 。</p></li>
<li><p>根据止骤 (2) 计算出来的被试能力参数 <span class="math inline">\(\theta_{1}\)</span> ，估计项目参数 <span class="math inline">\(a_{1}, b_{1}\)</span> 。
各项目的区分度参数和难度参数 <span class="math inline">\(a_{*}, b_{*}\)</span> 分别独立地从建议分布 <span class="math inline">\(q_{a}, q_{b}\)</span> 中选取，我们取区分度参数和难度参数的建议分布为 <span class="math inline">\(\log \left(a_{*}\right) N\left(a_{0}, c_{a}^{2}\right), b * N\left(b_{0}, c_{b}^{2}\right)\)</span>, 其中 <span class="math inline">\(c_{a}=0.3, c_{b}=0.3\)</span> 。
计算从状态 <span class="math inline">\(\left(a_{0}, b_{0}\right)\)</span> 转移至状态 <span class="math inline">\(\left(a_{*}, b_{*}\right)\)</span> 的接收概率 <span class="math inline">\(\alpha\left(a_{0}, b_{0}, a_{*}, b_{*}\right)=\min \left(1, R_{a, b}^{0}\right)\)</span> ，由它来决定是否发生状态的 转移。
<span class="math inline">\(R_{a, b} 0=\frac{\left[\prod_{j} p_{i j}\left(\theta_{i}^{1}, a_{j}^{*}, b_{j}^{*}\right)^{x_{j}}\left(1-p_{i j}\left(\theta_{i}^{1}, a_{j}^{*}, b_{j}^{*}\right)\right)^{1-x_{j}}\right] \exp -\frac{1}{2 \sigma_{b}^{2}}\left(b_{j}^{*}\right)^{2} \frac{1}{a_{j}^{*}} \exp -\frac{1}{2 \sigma_{a}^{2}} \log \left(a_{j}^{*}\right)^{2}}{\left[\prod_{j} p_{i j}\left(\theta_{i}^{1}, a_{j}^{0}, b_{j}^{0}\right)^{x_{j}}\left(1-p_{i j}\left(\theta_{i}^{1}, a_{j}^{0}, b_{j}^{0}\right)\right)^{1-x_{j}}\right] \exp -\frac{1}{2 \sigma_{b}^{2}}\left(b_{j}^{0}\right)^{2} \frac{1}{a_{j}^{0}} \exp -\frac{1}{2 \sigma_{a}^{2}} \log \left(a_{j}^{0}\right)^{2}} \times \frac{a_{j}^{0}}{a_{j}^{*}}\)</span>
其中
<span class="math display">\[
p_{i j}\left(\theta_{i}^{1}, a_{j}, b_{j}\right)=\frac{1}{1+\exp \left[-1.7 a_{j}\left(\theta_{i}^{1}+b_{j}\right)\right]}
\]</span>
生成随机数 <span class="math inline">\(r_{2} U(0,1)\)</span> ，比较 <span class="math inline">\(r_{2}\)</span> 与 <span class="math inline">\(\alpha\left(a_{0}, b_{0}, a_{*}, b_{*}\right)\)</span> 的大小, 进行状态转移判断:
若 <span class="math inline">\(\alpha\left(a_{0}, b_{0}, a_{*}, b_{*}\right) \geq r_{2}\)</span> ，则 <span class="math inline">\(a_{1}=a_{*}, b_{1}=b_{*}\)</span>; 否则 <span class="math inline">\(a_{1}=a_{0}, b_{1}=b_{0}\)</span> 。</p></li>
<li><p>重复步骤 (2) 和 (3) <span class="math inline">\(n\)</span> 次，删除为首的 <span class="math inline">\(w\)</span> 次，取剩余的 <span class="math inline">\(m=n-w\)</span> 次迭代所得结果的均值即为参数的估计值。</p></li>
<li><p>步骤 (4) 会生成一条长度为 <span class="math inline">\(n\)</span> 的 Markov 链，重复步骤 (4) <span class="math inline">\(i\)</span> 次 ( <span class="math inline">\(i\)</span> 次一般小于 5 )，即可以得到 <span class="math inline">\(i\)</span> 条 Markov 链, 将这 <span class="math inline">\(i\)</span> 条链得到的参数估计值的均值为最终的参数估计值。</p></li>
</ol>
</div>
<div id="unidimensional-irt-models" class="section level3" number="30.7.4">
<h3><span class="header-section-number">30.7.4</span> Unidimensional IRT Models</h3>
<p><strong>For Dichotomously Scored Responses</strong></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regularization-penalized-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="smoothing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/31-Bayesian-Analysis.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
