[["bayesian-theory.html", "Chapter 31 Bayesian Theory 31.1 Introduction of Bayesian 31.2 Parameter estimates 31.3 Prior Distributions 31.4 MCMC 31.5 Regression and Variable Selection 31.6 Bayesian linear regression", " Chapter 31 Bayesian Theory 31.1 Introduction of Bayesian 31.1.1 Frequency and Bayesian A set of random samples, the frequency school believes that the overall parameters are constant, and the samples are obtained randomly; The Bayesian school believes that the overall parameters are random, and the sample obtained is constant. The Bayesian school does not care much about the correct parameters, but needs to obtain the posterior by adding the acquired data to the prior knowledge  .  ,   The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameters value. More narrow posterior distributions can be obtained by collecting more data.    \\[\\mathrm{P}(\\theta | \\text{data})\\]  31.1.2 Bayes Rule \\[ \\overbrace{p(\\theta/D)}^{Posterior}=\\frac{\\overbrace{p(D/\\theta)}^{Likelihood}.\\overbrace{p(\\theta)}^{Prior}}{\\underbrace{p(D)}_{Evidence}} \\] \\[ P(H\\mid E)={\\frac {P(E\\mid H)\\cdot P(H)}{P(E)}} \\] \\(P(H)\\) EH.   marginalizationAP(A)BP(B) \\[\\textstyle P(H\\mid E)\\] ABP(A|B) BA,The posterior distribution summarises our uncertainty over the value of a parameter. If the distribution is narrower, then this indicates that we have greater confidence in our estimates of the parameters value. More narrow posterior distributions can be obtained by collecting more data. The posterior probability is the probability of the parameters \\(\\theta\\) given the evidence \\(X: p(\\theta \\mid X)\\) It contrasts with the likelihood function, which is the probability of the evidence given the parameters: \\(p(X \\mid \\theta)\\) \\[\\textstyle P(E\\mid H)\\]    31.1.3 Bootstrap Bootstrap Bradley Efron70 resample bootstrap BootstrapCross-Validation Bootstrap bootstrapkk Bootstrap VS Monte Carlo Bootstrap,estimator. estimator variation or distribution. Monte Carlo algorithm, algorithmMonte Carlo Bootstrap Monte Carlo. {Mente Carlo closed form Mente Carlo Mente Carlo} 31.1.4 Posterior Distribution Given an independent and identically distributed (later abbreviated as iid) sample \\(\\mathscr{D}_{n}=\\left(x_{1}, \\ldots, x_{n}\\right)\\) from a density \\(f(x \\mid \\theta)\\), depending upon an unknown parameter \\(\\theta \\in \\Theta\\), for instance the mean \\(\\mu\\) of the benchmark normal distribution, the associated likelihood function is \\[ \\ell\\left(\\theta \\mid \\mathscr{D}_{n}\\right)=\\prod_{i=1}^{n} f\\left(x_{i} \\mid \\theta\\right) \\] This function of \\(\\theta\\) is a fundamental entity for the analysis of the information provided about \\(\\theta\\) by the sample \\(\\mathscr{D}_{n}\\), and Bayesian analysis relies on (2.1) to draw its inference on \\(\\theta\\). For instance, when \\(\\mathscr{D}_{n}\\) is a normal \\(\\mathscr{N}\\left(\\mu, \\sigma^{2}\\right)\\) sample of size \\(n\\) and \\(\\theta=\\left(\\mu, \\sigma^{2}\\right)\\), we get \\[ \\begin{array}{l} \\ell\\left(\\theta \\mid \\mathscr{D}_{n}\\right)=\\prod_{i=1}^{n} \\exp \\left\\{-\\left(x_{i}-\\mu\\right)^{2} / 2 \\sigma^{2}\\right\\} / \\sqrt{2 \\pi} \\sigma\\\\ \\propto \\exp \\left\\{-\\sum_{i=1}\\left(x_{i}-\\mu\\right)^{2} / 2 \\sigma^{2}\\right\\} / \\sigma^{n} \\\\ \\propto \\exp \\left\\{-\\left(n \\mu^{2}-2 n \\bar{x} \\mu+\\sum_{i=1} x_{i}^{2}\\right) / 2 \\sigma^{2}\\right\\} / \\sigma^{n} \\\\ \\propto \\exp \\left\\{-\\left[n(\\mu-\\bar{x})^{2}+s^{2}\\right] / 2 \\sigma^{2}\\right\\} / \\sigma^{n} \\end{array} \\] where \\(\\bar{x}\\) denotes the empirical mean and where \\(s^{2}\\) is the sum \\(\\sum_{i=1}^{n}\\left(x_{i}-\\bar{x}\\right)^{2}\\). This shows in particular that \\(\\bar{x}\\) and \\(s^{2}\\) are sufficient statistics. The major input of the Bayesian approach, compared with a traditional likelihood approach, is that it modifies the likelihood function into a posterior distribution, which is a valid probability distribution on \\(\\Theta\\) defined by the classical Bayes formula (or theorem) \\[ \\pi\\left(\\theta \\mid \\mathscr{D}_{n}\\right)=\\frac{\\ell\\left(\\theta \\mid \\mathscr{D}_{n}\\right) \\pi(\\theta)}{\\int \\ell\\left(\\theta \\mid \\mathscr{D}_{n}\\right) \\pi(\\theta) \\mathrm{d} \\theta} \\] The factor \\(\\pi(\\theta)\\) is called the prior and it obviously has to be chosen to start the analysis. 31.1.5 Bayesian Credible Intervals Bayesian approach is a complete inferential approach. Therefore, it covers confidence evaluation, testing, prediction, model checking, and point estimation. As with everything else, the derivation of the confidence intervals (or confidence regions in more general settings) is based on the posterior distribution \\(\\pi\\left(\\theta \\mid \\mathscr{D}_{n}\\right) .\\) Since the Bayesian approach processes \\(\\theta\\) as a random variable, a natural definition of a confidence region on \\(\\theta\\) is to determine \\(C\\left(\\mathscr{D}_{n}\\right)\\) such that \\[ \\pi\\left(\\theta \\in C\\left(\\mathscr{D}_{n}\\right) \\mid \\mathscr{D}_{n}\\right)=1-\\alpha \\] where \\(\\alpha\\) is a predetermined level such as \\(0.05\\) The important difference with a traditional perspective is that the integration is done over the parameter space, rather than over the observation space. The quantity \\(1-\\alpha\\) thus corresponds to the probability that a random \\(\\theta\\) belongs to this set \\(C\\left(\\mathscr{D}_{n}\\right)\\), rather than to the probability that the random set contains the true value of \\(\\theta\\). Given this drift in the interpretation of a confidence set (rather called a credible set by Bayesians), the determination of the best credible set turns out to be easier than in the classical sense: indeed, this set simply corresponds to the values of \\(\\theta\\) with the highest posterior values, \\[ C\\left(\\mathscr{D}_{n}\\right)=\\left\\{\\theta ; \\pi\\left(\\theta \\mid \\mathscr{D}_{n}\\right) \\geq k_{\\alpha}\\right\\} \\] where \\(k_{\\alpha}\\) is determined by the coverage constraint. This region is called the highest posterior density \\((\\mathrm{HPD})\\) region. 31.2 Parameter estimates  ()  linear regression, W), WW)yp(y|x,D)WW.MCMC   Wposterior inference.  Maximum likelihood estimation (ML) (point estimation) Maximum a posteriori estimationMAP) (point estimation) Bayesian Model (distribution estimation) 31.2.1 Maximum likelihood estimation point estimation, P(D|W), W.   M ijjjij  (iid)  x1,x2,,xN p(x;)  p(X;) \\[ p(X;\\theta)\\equiv p(x_1,x_2,...,x_N;\\theta)=\\prod_{k=1}^Np(x_k;\\theta) \\] (Maximum Likelihood,ML) \\[ \\hat{\\theta}_{ML}=arg\\max_{\\theta}\\prod_{k=1}^Np(x_k;\\theta) \\] \\[\\theta^{\\text{ML}}\\] ,0 \\[ \\frac{\\partial \\prod_{k=1}^Np(x_k;\\theta)}{\\partial\\theta}=0 \\]  \\[ L(\\theta)\\equiv ln\\prod_{k=1}^Np(x_k;\\theta) \\] \\[ \\frac{\\partial L(\\theta)}{\\partial \\theta}=\\sum_{k=1}^N \\frac{\\partial ln p(x_k;\\theta)}{\\partial \\theta}=\\sum_{k=1}^N\\frac{1}{p(x_k;\\theta)} \\frac{\\partial p(x_k;\\theta)}{\\partial \\theta}=0 \\] \\[_0\\]p(x;)     \\[\\lim_{N \\to \\infty}E[\\hat{\\theta}_{ML}]=\\theta_0\\], ** ^MLX ^ML ** \\[\\lim_{N \\to \\infty}prob\\{ \\lVert \\hat{\\theta}_{ML}- \\theta_0 \\rVert \\leqslant \\epsilon\\} = 1\\],: \\[\\lim_{N \\to \\infty} E \\lVert \\hat{\\theta}_{ML}- \\theta_0 \\rVert^2 = 0\\], ML  -0-. \\[N \\to \\infty\\]N. 31.2.2 Maximum a posteriori estimation  {x1,x2,,xN}   X p(|X). Maximum a posteriori estimation (MAP). MLprior, P() \\[ p(\\theta|X)=\\frac{p(\\theta)p(X|\\theta)}{p(X)} \\] Xp(X)p(X) \\[ \\hat{\\theta}_{MAP}=arg\\max_{\\theta}p(\\theta|X)=arg\\max_{\\theta}p(\\theta)p(X|\\theta) \\] MLp(|X)0 \\[ \\frac{p(\\theta|X)}{\\partial\\theta}=\\frac{p(\\theta)p(X|\\theta}{\\partial\\theta}=0 \\] p(X|)p(X;) MAPMLMAPMLp(). MAPp()p()MAPMLp()p()MAPML MAP and MLE The similarity of maximum a posteriori estimator (MAP) \\[ \\hat{\\theta}=\\arg \\max _{\\theta} \\pi\\left(\\theta \\mid \\mathscr{D}_{n}\\right)=\\arg \\max _{\\theta} \\pi(\\theta) \\ell\\left(\\theta \\mid \\mathscr{D}_{n}\\right) \\] with the maximum likelihood estimator (MLE): The influence of the prior distribution \\(\\pi(\\theta)\\) on the estimate progressively disappears as the number of observations \\(n\\) increases, and the MAP estimator often recovers the asymptotic properties of the MLE. For normaldata, since the posterior distribution on \\(\\sigma^{-2}\\) is a \\(\\mathscr{G}(32,1.82)\\) distribution, the posterior expectation of \\(\\sigma^{-2}\\) given Illingworths experimental data is \\(32 / 1.82=17.53\\). The posterior expectation of \\(\\sigma^{2}\\) requires a supplementary effort in order to derive the mean of an inverse gamma distribution (see Exercise 2.2), namely \\[ \\mathbb{E}^{\\pi}\\left[\\sigma^{2} \\mid \\mathscr{D}_{n}\\right]=1.82 /(33-1)=0.057 \\] Similarly, the MAP estimate is given here by \\[ \\arg \\max _{\\theta} \\pi\\left(\\sigma^{2} \\mid \\mathscr{D}_{n}\\right)=1.82 /(33+1)=0.054 \\] These values therefore reinforce our observation that the Michelson-Morley precision is not appropriate for the Illingworth experiment, which is much more precise indeed. 31.2.3 Bayesian Model MAPlimitation . XX overfitting. DX D p(x)xp(x|D)p(x|D)p(x)xx p(x) p(x)p(x|), . p(x|)x  x   p() p(|D) p(|D) p(|D) p(x|D)p(x|)p(|D) \\[ p(x|D)=\\int p(x,\\theta|D) d\\theta=\\int p(x|\\theta,D)p(\\theta|D)d\\theta \\] x  D xD, p(x|,D)p(x|),  \\[ p(x|D)=\\int p(x|\\theta)p(\\theta|D)d\\theta \\] p(x|D) Dx p(x|) p(x), p(x|), p(x|) x p(|D) p()p(|D) (p(|D)) \\[ p(\\theta|D)=\\frac{p(D|\\theta)p(\\theta)}{p(D)}=\\frac{p(D|\\theta)p(\\theta)}{\\int p(D|\\theta)p(\\theta)d\\theta} \\] \\[ p(D|\\theta)=\\prod_{k=1}^N p(x_k|\\theta) \\] 31.2.3.1 Full-Bayesian MAP Step 1: likelihoodpriorposterior. Step 2: xposterior  Laplace GibbsHMC 31.3 Prior Distributions 31.3.1 Conjugate Prior Distributions An important feature of conjugate priors is that one has a priori to select two hyperparameters, e.g., a mean and a variance in the normal case. On the one hand, this is an advantage when using a conjugate prior, namely that one has to select only a few parameters to determine the prior distribution. On the other hand, this is a drawback in that the information known a priori on \\(\\mu\\) may be either insufficient to determine both parameters or incompatible with the structure imposed by conjugacy. Figure 31.1: Conjugate priors for the most common statistical families 31.3.2 Non-informativ Priors :   Bayes   31.3.2.1 Jeffreys Prior JeffreysJeffreys  invariant g() Fisher 31.3.2.2 Reference Prior Reference priorJeffreys prior Reference priorKullbackLeibler divergencereference prior KullbackLeibler divergencereference priornoninformative prior 31.4 MCMC MCMCMCMonte Carlo SimulationMCMarkov Chain MC 31.4.1 Monte Carlo Simulation  \\[\\theta = \\int_a^b f(x)dx\\] x[a,b]p(x) \\[ \\theta = \\int_a^b f(x)dx = \\int_a^b \\frac{f(x)}{p(x)}p(x)dx \\approx \\frac{1}{n}\\sum\\limits_{i=0}^{n-1}\\frac{f(x_i)}{p(x_i)} \\] x[a,b] \\(p(x_i) = 1/(b-a)\\) \\[ \\frac{1}{n}\\sum\\limits_{i=0}^{n-1}\\frac{f(x_i)}{1/(b-a)} = \\frac{b-a}{n}\\sum\\limits_{i=0}^{n-1}f(x_i) \\] 31.4.2  xxnx nx uniform(0,1)(0,1)uniform(0,1) \\[(Z_1,Z_2)\\] uniform(0,1)\\[(X_1,X_2)\\] \\[ Z_1 = \\sqrt{-2 ln X_1}cos(2\\pi X_2) \\] \\[ Z_2 = \\sqrt{-2 ln X_1}sin(2\\pi X_2) \\] tFBetaGammauniform(0,1) 31.4.3 - - p(x)  q(x)  p(x) q(x) proposal distribution  q(x) k p(x)  kq(x) q(x)z0 \\[(0, kq(z_0))\\] u. uz0nz0,z1,zn1, \\[ \\frac{1}{n}\\sum\\limits_{i=0}^{n-1}\\frac{f(z_i)}{p(z_i)} \\] 31.4.4 Markov Chain  \\[...X_{t-2}, X_{t-1}, X_{t}, X_{t+1},...\\] Xt+1Xt \\[ P(X_{t+1} |...X_{t-2}, X_{t-1}, X_{t} ) = P(X_{t+1} | X_{t}) \\]  Bull market, Bear marketStagnant market0.025P\\[P(i,j)\\] \\[P(j|i)\\] ij0 1, 2.  \\[ P=\\left( \\begin{array}{ccc} 0.9&amp;0.075&amp;0.025 \\\\ 0.15&amp;0.8&amp; 0.05 \\\\ 0.25&amp;0.25&amp;0.5 \\end{array} \\right) \\] [0.625 0.3125 0.0625]  31.4.5  P,  \\(\\lim_{n \\to \\infty}P_{ij}^n\\) i 1. \\(\\lim_{n \\to \\infty}P_{ij}^n = \\pi(j)\\) 2. \\(\\lim_{n \\to \\infty}P^n = \\left( \\begin{array}{ccc} \\pi(1)&amp;\\pi(2)&amp;\\ldots&amp;\\pi(j)&amp;\\ldots \\\\ \\pi(1)&amp;\\pi(2)&amp;\\ldots&amp;\\pi(j)&amp;\\ldots \\\\ \\ldots&amp;\\ldots&amp;\\ldots&amp;\\ldots&amp;\\ldots \\\\ \\pi(1)&amp;\\pi(2)&amp;\\ldots&amp;\\pi(j)&amp;\\ldots \\\\ \\ldots&amp;\\ldots&amp;\\ldots&amp;\\ldots&amp;\\ldots \\end{array} \\right)\\) 3. \\(\\pi(j) = \\sum\\limits_{i=0}^{\\infty}\\pi(i)P_{ij}\\) 4. \\(\\pi\\) \\(\\pi P = \\pi\\)$  \\(\\pi = [\\pi(1),\\pi(2),...,\\pi(j),...]\\;\\; \\sum\\limits_{i=0}^{\\infty}\\pi(i) = 1\\)  id \\(\\{n \\mid n \\geq 1,P_{ii}^n&gt;0 \\}\\)  d=1d=1  0  \\(\\pi\\) 31.4.6   \\(\\pi_0(x)\\) , \\(\\pi_1(x)\\)i\\(\\pi_i(x)\\)n\\(\\pi(x)\\) \\[ \\pi_n(x) = \\pi_{n+1}(x) = \\pi_{n+2}(x) =... = \\pi(x) \\] \\(\\pi_i(x)\\) \\[ \\pi_i(x) = \\pi_{i-1}(x)P = \\pi_{i-2}(x)P^2 = \\pi_{0}(x)P^i \\] 0(x)x0 \\(P(x|x_0)\\) x1n \\((x_n,x_{n+1},x_{n+2},...)\\)  :  \\[P\\],  \\(n_{1},\\)  \\(n_{2}\\)  \\(x_{0}\\) for \\(t=0\\) to \\(n_{1}+n_{2}-1:\\)  \\(P\\left(x \\mid x_{t}\\right)\\)  \\(x_{t+1}\\)  \\(\\left(x_{n_{1}}, x_{n_{1}+1}, \\ldots, x_{n_{1}+n_{2}-1}\\right)\\)  ,PMCMC. 31.4.7 MCMC 31.4.7.1  , PP(x)i,j \\[ \\pi(i)P(i,j) = \\pi(j)P(j,i) \\] (x)P \\[ \\sum\\limits_{i=1}^{\\infty}\\pi(i)P(i,j) = \\sum\\limits_{i=1}^{\\infty} \\pi(j)P(j,i) = \\pi(j)\\sum\\limits_{i=1}^{\\infty} P(j,i) = \\pi(j) \\]  \\(\\pi P = \\pi\\) P(x),Q, \\[ \\pi(i)Q(i,j) \\neq \\pi(j)Q(j,i) \\]  \\(\\alpha(i,j)\\) , \\[ \\pi(i)Q(i,j)\\alpha(i,j) = \\pi(j)Q(j,i)\\alpha(j,i) \\] \\[\\alpha(i,j)\\] \\[ \\alpha(i,j) = \\pi(j)Q(j,i) \\] \\[ \\alpha(j,i) = \\pi(i)Q(i,j) \\] (x)P \\[ P(i,j) = Q(i,j)\\alpha(i,j) \\] \\(\\alpha(i,j)\\)[0,1]PQ 31.4.7.2 MCMC  \\(Q,\\)  \\(\\pi(x),\\)  \\(n_{1},\\)  \\(n_{2}\\)  \\(x_{0}\\) for \\(t=0\\) to \\(n_{1}+n_{2}-1\\) :  \\(Q\\left(x \\mid x_{t}\\right)\\)  \\(x_{*}\\)  \\(u \\sim\\)$ $\\(uniform [0,1]\\)  \\(u&lt;\\alpha\\left(x_{t}, x_{*}\\right)=\\pi\\left(x_{*}\\right) Q\\left(x_{*}, x_{t}\\right),\\)  \\(x_{t} \\rightarrow x_{*},\\)  \\(x_{t+1}=x_{*}\\) ,  \\(x_{t+1}=x_{t}\\)  \\(\\left(x_{n_{1}}, x_{n_{1}+1}, \\ldots, x_{n_{1}+n_{2}-1}\\right)\\)  c \\(\\alpha(x_t,x_{*})\\)0.1n1M-H 31.4.8 M-H M-HMetropolis-HastingsMetropolisHastingsMetropolis-HastingsM-H. M-HMCMC MCMC \\(\\pi(i)Q(i,j)\\alpha(i,j) = \\pi(j)Q(j,i)\\alpha(j,i)\\)  \\(\\alpha(i,j)\\) 0.1\\(\\alpha(j,i)\\)0.2 \\(\\pi(i)Q(i,j)\\times 0.1 = \\pi(j)Q(j,i)\\times 0.2\\) , 0.5 \\(\\pi(i)Q(i,j)\\times 0.5 = \\pi(j)Q(j,i)\\times 1\\)  \\[ \\alpha(i,j) = min\\{ \\frac{\\pi(j)Q(j,i)}{\\pi(i)Q(i,j)},1\\} \\] M-H  \\(Q,\\)  \\(\\pi(x),\\)  \\(n_{1},\\)  \\(n_{2}\\)  \\(x_{0}\\) for \\(t=0\\) to \\(n_{1}+n_{2}-1\\) :  \\(Q\\left(x \\mid x_{t}\\right)\\)  \\(x_{*}\\)  \\(u \\sim\\) uniform [0,1]  \\(u&lt;\\alpha\\left(x_{t}, x_{*}\\right)=\\min \\left\\{\\frac{\\pi(j) Q(j, i)}{\\pi(i) Q(i, j)}, 1\\right\\},\\)  \\(x_{t} \\rightarrow x_{*},\\)  \\(x_{t+1}=x_{*}\\)   \\(x_{t+1}=x_{t}\\)  \\(\\left(x_{n_{1}}, x_{n_{1}+1}, \\ldots, x_{n_{1}+n_{2}-1}\\right)\\)  , Q,  \\(Q(i, j)=Q(j, i)\\), \\[ \\alpha(i, j)=\\min \\left\\{\\frac{\\pi(j)}{\\pi(i)}, 1\\right\\} \\] M-H. M-H M-H\\(\\frac{\\pi(j)Q(j,i)}{\\pi(i)Q(i,j)}\\)\\(\\alpha(i,j)\\)1  Gibbs 31.4.9 Gibbs M-HM-HM-H P(x)i,j\\(\\pi(i)Q(i,j)\\alpha(i,j) = \\pi(j)Q(j,i)\\alpha(j,i)\\)(x)P,  \\(\\pi(x_1,x_2)\\)\\(A(x_1^{(1)},x_2^{(1)})\\)\\(B(x_1^{(1)},x_2^{(1)})\\) \\[ \\pi(x_1^{(1)},x_2^{(1)}) \\pi(x_2^{(2)} | x_1^{(1)}) = \\pi(x_1^{(1)})\\pi(x_2^{(1)}|x_1^{(1)}) \\pi(x_2^{(2)} | x_1^{(1)}) \\] \\[ \\pi(x_1^{(1)},x_2^{(2)}) \\pi(x_2^{(1)} | x_1^{(1)}) = \\pi(x_1^{(1)}) \\pi(x_2^{(2)} | x_1^{(1)})\\pi(x_2^{(1)}|x_1^{(1)}) \\]  \\[ \\pi(x_1^{(1)},x_2^{(1)}) \\pi(x_2^{(2)} | x_1^{(1)}) = \\pi(x_1^{(1)},x_2^{(2)}) \\pi(x_2^{(1)} | x_1^{(1)}) \\] \\[ \\pi(A) \\pi(x_2^{(2)} | x_1^{(1)}) = \\pi(B) \\pi(x_2^{(1)} | x_1^{(1)}) \\] ,  \\(x_{1}=x_{1}^{(1)}\\) ,  \\(\\pi\\left(x_{2} \\mid x_{1}^{(1)}\\right.)\\) ,  ! ,  \\(x_{2}=x_{2}^{(1)}\\) ,  \\(\\pi\\left(x_{1} \\mid x_{2}^{(1)}\\right.)\\)  ,  \\(C\\left(x_{1}^{(2)}, x_{2}^{(1)}\\right)\\),: \\[ \\pi(A) \\pi\\left(x_{1}^{(2)} \\mid x_{2}^{(1)}\\right)=\\pi(C) \\pi\\left(x_{1}^{(1)} \\mid x_{2}^{(1)}\\right) \\] ,  \\(\\pi\\left(x_{1}, x_{2}\\right)\\)  \\(P\\) : \\[ \\begin{array}{c} P(A \\rightarrow B)=\\pi\\left(x_{2}^{(B)} \\mid x_{1}^{(1)}\\right) \\text { if } x_{1}^{(A)}=x_{1}^{(B)}=x_{1}^{(1)} \\\\ P(A \\rightarrow C)=\\pi\\left(x_{1}^{(C)} \\mid x_{2}^{(1)}\\right) \\text { if } x_{2}^{(A)}=x_{2}^{(C)}=x_{2}^{(1)} \\\\ P(A \\rightarrow D)=0 \\text { else } \\end{array} \\] E,F \\[ \\pi(E)P(E \\to F) = \\pi(F)P(F \\to E) \\] 31.4.9.1 Gibbs Gibbs  \\(\\pi\\left(x_{1}, x_{2}\\right),\\)  \\(n_{1},\\)  \\(n_{2}\\)  \\(x_{1}^{(0)}\\)  \\(x_{2}^{(0)}\\) for \\(t=0\\) to \\(n_{1}+n_{2}-1\\):  \\(P\\left(x_{2} \\mid x_{1}^{(t)}\\right)\\)  \\(x_{2}^{t+1}\\)  \\(P\\left(x_{1} \\mid x_{2}^{(t+1)}\\right)\\)  \\(x_{1}^{t+1}\\)  \\(\\left\\{\\left(x_{1}^{\\left(n_{1}\\right)}, x_{2}^{\\left(n_{1}\\right)}\\right),\\left(x_{1}^{\\left(n_{1}+1\\right)}, x_{2}^{\\left(n_{1}+1\\right)}\\right), \\ldots,\\left(x_{1}^{\\left(n_{1}+n_{2}-1\\right)}, x_{2}^{\\left(n_{1}+n_{2}-1\\right)}\\right)\\right\\}\\)  ,  \\[ \\left(x_{1}^{(1)}, x_{2}^{(1)}\\right) \\rightarrow\\left(x_{1}^{(1)}, x_{2}^{(2)}\\right) \\rightarrow\\left(x_{1}^{(2)}, x_{2}^{(2)}\\right) \\rightarrow \\ldots \\rightarrow\\left(x_{1}^{\\left(n_{1}+n_{2}-1\\right)}, x_{2}^{\\left(n_{1}+n_{2}-1\\right)}\\right) \\] GibbsGibbsMCMCGibbsGibbsM-HGibbsGibbs,M-HGibbsMCMC 31.5 Regression and Variable Selection 31.5.1 Classical Least Squares Estimator  1973  500  n = 33  p = 8  x1 x2 x3 x4 x5  1  2 2x6 x7 x8  1 2 For caterpillar, where \\(n=33\\) and \\(p=8\\), we thus assume that the expected lognumber \\(y_{i}\\) of caterpillar nests per tree over an area is modeled as a linear combination of an intercept and eight predictor variables \\((i=1, \\ldots, n)\\), \\[ \\mathbb{E}\\left[y_{i} \\mid \\alpha, \\boldsymbol{\\beta}, \\sigma^{2}\\right]=\\alpha+\\sum_{j=1}^{8} \\beta_{j} x_{i j} \\] library(bayess) ## Demo code https://rdrr.io/cran/bayess/f/ data(caterpillar) y=log(caterpillar$y) X=as.matrix(caterpillar[,1:8]) vnames=names(caterpillar) par(mfrow=c(2,4),mar=c(4.2,2,2,1.2)) for (i in 1:8) plot(X[,i],y,xlab=vnames[i],pch=19, col=&quot;sienna4&quot;,xaxt=&quot;n&quot;,yaxt=&quot;n&quot;) S=readline(prompt=&quot;Type &lt;Return&gt; to continue : &quot;) ## Type &lt;Return&gt; to continue : The parameter \\(\\boldsymbol{\\beta}\\) can obviously be estimated via maximum likelihood estimation. In order to avoid non-identifiability and uniqueness problems, we assume that \\(\\left[\\mathbf{1}_{n} \\quad \\mathbf{X}\\right]\\) is of full \\(\\operatorname{rank}\\), that is, \\(\\operatorname{rank}\\left[\\mathbf{1}_{n} \\quad \\mathbf{X}\\right]=p+1\\). This also means that there is no redundant structure among the explanatory variables. We suppose in addition that \\(p+\\) \\(1&lt;n\\) in order to obtain well-defined estimates for all parameters. The likelihood \\(\\ell\\left(\\alpha, \\boldsymbol{\\beta}, \\sigma^{2} \\mid \\mathbf{y}\\right)\\) of the standard normal linear model is provided by the following matrix representation: \\[ \\frac{1}{\\left(2 \\pi \\sigma^{2}\\right)^{n / 2}} \\exp \\left\\{-\\frac{1}{2 \\sigma^{2}}\\left(\\mathbf{y}-\\alpha \\mathbf{1}_{n}-\\mathbf{X} \\boldsymbol{\\beta}\\right)^{\\mathrm{T}}\\left(\\mathbf{y}-\\alpha \\mathbf{1}_{n}-\\mathbf{X} \\boldsymbol{\\beta}\\right)\\right\\} \\] The maximum likelihood estimators of \\(\\alpha\\) and \\(\\boldsymbol{\\beta}\\) are then the solution of the (least squares) minimization problem \\[ \\begin{array}{l} \\min _{\\alpha, \\boldsymbol{\\beta}}\\left(\\mathbf{y}-\\alpha \\mathbf{1}_{n}-\\mathbf{X} \\boldsymbol{\\beta}\\right)^{\\mathrm{T}}\\left(\\mathbf{y}-\\alpha \\mathbf{1}_{n}-\\mathbf{X} \\boldsymbol{\\beta}\\right) \\\\ \\quad=\\min _{\\alpha, \\boldsymbol{\\beta}} \\sum_{i=1}^{n}\\left(y_{i}-\\alpha-\\beta_{1} x_{i 1}-\\ldots-\\beta_{p} x_{i p}\\right)^{2} \\end{array} \\] We get solutions \\[ \\hat{\\alpha}=\\overline{\\mathbf{y}}, \\quad \\hat{\\boldsymbol{\\beta}}=\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1} \\mathbf{X}^{\\top}(\\mathbf{y}-\\bar{y}) \\] best linear unbiased estimator (see, e.g., Christensen, 2002) states that \\((\\hat{\\alpha}, \\hat{\\beta})\\) is the best linear unbiased estimator of \\((\\alpha, \\beta)\\). This means that, for all \\(a \\in \\mathbb{R}^{p+1}\\), and with the abuse of notation that, here, \\((\\hat{\\alpha}, \\hat{\\beta})\\) represents a column vector, \\[ \\mathbb{V}\\left(a^{\\top}(\\hat{\\alpha}, \\hat{\\beta}) \\mid \\alpha, \\boldsymbol{\\beta}, \\sigma^{2}\\right) \\leq \\mathbb{V}\\left(a^{\\top}(\\tilde{\\alpha}, \\tilde{\\beta}) \\mid \\alpha, \\boldsymbol{\\beta}, \\sigma^{2}\\right) \\] for any unbiased linear estimator \\((\\tilde{\\alpha}, \\tilde{\\beta})\\) of \\((\\alpha, \\beta)\\). An unbiased estimator of \\(\\sigma^{2}\\) is \\[ \\hat{\\sigma}^{2}=\\frac{1}{n-p-1}\\left(\\mathbf{y}-\\hat{\\alpha} \\mathbf{1}_{n}-\\mathbf{X} \\hat{\\boldsymbol{\\beta}}\\right)^{\\top}\\left(\\mathbf{y}-\\hat{\\alpha} \\mathbf{1}_{n}-\\mathbf{X} \\hat{\\boldsymbol{\\beta}}\\right)=\\frac{s^{2}}{n-p-1} \\] and \\(\\hat{\\sigma}^{2}\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1}\\) approximates the covariance matrix of \\(\\hat{\\boldsymbol{\\beta}}\\). Note that the MLE of \\(\\sigma^{2}\\) is \\(\\operatorname{not} \\hat{\\sigma}^{2}\\) but \\(\\tilde{\\sigma}^{2}=s^{2} / n\\) X=scale(X) summary(lm(y~X)) ## S=readline(prompt=&quot;Type &lt;Return&gt; to continue : &quot;) 31.5.2 The Jeffreys Prior Analysis Considering only the case of a complete lack of prior information on the parameters of the linear model, we first describe a noninformative solution based on the Jeffreys prior. It is rather easy to show that the Jeffreys prior in this case is \\[ \\pi^{J}\\left(\\alpha, \\boldsymbol{\\beta}, \\sigma^{2}\\right) \\propto \\sigma^{-2} \\] which is equivalent to a flat prior on \\(\\left(\\alpha, \\boldsymbol{\\beta}, \\log \\sigma^{2}\\right)\\). We could deduce the following (conditional and marginal) posterior distributions \\[ \\begin{aligned} \\alpha \\mid \\sigma^{2}, \\mathbf{y} \\sim \\mathscr{N} &amp;\\left(\\hat{\\alpha}, \\sigma^{2} / n\\right) \\\\ \\boldsymbol{\\beta} \\mid \\sigma^{2}, \\mathbf{y} &amp; \\sim \\mathscr{N}_{p}\\left(\\hat{\\boldsymbol{\\beta}}, \\sigma^{2}\\left(\\mathbf{X}^{\\top} \\mathbf{X}\\right)^{-1}\\right) \\\\ \\sigma^{2} \\mid \\mathbf{y} &amp; \\sim \\mathscr{I} \\mathscr{G}\\left((n-p-1) / 2, s^{2} / 2\\right) \\end{aligned} \\] The corresponding Bayesian estimates of \\(\\alpha, \\boldsymbol{\\beta}\\) and \\(\\sigma^{2}\\) are thus given by \\[ \\mathbb{E}^{\\pi}[\\alpha \\mid \\mathbf{y}]=\\hat{\\alpha}, \\quad \\mathbb{E}^{\\pi}[\\boldsymbol{\\beta} \\mid \\mathbf{y}]=\\hat{\\boldsymbol{\\beta}} \\quad \\text { and } \\quad \\mathbb{E}^{\\pi}\\left[\\sigma^{2} \\mid \\mathbf{y}\\right]=\\frac{s^{2}}{n-p-3} \\] respectively. Unsurprisingly, the Jeffreys prior estimate of \\(\\alpha\\) is the empirical mean. Further, the posterior expectation of \\(\\boldsymbol{\\beta}\\) is the maximum likelihood estimate. Note also that the Jeffreys prior estimate of \\(\\sigma^{2}\\) is larger (and thus more pessimistic) than both the maximum likelihood estimate \\(s^{2} / n\\) and the classical unbiased estimate \\(s^{2} /(n-p-1)\\). Jeffreys  \\(\\alpha\\)  \\(\\boldsymbol{\\beta}\\)  Jeffreys  \\(\\sigma^{2}\\)  \\(s^{2}/n\\)  \\(s^{2}\\)  \\(/(np-1)\\) 31.5.3 Zellners G-prior analysis Zellner    Zellner  G-priorG Zellner  Semi-noninformative Solution  Zellner  G-prior . Zellner . Zellner  G-prior    (, 2) inproper (Jeffreys)  We could deduce that, conditionally on \\(\\mathbf{y}, \\mathbf{X}\\) and \\(\\sigma^{2}\\), the parameters \\(\\alpha\\) and \\(\\boldsymbol{\\beta}\\) are independent and such that \\[ \\begin{array}{c} \\alpha \\mid \\sigma^{2}, \\mathbf{y} \\sim \\mathscr{N}_{1}\\left(\\overline{\\mathbf{y}}, \\sigma^{2} / n\\right) \\\\ \\boldsymbol{\\beta} \\mid \\mathbf{y}, \\sigma^{2} \\sim \\mathscr{N}_{p}\\left(\\frac{g}{g+1}(\\hat{\\boldsymbol{\\beta}}+\\mathbf{X} \\tilde{\\boldsymbol{\\beta}} / g), \\frac{\\sigma^{2} g}{g+1}\\left\\{\\mathbf{X}^{\\mathrm{T}} \\mathbf{X}\\right\\}^{-1}\\right) \\end{array} \\] where \\(\\hat{\\boldsymbol{\\beta}}=\\left\\{\\mathbf{X}^{\\mathrm{T}} \\mathbf{X}\\right\\}^{-1} \\mathbf{X}^{\\mathrm{T}} \\mathbf{y}\\) is the maximum likelihood (and least squares) estimator of \\(\\boldsymbol{\\beta}\\). The posterior independence between \\(\\alpha\\) and \\(\\boldsymbol{\\beta}\\) is due to the fact that \\(\\mathbf{X}\\) is centered and that \\(\\alpha\\) and \\(\\boldsymbol{\\beta}\\) are a priori independent. Moreover, the posterior distribution of \\(\\sigma^{2}\\) is given by \\[ \\sigma^{2} \\mid \\mathbf{y} \\sim I \\mathscr{G}\\left[(n-1) / 2, s^{2}+(\\tilde{\\boldsymbol{\\beta}}-\\hat{\\boldsymbol{\\beta}})^{\\mathrm{T}} \\mathbf{X}^{\\mathrm{T}} \\mathbf{X}(\\tilde{\\boldsymbol{\\beta}}-\\hat{\\boldsymbol{\\beta}}) /(g+1)\\right] \\] where \\(I \\mathscr{G}(a, b)\\) is an inverse Gamma distribution with mean \\(b /(a-1)\\) and where \\(s^{2}=\\left(\\mathbf{y}-\\overline{\\mathbf{y}} \\mathbf{1}_{n}-\\mathbf{X} \\hat{\\boldsymbol{\\beta}}\\right)^{\\mathrm{T}}\\left(\\mathbf{y}-\\overline{\\mathbf{y}} \\mathbf{1}_{n}-\\mathbf{X} \\hat{\\boldsymbol{\\beta}}\\right)\\) corresponds to the (classical) residual sum of squares. library(bayess) ## Demo code https://rdrr.io/cran/bayess/f/ ## postmeancoeff posterior mean of the regression coefficients ## postsqrtcoeff posterior standard deviation of the regression coefficients ## log10bf log-Bayes factors against the full model ## postmeansigma2 posterior mean of the variance of the model ## postvarsigma2 posterior variance of the variance of the model data(faithful) BayesReg(faithful[,1],faithful[,2]) ## ## PostMean PostStError Log10bf EvidAgaH0 ## Intercept 3.4878 0.0304 ## x1 1.0225 0.0303 Inf (****) ## ## ## Posterior Mean of Sigma2: 0.2513 ## Posterior StError of Sigma2: 0.3561 ## $postmeancoeff ## [1] 3.487783 1.022509 ## ## $postsqrtcoeff ## [1] 0.03039825 0.03034252 ## ## $log10bf ## [,1] ## [1,] Inf ## ## $postmeansigma2 ## [1] 0.2513425 ## ## $postvarsigma2 ## [1] 0.1268176 31.6 Bayesian linear regression # suppressPackageStartupMessages(library(rstanarm)) # suppressPackageStartupMessages(library(bayestestR)) # suppressPackageStartupMessages(library(bayesplot)) # suppressPackageStartupMessages(library(insight)) ## use the BostonHousing data from mlbench package library(mlbench) data(&quot;BostonHousing&quot;) str(BostonHousing) ## &#39;data.frame&#39;: 506 obs. of 14 variables: ## $ crim : num 0.00632 0.02731 0.02729 0.03237 0.06905 ... ## $ zn : num 18 0 0 0 0 0 12.5 12.5 12.5 12.5 ... ## $ indus : num 2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ... ## $ chas : Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ nox : num 0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ... ## $ rm : num 6.58 6.42 7.18 7 7.15 ... ## $ age : num 65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ... ## $ dis : num 4.09 4.97 4.97 6.06 6.06 ... ## $ rad : num 1 2 2 3 3 3 5 5 5 5 ... ## $ tax : num 296 242 242 222 222 222 311 311 311 311 ... ## $ ptratio: num 15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ... ## $ b : num 397 397 393 395 397 ... ## $ lstat : num 4.98 9.14 4.03 2.94 5.33 ... ## $ medv : num 24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ... bost &lt;- BostonHousing[,c(&quot;medv&quot;,&quot;age&quot;,&quot;dis&quot;,&quot;chas&quot;)] summary(bost) ## medv age dis chas ## Min. : 5.00 Min. : 2.90 Min. : 1.130 0:471 ## 1st Qu.:17.02 1st Qu.: 45.02 1st Qu.: 2.100 1: 35 ## Median :21.20 Median : 77.50 Median : 3.207 ## Mean :22.53 Mean : 68.57 Mean : 3.795 ## 3rd Qu.:25.00 3rd Qu.: 94.08 3rd Qu.: 5.188 ## Max. :50.00 Max. :100.00 Max. :12.127 ## Classical linear regression model model_freq&lt;-lm(medv~., data=bost) library(broom) tidy(model_freq) ## # A tibble: 4 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 32.7 2.25 14.6 2.33e-40 ## 2 age -0.143 0.0198 -7.21 2.09e-12 ## 3 dis -0.246 0.265 -0.928 3.54e- 1 ## 4 chas1 7.51 1.46 5.13 4.16e- 7 # ## Bayesian regression # library(rstanarm) # https://www.r-bloggers.com/2020/04/bayesian-linear-regression/ "],["item-response-theory.html", "Chapter 32 Item Response Theory 32.1 Introduction", " Chapter 32 Item Response Theory 32.1 Introduction 32.1.1 Item response theory IRT (item response theory ) IRT IRT \\(\\theta\\)  IRT2-PL3-PL: two-parameter logistic (2-PL) Model 2-PL: \\[ p_{i, j}\\left(\\theta_{i}\\right)=\\frac{1}{1+\\exp \\left[-D a_{j}\\left(\\theta_{i}-b_{j}\\right)\\right]} \\]  \\(\\theta_{i}\\)  \\(a_{j}\\)  \\(b_{j}\\) D \\(1.7\\)  3-PL Model 3-PL \\(c_{j}\\)   3-PL: \\[ p_{i, j}\\left(\\theta_{i}\\right)=c_{j}+\\frac{1-c_{j}}{1+\\exp \\left[-D a_{j}\\left(\\theta_{i}-b_{j}\\right)\\right]} \\] \\(c_{j}\\) 2-PL Assumptions IRT IRT IRT \\(\\theta_{i}\\)  \\(i\\)  \\(Y_{i, j}\\) ;  \\(Y_{i}\\)   IRT 32.1.2 EM algorithm EM 3ABCpqABCBC10BCAAAA \\(\\mathrm{Y}=\\left(\\mathrm{Y}_{1}, \\mathrm{Y}_{2}, \\ldots, \\mathrm{Y}_{\\mathrm{n}}\\right)\\), \\(\\mathrm{Z}=\\left(\\mathrm{Z} 1, \\mathrm{Z}_{2}, \\ldots, \\mathrm{Z}_{\\mathrm{n}}\\right)\\),  \\(P(Y \\mid \\theta)=\\sum_{\\mathrm{Z}} P(Z \\mid \\theta) P(Y \\mid Z, \\theta)\\)  \\(P(Y \\mid \\theta)\\)  \\(P(Y, Z \\mid \\theta)\\)  \\[ \\begin{aligned} L(\\theta) &amp;=\\log P(Y \\mid \\theta)=\\log \\sum_{Z} P(Y, Z \\mid \\theta) \\\\ &amp;=\\log \\left(\\sum_{Z} P(Y \\mid Z, \\theta) P(Z \\mid \\theta)\\right) \\end{aligned} \\]  \\(\\theta\\)  \\(\\mathrm{Z}\\)  \\(\\mathrm{EM}\\)  i  \\(\\theta\\)  \\(\\theta^{(i)}\\)  \\(L(\\theta)\\)  \\(+1\\)  : \\[ L(\\theta)-L\\left(\\theta^{(i)}\\right)=\\log \\left(\\sum_{Z} P(Y \\mid Z, \\theta) P(Z \\mid \\theta)\\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\] Jensen \\[ \\begin{aligned} L(\\theta)-L\\left(\\theta^{(i)}\\right) &amp;=\\log \\left(\\sum_{Z} P\\left(Y \\mid Z, \\theta^{(i)}\\right) \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Y \\mid Z, \\theta^{(i)}\\right)}\\right)-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\ &amp; \\geqslant \\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right)}-\\log P\\left(Y \\mid \\theta^{(i)}\\right) \\\\ &amp;=\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right) P\\left(Y \\mid \\theta^{(i)}\\right)} \\end{aligned} \\] \\[ B\\left(\\theta, \\theta^{(i)}\\right) \\triangleq L\\left(\\theta^{(i)}\\right)+\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right) P\\left(Y \\mid \\theta^{(i)}\\right)} \\]  \\[ L(\\theta) \\geqslant B\\left(\\theta, \\theta^{(i)}\\right) \\]  \\(B\\left(\\theta, \\theta^{(i)}\\right)\\)  \\(L(\\theta)\\)  \\[ L\\left(\\theta^{(i)}\\right)=B\\left(\\theta^{(i)}, \\theta^{(i)}\\right) \\]  \\(B\\left(\\theta, \\theta^{(i)}\\right)\\)  \\(\\theta\\)  \\(L(\\theta)\\)  \\(\\theta\\)  \\(B\\left(\\theta, \\theta^{(i)}\\right)\\)  \\(\\theta\\)  \\(L(\\theta)\\)  \\(\\theta^{(i+1)}=\\arg \\max _{\\theta} B\\left(\\theta, \\theta^{(i)}\\right)\\)  () \\[ \\begin{aligned} \\theta^{(i+1)} &amp;=\\arg \\max _{\\theta}\\left(L\\left(\\theta^{(i)}\\right)+\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log \\frac{P(Y \\mid Z, \\theta) P(Z \\mid \\theta)}{P\\left(Z \\mid Y, \\theta^{(i)}\\right) P\\left(Y \\mid \\theta^{(i)}\\right)}\\right) \\\\ &amp;=\\arg \\max _{\\theta}\\left(\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log (P(Y \\mid Z, \\theta) P(Z \\mid \\theta))\\right) \\\\ &amp;=\\arg \\max _{\\theta}\\left(\\sum_{Z} P\\left(Z \\mid Y, \\theta^{(i)}\\right) \\log P(Y, Z \\mid \\theta)\\right) \\\\ &amp;=\\arg \\max _{\\theta} Q\\left(\\theta, \\theta^{(i)}\\right) \\end{aligned} \\]  \\(Q\\) EM \\(\\theta\\)  \\(\\theta^{(0)}\\)  \\(\\theta\\)   \\(L(\\theta)\\)  ()  EM EM E M E M For 2-PL Model :  \\(i\\)  \\(j\\)  \\(y_{i, j}\\)  \\(y_{i}=\\left(y_{i 1}, y_{i 2}, \\ldots \\ldots, y_{i m}\\right)\\)  \\(i=1,2, \\ldots, N, j=1,2, \\ldots, m\\)  \\(y_{i j}\\)  0  1   () :  \\(\\theta=\\left(\\theta_{1}, \\theta_{2}, \\ldots \\ldots, \\theta_{N}\\right) \\)  \\(\\theta_{i}\\)  \\(i\\)  :  \\(\\left[\\left(y_{1}, \\theta_{1}\\right),\\left(y_{2}, \\theta_{2}\\right), \\ldots,\\left(y_{N}, \\theta_{N}\\right)\\right]\\)  EMIRTEM E ME EM IRT \\(\\theta\\) EM \\(\\theta\\)  \\(q_{1}, q_{2}, \\ldots \\ldots, q_{K}, \\mathrm{~K}\\)  \\(P\\left(\\theta=q_{k}\\right)=\\pi_{k}\\)   \\(Y\\)  \\(\\Delta=\\left[\\delta_{1}, \\ldots \\ldots, \\delta_{J}\\right]\\)  \\(\\pi=\\left(\\Pi_{1}, \\ldots \\ldots, \\Pi_{K}\\right)\\) E : \\[ \\begin{aligned} Q\\left(\\Delta, \\pi \\mid \\Delta^{(s)}, \\pi^{(s)}\\right) &amp;=\\mathrm{E}_{Z_{\\mathrm{mis}} \\mid Z_{\\mathrm{obs}}, \\Delta^{(s)}, \\pi^{(s)}}\\left[\\log L\\left(\\Delta, \\pi \\mid Z_{\\mathrm{obs}}, Z_{\\mathrm{mis}}\\right)\\right] \\\\ &amp;=\\mathrm{E}_{\\theta \\mid Y, \\Delta^{(s)}, \\pi^{(s)}}[\\log L(\\Delta, \\pi \\mid Y, \\theta)] \\\\ &amp;=\\mathrm{E}_{\\theta \\mid Y, \\Delta^{(s)}, \\pi^{(s)}}\\left[\\log \\prod_{i=1}^{N} f\\left(\\mathbf{y}_{i}, \\theta_{i} \\mid \\Delta, \\pi\\right)\\right] \\\\ &amp;=\\sum_{i=1}^{N} \\mathrm{E}_{\\theta_{i} \\mid \\mathbf{y}_{i}, \\Delta^{(s)}, \\pi^{(s)}}\\left[\\log f\\left(\\mathbf{y}_{i}, \\theta_{i} \\mid \\Delta, \\pi\\right)\\right] \\end{aligned} \\] : \\[ Q\\left(\\Delta, \\pi \\mid \\Delta^{(s)}, \\pi^{(s)}\\right)=\\phi(\\Delta)+\\psi(\\pi) \\]  \\(\\phi(\\Delta)\\)  \\(\\psi(\\pi)\\) : \\[ \\begin{array}{c} \\phi(\\Delta)=\\sum_{k=1}^{K} \\sum_{j=1}^{J}\\left\\{\\log \\left[P\\left(q_{k}, \\delta_{j}\\right)\\right] r_{j k}^{(s)}+\\log \\left[Q\\left(q_{k}, \\delta_{j}\\right)\\right]\\left(n_{k}^{(s)}-r_{j k}^{(s)}\\right)\\right\\} \\\\ \\end{array} \\] \\[ \\psi(\\pi)=\\sum_{k=1}^{K} \\log \\left(\\pi_{k}\\right) n_{k}^{(s)} \\] : \\[ \\begin{aligned} n_{k}^{(s)} &amp;=\\sum_{i=1}^{N} \\frac{f\\left(\\mathbf{y}_{i} \\mid q_{k}, \\Delta^{(s)}\\right) \\pi_{k}^{(s)}}{\\sum_{k^{\\prime}=1}^{K} f\\left(\\mathbf{y}_{i} \\mid q_{k^{\\prime}}, \\Delta^{(s)}\\right) \\pi_{k^{\\prime}}^{(s)}} \\\\ r_{j k}^{(s)} &amp;=\\sum_{i=1}^{N} \\frac{y_{i j} f\\left(\\mathbf{y}_{i} \\mid q_{k}, \\Delta^{(s)}\\right) \\pi_{k}^{(s)}}{\\sum_{k^{\\prime}=1}^{K} f\\left(\\mathbf{y}_{i} \\mid q_{k^{\\prime}}, \\Delta^{(s)}\\right) \\pi_{k^{\\prime}}^{(s)}} \\\\ f\\left(\\mathbf{y}_{i} \\mid q_{k}, \\Delta^{(s)}\\right) &amp;=\\prod_{j=1}^{J} P\\left(q_{k}, \\delta_{j}^{(s)}\\right)^{y_{i j}}\\left[1-P\\left(q_{k}, \\delta_{j}^{(s)}\\right)\\right]^{1-y_{i j}} \\end{aligned} \\]  \\(n_{k}^{(s)}\\)  \\(N\\)  \\(q_{k}\\)  ( \\(q_{k}\\) ) \\(r_{j k}^{(s)}\\)   \\(N\\)  \\(q_{k}\\)  \\(j\\)  \\(n_{k}^{(s)}\\)  \\(r_{j k}^{(s)}\\)  EM \\(s\\)  E:  \\(s-1\\)  \\(\\Delta^{(s)}\\)  \\(\\pi_{k}^{(s)}\\)  \\(n_{k}^{(s)}\\)  \\(r_{j k}^{(s)}\\) ( \\(\\Delta^{(0)}\\)  \\(\\pi_{k}^{(0)}\\) )  M: E \\(n_{k}^{(s)}\\)  \\(r_{j k}^{(s)}\\)  \\(\\phi(\\Delta)\\)  \\(\\psi(\\pi)\\)  \\(\\Delta\\)  \\(\\pi\\)  \\(\\Delta^{(s+1)}\\)  \\(\\pi_{k}^{(s+1)}\\) : \\[ \\pi_{k}^{(s+1)}=\\frac{n_{k}^{(s)}}{\\sum_{k^{\\prime}=1}^{K} n_{k^{\\prime}}^{(s)}} \\] \\(\\pi_{k}^{(s+1)}\\)   \\(\\Delta^{(s+1)}\\) - EMIRT: E:  \\(q_{k}\\)  \\(\\pi_{k}\\);  \\(\\Delta^{(s)}\\)  \\(\\pi_{k}^{(s)}\\)  \\(n_{k}^{(s)}\\)  \\(r_{j k}^{(s)}\\)  M: \\(\\delta_{j}^{(s+1)}\\)\\(\\pi^{(s+1)}\\) EM 32.1.3 MCMC algorithm MCMCMCMC MCMC \\(2-\\mathrm{PL}\\) : 1) : \\(\\theta N(0,1), \\log (a) N(0,1), b N(0,1)\\)  \\(\\theta_{0}=0, a_{0}=1, b_{0}=0\\)   \\(a_{0}, b_{0}\\)  \\(\\theta_{1}\\)   \\(\\theta_{*}\\)  \\(q_{\\theta}\\)  \\(\\theta_{*} N\\left(\\theta_{0}, c_{\\theta}^{2}\\right)\\)  \\(c_{\\theta}=1.1\\)   \\(\\theta_{0}\\)  \\(\\theta_{1}\\)  \\(a\\left(\\theta_{0}, \\theta_{*}\\right)=\\min \\left(1, R_{\\theta}^{0}\\right)\\)  \\[ R_{\\theta} 0=\\frac{\\left[\\prod_{j} p_{i j}\\left(\\theta_{i}^{*}, a_{j}^{0}, b_{j}^{0}\\right)^{x_{i j}}\\left(1-p_{i j}\\left(\\theta_{i}^{*}, a_{j}^{0}, b_{j}^{0}\\right)\\right)^{1-x_{i j}}\\right] \\exp -\\frac{1}{2 \\sigma_{\\theta}^{2}}\\left(\\theta_{i}^{*}\\right)^{2}}{\\left[\\prod_{j} p_{i j}\\left(\\theta_{i}^{0}, a_{j}^{0}, b_{j}^{0}\\right)^{x_{y_{y}}}\\left(1-p_{i j}\\left(\\theta_{i}^{0}, a_{j}^{0}, b_{j}^{0}\\right)\\right)^{1-x_{y}}\\right] \\exp -\\frac{1}{2 \\sigma_{\\theta}^{2}}\\left(\\theta_{i}^{0}\\right)^{2}} \\]  \\[ p_{i j}\\left(\\theta_{i}, a_{j}^{0}, b_{j}^{0}\\right)=\\frac{1}{1+\\exp \\left[-1.7 a_{i}^{0}\\left(\\theta_{i}+b_{i}^{0}\\right)\\right]} \\]  \\(r_{1} U(0,1)\\)  \\(r_{1}\\)  \\(a\\left(\\theta_{0}, \\theta_{*}\\right)\\) :  \\(a\\left(\\theta_{0}, \\theta_{*}\\right) \\geq r_{1}\\)  \\(\\theta_{1}=\\theta_{*}\\)  \\(\\theta_{1}=\\theta_{*}\\)   (2)  \\(\\theta_{1}\\)  \\(a_{1}, b_{1}\\)   \\(a_{*}, b_{*}\\)  \\(q_{a}, q_{b}\\)  \\(\\log \\left(a_{*}\\right) N\\left(a_{0}, c_{a}^{2}\\right), b * N\\left(b_{0}, c_{b}^{2}\\right)\\),  \\(c_{a}=0.3, c_{b}=0.3\\)   \\(\\left(a_{0}, b_{0}\\right)\\)  \\(\\left(a_{*}, b_{*}\\right)\\)  \\(\\alpha\\left(a_{0}, b_{0}, a_{*}, b_{*}\\right)=\\min \\left(1, R_{a, b}^{0}\\right)\\)   \\(R_{a, b} 0=\\frac{\\left[\\prod_{j} p_{i j}\\left(\\theta_{i}^{1}, a_{j}^{*}, b_{j}^{*}\\right)^{x_{j}}\\left(1-p_{i j}\\left(\\theta_{i}^{1}, a_{j}^{*}, b_{j}^{*}\\right)\\right)^{1-x_{j}}\\right] \\exp -\\frac{1}{2 \\sigma_{b}^{2}}\\left(b_{j}^{*}\\right)^{2} \\frac{1}{a_{j}^{*}} \\exp -\\frac{1}{2 \\sigma_{a}^{2}} \\log \\left(a_{j}^{*}\\right)^{2}}{\\left[\\prod_{j} p_{i j}\\left(\\theta_{i}^{1}, a_{j}^{0}, b_{j}^{0}\\right)^{x_{j}}\\left(1-p_{i j}\\left(\\theta_{i}^{1}, a_{j}^{0}, b_{j}^{0}\\right)\\right)^{1-x_{j}}\\right] \\exp -\\frac{1}{2 \\sigma_{b}^{2}}\\left(b_{j}^{0}\\right)^{2} \\frac{1}{a_{j}^{0}} \\exp -\\frac{1}{2 \\sigma_{a}^{2}} \\log \\left(a_{j}^{0}\\right)^{2}} \\times \\frac{a_{j}^{0}}{a_{j}^{*}}\\)  \\[ p_{i j}\\left(\\theta_{i}^{1}, a_{j}, b_{j}\\right)=\\frac{1}{1+\\exp \\left[-1.7 a_{j}\\left(\\theta_{i}^{1}+b_{j}\\right)\\right]} \\]  \\(r_{2} U(0,1)\\)  \\(r_{2}\\)  \\(\\alpha\\left(a_{0}, b_{0}, a_{*}, b_{*}\\right)\\) , :  \\(\\alpha\\left(a_{0}, b_{0}, a_{*}, b_{*}\\right) \\geq r_{2}\\)  \\(a_{1}=a_{*}, b_{1}=b_{*}\\);  \\(a_{1}=a_{0}, b_{1}=b_{0}\\)   (2)  (3) \\(n\\)  \\(w\\)  \\(m=n-w\\)   (4)  \\(n\\)  Markov  (4) \\(i\\)  ( \\(i\\)  5 ) \\(i\\)  Markov ,  \\(i\\)  32.1.4 Unidimensional IRT Models For Dichotomously Scored Responses "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
