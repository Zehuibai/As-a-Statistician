# Adaptive designs


 
```{r mind map,echo = F,message = FALSE, error = FALSE, warning = FALSE}
library('mindr')
### text -> widget
### input <- c("# Chapter 1", "## Section 1.1", "### Section 1.1.1", "## Section 1.2", "# Chapter 2")
### mm(from = input, type = "text", root = "mindr")
filename <- rstudioapi::getSourceEditorContext()$path
widget <- mm(from = filename, type = "file", root = "")
widget
```



## Introduction

An adaptive design is a design that allows adaptations or modifications to some aspects of a trial after its initiation without undermining the validity and integrity of the trial. The adaptations may include, but are not limited to, sample-size reestimation, early stopping for efficacy or futility, response-adaptive randomization, and dropping inferior treatment groups. Adaptive designs usually require unblinding data and invoke a dependent sampling procedure. Therefore, theory behind adaptive design is much more complicated than that behind classical design.

In general, adaptive designs allow various adaptations of the study design based on data
gained during an interim analysis. Possible adaptions could be:

* Early termination of the trial due to futility
* Early termination of the trial due to efficacy
* Sample size recalculation
* Selection of the primary endpoint
* Dropping of treatment arm(s)
* Switching from non-inferiority to superiority
* Patient allocation to the treatment arms
* Selection of the patient population (enrichment designs)
* Further change in the study design

However, only with proper implementation of these designs, the validity and the integrity of
the clinical trial are not undermined. Each of the adaptions might have an influence on the
interpretation of the study results. Special attention should be paid for the comparability of
the different stages of the study.

### Early termination due to futility

The study can be stopped earlier due to futility using non-binding or binding futility rules. Non-binding futility bounds (i.e., the final decision is not only based on the suggestion made by the futility bounds) does not further increase the type I error. On the other hand, binding futility bounds can provide advantage in the efficacy analysis but may inflate the type I error if the stopping rule is not followed. 

> 由于使用无约束力的或无约束力的无效性规则会导致无效性，因此可以更早地停止研究。 无约束力的无效边界（即最终决定不仅基于无效边界提出的建议）不会进一步增加I型错误。 另一方面，无用的约束范围可以在功效分析中提供优势，但是如果不遵循停止规则，则可能会夸大I型错误。

### Early termination due to efficacy

The trial could also be stopped earlier if the efficacy of the primary endpoint is already shown by the results of the interim analysis. Efficacy bounds can be implemented by using groups sequential design methods. If efficacy bounds are used, it should be ensured that the sample size at the interim analysis is sufficient to show further objectives of the study (e.g., safety profile and secondary endpoints), which is typically not the case in phase III or premarket trials. If groups sequential design methods are used, the treatment effect tend to be biased towards greater values (especially the mean). Consequently, the confidence intervals will not have the desired coverage probability. Therefore, methods for reducing or removing the introduced bias and increasing the coverage probability should be applied if they exist. If no methods for these issues exist, the extent of bias should be discussed, and the resulting estimates should be used with caution.

> 如果主要终点的疗效已经通过中期分析的结果表明，则该试验也可以更早停止。 功效范围可以通过使用组顺序设计方法来实现。 如果使用疗效界限，则应确保中期分析中的样本量足以显示研究的进一步目标（例如安全性和次要终点），通常在III期或上市前试验中并非如此。 如果使用分组顺序设计方法，则治疗效果倾向于偏向更大的值（尤其是平均值）。 因此，置信区间将不会具有所需的覆盖概率。 因此，如果存在减少或消除引入的偏差并增加覆盖概率的方法，则应采用。 如果没有解决这些问题的方法，则应讨论偏差的程度，并谨慎使用得出的估计值。


### Sample size reassessment

Adaptations like sample size reassessment are not a substitute for careful planning. Sample size reassessment which is based on results of an ongoing trial is only a valid option if it can be shown that the uncertainty about the required sample size is not the result of an inadequate research in earlier stages of the study. If possible, the sample size should be recalculated in a blinded fashion. For a study with the objective to show superiority regarding a continuous primary endpoint, the type I error is generally not inflated if the method of Gould and Shih is applied (Gould and Shih, 1992). 

For non-inferiority and equivalence hypotheses, the type I error could be inflated to a limited extend (Friede and Kieser, 2003). If a blinded sample size calculation is not appropriate or possible, the procedure of Chen and his colleagues (Chen et al., 2004) offers a sample size adaption without inflating the type I error. Details are described in the paper. The procedure of the reassessment should be planned a priori, must not question the validity of the study results, and has to maintain the type I error. But if more than one sample size reassessment is required, this can be a sign for varying experimental conditions and a sign that they are not fully understood.

> 诸如样本量重新评估之类的调整并不能代替精心计划。如果可以证明对所需样本量的不确定性不是研究早期阶段研究不足的结果，则基于正在进行的试验结果进行的样本量重新评估只是一个有效的选择。如果可能，应以盲法重新计算样本量。对于旨在显示出连续主要终点指标优越性的研究，如果采用Gould and Shih的方法，通常不会夸大I型错误（Gould and Shih，1992）。

> 对于非自卑和对等假说，I型错误可能会扩大到有限的范围（Friede和Kieser，2003年）。如果盲目的样本量计算不合适或不可行，Chen和他的同事（Chen等，2004）的程序可以对样本量进行调整，而不会增加I型错误。详细信息在本文中进行了描述。重新评估的程序应事先进行计划，不得质疑研究结果的有效性，并且必须保持I型错误。但是，如果需要进行多个样本大小的重新评估，则可能是变化的实验条件的信号，也可能是对它们没有完全了解的信号。

### Change or modification of the primary endpoint 

There are several therapeutic areas where guidelines for the change or modification of the primary endpoint have not been developed. Adaptive designs are recommended if the assumptions and expectations of the primary endpoint seem to be not correct. Such information may be obtained through external knowledge in form of other studies or through interim results. In these situations, an adaptive design can be used for changes of the definition of a primary endpoint, for changes of the primary endpoint and for changes in the components of a composed primary endpoint. However, it should be noted that a change in a primary endpoint is generally difficult to justify and thus should be avoided.

> 在一些治疗领域，尚未制定出主要终点改变或修改的指南。 如果主要终点的假设和期望似乎不正确，则建议采用自适应设计。 此类信息可以通过其他研究形式的外部知识或中期结果获得。 在这些情况下，可以将自适应设计用于主要端点定义的更改，主要端点的更改以及组成的主要端点的组件的更改。 但是，应注意的是，主要终点的变化通常难以证明是正确的，因此应避免。

### Discontinuing treatment arms 

Discontinuation of treatment arms is worth consideration in case of multiple treatment arms – especially if one of them is a placebo arm. If data depending on discontinuation of treatment arms is favoured, the study should be planned with an appropriate adaptive design in combination with a multiple testing procedure to offer the chance to stop recruitment to the placebo group if an interim analysis has demonstrated superiority of the treatment over placebo. An application for an early phase study would be a drop-the-loser design (Sampson and Sill, 2005), where at the interim analysis of a two-stage design, one winner arm will be selected to enter the second stage of the trial (beside the control arm). Further details could be obtained from the original publication. This approach is more general described in the multiarm multi-stage approach (MAMS) by Magirr and his colleagues (Magirr et al.,2012).

> 如果有多个治疗臂，则应考虑停用治疗臂-尤其是其中一个是安慰剂臂时。 如果偏爱根据治疗组停用的数据，则应采用适当的适应性设计并结合多种测试程序来计划研究，如果中期分析表明治疗优于治疗组，则有机会停止募集安慰剂组。 安慰剂。 早期研究的应用程序将是失败者设计（Sampson和Sill，2005年），其中在两阶段设计的中期分析中，将选择一个获胜者的手臂进入试验的第二阶段。 （在控制臂旁边）。 可以从原始出版物中获得更多详细信息。 Magirr及其同事在多臂多阶段方法（MAMS）中对这种方法进行了更一般的描述（Magirr等，2012）。


### Switching between superiority and non-inferiority
 
If both, superiority and/or non-inferiority of an experimental treatment to an active comparator are acceptable outcomes, the study should be planned as a non-inferiority trial with the possibility to switch to superiority based on the trial results. A change from superiority to non-inferiority is not acceptable in the adaptive design after interim results are available

> 如果对积极比较者的实验治疗的优越性和/或非劣效性均可以接受，则应将该研究计划为一项非劣效性试验，并有可能根据试验结果转向优势性。 在获得中期结果后，在自适应设计中从优劣变为非劣势是不可接受的


### Selection of the patient population 

If the objective of a trial is not only to show efficacy, but efficacy in a certain population, so called enrichment designs could be applied. In such a design, for example, a general population is enrolled in the first stage. Based on the results of the interim analysis of the prespecified subgroups, only the most promising study population could be further investigated in the second part of the trial. The results from the first and the second stage could be combined using combination test describe in section below. A more detailed overview about enrichment can be found in article of Wang and his colleagues (Wang et al., 2009). 

> 如果试验的目的不仅是显示功效，而且是在一定人群中的功效，那么可以应用所谓的富集设计。例如，在这样的设计中，第一阶段是一般人群。根据预先确定的亚组的中期分析结果，只有最有前途的研究人群可以在试验的第二部分中进行进一步研究。第一阶段和第二阶段的结果可以使用以下部分所述的组合测试进行组合。可以在Wang和他的同事的文章中找到有关浓缩的更详细的概述（Wang等，2009）。


### Methods

Many interesting methods for adaptive design have been developed. Virtually all methods can be viewed as some **combination of stagewise p-values**. The stagewise p-values are obtained based on the subsample from each stage; therefore, they are mutually independent and uniformly distributed over [0,1] under the null hypothesis. 

The first method uses the same stopping boundaries as a classical group sequential design (O’Brien and Fleming, 1979; Pocock, 1977) and **allows stopping for early efficacy or futility**. Lan and DeMets (1983) proposed the error spending method (ESM), in which the timing and number of analyses can be changed based on a prespecified error-spending function. ESM is derived from Brownian motion. The method has been extended to allow for sample-size reestimation (SSR) (Cui, Hung, and Wang, 1999). It can be viewed as a fixed-weight method (i.e., using fixed weights for z-scores from the first and second stages regardless of sample-size change). Lehmacher and Wassmer (1999) further degeneralized this **weight method by using the inverse-normal method**, in which the z-score is not necessarily taken from a normal endpoint, but from the inverse-normal function of stagewise p-values. Hence, the method can be used for any type of endpoint. 

> 第一种方法使用与经典组顺序设计相同的停止边界（O'Brien 和 Fleming，1979 年；Pocock，1977 年）并且 ** 允许停止以获得早期有效性或无效**。 Lan 和 DeMets (1983) 提出了错误消耗方法 (ESM)，其中可以根据预先指定的错误消耗函数更改分析的时间和数量。 ESM 源自布朗运动。该方法已扩展到允许样本大小重新估计 (SSR)（Cui、Hung 和 Wang，1999）。它可以被视为一种固定权重方法（即，无论样本大小如何变化，对第一和第二阶段的 z 分数使用固定权重）。 Lehmacher 和 Wassmer (1999) 通过使用逆正态方法进一步取消了这种权重方法，其中 z 分数不一定取自正态端点，而是取自阶段性 p 值的逆正态函数。因此，该方法可用于任何类型的端点。


The second method is based on a **direct combination of stagewise pvalues**. Bauer and Kohne (1994) use the **Fisher combination (product) of stagewise p-values** to derive the stopping boundaries. Chang (2006a) used the **sum of the stagewise p-values** to construct a test statistic and derived a closed form for determination of stopping boundaries and p-value calculations as well as conditional power for trial monitoring. 

> 第二种方法是基于stagewise pvalues的**直接组合**。 Bauer and Kohne (1994)使用stagewise p-values的Fisher组合（乘积）来推导停止边界。 Chang (2006a) 使用 ** 阶段性 p 值之和 ** 来构建检验统计量，并推导出封闭形式，用于确定停止边界和 p 值计算以及用于试验监测的条件功效。

The third method is based on the **conditional error function**. Proschan and Hunsberger (1995) developed an adaptive design method based on the conditional error function for two-stage designs with normal test statistics. Müller and Schäfer (2001) developed the conditional error method where the conditional error function is avoided and replaced with a conditional error that is calculated on fly. Instead of a two-stage design, Müller and Schäfer ’s method can be applied to a K-stage design and allows for many adaptations. 

> 第三种方法是基于条件误差函数。 Proschan和Hunsberger（1995）开
发了一种基于条件误差函数的自适应设计方法，
用于具有正常检验统计量的两阶段设计。 Müller 和 Schäfer (2001) 开发了条件误差方法，其中避免了条件误差函数并用动态计算的条件
误差代替。 Müller 和 Schäfer 的方法可以应用于 K 阶段设计，
而不是两阶段设计，并允许进行许多调整。

The fourth method is based on **recursive algorithms** such as Brannath Posch-Bauer’s recursive combination tests (Brannath, Posch and Bauer, 2002), Müller and Schäfer’s decision-function method (Müller and Schäfer, 2004), and Chang’s (2006e) recursive two-stage adaptive design (RTAD). All four recursive methods are developed for K-stage designs allowing for general adaptations. 

> 第四种方法基于 ** 递归算法**，例如 Brannath Posch-Bauer 的递归组合测试（Brannath、Posch 和 Bauer，2002）、Müller 和 Schäfer 的决策函数方法（Müller 和 Schäfer，2004）和 Chang (2006e) ) 递归两阶段自适应设计 (RTAD)。所有四种递归方法都是为 K 阶段设计开发的，允许进行一般调整。


Focus on three major issues: type-I error control, analysis including point and confidence interval estimations, and design evaluations.


##  General Theory

### Stopping Boundary

$$
H_{0}: H_{01} \cap \ldots \cap H_{0 K}
$$
where $H_{0 k}(k=1, \ldots, K)$ is the null hypothesis at the $k$ th interim analysis.

The stopping rules are given by
$$
\left\{\begin{array}{ll}
\text { Stop for efficacy } & \text { if } T_{k} \leq \alpha_{k} \\
\text { Stop for futility } & \text { if } T_{k}>\beta_{k}, \\
\text { Continue with adaptations}& \text { if }  \alpha_{k}<T_{k} \leq \beta_{k}
\end{array}\right.
$$
where $\alpha_{k}<\beta_{k}(k=1, \ldots, K-1)$, and $\alpha_{K}=\beta_{K}$. For convenience, $\alpha_{k}$ and $\beta_{k}$ are called the efficacy and futility boundaries, respectively.

To reach the $k$ th stage, a trial has to pass the 1 th to $(k-1)$ th stages. Therefore, the probability of rejecting the null hypothesis $H_{0}$ or simply, the rejection probability at the $k$ th stage is given by $\psi_{k}\left(\alpha_{k}\right)$, where
$$
\begin{aligned}
\psi_{k}(t) &=\operatorname{Pr}\left(\alpha_{1}<T_{1}<\beta_{1}, \ldots, \alpha_{k-1}<T_{k-1}<\beta_{k-1}, T_{k}<t\right) \\
&=\int_{\alpha_{1}}^{\beta_{1}} \cdots \int_{\alpha_{k-1}}^{\beta_{k-1}} \int_{-\infty}^{t} f_{T_{1} \ldots T_{k}} d t_{k} d t_{k-1} \ldots d t_{1}
\end{aligned}
$$
where $f_{T_{1} \ldots T_{k}}$ is the joint pdf of $T_{1}, \ldots$, and $T_{k}$.



### Power and Adjusted p-value

Definition 3.1: The $p$ -value associated with a test is the smallest significance level $\alpha$ for which the null hypothesis is rejected. Let
$$
p_{c}(t ; k)=\psi_{k}\left(t \mid H_{0}\right)
$$
The error rate $(\alpha$ spent) at the $k$ th stage is given by
$$
\pi_{k}=\psi_{k}\left(\alpha_{k} \mid H_{0}\right) .
$$
It is the key to determining the stopping boundaries’ adaptive designs. When $\sum_{i=1}^{k} \pi_{i}$ is reviewed as a function of information time or stage $k$, it is the so-called error-spending function. 

The power of rejecting $H_{0}$ at the $k$ th stage is given by
$$
\varpi_{k}=\psi_{k}\left(\alpha_{k} \mid H_{a}\right) .
$$
When efficacy is claimed at a certain stage, the trial is stopped. Therefore, the type-I errors at different stages are mutually exclusive. Hence, the experiment-wise type-I error rate can be written as
$$
\alpha=\sum_{k=1}^{K} \pi_{k} .
$$
Similarly, the power is given by
$$
\text { power }=\sum_{k=1}^{K} \varpi_{k} .
$$

It is interesting to define an adjusted $p$ -value by
$$
p_{a}(t ; k)=\min \left\{1, \sum_{i=1}^{k-1} \pi_{i}+p_{c}(t ; k)\right\}
$$
An important characteristic of this adjusted $p$ -value is that when the test statistic $t$ is on stopping boundary $a_{k}, p_{k}$ must be equal to alpha spent so far.

Note that the adjusted $p$ -value is a measure of overall statistical strength against $H_{0}$. The later the $H_{0}$ is rejected, the larger the adjusted $p$ -value is, and the weaker the statistical evidence (against $H_{0}$ ) is. A late rejection leading to a larger $p$ -value is reasonable because the alpha at earlier stages has been spent.

> 调整后的 $p$ 值是对 $H_{0}$ 的整体统计强度的衡量。 $H_{0}$被拒绝的越晚，调整后的$p$值越大，统计证据（针对$H_{0}$）就越弱。 延迟拒绝导致更大的 $p$ 值是合理的，因为早期阶段的 alpha 已经用完。


### Stopping Probabilities (Design Evaluation)

> 每个阶段的停止概率是自适应设计的一个重要属性，因为它提供了上市时间和相关的成功概率。 它还提供有关试验成本（样本量）和相关概率的信息。

n fact, the stopping probabilities are used to calculate the expected samples that present the average cost or efficiency of the trial design and the duration of the trial. There are two types of stopping probabilities: 

1. unconditional probability of stopping to claim efficacy (reject H0) and 
2. unconditional probability of futility (accept H0). 

The former refers to the efficacy stopping probability (ESP), and the latter refers to the futility stopping probability (FSP).

From
$$
\begin{aligned}
\psi_{k}(t) &=\operatorname{Pr}\left(\alpha_{1}<T_{1}<\beta_{1}, \ldots, \alpha_{k-1}<T_{k-1}<\beta_{k-1}, T_{k}<t\right) \\
&=\int_{\alpha_{1}}^{\beta_{1}} \ldots \int_{\alpha_{k-1}}^{\beta_{k-1}} \int_{-\infty}^{t} f_{T_{1} \ldots T_{k}} d t_{k} d t_{k-1} \ldots d t_{1}
\end{aligned}
$$
the ESP at the kth stage is given by
$$
E S P_{k}=\psi_{k}\left(\alpha_{k}\right)
$$
and the FSP at the $k$ th stage is given by
$$
F S P_{k}=\psi_{k-1}\left(\beta_{k-1}\right)-\psi_{k-1}\left(\alpha_{k-1}\right)-\psi_{k}\left(\beta_{k}\right)
$$




### Expected Duration of an Adaptive Trial (Design Evaluation)

The stopping probabilities can be used to calculate the expected trial duration, which is definitely an important feature of an adaptive design. The conditionally (on the efficacy claim) expected trial duration is given by
$$
\bar{t}_{e}=\sum_{k=1}^{K} E S P_{k} t_{k}
$$
where $t_{k}$ is the time from the first-patient-in to the $k$ th interim analysis.

The conditionally (on the futility claim) expected trial duration is given by
$$
\bar{t}_{f}=\sum_{k=1}^{K} F S P_{k} t_{k} .
$$
The unconditionally expected trial duration is given by
$$
\bar{t}=\sum_{k=1}^{K}\left(E S P_{k}+F S P_{k}\right) t_{k} .
$$


### Expected Sample Sizes (Design Evaluation)

The expected sample size is a commonly used measure of the **efficiency**
(cost and timing of the trial) of the design. The expected sample size is a
function of the treatment difference and its variability, which are unknowns.
Therefore, expected sample size is really **based on hypothetical values of
the parameters**. For this reason, it is beneficial and important to calculate
the expected sample size **under various critical or possible values** of the
parameters. The total expected sample size per group can be expressed as
$$
N_{\exp }=\sum_{k=1}^{K} N_{k}\left(E S P_{k}+F S P_{k}\right)
$$
It can also be written as
$$
N_{\exp }=\sum_{k=1}^{K} N_{k}\left(\psi_{k}\left(\alpha_{k}\right)+\psi_{k-1}\left(\beta_{k-1}\right)-\psi_{k}\left(\beta_{k}\right)-\psi_{k-1}\left(\alpha_{k-1}\right)\right)
$$
where $N_{k}=\sum_{i=1}^{k} n_{i}$ is the cumulative sample size per group.


### Conditional Power and futility index

The conditional power is the **conditional probability of rejecting the null hypothesis during the rest of the trial based on the observed interim data**. The conditional power is commonly used for monitoring an ongoing trial. Similar to the ESP and FSP, conditional power is dependent on the population parameters or treatment effect and its variability. The conditional power at the $k$ th stage is the sum of the probability of rejecting the null hypothesis at stage $k+1$ to $K(K$ does not have to be predetermined), given the observed data from stages 1 through $k$.
$$
c P_{k}=\sum_{j=k+1}^{K} \operatorname{Pr}\left(\cap_{i=k+1}^{j-1}\left(a_{i}<T_{i}<\beta_{i}\right) \cap T_{j} \leq \alpha_{j} \mid \cap_{i=1}^{k} T_{i}=t_{i}\right)
$$
where $t_{i}$ is the observed test statistic $T_{i}$ at the $i$ th stage. For a two-stage design, the conditional power can be expressed as
$$
c P_{1}=\operatorname{Pr}\left(T_{2} \leq \alpha_{2} \mid t_{1}\right) .
$$
The futility index is defined as the conditional probability of accepting the null hypothesis:
$$
F I_{k}=1-c P_{k}
$$


## Method with Direct Combination of p-values

focus on two-stage designs and derive the closed forms for determination of stopping boundaries and adjusted pvalues. 

* method based on individual p-values (MIP)
* method based on the sum of p-values (MSP)
* method based on the product of p-values (MPP) 


### Method Based on Individual p-values

$$
T_{k}=p_{k}
$$
where $p_{k}$ is the stagewise $p$ -value from the $k$ th stage subsample. A level- $\alpha$ test requires
$$
\alpha=\sum_{k=1}^{K} \alpha_{k} \prod_{i=1}^{k-1}\left(\beta_{i}-\alpha_{i}\right)
$$
$\alpha_{k}$ and $\beta_{k}$ are called the efficacy and futility boundaries, respectively.
For a two-stage design,$\alpha=\alpha_{1}+\alpha_{2}\left(\beta_{1}-\alpha_{1}\right)$
The $p$ -value is given by
$$
p(t ; k)=\left\{\begin{array}{lr}
t, & k=1 \\
\alpha_{1}+t\left(\beta_{1}-\alpha_{1}\right) k & =2 .
\end{array}\right.
$$
MIP is useful in the sense that it is very simple and can serve as the "baseline" for comparing different methods. MIP does not use combined data from different stages, while most other adaptive designs do.


### Method Based on the Sum of p-values

Chang (2006a) proposed an adaptive design method, in which the test statistic is defined as the sum of the stagewise $p$ -values. This method is referred to as MSP. At the $k$ th stage, the test statistic is defined as
$$
T_{k}=\Sigma_{i=1}^{k} p_{i}, k=1, \ldots, K
$$
The key to derive the stopping boundary is to calculate the probability function $\psi_{k}(t)$ under the null hypothesis and the decision rules. For a two stage design, the stopping rules are
$$
\text { At Stage 1, }\left\{\begin{array}{ll}
\text { Reject } H_{0} & \text { if } T_{1} \leq \alpha_{1} \\
\text { Accept } H_{0} & \text { if } T_{1}>\beta_{1} \\
\text { Continue with adaptations if } \alpha_{1}<T_{1} \leq \beta_{1} \text { , }
\end{array}\right.
$$
where $0<\alpha_{1}<\beta_{1} \leq 1$.
$$
\text { At Stage 2, }\left\{\begin{array}{ll}
\text { Reject } H_{0} & \text { if } T_{2} \leq \alpha_{2} \\
\text { Accept } H_{0} & \text { if } T_{2}>\alpha_{2}
\end{array}\right. \text { . }
$$
Noticing that $p_{i}$ is often uniformly distributed in $[0,1]$ under the null hypotheis, for the first stage we have
$$
\psi_{1}\left(t \mid H_{0}\right)=\int_{0}^{t} d t_{1}=t .
$$
For the second stage, we have
$$
\psi_{2}\left(t \mid H_{0}\right)=\int_{\alpha_{1}}^{\beta_{1}} \int_{0}^{t} f_{T_{1} T_{2}} d t_{2} d t_{1}
$$
$$
\begin{array}{l}
\text { Noticing that } p_{1} \text { and } p_{2} \text { are indepedent, we have } f_{T_{1} T_{2}}=\\
f\left(T_{2} \mid T_{1}\right) f\left(T_{1}\right)=f\left(p_{1}+p_{2} \mid p_{1}\right) f\left(p_{1}\right)=1 \text { . We will prove that }\\
\psi_{2}\left(t \mid H_{0}\right)=\left\{\begin{array}{ll}
\frac{1}{2}\left(t-\alpha_{1}\right)^{2}, & \text { when } \alpha_{1}<t \leq \beta_{1} \\
\left(\beta_{1}-\alpha_{1}\right) t-\frac{1}{2}\left(\beta_{1}^{2}-\alpha_{1}^{2}\right), & \text { when } \beta_{1}<t \leq \alpha_{1}+1 \\
t-\alpha_{1}+t \beta_{1}-\frac{1}{2} t^{2}-\frac{1}{2} \beta_{1}^{2}-\frac{1}{2}, & \text { when } \alpha_{1}+1<t \leq 2 \\
0, & \text { otherwise }
\end{array}\right.
\end{array}
$$


### Method with Product of p-values

This method is referred to as MPP. The test statistic in this method is based on the product of the stagewise $p$ -values from the subsamples. For two-stage designs, the test statistic is defined as
$$
T_{k}=\Pi_{i=1}^{k} p_{i}, k=1,2 .
$$
The $\alpha$ spent in the two stages is given by
$$
\pi_{1}=\int_{0}^{\alpha_{1}} d t_{1}=\alpha_{1}
$$
and
$$
\pi_{2}=\int_{\alpha_{1}}^{\beta_{1}} \int_{0}^{\alpha_{2}} \frac{1}{t_{1}} d t_{2} d t_{1}
$$
We can obtain the following formulation for determining stopping boundaries:
$$
\alpha=\alpha_{1}+\alpha_{2} \ln \frac{\beta_{1}}{\alpha_{1}}, \alpha_{1}<\beta_{1} \leq 1
$$
Note that the stopping boundaries based on Fisher's criterion are special cases of obove function, where $\alpha_{2}=\exp \left[-\frac{1}{2} \chi_{4}^{2}(1-\alpha)\right]$.

 

### Fisher’s product test (Combination Tests)

* p = p-value (e.g. from z-test) of first n1 patients (stage 1) 
* q = p-value (e.g. from z-test) of second n2 patients (stage 2)

At stage 2 combine the stage-wise p-values p and q by a pre-specified function (“**combination function**”). Then compare this with to a pre-specified critical value. (Pre-specified critical region in (p, q)-plane), Control of type I error rate possible, since p and q are independent and on [0, 1] uniformly distributed under H0.

```{r Fisher-product-test-1, echo=FALSE, fig.align="center", out.width = '100%',fig.cap="Figure: Fisher’s product test, (BAUER 1989, BAUER & KÖHNE 1994)"}
knitr::include_graphics("./02_Plots/Fisher-product-test-1.png")
knitr::include_graphics("./02_Plots/Fisher-product-test-1g.png")
```


### Fisher’s product test with early rej. and acceptance

```{r Fisher-product-test-2, echo=FALSE, fig.align="center", out.width = '100%',fig.cap="Figure: Fisher’s product test with early rej. and acceptance"}
knitr::include_graphics("./02_Plots/Fisher-product-test-2a.png")
knitr::include_graphics("./02_Plots/Fisher-product-test-2.png")
```

**Choice of critical values**

1. Full second stage level
2. Equal local rejection levels
3. Choice of $\alpha, \alpha_{1}$ and $\alpha_{0}$


**Full second stage level**

Choose $\alpha_{2}=\alpha$, i.e. critical value $c_{\alpha}=e^{-\chi_{4,1-\alpha_{2}}^{-2} / 2}$ and $\alpha_{0}<1$. Determine $\alpha_{1}$ such that
$$
\mathbf{P}_{\Delta=0}\left(p_{1} \leq \alpha_{1}\right)+\mathbf{P}_{\Delta=0}\left(\alpha_{1}<p_{1} \leq \alpha_{0}, p q \leq c_{\alpha}\right)=\alpha
$$
Type I error rate calculation:
$$
\begin{array}{c}
\alpha=\mathbf{P}_{\Delta=0}\left(p_{1} \leq \alpha_{1}\right)+\mathbf{P}_{\Delta=0}\left(\alpha_{1}<p_{1} \leq \alpha_{0}, p q \leq c_{\alpha}\right) \\
=\alpha_{1}+\int_{\alpha_{1}}^{\alpha_{0}} \int_{0}^{1} \mathbf{1}_{\left\{p q \leq c_{\alpha}\right\}} d p d q=\alpha_{1}+\int_{\alpha_{1}}^{\alpha_{0}}\left(\frac{C_{\alpha}}{p}\right) d p \\
=\alpha_{1}+c_{\alpha}\left[\ln \left(\alpha_{0}\right)-\ln \left(\alpha_{1}\right)\right]
\end{array}
$$

**Equal local rejection levels**

Fix $\alpha_{0}<1$ and $\alpha_{1}=\alpha_{2}=\alpha^{*}<\alpha$ such that the type I error rate
$$
\alpha^{*}+c_{\alpha}\left[\ln \left(\alpha_{0}\right)-\ln \left(\alpha^{*}\right)\right]=\alpha
$$

**Choice of $\alpha, \alpha_{1}$ and $\alpha_{0}$**

Fix $\alpha, \alpha_{1}$ and $\alpha_{0}$ and calculate the critical value $c$ as
$$
c=\frac{\alpha-\alpha_{1}}{\ln \left(\alpha_{0}\right)-\ln \left(\alpha_{1}\right)}
$$
Non-stochastic curtailment:
$$
\alpha_{1}>c \quad \Longleftrightarrow \quad \alpha_{1}+\alpha_{1}\left(\ln \left(\alpha_{0}\right)-\ln \left(\alpha_{1}\right)\right) \geq \alpha
$$


## Inverse normal combination function

Use of the combination function:
$$
C(p, q)=1-\Phi(\sqrt{0.5} \underbrace{\Phi^{-1}(1-p)}_{z_{1}}+\sqrt{0.5} \underbrace{\Phi^{-1}(1-q)}_{z_{2}})
$$
We have that

* $Z_{1}=\Phi^{-1}(1-p) \sim N(0,1)$ and $Z_{2}=\Phi^{-1}(1-q) \sim N(0,1)$
* $Z_{1}$ and $Z_{2}$ are independent and standard normal.
$\mathbf{D}$ Therefore: $\quad Z_{2}^{*}=\sqrt{0.5} Z_{1}+\sqrt{0.5} Z_{2} \sim N(0,1)$
("weighted $z$ -score")
* $\mathbf{\Sigma} C(p, q)=1-\Phi(Z)$ is uniformly distributed under $H_{0}$.

  

```{r Inverse-normal-combination-1, echo=FALSE, fig.align="center", out.width = '100%',fig.cap="Figure: Comparison to Fisher’s product test (alpha_0 = 1)"}
knitr::include_graphics("./02_Plots/Inverse-normal-combination-1.png")
```


**Weighted inverse normal method**

Prefix $0 \leq w_{1}, w_{2} \leq 1$ with $w_{1}^{2}+w_{2}^{2}=1$ and use the combination function:
$$
C(p, q)=1-\Phi(w_{1} \underbrace{\Phi^{-1}(1-p)}_{Z_{1}}+w_{2} \underbrace{\Phi^{-1}(1-q)}_{Z_{2}})
$$
This implies
* $Z_{2}^{*}=w_{1} Z_{1}+w_{2} Z_{2} \sim N(0,1)$ with $\operatorname{Cov}\left(Z_{1}, Z_{2}^{*}\right)=w_{1}$
* Distribution as in GSD with interim information time $t=w_{1}^{2}$.
* We can use local levels from any GSD with $t_{1}=w_{1}^{2}$.
* This adaptive GSD is also called "weighted $z$ -score test" (Cui et al., 1999 ) and can be extended to designs with $K>2$ stages.
