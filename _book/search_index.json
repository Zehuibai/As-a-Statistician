[["meta-analysis.html", "Chapter 27 Meta Analysis 27.1 Introduction 27.2 Fixed Effect Model for Continuous Outcomes 27.3 Random Effects Model for Continuous Outcomes 27.4 Meta-Regression 27.5 Meta-Analysis with Binary Outcomes", " Chapter 27 Meta Analysis 27.1 Introduction .  Inverse variance method  27.1.1 meta-analysis for different data Meta-analysis of binary outcome data metabin Meta-analysis of continuous outcome data metacont Meta-analysis of correlations metacor Meta-analysis of incidence rates metainc Meta-regression metareg Meta-analysis of single proportions metaprop Meta-analysis of single means metamean Merge pooled results of two meta-analyses metamerge Combine and summarize meta-analysis objects metabind Meta-Analysis with Survival Outcomes library(&quot;meta&quot;) data4 &lt;- read.csv(&quot;./01_Datasets/dataset04.csv&quot;, as.is=TRUE) mg1 &lt;- metagen(logHR, selogHR, studlab=paste(author, year), data=data4, sm=&quot;HR&quot;) print(mg1, digits=2) ## Number of studies combined: k = 4 ## ## HR 95%-CI z p-value ## Common effect model 0.89 [0.78; 1.01] -1.82 0.0688 ## Random effects model 0.89 [0.78; 1.01] -1.82 0.0688 ## ## Quantifying heterogeneity: ## tau^2 &lt; 0.0001 [0.0000; 1.2885]; tau = 0.0011 [0.0000; 1.1351] ## I^2 = 17.2% [0.0%; 87.3%]; H = 1.10 [1.00; 2.81] ## ## Test of heterogeneity: ## Q d.f. p-value ## 3.62 3 0.3049 ## ## Details on meta-analytical method: ## - Inverse variance method ## - Restricted maximum-likelihood estimator for tau^2 ## - Q-profile method for confidence interval of tau^2 and tau Meta-Analysis of Cross-Over Trials data5 &lt;- read.csv(&quot;./01_Datasets/dataset05.csv&quot;, as.is=TRUE) ## meta-analysis of these cross-over trials mg2 &lt;- metagen(mean, SE, studlab=paste(author, year), data=data5, sm=&quot;MD&quot;) print(summary(mg2), digits=2) ## MD 95%-CI %W(common) %W(random) ## Skrabal et al. 1981a -4.50 [ -8.62; -0.38] 2.2 4.6 ## Skrabal et al. 1981b -0.50 [ -3.83; 2.83] 3.3 5.0 ## MacGregor et al. 1982 -4.00 [ -7.72; -0.28] 2.6 4.8 ## Khaw and Thom 1982 -2.40 [ -4.56; -0.24] 7.9 5.6 ## Richards et al. 1984 -1.00 [ -7.66; 5.66] 0.8 3.3 ## Smith et al. 1985 0.00 [ -3.72; 3.72] 2.6 4.8 ## Kaplan et al. 1985 -5.80 [ -8.94; -2.66] 3.7 5.1 ## Zoccali et al. 1985 -3.00 [ -8.88; 2.88] 1.1 3.6 ## Matlou et al. 1986 -3.00 [ -5.94; -0.06] 4.2 5.2 ## Barden et al. 1986 -1.50 [ -4.24; 1.24] 4.9 5.3 ## Poulter and Sever 1986 2.00 [ -2.31; 6.31] 2.0 4.5 ## Grobbee et al. 1987 -0.30 [ -3.24; 2.64] 4.2 5.2 ## Krishna et al. 1989 -8.00 [-12.31; -3.69] 2.0 4.5 ## Mullen and O&#39;Connor 1990a 3.00 [ -0.92; 6.92] 2.4 4.7 ## Mullen and O&#39;Connor 1990b 1.40 [ -2.52; 5.32] 2.4 4.7 ## Patki et al. 1990 -13.10 [-14.47; -11.73] 19.5 5.9 ## Valdes et al. 1991 -3.00 [ -6.92; 0.92] 2.4 4.7 ## Barden et al. 1991 -0.60 [ -1.78; 0.58] 26.5 5.9 ## Overlack et al. 1991 3.00 [ -0.92; 6.92] 2.4 4.7 ## Smith et al. 1992 -1.70 [ -6.60; 3.20] 1.5 4.1 ## Fotherby and Potter 1992 -6.00 [-10.90; -1.10] 1.5 4.1 ## ## Number of studies combined: k = 21 ## ## MD 95%-CI z p-value ## Common effect model -3.71 [-4.32; -3.11] -12.03 &lt; 0.0001 ## Random effects model -2.43 [-4.19; -0.66] -2.69 0.0071 ## ## Quantifying heterogeneity: ## tau^2 = 13.3645 [6.2066; 27.6896]; tau = 3.6558 [2.4913; 5.2621] ## I^2 = 92.5% [89.9%; 94.5%]; H = 3.66 [3.14; 4.25] ## ## Test of heterogeneity: ## Q d.f. p-value ## 267.24 20 &lt; 0.0001 ## ## Details on meta-analytical method: ## - Inverse variance method ## - Restricted maximum-likelihood estimator for tau^2 ## - Q-profile method for confidence interval of tau^2 and tau 27.2 Fixed Effect Model for Continuous Outcomes 27.2.1 Effect Measures Meta-analysis typically focuses on comparing two interventions, which we refer to as experimental and control. When the response is continuous (i.e. quantitative) typically the mean, standard deviation and sample size are reported for each group. \\[ \\begin{array}{|l|l} \\hline n_{e} &amp; \\text { Number of patients in the experimental (i.e. active) treatment arm } \\\\ \\hline \\hat{\\mu}_{e} &amp; \\text { Mean response in the experimental treatment arm } \\\\ \\hline s_{e} &amp; \\text { Standard deviation of the response in the experimental treatment arm } \\\\ n_{c} &amp; \\text { Number of patients in the control (often equivalent to placebo) arm } \\\\ \\hline \\hat{\\mu}_{c} &amp; \\text { Mean response in the control arm } \\\\ \\hline s_{c} &amp; \\text { Standard deviation of the response in the control arm } \\\\ \\hline \\end{array} \\] 27.2.2 Standardized Mean Difference Mean difference For study \\(k\\), the estimated mean difference is \\[ \\hat{\\mu}_{k}=\\hat{\\mu}_{e k}-\\hat{\\mu}_{c k}, \\] with variance estimate \\[ \\widehat{\\operatorname{Var}}\\left(\\hat{\\mu}_{k}\\right)=\\frac{s_{e k}^{2}}{n_{e k}}+\\frac{s_{c k}^{2}}{n_{c k}} \\] An approximate two-sided \\((1-\\alpha)\\) confidence interval for the mean difference is given by \\[ \\left(\\hat{\\mu}_{e k}-\\hat{\\mu}_{c k}\\right) \\pm z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{s_{e k}^{2}}{n_{e k}}+\\frac{s_{c k}^{2}}{n_{c k}}} \\] Standardized Mean Difference ,  , ,   () ,   dimensionless effect,   RmetametacontHedgesk : \\[ \\hat{g}_{k}=\\left(1-\\frac{3}{4 n_{k}-9}\\right) \\frac{\\hat{\\mu}_{e k}-\\hat{\\mu}_{c k}}{\\sqrt{\\left(\\left(n_{e k}-1\\right) s_{e k}^{2}+\\left(n_{c k}-1\\right) s_{c k}^{2}\\right) /\\left(n_{k}-2\\right)}} \\] where \\(n_{k}=n_{e k}+n_{c k}\\) and the factor \\(1-3 /\\left(4 n_{k}-9\\right)\\) corrects for the bias in the estimated standard error. To calculate a confidence interval for \\(\\hat{g}_{k}\\), we need its variance; again following RevMan is calculated as \\[ \\widehat{\\operatorname{Var}}\\left(\\hat{g}_{k}\\right)=\\frac{n_{k}}{n_{e k} \\cdot n_{c k}}+\\frac{\\hat{g}_{k}^{2}}{2\\left(n_{k}-3.94\\right)} \\] Once \\(\\hat{g}_{k}\\) and \\(\\widehat{\\operatorname{Var}}\\left(\\hat{g}_{k}\\right)\\) are calculated a two-sided \\((1-\\alpha)\\) confidence interval can be calculated by \\[\\hat{g}_{k} \\pm z_{1-\\frac{\\alpha}{2}} \\text { S.E. }\\left(\\hat{g}_{k}\\right)\\] Once \\(\\hat{g}_{k}\\) and \\(\\overline{\\operatorname{Var}}\\left(\\hat{g}_{k}\\right)\\) are calculated a two-sided \\((1-\\alpha)\\) confidence interval can be calculated by with standard error S.E. \\(\\left(\\hat{g}_{k}\\right)=\\sqrt{\\overline{\\operatorname{Var}}\\left(\\hat{g}_{k}\\right)}\\) and \\(z_{1-\\frac{\\alpha}{2}}\\) denoting the \\(1-\\frac{\\alpha}{2}\\) quantile of the standard normal distribution. use the metacont function to calculate mean difference and confidence interval ## use the metacont function to calculate mean difference and confidence interval ## sm=&quot;MD&quot; (i.e. summary measure is the Mean Difference) as default setting. data(Fleiss1993cont) library(&quot;meta&quot;) m1 &lt;- metacont(n.psyc, mean.psyc, sd.psyc, n.cont, mean.cont, sd.cont, data = Fleiss1993cont, sm = &quot;SMD&quot;) m1 ## Number of studies combined: k = 5 ## Number of observations: o = 232 ## ## SMD 95%-CI z p-value ## Common effect model -0.3434 [-0.6068; -0.0801] -2.56 0.0106 ## Random effects model -0.3434 [-0.6068; -0.0801] -2.56 0.0106 ## ## Quantifying heterogeneity: ## tau^2 = 0 [0.0000; 0.7255]; tau = 0 [0.0000; 0.8518] ## I^2 = 0.0% [0.0%; 79.2%]; H = 1.00 [1.00; 2.19] ## ## Test of heterogeneity: ## Q d.f. p-value ## 3.68 4 0.4514 ## ## Details on meta-analytical method: ## - Inverse variance method ## - Restricted maximum-likelihood estimator for tau^2 ## - Q-profile method for confidence interval of tau^2 and tau ## - Hedges&#39; g (bias corrected standardised mean difference; using exact formulae) 27.2.3 Inverse variance-weighted average method There are two methods for the fixed effects model meta-analysis: the IVW and weighted SZ. The fixed effects model assumes that all studies in a meta-analysis share a single true effect size.  component studies  single homogeneous populatio  More formally, let \\(k=1, \\ldots, K\\) index study, \\(\\hat{\\theta}_{k}\\) denote the intervention effect estimate from study \\(k\\), and \\(\\theta\\) denote the intervention effect in the population, which we wish to estimate. Denote by \\(\\hat{\\sigma}_{k}^{2}\\) the sample estimate of \\(\\operatorname{Var}\\left(\\hat{\\theta}_{k}\\right)\\). The fixed effect model is \\[ \\hat{\\theta}_{k}=\\theta+\\sigma_{k} \\epsilon_{k}, \\quad \\epsilon_{k}^{\\mathrm{i} . \\mathrm{i} . \\mathrm{d} .} N(0,1) \\] We now consider the fixed effect estimate of \\(\\theta\\), denoted by \\(\\hat{\\theta}_{F}\\). Given estimates \\(\\left(\\hat{\\theta}_{k}, \\hat{\\sigma}_{k}\\right), k=1, \\ldots, K\\), the maximum-likelihood estimate under model (2.7) is \\[ \\hat{\\theta}_{F}=\\frac{\\sum_{k=1}^{K} \\hat{\\theta}_{k} / \\hat{\\sigma}_{k}^{2}}{\\sum_{k=1}^{K} 1 / \\hat{\\sigma}_{k}^{2}}=\\frac{\\sum_{k=1}^{K} w_{k} \\hat{\\theta}_{k}}{\\sum_{k=1}^{K} w_{k}} \\] Accordingly, \\(\\hat{\\theta}_{F}\\) is a weighted average of the individual effect estimates \\(\\hat{\\theta}_{k}\\) with weights \\(w_{k}=1 / \\hat{\\sigma}_{k}^{2}\\). Therefore, this method is called the inverse variance method. The variance of \\(\\hat{\\theta}_{F}\\) is estimated by \\[ \\widehat{\\operatorname{Var}}\\left(\\hat{\\theta}_{F}\\right)=\\frac{1}{\\sum_{k=1}^{K} w_{k}} \\] \\((1-\\alpha)\\) confidence interval for \\(\\hat{\\theta}_{F}\\) can be calculated by \\[\\hat{\\theta}_{F} \\pm z_{1-\\frac{\\alpha}{2}} \\text { SE }\\left(\\hat{\\theta}_{F}\\right)\\] data1 &lt;- read.csv(&quot;./01_Datasets/dataset01.csv&quot;, as.is=TRUE) data2 &lt;- read.csv(&quot;./01_Datasets/dataset02.csv&quot;, as.is=TRUE) ## The fixed effect estimate and its variance can be calculated using base R code ## 1. Calculate mean difference, variance and weights MD &lt;- with(data1, Me - Mc) varMD &lt;- with(data1, Se^2/Ne + Sc^2/Nc) weight &lt;- 1/varMD ## 2. Calculate the inverse variance estimator ## the standard weighted.mean function is used to calculate theta_F. round(weighted.mean(MD, weight), 4) ## [1] -15.514 ## 3. Calculate the variance round(1/sum(weight), 4) ## [1] 1.4126 ## Alternative easier using the metacont function which yields identical results mc1 &lt;- metacont(Ne, Me, Se, Nc, Mc, Sc, data=data1, studlab=paste(author, year)) round(c(mc1$TE.fixed, mc1$seTE.fixed^2), 4) ## [1] -15.5140 1.4126 ## Forest Plot ## pdf(file=&quot;Schwarzer-Fig2.3.pdf&quot;, width=9.6) ## uncomment line to generate PDF file forest(mc1, comb.random=FALSE, xlab= &quot;Difference in mean response (intervention - control) units: maximum % fall in FEV1&quot;, xlim=c(-50,10), xlab.pos=-20, smlab.pos=-20) ## invisible(dev.off()) ## uncomment line to save PDF file 27.2.4 Generic inverse variance meta-analysis metagen Fixed effect and random effects meta-analysis based on estimates (e.g. log hazard ratios) and their standard errors. The inverse variance method is used for pooling. sm: A character string indicating underlying summary measure, e.g., RD, RR, OR, ASD, HR, MD, SMD, or ROM. Confidence intervals for individual studies: For the mean difference (argument sm = MD), the confidence interval for individual studies can be based on the standard normal distribution (method.ci = z), or t-distribution (method.ci = t). Estimation of between-study variance: method.tau = \"DL\" DerSimonian-Laird estimator (DerSimonian and Laird, 1986) method.tau = \"PM\" Paule-Mandel estimator (Paule and Mandel, 1982) method.tau = \"REML\" Restricted maximum-likelihood estimator (Viechtbauer, 2005) method.tau = \"ML\" Maximum-likelihood estimator (Viechtbauer, 2005) method.tau = \"HS\" Hunter-Schmidt estimator (Hunter and Schmidt, 2015) method.tau = \"SJ\" Sidik-Jonkman estimator (Sidik and Jonkman, 2005) method.tau = \"HE\" Hedges estimator (Hedges and Olkin, 1985) method.tau = \"EB\" Empirical Bayes estimator (Morris, 1983) Confidence interval for the between-study variance: method.tau.ci = \"J\" Method by Jackson (2013) method.tau.ci = \"BJ\" Method by Biggerstaff and Jackson (2008) method.tau.ci = \"QP\" Q-Profile method (Viechtbauer, 2007) method.tau.ci = \"PL\" Profile-Likelihood method for three-level meta-analysis model (Van den Noortgate et al., 2013) mc1.gen &lt;- metagen(TE, seTE, data=mc1, sm=&quot;MD&quot;) ## Print results for fixed effect and random effects method c(mc1$TE.fixed, mc1$TE.random) ## [1] -15.51403 -15.64702 c(mc1.gen$TE.fixed, mc1.gen$TE.random) ## [1] -15.51403 -15.64702 27.2.5 Weighted Sum of Z-Scores Another popular method for the fixed effects model meta-analysis is calculating the weighted SZ from the follows studies. Let \\(Z_{i}\\) be the z-score from study \\(i\\), which \\(N(0,1)\\) under the null hypothesis of no effects. Then, the weighted SZ statistic is \\[ Z_{S Z}=\\frac{\\sum w_{S Z, i} Z_{i}}{\\sqrt{\\sum w_{S Z, i}{ }^{2}}} \\] By the characteristic of a normal distribution, \\(\\mathrm{Z}_{\\mathrm{SZ}}\\) also follows \\(N(0,1)\\) under the null hypothesis. To combine z-scores from multiple studies, a per-study sample size was suggested as weights of each study, as follows: \\[ w_{S Z, i}=\\sqrt{N_{i}} \\] 27.3 Random Effects Model for Continuous Outcomes 27.3.1 Introduction The random effects model seeks to account for the fact that the study effect estimates \\(\\hat{\\theta}_{k}\\) are often more variable than assumed in the fixed effect model. Under the random effects model, \\[ \\hat{\\theta}_{k}=\\theta+u_{k}+\\sigma_{k} \\epsilon_{k}, \\quad \\epsilon_{k}^{\\text {i.i.d. }} N(0,1) ; u_{k}^{\\text {i.i.d. }} N\\left(0, \\tau^{2}\\right) \\] where the \\(u\\) s and \\(\\epsilon\\) s are independent. Define \\[ Q=\\sum_{k=1}^{K} w_{k}\\left(\\hat{\\theta}_{k}-\\hat{\\theta}_{F}\\right)^{2} \\] the weighted sum of squares about the fixed effect estimate with \\(w_{k}=1 / \\hat{\\sigma}_{k}^{2}\\). This is usually referred to as either the homogeneity test statistic or the heterogeneity statistic. Next define \\[ S=\\sum_{k=1}^{K} w_{k}-\\frac{\\sum_{k=1}^{K} w_{k}^{2}}{\\sum_{k=1}^{K} w_{k}} \\] If \\(Q&lt;(K-1)\\), then \\(\\hat{\\tau}^{2}\\) is set to 0 and the random effects estimate \\(\\hat{\\theta}_{R}\\) is set equal to the fixed effect estimate \\(\\hat{\\theta}_{F}\\). Otherwise, the Dersimonian-Laird estimator of the between-study variance is defined as \\[ \\hat{\\tau}^{2}=\\frac{Q-(K-1)}{S} \\] and the random effects estimate and its variance are given by \\[ \\begin{array}{c} \\hat{\\theta}_{R}=\\frac{\\sum_{k=1}^{K} w_{k}^{*} \\hat{\\theta}_{k}}{\\sum_{k=1}^{K} w_{k}^{*}} \\\\ \\operatorname{Var}\\left(\\hat{\\theta}_{R}\\right)=\\frac{1}{\\sum_{k=1}^{K} w_{k}^{*}} \\end{array} \\] with weights \\(w_{k}^{*}=1 /\\left(\\hat{\\sigma}_{k}^{2}+\\hat{\\tau}^{2}\\right)\\). The random effects estimator \\(\\hat{\\theta}_{R}\\) is a weighted average of the individual effect estimates \\(\\hat{\\theta}_{k}\\) with weights \\(1 /\\left(\\hat{\\sigma}_{k}^{2}+\\hat{\\tau}^{2}\\right)\\). Accordingly, this method is often called Inverse variance method, too. A \\((1-\\alpha)\\) confidence interval for \\(\\hat{\\theta}_{R}\\) can be calculated by \\[\\hat{\\theta}_{R} \\pm z_{1-\\frac{\\alpha}{2}} \\text { S.E. }\\left(\\hat{\\theta}_{R}\\right)\\] 27.3.2 Implementation Estimation of Between-Study Variance DerSimonianLaird estimator (method.tau=DL) (default) PauleMandel estimator (method.tau=PM) Restricted maximum-likelihood estimator (method.tau=REML) Maximum-likelihood estimator (method.tau=ML) HunterSchmidt estimator (method.tau=HS) SidikJonkman estimator (method.tau=SJ) Hedges estimator (method.tau=HE) Empirical Bayes estimator (method.tau=EB). # 1. Conduct meta-analyses # 1a. DerSimonian-Laird estimator (default) mg1.DL &lt;- metagen(TE, seTE, data=mc1) # 1b. Paule-Mandel estimator mg1.PM &lt;- metagen(TE, seTE, data=mc1, method.tau=&quot;PM&quot;) # 1c. Restricted maximum-likelihood estimator mg1.RM &lt;- metagen(TE, seTE, data=mc1, method.tau=&quot;REML&quot;) # 1d. Maximum-likelihood estimator mg1.ML &lt;- metagen(TE, seTE, data=mc1, method.tau=&quot;ML&quot;) # 1e. Hunter-Schmidt estimator mg1.HS &lt;- metagen(TE, seTE, data=mc1, method.tau=&quot;HS&quot;) # 1f. Sidik-Jonkman estimator mg1.SJ &lt;- metagen(TE, seTE, data=mc1, method.tau=&quot;SJ&quot;) # 1g. Hedges estimator mg1.HE &lt;- metagen(TE, seTE, data=mc1, method.tau=&quot;HE&quot;) # 1h. Empirical Bayes estimator mg1.EB &lt;- metagen(TE, seTE, data=mc1, method.tau=&quot;EB&quot;) # 2. Extract between-study variance tau-squared tau2 &lt;- data.frame(tau2=round(c(0, mg1.DL$tau^2, mg1.PM$tau^2, mg1.RM$tau^2, mg1.ML$tau^2, mg1.HS$tau^2, mg1.SJ$tau^2, mg1.HE$tau^2, mg1.EB$tau^2), 2), row.names=c(&quot;FE&quot;, &quot;DL&quot;, &quot;PM&quot;, &quot;REML&quot;, &quot;ML&quot;, &quot;HS&quot;, &quot;SJ&quot;, &quot;HE&quot;, &quot;EB&quot;)) # 3. Print tau-squared values t(tau2) ## FE DL PM REML ML HS SJ HE EB ## tau2 0 2.52 2.48 2.52 0.06 0.81 15.75 0 2.48 # 4. Create dataset with summaries res &lt;- data.frame(MD=c(mg1.DL$TE.fixed, mg1.DL$TE.random, mg1.PM$TE.random, mg1.RM$TE.random, mg1.ML$TE.random, mg1.HS$TE.random, mg1.SJ$TE.random, mg1.HE$TE.random, mg1.EB$TE.random), seMD=c(mg1.DL$seTE.fixed, mg1.DL$seTE.random, mg1.PM$seTE.random, mg1.RM$seTE.random, mg1.ML$seTE.random, mg1.HS$seTE.random, mg1.SJ$seTE.random, mg1.HE$seTE.random, mg1.EB$seTE.random), method=c(&quot;&quot;, &quot;DerSimonian-Laird&quot;, &quot;Paule-Mandel&quot;, &quot;Restricted maximum-likelihood&quot;, &quot;Maximum-likelihood&quot;, &quot;Hunter-Schmidt&quot;, &quot;Sidik-Jonkman&quot;, &quot;Hedges&quot;, &quot;Empirical Bayes&quot;), tau2=tau2, model=c(&quot;Fixed-effect model&quot;, rep(&quot;Random-effect model&quot;, 8))) knitr::kable(res) MD seMD method tau2 model FE -15.51403 1.188538 0.00 Fixed-effect model DL -15.64702 1.274628 DerSimonian-Laird 2.52 Random-effect model PM -15.64543 1.273478 Paule-Mandel 2.48 Random-effect model REML -15.64702 1.274628 Restricted maximum-likelihood 2.52 Random-effect model ML -15.51773 1.190701 Maximum-likelihood 0.06 Random-effect model HS -15.56254 1.217847 Hunter-Schmidt 0.81 Random-effect model SJ -15.95615 1.603754 Sidik-Jonkman 15.75 Random-effect model HE -15.51403 1.188538 Hedges 0.00 Random-effect model EB -15.64543 1.273478 Empirical Bayes 2.48 Random-effect model # 5. Do meta-analysis m &lt;- metagen(MD, seMD, data=res, studlab=method, sm=&quot;MD&quot;, comb.fixed=FALSE, comb.random=FALSE, byvar=model) knitr::kable(m) studlab TE seTE lower upper statistic pval zval df w.fixed w.random data.MD data.seMD data.method data.tau2 data.model data..TE data..seTE data..studlab data..subgroup subgroup byvar FE -15.51403 1.188538 -17.84353 -13.18454 -13.053036 0 -13.053036 NA 0.7079028 0.7079028 -15.51403 1.188538 0.00 Fixed-effect model -15.51403 1.188538 Fixed-effect model Fixed-effect model Fixed-effect model DL DerSimonian-Laird -15.64702 1.274628 -18.14525 -13.14880 -12.275758 0 -12.275758 NA 0.6155073 0.6155073 -15.64702 1.274628 DerSimonian-Laird 2.52 Random-effect model -15.64702 1.274628 DerSimonian-Laird Random-effect model Random-effect model Random-effect model PM Paule-Mandel -15.64543 1.273478 -18.14140 -13.14946 -12.285593 0 -12.285593 NA 0.6166196 0.6166196 -15.64543 1.273478 Paule-Mandel 2.48 Random-effect model -15.64543 1.273478 Paule-Mandel Random-effect model Random-effect model Random-effect model REML Restricted maximum-likelihood -15.64702 1.274628 -18.14525 -13.14880 -12.275758 0 -12.275758 NA 0.6155073 0.6155073 -15.64702 1.274628 Restricted maximum-likelihood 2.52 Random-effect model -15.64702 1.274628 Restricted maximum-likelihood Random-effect model Random-effect model Random-effect model ML Maximum-likelihood -15.51773 1.190701 -17.85146 -13.18400 -13.032432 0 -13.032432 NA 0.7053334 0.7053334 -15.51773 1.190701 Maximum-likelihood 0.06 Random-effect model -15.51773 1.190701 Maximum-likelihood Random-effect model Random-effect model Random-effect model HS Hunter-Schmidt -15.56254 1.217847 -17.94947 -13.17560 -12.778728 0 -12.778728 NA 0.6742399 0.6742399 -15.56254 1.217847 Hunter-Schmidt 0.81 Random-effect model -15.56254 1.217847 Hunter-Schmidt Random-effect model Random-effect model Random-effect model SJ Sidik-Jonkman -15.95615 1.603754 -19.09945 -12.81285 -9.949252 0 -9.949252 NA 0.3887986 0.3887986 -15.95615 1.603754 Sidik-Jonkman 15.75 Random-effect model -15.95615 1.603754 Sidik-Jonkman Random-effect model Random-effect model Random-effect model HE Hedges -15.51403 1.188538 -17.84353 -13.18454 -13.053036 0 -13.053036 NA 0.7079028 0.7079028 -15.51403 1.188538 Hedges 0.00 Random-effect model -15.51403 1.188538 Hedges Random-effect model Random-effect model Random-effect model EB Empirical Bayes -15.64543 1.273478 -18.14140 -13.14946 -12.285593 0 -12.285593 NA 0.6166196 0.6166196 -15.64543 1.273478 Empirical Bayes 2.48 Random-effect model -15.64543 1.273478 Empirical Bayes Random-effect model Random-effect model Random-effect model # 6. Do forest plot # pdf(file=&quot;Schwarzer-Fig2.5.pdf&quot;, width=8.1, height=4.0) # uncomment line to generate PDF file forest(m, xlim=c(-20, -12), hetstat=FALSE, smlab=&quot;&quot;, leftcols=c(&quot;studlab&quot;, &quot;tau2&quot;), leftlabs=c(&quot;Method&quot;, &quot;Between-study\\nheterogeneity&quot;), print.byvar=FALSE) # invisible(dev.off()) # uncomment line to save PDF file 27.3.3 Hartung-Knapp Adjustment Hartung and Knapp (2001a,b) proposed an alternative method for random effects meta-analysis based on a refined variance estimator for the treatment estimate. Simulation studies (Hartung and Knapp, 2001a,b; IntHout et al., 2014; Langan et al., 2019) show improved coverage probabilities compared to the classic random effects method. HartungKnapp DerSimonianLairdHartung-Knapp  \\[ \\widehat{\\operatorname{Var}}\\left(\\hat{\\theta}_{R}\\right)=\\frac{1}{\\sum_{k=1}^{K} w_{k}^{*}} \\] Instead of using the variance estimate given in Eq. (2.14), Hartung and Knapp propose to use the following variance estimator for \\(\\hat{\\theta}_{R}\\) : \\[ \\widehat{\\operatorname{Var}}_{\\mathrm{HK}}\\left(\\hat{\\theta}_{R}\\right)=\\frac{1}{K-1} \\sum_{k=1}^{K} \\frac{w_{k}^{*}}{w^{*}}\\left(\\hat{\\theta}_{k}-\\hat{\\theta}_{R}\\right)^{2} \\] with weights \\(w_{k}^{*}\\) as given in above and \\(w=\\sum k=1^{K} w k\\). Hartung showed that \\[ \\frac{\\hat{\\theta}_{R}-\\theta}{\\text { S.E. } \\mathrm{HK}\\left(\\hat{\\theta}_{R}\\right)} \\] with standard error s.E. \\(\\mathrm{HK}\\left(\\hat{\\theta}_{R}\\right)=\\sqrt{\\widehat{\\operatorname{Var}}_{\\mathrm{HK}}\\left(\\hat{\\theta}_{R}\\right)}\\) follows a \\(t\\) -distribution with \\(K-1\\) degrees of freedom. Accordingly, a \\((1-\\alpha)\\) confidence interval for \\(\\hat{\\theta}_{R}\\) based on the Hartung-Knapp method can be calculated by \\[ \\hat{\\theta}_{R} \\pm t_{K-1 ; 1-\\frac{\\alpha}{2}} \\text { S.E. } \\mathrm{HK}\\left(\\hat{\\theta}_{R}\\right) \\] ## use the metacont function to conduct the HartungKnapp adjustment mc2.hk &lt;- metacont(Ne, Me, Se, Nc, Mc, Sc, sm=&quot;SMD&quot;, data=data2, comb.fixed=FALSE, hakn=TRUE) However, in rare settings with very homogeneous treatment estimates, the Hartung-Knapp (HK) variance estimate can be arbitrarily small resulting in a very narrow confidence interval (Knapp and Hartung, 2003; Wiksten et al., 2016). In such cases, an ad hoc variance correction has been proposed by utilising the variance estimate from the classic random effects model with the HK method (Knapp and Hartung, 2003; IQWiQ, 2020). An alternative approach is to use the wider confidence interval of classic fixed or random effects meta-analysis and the HK method (Wiksten et al., 2016; Jackson et al., 2017). adhoc.hakn = \"\" Ad hoc method not used adhoc.hakn = \"se\" use variance correction if HK standard error is smaller than standard error from classic random effects meta-analysis (Knapp and Hartung, 2003) adhoc.hakn = \"iqwig6\" use variance correction if HK confidence interval is narrower than CI from classic random effects model with DerSimonian-Laird estimator (IQWiG, 2020) adhoc.hakn = \"ci\" use wider confidence interval of classic random effects and HK meta-analysis (Hybrid method 2 in Jackson et al., 2017) 27.4 Meta-Regression /Meta-regression model \\[ \\hat{\\theta}_{k}=\\theta+\\beta_{1} x_{1 k}+\\cdots+\\beta_{P} x_{P k}+u_{k}+\\sigma_{k} \\epsilon_{k}, \\quad \\epsilon_{k}^{\\text {i.i.d. }} N(0,1) ; u_{k}^{\\text {i.i.d. }} N\\left(0, \\tau^{2}\\right) \\] with \\(k=1, \\ldots, K\\) and independent error terms \\(u\\) and \\(\\epsilon\\). As this model has both fixed effect \\((\\beta \\mathrm{s})\\) and random effects terms \\(\\left(u_{k}\\right.\\) with variance \\(\\left.\\tau^{2}\\right)\\) this meta-regression model is also called a mixed effects model. The fixed effect meta-regression is a special case of the mixed effects model when the between-study variance \\(\\tau^{2}=0\\). n order to calculate 95 % confidence intervals for studies with longer study duration based on information from the meta-regression model, the variancecovariance matrix of the estimated coefficients has to be taken into account. data3 &lt;- read.csv(&quot;./01_Datasets/dataset03.csv&quot;, as.is=TRUE) ## Meta-Regression with a Categorical Covariate mc3s.c &lt;- metacont(Ne, Me, Se, Nc, Mc, Sc, data=data3, studlab=paste(author, year), byvar=duration, print.byvar=FALSE, tau.common=TRUE, comb.fixed=FALSE) print(summary(mc3s.c), digits=2) ## MD 95%-CI %W(random) duration ## Bontognali 1991 -0.57 [-2.69; 1.55] 0.0 &lt;= 3 months ## Castiglioni 1986 -0.10 [-0.14; -0.06] 5.8 &lt;= 3 months ## Cremonini 1986 -0.46 [-0.62; -0.30] 2.7 &lt;= 3 months ## Grassi 1994 -0.29 [-0.45; -0.13] 2.7 &lt;= 3 months ## Jackson 1984 -0.02 0.0 &lt;= 3 months ## Allegra 1996 -0.04 [-0.06; -0.02] 6.1 &gt; 3 months ## Babolini 1980 -0.20 [-0.24; -0.16] 5.8 &gt; 3 months ## Boman 1983 -0.12 [-0.20; -0.04] 4.8 &gt; 3 months ## Borgia 1981 -0.10 [-0.22; 0.02] 3.6 &gt; 3 months ## Decramer 2005 -0.01 [-0.03; 0.01] 6.1 &gt; 3 months ## Grassi 1976 -0.13 [-0.22; -0.04] 4.5 &gt; 3 months ## Grillage 1985 -0.02 0.0 &gt; 3 months ## Hansen 1994 -0.05 [-0.11; 0.01] 5.3 &gt; 3 months ## Malerba 2004 -0.01 [-0.03; 0.01] 6.2 &gt; 3 months ## McGavin 1985 -0.10 [-0.21; 0.01] 3.8 &gt; 3 months ## Meister 1986 -0.05 [-0.10; -0.00] 5.6 &gt; 3 months ## Meister 1999 -0.04 [-0.08; -0.00] 5.9 &gt; 3 months ## Moretti 2004 -0.05 [-0.10; 0.00] 5.4 &gt; 3 months ## Nowak 1999 -0.03 [-0.05; -0.01] 6.1 &gt; 3 months ## Olivieri 1987 -0.15 [-0.25; -0.05] 4.2 &gt; 3 months ## Parr 1987 -0.03 [-0.07; 0.01] 5.8 &gt; 3 months ## Pela 1999 -0.12 [-0.20; -0.04] 4.7 &gt; 3 months ## Rasmussen 1988 -0.01 [-0.09; 0.07] 4.7 &gt; 3 months ## ## Number of studies combined: k = 21 ## Number of observations: o = 5055 ## ## MD 95%-CI z p-value ## Random effects model -0.09 [-0.12; -0.05] -4.89 &lt; 0.0001 ## ## Quantifying heterogeneity: ## tau^2 = 0.0051 [0.0029; 0.0196]; tau = 0.0711 [0.0536; 0.1401] ## I^2 = 85.5% [79.1%; 89.9%]; H = 2.63 [2.19; 3.15] ## ## Quantifying residual heterogeneity: ## tau^2 = 0.0040; tau = 0.0636; I^2 = 83.8% [76.2%; 89.0%]; H = 2.49 [2.05; 3.01] ## ## Test of heterogeneity: ## Q d.f. p-value ## 138.08 20 &lt; 0.0001 ## ## Results for subgroups (random effects model): ## k MD 95%-CI tau^2 tau Q I^2 ## &lt;= 3 months 4 -0.23 [-0.32; -0.13] 0.0040 0.0636 22.43 86.6% ## &gt; 3 months 17 -0.07 [-0.10; -0.03] 0.0040 0.0636 94.92 83.1% ## ## Test for subgroup differences (random effects model): ## Q d.f. p-value ## Between groups 9.15 1 0.0025 ## Within groups 117.35 19 &lt; 0.0001 ## ## Details on meta-analytical method: ## - Inverse variance method ## - Restricted maximum-likelihood estimator for tau^2 ## (assuming common tau^2 in subgroups) ## - Q-profile method for confidence interval of tau^2 and tau mc3s.mr &lt;- metareg(mc3s.c, duration) print(mc3s.mr, digits=2) ## ## Mixed-Effects Model (k = 21; tau^2 estimator: REML) ## ## tau^2 (estimated amount of residual heterogeneity): 0.00 (SE = 0.00) ## tau (square root of estimated tau^2 value): 0.06 ## I^2 (residual heterogeneity / unaccounted variability): 89.66% ## H^2 (unaccounted variability / sampling variability): 9.67 ## R^2 (amount of heterogeneity accounted for): 19.93% ## ## Test for Residual Heterogeneity: ## QE(df = 19) = 117.35, p-val &lt; .01 ## ## Test of Moderators (coefficient 2): ## QM(df = 1) = 9.15, p-val &lt; .01 ## ## Model Results: ## ## estimate se zval pval ci.lb ci.ub ## intrcpt -0.23 0.05 -4.58 &lt;.01 -0.32 -0.13 *** ## duration&gt; 3 months 0.16 0.05 3.02 &lt;.01 0.06 0.26 ** ## ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Variance-covariance matrix varcov &lt;- vcov(mc3s.mr) # Estimated treatment effect in studies with longer duration TE.s2 &lt;- sum(coef(mc3s.mr)) # Standard error of treatment effect seTE.s2 &lt;- sqrt(sum(diag(varcov)) + 2*varcov[1,2]) ## The quantities TE.s2 and seTE.s2 can be used as input to the metagen function to estimate a 95 % confidence interval. print(metagen(TE.s2, seTE.s2, sm=&quot;MD&quot;), digits=2) ## ## MD 95%-CI z p-value ## -0.07 [-0.10; -0.03] -3.93 &lt; 0.0001 ## ## Details: ## - Inverse variance method 27.5 Meta-Analysis with Binary Outcomes 27.5.1 Effect Measures The most commonly used effect measures for binary outcomes are the odds ratio, risk ratio and risk difference. Another effect measure, the arcsine difference (), which is used in tests for small-study effects these relative effect measures are on average more stable across studies than the risk difference () Summary data of study k in meta-analysis with binary responses .\\(k =1;...; K\\) \\[\\begin{array}{l|l|l|l} \\hline &amp; \\text { Event } &amp; \\text { No event } &amp; \\text { Group size } \\\\ \\hline \\text { Experimental } &amp; a_{k} &amp; b_{k} &amp; n_{e k}=a_{k}+b_{k} \\\\ \\hline \\text { Control } &amp; c_{k} &amp; d_{k} &amp; n_{c k}=c_{k}+d_{k} \\\\ \\hline &amp; a_{k}+c_{k} &amp; b_{k}+d_{k} &amp; n_{k} \\\\ \\hline \\end{array}\\] These probabilities are estimated from the observed cell counts by \\[\\hat{p}_{e k}=a_{k} /\\left(a_{k}+b_{k}\\right)=a_{k} / n_{e k} \\text { and } \\hat{p}_{c k}=c_{k} /\\left(c_{k}+d_{k}\\right)=c_{k} / n_{c k}\\] 27.5.1.1 Odds Ratio The odds ratio for study \\(k, \\psi_{k}\\), is defined as the ratio of the odds of an event in the experimental arm to that in the control arm. That is \\[ \\psi_{k}=\\frac{\\left(\\frac{p_{e k}}{1-p_{e k}}\\right)}{\\left(\\frac{p_{c k}}{1-p_{c k}}\\right)}=\\frac{p_{e k}\\left(1-p_{c k}\\right)}{p_{c k}\\left(1-p_{e k}\\right)} \\] - If either of the two estimated event probabilities is zero the log odds ratio, \\(\\log \\psi_{k}\\), is either \\(-\\infty\\) or \\(+\\infty\\) - If both are zero, the log odds ratio is undefined. The odds ratio from study \\(k\\) is estimated by \\[ \\hat{\\psi}_{k}=\\frac{a_{k} d_{k}}{b_{k} c_{k}} \\] variance of the natural logarithm of the odds ratio is well approximated by \\[ \\widehat{\\operatorname{Var}}\\left(\\log \\hat{\\psi}_{k}\\right)=\\frac{1}{a_{k}}+\\frac{1}{b_{k}}+\\frac{1}{c_{k}}+\\frac{1}{d_{k}} \\] where the approximation improves as nek and \\(n_{c k}\\) increase. Using the estimate of the log odds ratio, and its estimated variance, an approximate two-sided \\((1-\\alpha)\\) confidence interval for the odds ratio is given by \\[\\exp \\left(\\log \\hat{\\psi}_{k} \\pm z_{1-\\frac{\\alpha}{2}} \\text { S.E. }\\left(\\log \\hat{\\psi}_{k}\\right)\\right)\\] metabin(Ee, Ne, Ec, Nc, sm=&quot;OR&quot;, method=&quot;I&quot;, data=data7, subset=study==&quot;Milpied&quot;) 27.5.1.2 Risk Ratio The risk ratio \\(\\phi_{k}\\), often called relative risk, is defined as the ratio of the two event probabilities, \\[ \\phi_{k}=\\frac{p_{e k}}{p_{c k}} \\] If either of the two event probabilities is zero the log risk ratio \\(\\log \\phi_{k}\\), is either \\(-\\infty\\) or \\(+\\infty .\\) If both probabilities are zero, the log risk ratio is undefined. The risk ratio is estimated by \\[ \\hat{\\phi}_{k}=\\frac{\\left(\\frac{a_{k}}{a_{k}+b_{k}}\\right)}{\\left(\\frac{c_{k}}{c_{k}+d_{k}}\\right)} \\] whose variance is approximated by \\[ \\widehat{\\operatorname{Var}}\\left(\\log \\hat{\\phi}_{k}\\right)=\\frac{1}{a_{k}}+\\frac{1}{c_{k}}-\\frac{1}{a_{k}+b_{k}}-\\frac{1}{c_{k}+d_{k}} \\] metabin(Ee, Ne, Ec, Nc, sm=&quot;RR&quot;, method=&quot;I&quot;, data=data7, subset=study==&quot;Milpied&quot;) 27.5.1.3 Risk Difference The risk difference \\(\\eta_{k}\\) is defined as the difference between the two event probabilities \\[ \\eta_{k}=p_{e k}-p_{c k} \\] The risk difference is always defined and has finite range from \\(-1\\) to 1 . The natural estimate of the risk difference is \\[ \\hat{\\eta}_{k}=\\frac{a_{k}}{a_{k}+b_{k}}-\\frac{c_{k}}{c_{k}+d_{k}} \\] with corresponding variance estimate \\[ \\widehat{\\operatorname{Var}}\\left(\\hat{\\eta}_{k}\\right)=\\frac{a_{k} b_{k}}{\\left(a_{k}+b_{k}\\right)^{3}}+\\frac{c_{k} d_{k}}{\\left(c_{k}+d_{k}\\right)^{3}} \\] An approximate two-sided \\((1-\\alpha)\\) confidence interval for the risk difference is thus \\[ \\hat{\\eta}_{k} \\pm z_{1-\\frac{\\alpha}{2}} \\text { S.E. }\\left(\\hat{\\eta}_{k}\\right) \\] metabin(Ee, Ne, Ec, Nc, sm=&quot;RD&quot;, method=&quot;I&quot;, data=data7, subset=study==&quot;Milpied&quot;) 27.5.1.4 Arcsine Difference The arcsine difference has been considered as a measure of effectiveness in clinical trials, though it is rarely used in practice. However, it has certain advantages when assessing whether a meta-analysis may be affected by publication bias or other small-study effects. The arcsine difference is defined as the difference of the arcsine-transformed event probabilities (), that is \\[\\Delta_{k}=\\arcsin \\sqrt{p_{e k}}-\\arcsin \\sqrt{p_{c k}}\\]  Like the risk difference, the arcsine difference is always defined, with a finite range from \\(-\\pi / 2\\) to \\(\\pi / 2\\). The value of the arcsine difference is similar to the risk difference if both event probabilities are close to \\(0.5\\), otherwise the values can be quite different. The arcsine difference is estimated by \\[ \\hat{\\Delta}_{k}=\\arcsin \\sqrt{\\frac{a_{k}}{n_{e k}}}-\\arcsin \\sqrt{\\frac{c_{k}}{n_{c k}}} \\] with approximate variance \\[ \\widehat{\\operatorname{Var}}\\left(\\hat{\\Delta}_{k}\\right)=\\frac{1}{4 n_{e k}}+\\frac{1}{4 n_{c k}} \\approx \\frac{1}{n_{k}}, \\text { if } n_{e k} \\approx n_{c k} \\] where the approximation improves as nek and \\(n c k\\) increase. Notice that the approximate variance of \\(\\hat{\\Delta} k\\) only depends on the sample size in the two groups. A confidence interval for \\(\\hat{\\Delta} k\\) \\[ \\hat{\\Delta} k \\pm z_{1-\\frac{\\alpha}{2}} \\text { S.E. }(\\hat{\\Delta} k) \\] metabin(Ee, Ne, Ec, Nc, sm=&quot;ASD&quot;, method=&quot;I&quot;, data=data7, subset=study==&quot;Milpied&quot;) 27.5.2 Implementation The metabin function can smoothly realize the combination of effect sizes library(&quot;meta&quot;) data(Fleiss93) ##  ## 7 studies information ## event.e ## n.e ## event.c ## n.c metabin(event.e, n.e, event.c, n.c, data=Fleiss93, sm=&quot;OR&quot;) ## Number of studies combined: k = 7 ## Number of observations: o = 28003 ## Number of events: e = 4414 ## ## OR 95%-CI z p-value ## Common effect model 0.8969 [0.8405; 0.9570] -3.29 0.0010 ## Random effects model 0.8683 [0.7559; 0.9973] -2.00 0.0457 ## ## Quantifying heterogeneity: ## tau^2 = 0.0147 [0.0000; 0.1145]; tau = 0.1214 [0.0000; 0.3384] ## I^2 = 39.7% [0.0%; 74.6%]; H = 1.29 [1.00; 1.99] ## ## Test of heterogeneity: ## Q d.f. p-value ## 9.95 6 0.1269 ## ## Details on meta-analytical method: ## - Mantel-Haenszel method ## - Restricted maximum-likelihood estimator for tau^2 ## - Q-profile method for confidence interval of tau^2 and tau ## metaforest plot ## OR95% ## comb.random=FALSE metaresult&lt;-metabin(event.e, n.e,event.c,n.c,data=Fleiss93,sm=&quot;OR&quot;, studlab=paste(study, year),comb.random=FALSE) forest(metaresult) 27.5.3 Estimation in Sparse Data - Continuity correction We consider questions raised when the number of incidents in one or two research departments is small. In this case, we have noticed that the estimates of the odds ratio and the risk ratio may be uncertain. If the total sample size of the study is small, or the sample size is large, but the probability of the event is very close to zero or one, sparse data may appear. k akck012×2 GartZweifel [19]10.5. 0.5 0.50.010.1 \\[\\hat{\\psi}_{k}^{\\mathrm{mod}}=\\frac{\\left(a_{k}+0.5\\right)\\left(d_{k}+0.5\\right)}{\\left(b_{k}+0.5\\right)\\left(c_{k}+0.5\\right)}\\] \\[\\widehat{\\operatorname{Var}}\\left(\\log \\hat{\\psi}_{k}^{\\mathrm{mod}}\\right)=\\frac{1}{a_{k}+0.5}+\\frac{1}{b_{k}+0.5}+\\frac{1}{c_{k}+0.5}+\\frac{1}{d_{k}+0.5} .\\] Sweeting  \\[\\operatorname{incr}_{e}=\\frac{n_{e}}{n_{e}+n_{c}}\\] \\[\\operatorname{incr}_{c}=\\frac{n_{c}}{n_{e}+n_{c}}\\] 10.5  ## With 0.5 continuity correction for sparse data data8 &lt;- read.csv(&quot;./01_Datasets/dataset08.csv&quot;, as.is=TRUE) metabin(Ee, Ne, Ec, Nc, sm=&quot;OR&quot;, method=&quot;I&quot;, data=data8, subset=study==&quot;Australian&quot;) ## Number of observations: o = 595 ## Number of events: e = 1 ## ## OR 95%-CI z p-value ## 1 0.3267 [0.0133; 8.0515] -0.68 0.4938 ## ## Details: ## - Inverse variance method ## - Continuity correction of 0.5 in studies with zero cell frequencies ## With 0.1 continuity correction for sparse data metabin(Ee, Ne, Ec, Nc, sm=&quot;OR&quot;, method=&quot;I&quot;, data=data8, subset=study==&quot;Australian&quot;, incr=0.1) ## Number of observations: o = 595 ## Number of events: e = 1 ## ## OR 95%-CI z p-value ## 1 0.0891 [0.0001; 57.8269] -0.73 0.4642 ## ## Details: ## - Inverse variance method ## - Continuity correction of 0.1 in studies with zero cell frequencies ## conduct an analysis based on the treatment arm continuity correction ## using argument incr=&quot;TACC&quot; metabin(Ee, Ne, Ec, Nc, sm=&quot;OR&quot;, method=&quot;I&quot;, data=data8, subset=study==&quot;Australian&quot;, incr=&quot;TACC&quot;) ## Number of observations: o = 595 ## Number of events: e = 1 ## ## OR 95%-CI z p-value ## 1 0.3303 [0.0135; 8.0698] -0.68 0.4969 ## ## Details: ## - Inverse variance method ## - Treatment arm continuity correction in studies with zero cell frequencies Calculating the risk ratio with sparse data, (Pettigrew et al) \\[\\hat{\\phi}_{k}^{\\mathrm{mod}}=\\frac{a_{k}+0.5}{a_{k}+b_{k}+0.5} / \\frac{c_{k}+0.5}{c_{k}+d_{k}+0.5}\\] \\[\\widehat{\\operatorname{Var}}\\left(\\log \\hat{\\phi}_{k}^{\\bmod }\\right)=\\frac{1}{a_{k}+0.5}+\\frac{1}{c_{k}+0.5}-\\frac{1}{a_{k}+b_{k}+0.5}-\\frac{1}{c_{k}+d_{k}+0.5} \\cdot\\] 27.5.4 Peto Odds Ratio An alternative method for the estimation of the odds ratio, which we term the Peto Odds Ratio method, was proposed by Yusuf et al.   ak \\(E\\left(a_{k} \\mid \\ldots ; \\psi=1\\right)\\) The Peto estimate of the odds ratio is \\[ \\hat{\\psi}_{k}^{*}=\\exp \\left(\\frac{a_{k}-\\mathrm{E}\\left(a_{k} \\mid \\cdots ; \\psi_{k}=1\\right)}{\\operatorname{Var}\\left(a_{k} \\mid \\cdots ; \\psi_{k}=1\\right)}\\right) \\] where \\(\\mathrm{E}(a k \\mid \\cdots ; \\psi k=1)\\) and \\(\\operatorname{Var}(a k \\mid \\ldots ; \\psi k=1)\\) are the mean and variance of \\(a_{k}\\) under the hypergeometric distribution. Under this distribution, we have \\[ \\begin{array}{c} \\mathrm{E}\\left(a_{k} \\mid \\cdots ; \\psi_{k}=1\\right)=\\frac{\\left(a_{k}+b_{k}\\right)\\left(a_{k}+c_{k}\\right)}{n_{k}} \\\\ \\operatorname{Var}\\left(a_{k} \\mid \\cdots ; \\psi_{k}=1\\right)=\\frac{\\left(a_{k}+b_{k}\\right)\\left(c_{k}+d_{k}\\right)\\left(a_{k}+c_{k}\\right)\\left(b_{k}+d_{k}\\right)}{n_{k}^{2}\\left(n_{k}-1\\right)} \\end{array} \\] An estimator of the variance of \\(\\log \\hat{\\psi}_{k}^{*}\\) is \\[ \\widehat{\\operatorname{Var}}\\left(\\log \\hat{\\psi}_{k}^{*}\\right)=\\frac{1}{\\operatorname{Var}\\left(a_{k} \\mid \\ldots ; \\psi_{k}=1\\right)} \\] PetoneknckPeto 11Peto metabin(Ee, Ne, Ec, Nc, sm=&quot;OR&quot;, method=&quot;P&quot;, data=data8, subset=study==&quot;Australian&quot;) ## Number of observations: o = 595 ## Number of events: e = 1 ## ## OR 95%-CI z p-value ## 1 0.1331 [0.0026; 6.7068] -1.01 0.3132 ## ## Details: ## - Peto method 27.5.5 Fixed Effect Model: Inverse Variance Method     \\[ \\hat{\\theta}_{F}=\\frac{\\sum_{k=1}^{K} w_{k} \\hat{\\theta}_{k}}{\\sum_{k=1}^{K} w_{k}}, \\text { with } \\operatorname{Var}\\left(\\hat{\\theta}_{F}\\right)=\\left(\\sum_{k=1}^{K} w_{k}\\right)^{-1} \\] and weights \\(w k=\\widehat{\\operatorname{Var}}(\\hat{\\theta} k)^{-1}\\). As usual, an approximate two-sided \\((1-\\alpha)\\) confidence interval is given by \\[ \\hat{\\theta}_{F} \\pm z_{1-\\frac{\\alpha}{2}} \\mathrm{S.E.}\\left(\\hat{\\theta}_{F}\\right) \\]  27.5.6 Fixed Effect Model: MantelHaenszel Method MantelHaenszel. MH.exact = TRUEMantelHaenszel. Odds Ratio The pooled odds ratio is estimated by combining the individual odds ratios \\(\\hat{\\psi}_{k}\\) on the natural scale \\[ \\begin{array}{l} \\hat{\\psi}_{\\mathrm{MH}}=\\frac{\\sum_{k=1}^{K} w_{k} \\hat{\\psi}_{k}}{\\sum_{k=1}^{K} w_{k}} \\\\ \\text { with weights } w_{k}=\\frac{b_{k} c_{k}}{n_{k}} \\end{array} \\] An estimator of the variance of the logarithm of \\(\\hat{\\psi}_{M H}\\) that is robust both in sparse data and large strata models \\[ \\begin{aligned} \\overrightarrow{\\operatorname{Var}\\left(\\log \\hat{\\psi}_{\\mathrm{MH}}\\right)}=&amp; \\frac{\\sum_{k=1}^{K} P_{k} R_{k}}{2\\left(\\sum_{k=1}^{K} R_{k}\\right)^{2}}+\\frac{\\sum_{k=1}^{K}\\left(P_{k} S_{k}+Q_{k} R_{k}\\right)}{2 \\sum_{k=1}^{K} R_{k} \\sum_{k=1}^{K} S_{k}}+\\frac{\\sum_{k=1}^{K} Q_{k} S_{k}}{2\\left(\\sum_{k=1}^{K} S_{k}\\right)^{2}} \\\\ &amp; \\text { with } P_{k}=\\frac{a_{k}+d_{k}}{n_{k}}, Q_{k}=\\frac{b_{k}+c_{k}}{n_{k}}, R_{k}=\\frac{a_{k} d_{k}}{n_{k}}, \\text { and } S_{k}=\\frac{b_{k} c_{k}}{n_{k}} . \\end{aligned} \\] Risk Ratio The pooled risk ratio \\(\\hat{\\phi} \\mathrm{MH}\\) is calculated by combining individual risk ratios \\(\\hat{\\phi} k\\) on the natural scale \\[ \\begin{array}{c} \\hat{\\phi}_{\\mathrm{MH}}=\\frac{\\sum_{k=1}^{K} w_{k} \\hat{\\phi}_{k}}{\\sum_{k=1}^{K} w_{k}} \\\\ \\text { using weights } w_{k}=\\frac{\\left(a_{k}+b_{k}\\right) c_{k}}{n_{k}} \\end{array} \\] A robust estimator of the variance of the logarithm of \\(\\hat{\\phi}_{\\mathrm{MH}}\\) is given by Greenland and Robins \\[ \\overline{\\operatorname{Var}\\left(\\log \\hat{\\phi}_{\\mathrm{MH}}\\right)}=\\frac{\\sum_{k=1}^{K} \\frac{\\left(a_{k}+b_{k}\\right)\\left(c_{k}+d_{k}\\right)\\left(a_{k}+c_{k}\\right)-a_{k} c_{k} n_{k}}{n_{k}^{2}}}{\\sum_{k=1}^{K} \\frac{a_{k}\\left(c_{k}+d_{k}\\right)}{n_{k}} \\sum_{k=1}^{K} \\frac{c_{k}\\left(a_{k}+b_{k}\\right)}{n_{k}}} \\] Risk Difference The pooled risk difference \\(\\hat{\\eta} \\mathrm{MH}\\) is calculated by combining risk differences \\(\\hat{\\eta} k\\) \\[ \\hat{\\eta}_{\\mathrm{MH}}=\\frac{\\sum_{k=1}^{K} w_{k} \\hat{\\eta}_{k}}{\\sum_{k=1}^{K} w_{k}} \\] with weights \\(w k=\\frac{(a k+b k)(c k+d k)}{n k}\\) A robust estimator of the variance of \\(\\hat{\\eta}_{\\mathrm{MH}}\\) is given by \\[ \\widehat{\\operatorname{Var}\\left(\\hat{\\eta}_{\\mathrm{MH}}\\right)}=\\frac{\\sum_{k=1}^{K} \\frac{\\left(a_{k} b_{k} n_{c}\\right)^{3}+\\left(c_{k} d_{k} n_{e}\\right)^{3}}{\\left(n_{e} n_{c}\\left(n_{e}+n_{c}\\right)\\right)^{2}}}{\\left(\\sum_{k=1}^{K} \\frac{\\left(a_{k}+b_{k}\\right)\\left(c_{k}+d_{k}\\right)}{n_{k}}\\right)^{2}} \\] data7 &lt;- read.csv(&quot;./01_Datasets/dataset07.csv&quot;, as.is=TRUE) mb1.mh &lt;- metabin(Ee, Ne, Ec, Nc, sm=&quot;OR&quot;, data=data7, studlab=study) print(summary(mb1.mh), digits=2) ## OR 95%-CI %W(common) %W(random) ## De Souza 1.60 [0.54; 4.73] 2.6 4.1 ## Gianni 9.86 [2.11; 45.96] 0.7 2.2 ## Gisselbrecht 0.95 [0.62; 1.45] 21.8 13.4 ## Intragumtornchai 1.37 [0.43; 4.36] 2.4 3.6 ## Kaiser 1.35 [0.84; 2.16] 14.8 12.2 ## Kluin-Nelemans 1.54 [0.86; 2.78] 8.9 9.7 ## Martelli 1996 0.91 [0.18; 4.57] 1.5 2.0 ## Martelli 2003 1.49 [0.73; 3.06] 6.1 7.6 ## Milpied 2.37 [1.29; 4.35] 6.8 9.3 ## Rodriguez 2003 1.87 [0.84; 4.14] 4.4 6.6 ## Santini 1998 2.15 [1.01; 4.56] 4.6 7.1 ## Santini-2 1.07 [0.61; 1.87] 11.7 10.2 ## Verdonck 0.67 [0.24; 1.83] 4.6 4.6 ## Vitolo 0.61 [0.29; 1.27] 9.1 7.3 ## ## Number of studies combined: k = 14 ## Number of observations: o = 2126 ## Number of events: e = 1366 ## ## OR 95%-CI z p-value ## Common effect model 1.35 [1.12; 1.61] 3.21 0.0013 ## Random effects model 1.36 [1.07; 1.73] 2.50 0.0122 ## ## Quantifying heterogeneity: ## tau^2 = 0.0669 [0.0000; 0.7852]; tau = 0.2586 [0.0000; 0.8861] ## I^2 = 41.0% [0.0%; 68.6%]; H = 1.30 [1.00; 1.78] ## ## Test of heterogeneity: ## Q d.f. p-value ## 22.03 13 0.0549 ## ## Details on meta-analytical method: ## - Mantel-Haenszel method ## - Restricted maximum-likelihood estimator for tau^2 ## - Q-profile method for confidence interval of tau^2 and tau forest(mb1.mh, comb.random=FALSE, hetstat=FALSE, text.fixed=&quot;MH estimate&quot;) mb2.mh &lt;- metabin(Ee, Ne, Ec, Nc, sm=&quot;OR&quot;, method=&quot;MH&quot;, data=data8, studlab=study) print(summary(mb2.mh), digits=2) ## OR 95%-CI %W(common) %W(random) ## Australian 0.33 [0.01; 8.05] 1.4 0.8 ## CASTEL 0.72 [0.25; 2.01] 7.8 8.1 ## Coope 0.52 [0.13; 2.11] 5.3 4.4 ## EWPHE 0.83 [0.43; 1.61] 17.8 19.7 ## HDFP 0.55 [0.26; 1.16] 17.7 15.4 ## MRC 1.20 [0.36; 3.93] 4.6 6.1 ## MRC elderly 1.07 [0.55; 2.09] 15.3 19.3 ## STOP 0.10 [0.01; 0.77] 9.2 2.0 ## Shep 0.91 [0.35; 2.36] 8.1 9.4 ## Shep Pilot 0.50 [0.04; 5.57] 1.5 1.5 ## Syst-eur 0.94 [0.42; 2.10] 11.3 13.3 ## ## Number of studies combined: k = 11 ## Number of observations: o = 17604 ## Number of events: e = 194 ## ## OR 95%-CI z p-value ## Common effect model 0.75 [0.56; 1.00] -1.98 0.0479 ## Random effects model 0.78 [0.58; 1.05] -1.63 0.1026 ## ## Quantifying heterogeneity: ## tau^2 = 0 [0.0000; 0.6820]; tau = 0 [0.0000; 0.8258] ## I^2 = 0.0% [0.0%; 60.2%]; H = 1.00 [1.00; 1.59] ## ## Test of heterogeneity: ## Q d.f. p-value ## 7.22 10 0.7041 ## ## Details on meta-analytical method: ## - Mantel-Haenszel method ## - Restricted maximum-likelihood estimator for tau^2 ## - Q-profile method for confidence interval of tau^2 and tau ## - Continuity correction of 0.5 in studies with zero cell frequencies 27.5.7 Random Effects Model In a random effects model, the assumption of a constant treatment effect across studies is relaxed by allowing the treatment effect from each study to have a probability distribution about the pooled treatment effect. Usually a normal distribution is used, so that \\[\\hat{\\theta}_{k}=\\theta+u_{k}+\\sigma_{k} \\epsilon_{k}, \\quad \\epsilon_{k}^{\\text {i.i.d. }} N(0,1) ; u_{k}^{\\text {i.i.d. }} N\\left(0, \\tau^{2}\\right)\\] where the \\(u\\) s and \\(\\epsilon\\) s are independent. The between-study variance \\(\\tau^{2}\\) describes the extent of heterogeneity between individual study results. DerSimonianLaird Method \\[ \\hat{\\tau}^{2}=\\frac{Q-(K-1)}{\\sum_{k=1}^{K} w_{k}-\\frac{\\sum_{k=1}^{K} w_{k}^{2}}{\\sum_{k=1}^{k} w_{k}}} \\] where \\(Q\\), the heterogeneity statistic, is given by \\(Q=\\sum k=1^{K} w k(\\hat{\\theta} k-\\hat{\\theta} F)^{2}\\) and \\(w k=\\) \\(\\widehat{\\operatorname{Var}}(\\hat{\\theta} k)^{-1}\\). The estimator \\(\\hat{\\tau}^{2}\\) is set to zero if \\(Q&lt;K-1\\) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
