[["adaptive-designs.html", "Chapter 26 Adaptive designs 26.1 Introduction 26.2 General Theory 26.3 Method with Direct Combination of p-values 26.4 Inverse normal combination function", " Chapter 26 Adaptive designs 26.1 Introduction An adaptive design is a design that allows adaptations or modifications to some aspects of a trial after its initiation without undermining the validity and integrity of the trial. The adaptations may include, but are not limited to, sample-size reestimation, early stopping for efficacy or futility, response-adaptive randomization, and dropping inferior treatment groups. Adaptive designs usually require unblinding data and invoke a dependent sampling procedure. Therefore, theory behind adaptive design is much more complicated than that behind classical design. In general, adaptive designs allow various adaptations of the study design based on data gained during an interim analysis. Possible adaptions could be: Early termination of the trial due to futility Early termination of the trial due to efficacy Sample size recalculation Selection of the primary endpoint Dropping of treatment arm(s) Switching from non-inferiority to superiority Patient allocation to the treatment arms Selection of the patient population (enrichment designs) Further change in the study design However, only with proper implementation of these designs, the validity and the integrity of the clinical trial are not undermined. Each of the adaptions might have an influence on the interpretation of the study results. Special attention should be paid for the comparability of the different stages of the study. 26.1.1 Early termination due to futility The study can be stopped earlier due to futility using non-binding or binding futility rules. Non-binding futility bounds (i.e., the final decision is not only based on the suggestion made by the futility bounds) does not further increase the type I error. On the other hand, binding futility bounds can provide advantage in the efficacy analysis but may inflate the type I error if the stopping rule is not followed.  I I 26.1.2 Early termination due to efficacy The trial could also be stopped earlier if the efficacy of the primary endpoint is already shown by the results of the interim analysis. Efficacy bounds can be implemented by using groups sequential design methods. If efficacy bounds are used, it should be ensured that the sample size at the interim analysis is sufficient to show further objectives of the study (e.g., safety profile and secondary endpoints), which is typically not the case in phase III or premarket trials. If groups sequential design methods are used, the treatment effect tend to be biased towards greater values (especially the mean). Consequently, the confidence intervals will not have the desired coverage probability. Therefore, methods for reducing or removing the introduced bias and increasing the coverage probability should be applied if they exist. If no methods for these issues exist, the extent of bias should be discussed, and the resulting estimates should be used with caution.   III     26.1.3 Sample size reassessment Adaptations like sample size reassessment are not a substitute for careful planning. Sample size reassessment which is based on results of an ongoing trial is only a valid option if it can be shown that the uncertainty about the required sample size is not the result of an inadequate research in earlier stages of the study. If possible, the sample size should be recalculated in a blinded fashion. For a study with the objective to show superiority regarding a continuous primary endpoint, the type I error is generally not inflated if the method of Gould and Shih is applied (Gould and Shih, 1992). For non-inferiority and equivalence hypotheses, the type I error could be inflated to a limited extend (Friede and Kieser, 2003). If a blinded sample size calculation is not appropriate or possible, the procedure of Chen and his colleagues (Chen et al., 2004) offers a sample size adaption without inflating the type I error. Details are described in the paper. The procedure of the reassessment should be planned a priori, must not question the validity of the study results, and has to maintain the type I error. But if more than one sample size reassessment is required, this can be a sign for varying experimental conditions and a sign that they are not fully understood. Gould and ShihIGould and Shih1992 IFriedeKieser2003ChenChen2004II 26.1.4 Change or modification of the primary endpoint There are several therapeutic areas where guidelines for the change or modification of the primary endpoint have not been developed. Adaptive designs are recommended if the assumptions and expectations of the primary endpoint seem to be not correct. Such information may be obtained through external knowledge in form of other studies or through interim results. In these situations, an adaptive design can be used for changes of the definition of a primary endpoint, for changes of the primary endpoint and for changes in the components of a composed primary endpoint. However, it should be noted that a change in a primary endpoint is generally difficult to justify and thus should be avoided.      26.1.5 Discontinuing treatment arms Discontinuation of treatment arms is worth consideration in case of multiple treatment arms  especially if one of them is a placebo arm. If data depending on discontinuation of treatment arms is favoured, the study should be planned with an appropriate adaptive design in combination with a multiple testing procedure to offer the chance to stop recruitment to the placebo group if an interim analysis has demonstrated superiority of the treatment over placebo. An application for an early phase study would be a drop-the-loser design (Sampson and Sill, 2005), where at the interim analysis of a two-stage design, one winner arm will be selected to enter the second stage of the trial (beside the control arm). Further details could be obtained from the original publication. This approach is more general described in the multiarm multi-stage approach (MAMS) by Magirr and his colleagues (Magirr et al.,2012). -   SampsonSill2005   MagirrMAMSMagirr2012 26.1.6 Switching between superiority and non-inferiority If both, superiority and/or non-inferiority of an experimental treatment to an active comparator are acceptable outcomes, the study should be planned as a non-inferiority trial with the possibility to switch to superiority based on the trial results. A change from superiority to non-inferiority is not acceptable in the adaptive design after interim results are available /  26.1.7 Selection of the patient population If the objective of a trial is not only to show efficacy, but efficacy in a certain population, so called enrichment designs could be applied. In such a design, for example, a general population is enrolled in the first stage. Based on the results of the interim analysis of the prespecified subgroups, only the most promising study population could be further investigated in the second part of the trial. The results from the first and the second stage could be combined using combination test describe in section below. A more detailed overview about enrichment can be found in article of Wang and his colleagues (Wang et al., 2009). WangWang2009 26.1.8 Methods Many interesting methods for adaptive design have been developed. Virtually all methods can be viewed as some combination of stagewise p-values. The stagewise p-values are obtained based on the subsample from each stage; therefore, they are mutually independent and uniformly distributed over [0,1] under the null hypothesis. The first method uses the same stopping boundaries as a classical group sequential design (OBrien and Fleming, 1979; Pocock, 1977) and allows stopping for early efficacy or futility. Lan and DeMets (1983) proposed the error spending method (ESM), in which the timing and number of analyses can be changed based on a prespecified error-spending function. ESM is derived from Brownian motion. The method has been extended to allow for sample-size reestimation (SSR) (Cui, Hung, and Wang, 1999). It can be viewed as a fixed-weight method (i.e., using fixed weights for z-scores from the first and second stages regardless of sample-size change). Lehmacher and Wassmer (1999) further degeneralized this weight method by using the inverse-normal method, in which the z-score is not necessarily taken from a normal endpoint, but from the inverse-normal function of stagewise p-values. Hence, the method can be used for any type of endpoint. OBrien  Fleming1979 Pocock1977  ** ** Lan  DeMets (1983)  (ESM) ESM  (SSR)CuiHung  Wang1999 z  Lehmacher  Wassmer (1999)  z  p  The second method is based on a direct combination of stagewise pvalues. Bauer and Kohne (1994) use the Fisher combination (product) of stagewise p-values to derive the stopping boundaries. Chang (2006a) used the sum of the stagewise p-values to construct a test statistic and derived a closed form for determination of stopping boundaries and p-value calculations as well as conditional power for trial monitoring. stagewise pvalues Bauer and Kohne (1994)stagewise p-valuesFisher Chang (2006a)  **  p  **  p  The third method is based on the conditional error function. Proschan and Hunsberger (1995) developed an adaptive design method based on the conditional error function for two-stage designs with normal test statistics. Müller and Schäfer (2001) developed the conditional error method where the conditional error function is avoided and replaced with a conditional error that is calculated on fly. Instead of a two-stage design, Müller and Schäfer s method can be applied to a K-stage design and allows for many adaptations.  ProschanHunsberger1995   Müller  Schäfer (2001)   Müller  Schäfer  K   The fourth method is based on recursive algorithms such as Brannath Posch-Bauers recursive combination tests (Brannath, Posch and Bauer, 2002), Müller and Schäfers decision-function method (Müller and Schäfer, 2004), and Changs (2006e) recursive two-stage adaptive design (RTAD). All four recursive methods are developed for K-stage designs allowing for general adaptations.  ** ** Brannath Posch-Bauer BrannathPosch  Bauer2002Müller  Schäfer Müller  Schäfer2004 Chang (2006e) )  (RTAD) K  Focus on three major issues: type-I error control, analysis including point and confidence interval estimations, and design evaluations. 26.2 General Theory 26.2.1 Stopping Boundary \\[ H_{0}: H_{01} \\cap \\ldots \\cap H_{0 K} \\] where \\(H_{0 k}(k=1, \\ldots, K)\\) is the null hypothesis at the \\(k\\) th interim analysis. The stopping rules are given by \\[ \\left\\{\\begin{array}{ll} \\text { Stop for efficacy } &amp; \\text { if } T_{k} \\leq \\alpha_{k} \\\\ \\text { Stop for futility } &amp; \\text { if } T_{k}&gt;\\beta_{k}, \\\\ \\text { Continue with adaptations}&amp; \\text { if } \\alpha_{k}&lt;T_{k} \\leq \\beta_{k} \\end{array}\\right. \\] where \\(\\alpha_{k}&lt;\\beta_{k}(k=1, \\ldots, K-1)\\), and \\(\\alpha_{K}=\\beta_{K}\\). For convenience, \\(\\alpha_{k}\\) and \\(\\beta_{k}\\) are called the efficacy and futility boundaries, respectively. To reach the \\(k\\) th stage, a trial has to pass the 1 th to \\((k-1)\\) th stages. Therefore, the probability of rejecting the null hypothesis \\(H_{0}\\) or simply, the rejection probability at the \\(k\\) th stage is given by \\(\\psi_{k}\\left(\\alpha_{k}\\right)\\), where \\[ \\begin{aligned} \\psi_{k}(t) &amp;=\\operatorname{Pr}\\left(\\alpha_{1}&lt;T_{1}&lt;\\beta_{1}, \\ldots, \\alpha_{k-1}&lt;T_{k-1}&lt;\\beta_{k-1}, T_{k}&lt;t\\right) \\\\ &amp;=\\int_{\\alpha_{1}}^{\\beta_{1}} \\cdots \\int_{\\alpha_{k-1}}^{\\beta_{k-1}} \\int_{-\\infty}^{t} f_{T_{1} \\ldots T_{k}} d t_{k} d t_{k-1} \\ldots d t_{1} \\end{aligned} \\] where \\(f_{T_{1} \\ldots T_{k}}\\) is the joint pdf of \\(T_{1}, \\ldots\\), and \\(T_{k}\\). 26.2.2 Power and Adjusted p-value Definition 3.1: The \\(p\\) -value associated with a test is the smallest significance level \\(\\alpha\\) for which the null hypothesis is rejected. Let \\[ p_{c}(t ; k)=\\psi_{k}\\left(t \\mid H_{0}\\right) \\] The error rate \\((\\alpha\\) spent) at the \\(k\\) th stage is given by \\[ \\pi_{k}=\\psi_{k}\\left(\\alpha_{k} \\mid H_{0}\\right) . \\] It is the key to determining the stopping boundaries adaptive designs. When \\(\\sum_{i=1}^{k} \\pi_{i}\\) is reviewed as a function of information time or stage \\(k\\), it is the so-called error-spending function. The power of rejecting \\(H_{0}\\) at the \\(k\\) th stage is given by \\[ \\varpi_{k}=\\psi_{k}\\left(\\alpha_{k} \\mid H_{a}\\right) . \\] When efficacy is claimed at a certain stage, the trial is stopped. Therefore, the type-I errors at different stages are mutually exclusive. Hence, the experiment-wise type-I error rate can be written as \\[ \\alpha=\\sum_{k=1}^{K} \\pi_{k} . \\] Similarly, the power is given by \\[ \\text { power }=\\sum_{k=1}^{K} \\varpi_{k} . \\] It is interesting to define an adjusted \\(p\\) -value by \\[ p_{a}(t ; k)=\\min \\left\\{1, \\sum_{i=1}^{k-1} \\pi_{i}+p_{c}(t ; k)\\right\\} \\] An important characteristic of this adjusted \\(p\\) -value is that when the test statistic \\(t\\) is on stopping boundary \\(a_{k}, p_{k}\\) must be equal to alpha spent so far. Note that the adjusted \\(p\\) -value is a measure of overall statistical strength against \\(H_{0}\\). The later the \\(H_{0}\\) is rejected, the larger the adjusted \\(p\\) -value is, and the weaker the statistical evidence (against \\(H_{0}\\) ) is. A late rejection leading to a larger \\(p\\) -value is reasonable because the alpha at earlier stages has been spent.  \\(p\\)  \\(H_{0}\\)  \\(H_{0}\\)\\(p\\)\\(H_{0}\\)  \\(p\\)  alpha  26.2.3 Stopping Probabilities (Design Evaluation)   n fact, the stopping probabilities are used to calculate the expected samples that present the average cost or efficiency of the trial design and the duration of the trial. There are two types of stopping probabilities: unconditional probability of stopping to claim efficacy (reject H0) and unconditional probability of futility (accept H0). The former refers to the efficacy stopping probability (ESP), and the latter refers to the futility stopping probability (FSP). From \\[ \\begin{aligned} \\psi_{k}(t) &amp;=\\operatorname{Pr}\\left(\\alpha_{1}&lt;T_{1}&lt;\\beta_{1}, \\ldots, \\alpha_{k-1}&lt;T_{k-1}&lt;\\beta_{k-1}, T_{k}&lt;t\\right) \\\\ &amp;=\\int_{\\alpha_{1}}^{\\beta_{1}} \\ldots \\int_{\\alpha_{k-1}}^{\\beta_{k-1}} \\int_{-\\infty}^{t} f_{T_{1} \\ldots T_{k}} d t_{k} d t_{k-1} \\ldots d t_{1} \\end{aligned} \\] the ESP at the kth stage is given by \\[ E S P_{k}=\\psi_{k}\\left(\\alpha_{k}\\right) \\] and the FSP at the \\(k\\) th stage is given by \\[ F S P_{k}=\\psi_{k-1}\\left(\\beta_{k-1}\\right)-\\psi_{k-1}\\left(\\alpha_{k-1}\\right)-\\psi_{k}\\left(\\beta_{k}\\right) \\] 26.2.4 Expected Duration of an Adaptive Trial (Design Evaluation) The stopping probabilities can be used to calculate the expected trial duration, which is definitely an important feature of an adaptive design. The conditionally (on the efficacy claim) expected trial duration is given by \\[ \\bar{t}_{e}=\\sum_{k=1}^{K} E S P_{k} t_{k} \\] where \\(t_{k}\\) is the time from the first-patient-in to the \\(k\\) th interim analysis. The conditionally (on the futility claim) expected trial duration is given by \\[ \\bar{t}_{f}=\\sum_{k=1}^{K} F S P_{k} t_{k} . \\] The unconditionally expected trial duration is given by \\[ \\bar{t}=\\sum_{k=1}^{K}\\left(E S P_{k}+F S P_{k}\\right) t_{k} . \\] 26.2.5 Expected Sample Sizes (Design Evaluation) The expected sample size is a commonly used measure of the efficiency (cost and timing of the trial) of the design. The expected sample size is a function of the treatment difference and its variability, which are unknowns. Therefore, expected sample size is really based on hypothetical values of the parameters. For this reason, it is beneficial and important to calculate the expected sample size under various critical or possible values of the parameters. The total expected sample size per group can be expressed as \\[ N_{\\exp }=\\sum_{k=1}^{K} N_{k}\\left(E S P_{k}+F S P_{k}\\right) \\] It can also be written as \\[ N_{\\exp }=\\sum_{k=1}^{K} N_{k}\\left(\\psi_{k}\\left(\\alpha_{k}\\right)+\\psi_{k-1}\\left(\\beta_{k-1}\\right)-\\psi_{k}\\left(\\beta_{k}\\right)-\\psi_{k-1}\\left(\\alpha_{k-1}\\right)\\right) \\] where \\(N_{k}=\\sum_{i=1}^{k} n_{i}\\) is the cumulative sample size per group. 26.2.6 Conditional Power and futility index The conditional power is the conditional probability of rejecting the null hypothesis during the rest of the trial based on the observed interim data. The conditional power is commonly used for monitoring an ongoing trial. Similar to the ESP and FSP, conditional power is dependent on the population parameters or treatment effect and its variability. The conditional power at the \\(k\\) th stage is the sum of the probability of rejecting the null hypothesis at stage \\(k+1\\) to \\(K(K\\) does not have to be predetermined), given the observed data from stages 1 through \\(k\\). \\[ c P_{k}=\\sum_{j=k+1}^{K} \\operatorname{Pr}\\left(\\cap_{i=k+1}^{j-1}\\left(a_{i}&lt;T_{i}&lt;\\beta_{i}\\right) \\cap T_{j} \\leq \\alpha_{j} \\mid \\cap_{i=1}^{k} T_{i}=t_{i}\\right) \\] where \\(t_{i}\\) is the observed test statistic \\(T_{i}\\) at the \\(i\\) th stage. For a two-stage design, the conditional power can be expressed as \\[ c P_{1}=\\operatorname{Pr}\\left(T_{2} \\leq \\alpha_{2} \\mid t_{1}\\right) . \\] The futility index is defined as the conditional probability of accepting the null hypothesis: \\[ F I_{k}=1-c P_{k} \\] 26.3 Method with Direct Combination of p-values focus on two-stage designs and derive the closed forms for determination of stopping boundaries and adjusted pvalues. method based on individual p-values (MIP) method based on the sum of p-values (MSP) method based on the product of p-values (MPP) 26.3.1 Method Based on Individual p-values \\[ T_{k}=p_{k} \\] where \\(p_{k}\\) is the stagewise \\(p\\) -value from the \\(k\\) th stage subsample. A level- \\(\\alpha\\) test requires \\[ \\alpha=\\sum_{k=1}^{K} \\alpha_{k} \\prod_{i=1}^{k-1}\\left(\\beta_{i}-\\alpha_{i}\\right) \\] \\(\\alpha_{k}\\) and \\(\\beta_{k}\\) are called the efficacy and futility boundaries, respectively. For a two-stage design,\\(\\alpha=\\alpha_{1}+\\alpha_{2}\\left(\\beta_{1}-\\alpha_{1}\\right)\\) The \\(p\\) -value is given by \\[ p(t ; k)=\\left\\{\\begin{array}{lr} t, &amp; k=1 \\\\ \\alpha_{1}+t\\left(\\beta_{1}-\\alpha_{1}\\right) k &amp; =2 . \\end{array}\\right. \\] MIP is useful in the sense that it is very simple and can serve as the baseline for comparing different methods. MIP does not use combined data from different stages, while most other adaptive designs do. 26.3.2 Method Based on the Sum of p-values Chang (2006a) proposed an adaptive design method, in which the test statistic is defined as the sum of the stagewise \\(p\\) -values. This method is referred to as MSP. At the \\(k\\) th stage, the test statistic is defined as \\[ T_{k}=\\Sigma_{i=1}^{k} p_{i}, k=1, \\ldots, K \\] The key to derive the stopping boundary is to calculate the probability function \\(\\psi_{k}(t)\\) under the null hypothesis and the decision rules. For a two stage design, the stopping rules are \\[ \\text { At Stage 1, }\\left\\{\\begin{array}{ll} \\text { Reject } H_{0} &amp; \\text { if } T_{1} \\leq \\alpha_{1} \\\\ \\text { Accept } H_{0} &amp; \\text { if } T_{1}&gt;\\beta_{1} \\\\ \\text { Continue with adaptations if } \\alpha_{1}&lt;T_{1} \\leq \\beta_{1} \\text { , } \\end{array}\\right. \\] where \\(0&lt;\\alpha_{1}&lt;\\beta_{1} \\leq 1\\). \\[ \\text { At Stage 2, }\\left\\{\\begin{array}{ll} \\text { Reject } H_{0} &amp; \\text { if } T_{2} \\leq \\alpha_{2} \\\\ \\text { Accept } H_{0} &amp; \\text { if } T_{2}&gt;\\alpha_{2} \\end{array}\\right. \\text { . } \\] Noticing that \\(p_{i}\\) is often uniformly distributed in \\([0,1]\\) under the null hypotheis, for the first stage we have \\[ \\psi_{1}\\left(t \\mid H_{0}\\right)=\\int_{0}^{t} d t_{1}=t . \\] For the second stage, we have \\[ \\psi_{2}\\left(t \\mid H_{0}\\right)=\\int_{\\alpha_{1}}^{\\beta_{1}} \\int_{0}^{t} f_{T_{1} T_{2}} d t_{2} d t_{1} \\] \\[ \\begin{array}{l} \\text { Noticing that } p_{1} \\text { and } p_{2} \\text { are indepedent, we have } f_{T_{1} T_{2}}=\\\\ f\\left(T_{2} \\mid T_{1}\\right) f\\left(T_{1}\\right)=f\\left(p_{1}+p_{2} \\mid p_{1}\\right) f\\left(p_{1}\\right)=1 \\text { . We will prove that }\\\\ \\psi_{2}\\left(t \\mid H_{0}\\right)=\\left\\{\\begin{array}{ll} \\frac{1}{2}\\left(t-\\alpha_{1}\\right)^{2}, &amp; \\text { when } \\alpha_{1}&lt;t \\leq \\beta_{1} \\\\ \\left(\\beta_{1}-\\alpha_{1}\\right) t-\\frac{1}{2}\\left(\\beta_{1}^{2}-\\alpha_{1}^{2}\\right), &amp; \\text { when } \\beta_{1}&lt;t \\leq \\alpha_{1}+1 \\\\ t-\\alpha_{1}+t \\beta_{1}-\\frac{1}{2} t^{2}-\\frac{1}{2} \\beta_{1}^{2}-\\frac{1}{2}, &amp; \\text { when } \\alpha_{1}+1&lt;t \\leq 2 \\\\ 0, &amp; \\text { otherwise } \\end{array}\\right. \\end{array} \\] 26.3.3 Method with Product of p-values This method is referred to as MPP. The test statistic in this method is based on the product of the stagewise \\(p\\) -values from the subsamples. For two-stage designs, the test statistic is defined as \\[ T_{k}=\\Pi_{i=1}^{k} p_{i}, k=1,2 . \\] The \\(\\alpha\\) spent in the two stages is given by \\[ \\pi_{1}=\\int_{0}^{\\alpha_{1}} d t_{1}=\\alpha_{1} \\] and \\[ \\pi_{2}=\\int_{\\alpha_{1}}^{\\beta_{1}} \\int_{0}^{\\alpha_{2}} \\frac{1}{t_{1}} d t_{2} d t_{1} \\] We can obtain the following formulation for determining stopping boundaries: \\[ \\alpha=\\alpha_{1}+\\alpha_{2} \\ln \\frac{\\beta_{1}}{\\alpha_{1}}, \\alpha_{1}&lt;\\beta_{1} \\leq 1 \\] Note that the stopping boundaries based on Fishers criterion are special cases of obove function, where \\(\\alpha_{2}=\\exp \\left[-\\frac{1}{2} \\chi_{4}^{2}(1-\\alpha)\\right]\\). 26.3.4 Fishers product test (Combination Tests) p = p-value (e.g. from z-test) of first n1 patients (stage 1) q = p-value (e.g. from z-test) of second n2 patients (stage 2) At stage 2 combine the stage-wise p-values p and q by a pre-specified function (combination function). Then compare this with to a pre-specified critical value. (Pre-specified critical region in (p, q)-plane), Control of type I error rate possible, since p and q are independent and on [0, 1] uniformly distributed under H0. Figure 26.1: Figure: Fishers product test, (BAUER 1989, BAUER &amp; KÖHNE 1994) Figure 26.2: Figure: Fishers product test, (BAUER 1989, BAUER &amp; KÖHNE 1994) 26.3.5 Fishers product test with early rej. and acceptance Figure 26.3: Figure: Fishers product test with early rej. and acceptance Figure 26.4: Figure: Fishers product test with early rej. and acceptance Choice of critical values Full second stage level Equal local rejection levels Choice of \\(\\alpha, \\alpha_{1}\\) and \\(\\alpha_{0}\\) Full second stage level Choose \\(\\alpha_{2}=\\alpha\\), i.e. critical value \\(c_{\\alpha}=e^{-\\chi_{4,1-\\alpha_{2}}^{-2} / 2}\\) and \\(\\alpha_{0}&lt;1\\). Determine \\(\\alpha_{1}\\) such that \\[ \\mathbf{P}_{\\Delta=0}\\left(p_{1} \\leq \\alpha_{1}\\right)+\\mathbf{P}_{\\Delta=0}\\left(\\alpha_{1}&lt;p_{1} \\leq \\alpha_{0}, p q \\leq c_{\\alpha}\\right)=\\alpha \\] Type I error rate calculation: \\[ \\begin{array}{c} \\alpha=\\mathbf{P}_{\\Delta=0}\\left(p_{1} \\leq \\alpha_{1}\\right)+\\mathbf{P}_{\\Delta=0}\\left(\\alpha_{1}&lt;p_{1} \\leq \\alpha_{0}, p q \\leq c_{\\alpha}\\right) \\\\ =\\alpha_{1}+\\int_{\\alpha_{1}}^{\\alpha_{0}} \\int_{0}^{1} \\mathbf{1}_{\\left\\{p q \\leq c_{\\alpha}\\right\\}} d p d q=\\alpha_{1}+\\int_{\\alpha_{1}}^{\\alpha_{0}}\\left(\\frac{C_{\\alpha}}{p}\\right) d p \\\\ =\\alpha_{1}+c_{\\alpha}\\left[\\ln \\left(\\alpha_{0}\\right)-\\ln \\left(\\alpha_{1}\\right)\\right] \\end{array} \\] Equal local rejection levels Fix \\(\\alpha_{0}&lt;1\\) and \\(\\alpha_{1}=\\alpha_{2}=\\alpha^{*}&lt;\\alpha\\) such that the type I error rate \\[ \\alpha^{*}+c_{\\alpha}\\left[\\ln \\left(\\alpha_{0}\\right)-\\ln \\left(\\alpha^{*}\\right)\\right]=\\alpha \\] Choice of \\(\\alpha, \\alpha_{1}\\) and \\(\\alpha_{0}\\) Fix \\(\\alpha, \\alpha_{1}\\) and \\(\\alpha_{0}\\) and calculate the critical value \\(c\\) as \\[ c=\\frac{\\alpha-\\alpha_{1}}{\\ln \\left(\\alpha_{0}\\right)-\\ln \\left(\\alpha_{1}\\right)} \\] Non-stochastic curtailment: \\[ \\alpha_{1}&gt;c \\quad \\Longleftrightarrow \\quad \\alpha_{1}+\\alpha_{1}\\left(\\ln \\left(\\alpha_{0}\\right)-\\ln \\left(\\alpha_{1}\\right)\\right) \\geq \\alpha \\] 26.4 Inverse normal combination function Use of the combination function: \\[ C(p, q)=1-\\Phi(\\sqrt{0.5} \\underbrace{\\Phi^{-1}(1-p)}_{z_{1}}+\\sqrt{0.5} \\underbrace{\\Phi^{-1}(1-q)}_{z_{2}}) \\] We have that \\(Z_{1}=\\Phi^{-1}(1-p) \\sim N(0,1)\\) and \\(Z_{2}=\\Phi^{-1}(1-q) \\sim N(0,1)\\) \\(Z_{1}\\) and \\(Z_{2}\\) are independent and standard normal. \\(\\mathbf{D}\\) Therefore: \\(\\quad Z_{2}^{*}=\\sqrt{0.5} Z_{1}+\\sqrt{0.5} Z_{2} \\sim N(0,1)\\) (weighted \\(z\\) -score) \\(\\mathbf{\\Sigma} C(p, q)=1-\\Phi(Z)\\) is uniformly distributed under \\(H_{0}\\). Figure 26.5: Figure: Comparison to Fishers product test (\\(lpha_0\\) = 1) "]]
