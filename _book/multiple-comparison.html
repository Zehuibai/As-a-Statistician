<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Multiple-Comparison | As a Statistician</title>
  <meta name="description" content="This book involves different statistical principles and methods, including the application of SAS and R, and aims to accumulate personal statistical knowledge." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Multiple-Comparison | As a Statistician" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book involves different statistical principles and methods, including the application of SAS and R, and aims to accumulate personal statistical knowledge." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Multiple-Comparison | As a Statistician" />
  
  <meta name="twitter:description" content="This book involves different statistical principles and methods, including the application of SAS and R, and aims to accumulate personal statistical knowledge." />
  

<meta name="author" content="Zehui Bai" />


<meta name="date" content="2022-09-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="anova.html"/>
<link rel="next" href="correlation-and-regression.html"/>
<script src="libs/header-attrs-2.14/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/d3-3.5.17/d3.min.js"></script>
<link href="libs/markmap-0.3.3/view.mindmap.css" rel="stylesheet" />
<script src="libs/markmap-0.3.3/view.mindmap.js"></script>
<script src="libs/markmap-0.3.3/plugins/parsemd.min.js"></script>
<script src="libs/markmap-binding-1.2.3/markmap.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">As a Statistician</a></li>

<li class="divider"></li>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="data-management-in-sas.html#data-management-in-sas" id="toc-data-management-in-sas"><span class="toc-section-number">2</span> Data Management in SAS</a>
<ul>
<li><a href="data-management-in-sas.html#input-data-into-sas" id="toc-input-data-into-sas"><span class="toc-section-number">2.1</span> Input data into SAS</a>
<ul>
<li><a href="data-management-in-sas.html#native-datasets-input" id="toc-native-datasets-input"><span class="toc-section-number">2.1.1</span> Native datasets input</a></li>
<li><a href="data-management-in-sas.html#reading-free-formatted-data-instream" id="toc-reading-free-formatted-data-instream"><span class="toc-section-number">2.1.2</span> Reading free formatted data instream</a></li>
<li><a href="data-management-in-sas.html#reading-fixed-formatted-data-instream" id="toc-reading-fixed-formatted-data-instream"><span class="toc-section-number">2.1.3</span> Reading fixed formatted data instream</a></li>
<li><a href="data-management-in-sas.html#infile-reading-fixed-formatted-data-from-an-external-file" id="toc-infile-reading-fixed-formatted-data-from-an-external-file"><span class="toc-section-number">2.1.4</span> INFILE: Reading fixed formatted data from an external file</a></li>
<li><a href="data-management-in-sas.html#write-the-sas-file" id="toc-write-the-sas-file"><span class="toc-section-number">2.1.5</span> Write the SAS File</a></li>
<li><a href="data-management-in-sas.html#import-csv-data" id="toc-import-csv-data"><span class="toc-section-number">2.1.6</span> Import csv data</a></li>
<li><a href="data-management-in-sas.html#import" id="toc-import"><span class="toc-section-number">2.1.7</span> %Import</a></li>
<li><a href="data-management-in-sas.html#url" id="toc-url"><span class="toc-section-number">2.1.8</span> URL</a></li>
<li><a href="data-management-in-sas.html#infile-read-multiple-raw-data-files" id="toc-infile-read-multiple-raw-data-files"><span class="toc-section-number">2.1.9</span> Infile Read multiple raw data files</a></li>
<li><a href="data-management-in-sas.html#generate-automatic-file-name" id="toc-generate-automatic-file-name"><span class="toc-section-number">2.1.10</span> Generate automatic file name</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#format-the-variables" id="toc-format-the-variables"><span class="toc-section-number">2.2</span> Format the variables</a>
<ul>
<li><a href="data-management-in-sas.html#proc-format" id="toc-proc-format"><span class="toc-section-number">2.2.1</span> Proc format</a></li>
<li><a href="data-management-in-sas.html#copy-and-combine-sas-format-libraries" id="toc-copy-and-combine-sas-format-libraries"><span class="toc-section-number">2.2.2</span> Copy and combine SAS format libraries</a></li>
<li><a href="data-management-in-sas.html#build-a-format-from-a-dataset" id="toc-build-a-format-from-a-dataset"><span class="toc-section-number">2.2.3</span> Build a format from a dataset</a></li>
<li><a href="data-management-in-sas.html#output-format-as-datasets" id="toc-output-format-as-datasets"><span class="toc-section-number">2.2.4</span> Output format as datasets</a></li>
<li><a href="data-management-in-sas.html#delete-the-format" id="toc-delete-the-format"><span class="toc-section-number">2.2.5</span> Delete the format</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#array" id="toc-array"><span class="toc-section-number">2.3</span> Array</a>
<ul>
<li><a href="data-management-in-sas.html#defining" id="toc-defining"><span class="toc-section-number">2.3.1</span> Defining</a></li>
<li><a href="data-management-in-sas.html#format-multiple-variables" id="toc-format-multiple-variables"><span class="toc-section-number">2.3.2</span> Format multiple variables</a></li>
<li><a href="data-management-in-sas.html#arrays" id="toc-arrays"><span class="toc-section-number">2.3.3</span> 2*2 arrays</a></li>
<li><a href="data-management-in-sas.html#dynamic-element-list-using-macro-variables" id="toc-dynamic-element-list-using-macro-variables"><span class="toc-section-number">2.3.4</span> Dynamic Element List using Macro Variables</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#retain" id="toc-retain"><span class="toc-section-number">2.4</span> Retain</a>
<ul>
<li><a href="data-management-in-sas.html#generate-serial-number" id="toc-generate-serial-number"><span class="toc-section-number">2.4.1</span> Generate Serial Number</a></li>
<li><a href="data-management-in-sas.html#change-from-basilne" id="toc-change-from-basilne"><span class="toc-section-number">2.4.2</span> Change from Basilne</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#data-utilities" id="toc-data-utilities"><span class="toc-section-number">2.5</span> Data utilities</a>
<ul>
<li><a href="data-management-in-sas.html#scan" id="toc-scan"><span class="toc-section-number">2.5.1</span> %Scan</a></li>
<li><a href="data-management-in-sas.html#eval-and-syseval" id="toc-eval-and-syseval"><span class="toc-section-number">2.5.2</span> %eval and %syseval</a></li>
<li><a href="data-management-in-sas.html#macro-variable-status" id="toc-macro-variable-status"><span class="toc-section-number">2.5.3</span> Macro variable status</a></li>
<li><a href="data-management-in-sas.html#sysfunc" id="toc-sysfunc"><span class="toc-section-number">2.5.4</span> %SYSFUNC</a></li>
<li><a href="data-management-in-sas.html#quoting-function" id="toc-quoting-function"><span class="toc-section-number">2.5.5</span> Quoting Function</a></li>
<li><a href="data-management-in-sas.html#call-symput" id="toc-call-symput"><span class="toc-section-number">2.5.6</span> Call Symput</a></li>
<li><a href="data-management-in-sas.html#call-execute" id="toc-call-execute"><span class="toc-section-number">2.5.7</span> Call Execute</a></li>
<li><a href="data-management-in-sas.html#sysfunc-get-the-observations" id="toc-sysfunc-get-the-observations"><span class="toc-section-number">2.5.8</span> %sysfunc get the observations</a></li>
</ul></li>
<li><a href="data-management-in-sas.html#clean-up" id="toc-clean-up"><span class="toc-section-number">2.6</span> Clean Up</a>
<ul>
<li><a href="data-management-in-sas.html#basic-setting" id="toc-basic-setting"><span class="toc-section-number">2.6.1</span> Basic setting</a></li>
<li><a href="data-management-in-sas.html#delete-datasets" id="toc-delete-datasets"><span class="toc-section-number">2.6.2</span> Delete datasets</a></li>
<li><a href="data-management-in-sas.html#deleting-formats" id="toc-deleting-formats"><span class="toc-section-number">2.6.3</span> Deleting Formats</a></li>
<li><a href="data-management-in-sas.html#remove-assigned-formats" id="toc-remove-assigned-formats"><span class="toc-section-number">2.6.4</span> Remove assigned formats</a></li>
<li><a href="data-management-in-sas.html#delete-macro-variables" id="toc-delete-macro-variables"><span class="toc-section-number">2.6.5</span> Delete macro variables</a></li>
<li><a href="data-management-in-sas.html#delete-macro" id="toc-delete-macro"><span class="toc-section-number">2.6.6</span> Delete Macro</a></li>
</ul></li>
</ul></li>
<li><a href="data-management-in-r.html#data-management-in-r" id="toc-data-management-in-r"><span class="toc-section-number">3</span> Data Management in R</a>
<ul>
<li><a href="data-management-in-r.html#basic-data-management" id="toc-basic-data-management"><span class="toc-section-number">3.1</span> Basic data management</a>
<ul>
<li><a href="data-management-in-r.html#apply-family" id="toc-apply-family"><span class="toc-section-number">3.1.1</span> apply family</a></li>
</ul></li>
<li><a href="data-management-in-r.html#importimput" id="toc-importimput"><span class="toc-section-number">3.2</span> import/imput</a>
<ul>
<li><a href="data-management-in-r.html#package-readr" id="toc-package-readr"><span class="toc-section-number">3.2.1</span> Package readr</a></li>
<li><a href="data-management-in-sas.html#import-csv-data" id="toc-import-csv-data"><span class="toc-section-number">3.2.2</span> Import csv data</a></li>
<li><a href="data-management-in-r.html#import-txt-data" id="toc-import-txt-data"><span class="toc-section-number">3.2.3</span> Import txt data</a></li>
<li><a href="data-management-in-r.html#import-excel-data" id="toc-import-excel-data"><span class="toc-section-number">3.2.4</span> Import excel data</a></li>
<li><a href="data-management-in-r.html#import-stata-data" id="toc-import-stata-data"><span class="toc-section-number">3.2.5</span> Import stata data</a></li>
<li><a href="data-management-in-r.html#import-sas-data" id="toc-import-sas-data"><span class="toc-section-number">3.2.6</span> Import SAS data</a></li>
<li><a href="data-management-in-r.html#copy-from-clipboard" id="toc-copy-from-clipboard"><span class="toc-section-number">3.2.7</span> Copy from clipboard</a></li>
<li><a href="data-management-in-r.html#save-and-write-objective-in-r" id="toc-save-and-write-objective-in-r"><span class="toc-section-number">3.2.8</span> Save and write objective in R</a></li>
<li><a href="data-management-in-r.html#save-the-plot" id="toc-save-the-plot"><span class="toc-section-number">3.2.9</span> Save the plot</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-tidyr" id="toc-package-tidyr"><span class="toc-section-number">3.3</span> Package tidyr</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet" id="toc-cheat-sheet"><span class="toc-section-number">3.3.1</span> CHEAT SHEET</a></li>
<li><a href="data-management-in-r.html#pivoting" id="toc-pivoting"><span class="toc-section-number">3.3.2</span> Pivoting</a></li>
<li><a href="data-management-in-r.html#gather-and-spread" id="toc-gather-and-spread"><span class="toc-section-number">3.3.3</span> gather and spread</a></li>
<li><a href="data-management-in-r.html#separate-and-unite" id="toc-separate-and-unite"><span class="toc-section-number">3.3.4</span> separate and unite</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-dplyr" id="toc-package-dplyr"><span class="toc-section-number">3.4</span> Package dplyr</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-1" id="toc-cheat-sheet-1"><span class="toc-section-number">3.4.1</span> CHEAT SHEET</a></li>
<li><a href="data-management-in-r.html#across" id="toc-across"><span class="toc-section-number">3.4.2</span> across</a></li>
<li><a href="data-management-in-r.html#arrange" id="toc-arrange"><span class="toc-section-number">3.4.3</span> arrange</a></li>
<li><a href="data-management-in-r.html#coalesce" id="toc-coalesce"><span class="toc-section-number">3.4.4</span> coalesce</a></li>
<li><a href="data-management-in-r.html#filter" id="toc-filter"><span class="toc-section-number">3.4.5</span> filter</a></li>
<li><a href="data-management-in-r.html#if_else" id="toc-if_else"><span class="toc-section-number">3.4.6</span> if_else</a></li>
<li><a href="data-management-in-r.html#join" id="toc-join"><span class="toc-section-number">3.4.7</span> join</a></li>
<li><a href="data-management-in-r.html#mutate" id="toc-mutate"><span class="toc-section-number">3.4.8</span> mutate</a></li>
<li><a href="data-management-in-r.html#select" id="toc-select"><span class="toc-section-number">3.4.9</span> select</a></li>
<li><a href="data-management-in-r.html#summarise" id="toc-summarise"><span class="toc-section-number">3.4.10</span> summarise</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-stringr" id="toc-package-stringr"><span class="toc-section-number">3.5</span> Package stringr</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-2" id="toc-cheat-sheet-2"><span class="toc-section-number">3.5.1</span> CHEAT SHEET</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-forcats" id="toc-package-forcats"><span class="toc-section-number">3.6</span> Package forcats</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-3" id="toc-cheat-sheet-3"><span class="toc-section-number">3.6.1</span> CHEAT SHEET</a></li>
</ul></li>
<li><a href="data-management-in-r.html#package-lubridate" id="toc-package-lubridate"><span class="toc-section-number">3.7</span> Package lubridate</a>
<ul>
<li><a href="data-management-in-r.html#cheat-sheet-4" id="toc-cheat-sheet-4"><span class="toc-section-number">3.7.1</span> CHEAT SHEET</a></li>
</ul></li>
</ul></li>
<li><a href="ggplot2.html#ggplot2" id="toc-ggplot2"><span class="toc-section-number">4</span> ggplot2</a>
<ul>
<li><a href="ggplot2.html#parametric-rendering" id="toc-parametric-rendering"><span class="toc-section-number">4.1</span> Parametric Rendering</a>
<ul>
<li><a href="ggplot2.html#grammar" id="toc-grammar"><span class="toc-section-number">4.1.1</span> Grammar</a></li>
<li><a href="ggplot2.html#coordinate-system" id="toc-coordinate-system"><span class="toc-section-number">4.1.2</span> Coordinate system</a></li>
<li><a href="ggplot2.html#legend" id="toc-legend"><span class="toc-section-number">4.1.3</span> Legend</a></li>
<li><a href="ggplot2.html#geom" id="toc-geom"><span class="toc-section-number">4.1.4</span> geom</a></li>
<li><a href="ggplot2.html#position" id="toc-position"><span class="toc-section-number">4.1.5</span> position</a></li>
<li><a href="ggplot2.html#scale" id="toc-scale"><span class="toc-section-number">4.1.6</span> scale</a></li>
<li><a href="ggplot2.html#stat" id="toc-stat"><span class="toc-section-number">4.1.7</span> stat</a></li>
<li><a href="ggplot2.html#color" id="toc-color"><span class="toc-section-number">4.1.8</span> Color</a></li>
<li><a href="ggplot2.html#thema" id="toc-thema"><span class="toc-section-number">4.1.9</span> Thema</a></li>
<li><a href="ggplot2.html#saving-plots" id="toc-saving-plots"><span class="toc-section-number">4.1.10</span> Saving plots</a></li>
</ul></li>
<li><a href="ggplot2.html#scatter-plot" id="toc-scatter-plot"><span class="toc-section-number">4.2</span> Scatter plot</a>
<ul>
<li><a href="ggplot2.html#grouping-aesthetic" id="toc-grouping-aesthetic"><span class="toc-section-number">4.2.1</span> Grouping Aesthetic</a></li>
<li><a href="ggplot2.html#facet" id="toc-facet"><span class="toc-section-number">4.2.2</span> facet</a></li>
<li><a href="ggplot2.html#geom_smooth" id="toc-geom_smooth"><span class="toc-section-number">4.2.3</span> geom_smooth</a></li>
<li><a href="ggplot2.html#dot-plot" id="toc-dot-plot"><span class="toc-section-number">4.2.4</span> Dot Plot</a></li>
<li><a href="ggplot2.html#label-and-title" id="toc-label-and-title"><span class="toc-section-number">4.2.5</span> Label and Title</a></li>
<li><a href="ggplot2.html#residuals" id="toc-residuals"><span class="toc-section-number">4.2.6</span> Residuals</a></li>
<li><a href="ggplot2.html#encircling" id="toc-encircling"><span class="toc-section-number">4.2.7</span> Encircling</a></li>
<li><a href="ggplot2.html#dumbbell-plot" id="toc-dumbbell-plot"><span class="toc-section-number">4.2.8</span> Dumbbell Plot</a></li>
</ul></li>
<li><a href="ggplot2.html#histogram" id="toc-histogram"><span class="toc-section-number">4.3</span> Histogram</a>
<ul>
<li><a href="ggplot2.html#general-appearance" id="toc-general-appearance"><span class="toc-section-number">4.3.1</span> General appearance</a></li>
<li><a href="ggplot2.html#themes" id="toc-themes"><span class="toc-section-number">4.3.2</span> Themes</a></li>
<li><a href="ggplot2.html#geom_freqpoly" id="toc-geom_freqpoly"><span class="toc-section-number">4.3.3</span> geom_freqpoly()</a></li>
<li><a href="ggplot2.html#marginal-histogram-boxplot" id="toc-marginal-histogram-boxplot"><span class="toc-section-number">4.3.4</span> Marginal Histogram / Boxplot</a></li>
<li><a href="ggplot2.html#scales" id="toc-scales"><span class="toc-section-number">4.3.5</span> Scales</a></li>
</ul></li>
<li><a href="ggplot2.html#bar-plot" id="toc-bar-plot"><span class="toc-section-number">4.4</span> Bar plot</a>
<ul>
<li><a href="ggplot2.html#aesthetic" id="toc-aesthetic"><span class="toc-section-number">4.4.1</span> Aesthetic</a></li>
<li><a href="ggplot2.html#proportion" id="toc-proportion"><span class="toc-section-number">4.4.2</span> Proportion</a></li>
<li><a href="ggplot2.html#coord" id="toc-coord"><span class="toc-section-number">4.4.3</span> coord</a></li>
<li><a href="ggplot2.html#statidentity" id="toc-statidentity"><span class="toc-section-number">4.4.4</span> stat=“identity”</a></li>
<li><a href="ggplot2.html#ranking" id="toc-ranking"><span class="toc-section-number">4.4.5</span> Ranking</a></li>
<li><a href="ggplot2.html#means-and-error-bars" id="toc-means-and-error-bars"><span class="toc-section-number">4.4.6</span> Means and error bars</a></li>
<li><a href="ggplot2.html#waffle-chart" id="toc-waffle-chart"><span class="toc-section-number">4.4.7</span> Waffle Chart</a></li>
</ul></li>
<li><a href="ggplot2.html#box-plot" id="toc-box-plot"><span class="toc-section-number">4.5</span> Box plot</a>
<ul>
<li><a href="ggplot2.html#varwidth" id="toc-varwidth"><span class="toc-section-number">4.5.1</span> varwidth</a></li>
<li><a href="ggplot2.html#reorder" id="toc-reorder"><span class="toc-section-number">4.5.2</span> Reorder</a></li>
<li><a href="ggplot2.html#fill" id="toc-fill"><span class="toc-section-number">4.5.3</span> Fill</a></li>
<li><a href="ggplot2.html#statidentity-1" id="toc-statidentity-1"><span class="toc-section-number">4.5.4</span> stat=“identity”</a></li>
<li><a href="ggplot2.html#dot-box-plot" id="toc-dot-box-plot"><span class="toc-section-number">4.5.5</span> Dot + Box Plot</a></li>
<li><a href="ggplot2.html#violin-plot" id="toc-violin-plot"><span class="toc-section-number">4.5.6</span> Violin Plot</a></li>
</ul></li>
<li><a href="ggplot2.html#other-rendering" id="toc-other-rendering"><span class="toc-section-number">4.6</span> Other rendering</a>
<ul>
<li><a href="ggplot2.html#annotation" id="toc-annotation"><span class="toc-section-number">4.6.1</span> Annotation</a></li>
<li><a href="ggplot2.html#text-ggtext" id="toc-text-ggtext"><span class="toc-section-number">4.6.2</span> Text: ggtext</a></li>
<li><a href="ggplot2.html#text-ggrepel" id="toc-text-ggrepel"><span class="toc-section-number">4.6.3</span> Text: ggrepel</a></li>
<li><a href="ggplot2.html#arrage-gridextra" id="toc-arrage-gridextra"><span class="toc-section-number">4.6.4</span> Arrage: gridExtra</a></li>
<li><a href="ggplot2.html#interactive-charts-plotly" id="toc-interactive-charts-plotly"><span class="toc-section-number">4.6.5</span> Interactive charts: plotly</a></li>
</ul></li>
<li><a href="ggplot2.html#diagrammer" id="toc-diagrammer"><span class="toc-section-number">4.7</span> DiagrammeR</a>
<ul>
<li><a href="ggplot2.html#basic-flowchart-using-grviz" id="toc-basic-flowchart-using-grviz"><span class="toc-section-number">4.7.1</span> Basic flowchart using <code>grViz</code></a></li>
<li><a href="ggplot2.html#graphviz-attributes" id="toc-graphviz-attributes"><span class="toc-section-number">4.7.2</span> Graphviz Attributes</a></li>
<li><a href="ggplot2.html#gantt-chart" id="toc-gantt-chart"><span class="toc-section-number">4.7.3</span> Gantt chart</a></li>
</ul></li>
<li><a href="ggplot2.html#ggstatsplot" id="toc-ggstatsplot"><span class="toc-section-number">4.8</span> ggstatsplot</a>
<ul>
<li><a href="ggplot2.html#ggbetweenstats" id="toc-ggbetweenstats"><span class="toc-section-number">4.8.1</span> ggbetweenstats</a></li>
</ul></li>
</ul></li>
<li><a href="descriptive-statistics-in-r.html#descriptive-statistics-in-r" id="toc-descriptive-statistics-in-r"><span class="toc-section-number">5</span> Descriptive Statistics in R</a>
<ul>
<li><a href="descriptive-statistics-in-r.html#package-pape" id="toc-package-pape"><span class="toc-section-number">5.1</span> Package pape</a></li>
<li><a href="descriptive-statistics-in-r.html#package-summarytools" id="toc-package-summarytools"><span class="toc-section-number">5.2</span> Package summarytools</a></li>
<li><a href="descriptive-statistics-in-r.html#package-comparegroups" id="toc-package-comparegroups"><span class="toc-section-number">5.3</span> Package compareGroups</a></li>
<li><a href="descriptive-statistics-in-r.html#package-sjplot-for-models-summary" id="toc-package-sjplot-for-models-summary"><span class="toc-section-number">5.4</span> Package sjPlot for Models Summary</a>
<ul>
<li><a href="descriptive-statistics-in-r.html#tab_model-and-options" id="toc-tab_model-and-options"><span class="toc-section-number">5.4.1</span> tab_model and options</a></li>
<li><a href="descriptive-statistics-in-r.html#mixed-models" id="toc-mixed-models"><span class="toc-section-number">5.4.2</span> Mixed Models</a></li>
<li><a href="descriptive-statistics-in-r.html#plot_model" id="toc-plot_model"><span class="toc-section-number">5.4.3</span> plot_model</a></li>
</ul></li>
<li><a href="descriptive-statistics-in-r.html#package-kableextra" id="toc-package-kableextra"><span class="toc-section-number">5.5</span> Package kableExtra</a>
<ul>
<li><a href="descriptive-statistics-in-r.html#kable_styling" id="toc-kable_styling"><span class="toc-section-number">5.5.1</span> kable_styling</a></li>
<li><a href="descriptive-statistics-in-r.html#columnrow-specification" id="toc-columnrow-specification"><span class="toc-section-number">5.5.2</span> Column/Row Specification</a></li>
<li><a href="descriptive-statistics-in-r.html#grouping-columnsrows" id="toc-grouping-columnsrows"><span class="toc-section-number">5.5.3</span> Grouping columns/rows</a></li>
<li><a href="descriptive-statistics-in-r.html#add-footnote" id="toc-add-footnote"><span class="toc-section-number">5.5.4</span> Add Footnote</a></li>
</ul></li>
</ul></li>
<li><a href="parametric-test.html#parametric-test" id="toc-parametric-test"><span class="toc-section-number">6</span> Parametric Test</a>
<ul>
<li><a href="parametric-test.html#binomial-test" id="toc-binomial-test"><span class="toc-section-number">6.1</span> Binomial test</a>
<ul>
<li><a href="parametric-test.html#mathematical-formula" id="toc-mathematical-formula"><span class="toc-section-number">6.1.1</span> Mathematical Formula</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">6.1.2</span> R implementation</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">6.1.3</span> SAS Implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#fishers-exact-test" id="toc-fishers-exact-test"><span class="toc-section-number">6.2</span> Fisher’s Exact Test</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">6.2.1</span> Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">6.2.2</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">6.2.3</span> R implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#sensitivity-and-specificity" id="toc-sensitivity-and-specificity"><span class="toc-section-number">6.3</span> Sensitivity and specificity</a></li>
<li><a href="parametric-test.html#mcnemars-test" id="toc-mcnemars-test"><span class="toc-section-number">6.4</span> McNemar’s test</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">6.4.1</span> introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-2" id="toc-sas-implementation-2"><span class="toc-section-number">6.4.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-2" id="toc-r-implementation-2"><span class="toc-section-number">6.4.3</span> R Implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#cochranmantelhaenszel-test" id="toc-cochranmantelhaenszel-test"><span class="toc-section-number">6.5</span> Cochran–Mantel–Haenszel Test</a>
<ul>
<li><a href="parametric-test.html#r-implementation-3" id="toc-r-implementation-3"><span class="toc-section-number">6.5.1</span> R implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#correlation-test" id="toc-correlation-test"><span class="toc-section-number">6.6</span> Correlation Test</a>
<ul>
<li><a href="parametric-test.html#pearson-correlation" id="toc-pearson-correlation"><span class="toc-section-number">6.6.1</span> Pearson correlation</a></li>
<li><a href="parametric-test.html#spearman-correlation" id="toc-spearman-correlation"><span class="toc-section-number">6.6.2</span> Spearman correlation</a></li>
<li><a href="parametric-test.html#kendall-correlation" id="toc-kendall-correlation"><span class="toc-section-number">6.6.3</span> Kendall correlation</a></li>
</ul></li>
<li><a href="parametric-test.html#two-sample-t-test" id="toc-two-sample-t-test"><span class="toc-section-number">6.7</span> Two Sample T-Test</a>
<ul>
<li><a href="parametric-test.html#inreoduction" id="toc-inreoduction"><span class="toc-section-number">6.7.1</span> Inreoduction</a></li>
<li><a href="parametric-test.html#sas-implementation-3" id="toc-sas-implementation-3"><span class="toc-section-number">6.7.2</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-4" id="toc-r-implementation-4"><span class="toc-section-number">6.7.3</span> R implementation</a></li>
</ul></li>
<li><a href="parametric-test.html#normality-test" id="toc-normality-test"><span class="toc-section-number">6.8</span> Normality test</a>
<ul>
<li><a href="parametric-test.html#sas-implementation-4" id="toc-sas-implementation-4"><span class="toc-section-number">6.8.1</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-5" id="toc-r-implementation-5"><span class="toc-section-number">6.8.2</span> R implementation</a></li>
</ul></li>
</ul></li>
<li><a href="non-parametric-test.html#non-parametric-test" id="toc-non-parametric-test"><span class="toc-section-number">7</span> Non-Parametric Test</a>
<ul>
<li><a href="non-parametric-test.html#two-samples-hypotheses-testing" id="toc-two-samples-hypotheses-testing"><span class="toc-section-number">7.1</span> Two Samples Hypotheses Testing</a>
<ul>
<li><a href="non-parametric-test.html#sign-test-for-location-parameter-for-matched-paired-samples" id="toc-sign-test-for-location-parameter-for-matched-paired-samples"><span class="toc-section-number">7.1.1</span> Sign Test for Location Parameter for Matched Paired Samples</a></li>
<li><a href="non-parametric-test.html#wilcoxon-signed-rank-test-for-location-parameter-for-matched" id="toc-wilcoxon-signed-rank-test-for-location-parameter-for-matched"><span class="toc-section-number">7.1.2</span> Wilcoxon Signed-Rank Test for Location Parameter for Matched</a></li>
<li><a href="non-parametric-test.html#wilcoxon-rank-sum-test-for-location-parameter-for-two-independent-samples" id="toc-wilcoxon-rank-sum-test-for-location-parameter-for-two-independent-samples"><span class="toc-section-number">7.1.3</span> Wilcoxon Rank-Sum Test for Location Parameter for Two Independent Samples</a></li>
<li><a href="non-parametric-test.html#ansari-bradley-test-for-scale-parameter-for-two-independent-samples" id="toc-ansari-bradley-test-for-scale-parameter-for-two-independent-samples"><span class="toc-section-number">7.1.4</span> Ansari-Bradley Test for Scale Parameter for Two Independent Samples</a></li>
<li><a href="non-parametric-test.html#kolmogorov-smirnov-test-for-equality-of-distributions" id="toc-kolmogorov-smirnov-test-for-equality-of-distributions"><span class="toc-section-number">7.1.5</span> Kolmogorov-Smirnov Test for Equality of Distributions</a></li>
</ul></li>
<li><a href="non-parametric-test.html#several-samples-hypotheses-testing" id="toc-several-samples-hypotheses-testing"><span class="toc-section-number">7.2</span> Several Samples Hypotheses Testing</a>
<ul>
<li><a href="non-parametric-test.html#friedman-rank-test-for-location-parameter-for-several-dependent-samples" id="toc-friedman-rank-test-for-location-parameter-for-several-dependent-samples"><span class="toc-section-number">7.2.1</span> Friedman Rank Test for Location Parameter for Several Dependent Samples</a></li>
<li><a href="non-parametric-test.html#kruskal-wallis-h-test-for-location-parameter" id="toc-kruskal-wallis-h-test-for-location-parameter"><span class="toc-section-number">7.2.2</span> Kruskal-Wallis H-Test for Location Parameter</a></li>
</ul></li>
<li><a href="non-parametric-test.html#tests-for-categorical-data" id="toc-tests-for-categorical-data"><span class="toc-section-number">7.3</span> Tests for Categorical Data</a>
<ul>
<li><a href="non-parametric-test.html#spearman-rank-correlation-coefficient-test" id="toc-spearman-rank-correlation-coefficient-test"><span class="toc-section-number">7.3.1</span> Spearman Rank Correlation Coefficient Test</a></li>
<li><a href="non-parametric-test.html#fisher-exact-test" id="toc-fisher-exact-test"><span class="toc-section-number">7.3.2</span> Fisher Exact Test</a></li>
</ul></li>
<li><a href="non-parametric-test.html#permutation-test" id="toc-permutation-test"><span class="toc-section-number">7.4</span> Permutation test</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">7.4.1</span> Introduction</a></li>
<li><a href="non-parametric-test.html#package-coin" id="toc-package-coin"><span class="toc-section-number">7.4.2</span> Package: coin</a></li>
<li><a href="non-parametric-test.html#one-way-permutation-test-of-independence-for-ordinal-data" id="toc-one-way-permutation-test-of-independence-for-ordinal-data"><span class="toc-section-number">7.4.3</span> One-way Permutation Test of Independence for Ordinal Data</a></li>
<li><a href="non-parametric-test.html#one-way-permutation-test-of-symmetry-for-ordinal-data" id="toc-one-way-permutation-test-of-symmetry-for-ordinal-data"><span class="toc-section-number">7.4.4</span> One-way Permutation Test of Symmetry for Ordinal Data</a></li>
<li><a href="non-parametric-test.html#permutation-tests-for-medians-and-percentiles" id="toc-permutation-tests-for-medians-and-percentiles"><span class="toc-section-number">7.4.5</span> Permutation Tests for Medians and Percentiles</a></li>
</ul></li>
</ul></li>
<li><a href="sample-size-calculation.html#sample-size-calculation" id="toc-sample-size-calculation"><span class="toc-section-number">8</span> Sample Size Calculation</a>
<ul>
<li><a href="sample-size-calculation.html#distribution" id="toc-distribution"><span class="toc-section-number">8.1</span> Distribution</a>
<ul>
<li><a href="sample-size-calculation.html#quantile-function-in-sas" id="toc-quantile-function-in-sas"><span class="toc-section-number">8.1.1</span> Quantile Function in SAS</a></li>
<li><a href="sample-size-calculation.html#binomial-distribution" id="toc-binomial-distribution"><span class="toc-section-number">8.1.2</span> Binomial distribution</a></li>
<li><a href="sample-size-calculation.html#negative-binomial-distribution" id="toc-negative-binomial-distribution"><span class="toc-section-number">8.1.3</span> Negative binomial distribution</a></li>
<li><a href="sample-size-calculation.html#multinomial-distribution" id="toc-multinomial-distribution"><span class="toc-section-number">8.1.4</span> Multinomial distribution</a></li>
<li><a href="sample-size-calculation.html#normal-distribution" id="toc-normal-distribution"><span class="toc-section-number">8.1.5</span> Normal Distribution</a></li>
<li><a href="sample-size-calculation.html#multivariate-normal-distribution" id="toc-multivariate-normal-distribution"><span class="toc-section-number">8.1.6</span> Multivariate normal distribution</a></li>
<li><a href="sample-size-calculation.html#poisson-distribution" id="toc-poisson-distribution"><span class="toc-section-number">8.1.7</span> Poisson distribution</a></li>
<li><a href="sample-size-calculation.html#exponential-distribution" id="toc-exponential-distribution"><span class="toc-section-number">8.1.8</span> Exponential distribution</a></li>
<li><a href="sample-size-calculation.html#gamma-distribution" id="toc-gamma-distribution"><span class="toc-section-number">8.1.9</span> Gamma distribution</a></li>
<li><a href="sample-size-calculation.html#weibull-distribution" id="toc-weibull-distribution"><span class="toc-section-number">8.1.10</span> Weibull Distribution</a></li>
<li><a href="sample-size-calculation.html#chi-squared-distribution" id="toc-chi-squared-distribution"><span class="toc-section-number">8.1.11</span> Chi-Squared Distribution</a></li>
<li><a href="sample-size-calculation.html#beta-distribution" id="toc-beta-distribution"><span class="toc-section-number">8.1.12</span> Beta Distribution</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#binomial-ci" id="toc-binomial-ci"><span class="toc-section-number">8.2</span> Binomial CI</a>
<ul>
<li><a href="sample-size-calculation.html#point-estimates" id="toc-point-estimates"><span class="toc-section-number">8.2.1</span> Point Estimates</a></li>
<li><a href="sample-size-calculation.html#binomial-ci-for-small-samples" id="toc-binomial-ci-for-small-samples"><span class="toc-section-number">8.2.2</span> Binomial CI for Small Samples</a></li>
<li><a href="sample-size-calculation.html#r-packages" id="toc-r-packages"><span class="toc-section-number">8.2.3</span> R Packages</a></li>
<li><a href="sample-size-calculation.html#incidence-rate-ci" id="toc-incidence-rate-ci"><span class="toc-section-number">8.2.4</span> Incidence rate CI</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#test-1-sample-proportion" id="toc-test-1-sample-proportion"><span class="toc-section-number">8.3</span> Test 1-Sample Proportion</a></li>
<li><a href="sample-size-calculation.html#test-2-sample-proportions" id="toc-test-2-sample-proportions"><span class="toc-section-number">8.4</span> Test 2-Sample Proportions</a>
<ul>
<li><a href="sample-size-calculation.html#technical-details" id="toc-technical-details"><span class="toc-section-number">8.4.1</span> Technical details</a></li>
<li><a href="parametric-test.html#fishers-exact-test" id="toc-fishers-exact-test"><span class="toc-section-number">8.4.2</span> Fisher’s Exact Test</a></li>
<li><a href="sample-size-calculation.html#z-test-or-chi-square-test-pooled-and-unpooled" id="toc-z-test-or-chi-square-test-pooled-and-unpooled"><span class="toc-section-number">8.4.3</span> Z Test (or Chi-Square Test) (Pooled and Unpooled)</a></li>
<li><a href="sample-size-calculation.html#conditional-mantel-haenszel-test" id="toc-conditional-mantel-haenszel-test"><span class="toc-section-number">8.4.4</span> Conditional Mantel-Haenszel Test</a></li>
<li><a href="sample-size-calculation.html#paired-proportions-mcnemars-z-test" id="toc-paired-proportions-mcnemars-z-test"><span class="toc-section-number">8.4.5</span> Paired Proportions: McNemar’s Z-test</a></li>
<li><a href="sample-size-calculation.html#chi-square-test" id="toc-chi-square-test"><span class="toc-section-number">8.4.6</span> Chi-square test</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#test-means" id="toc-test-means"><span class="toc-section-number">8.5</span> Test Mean(s)</a>
<ul>
<li><a href="sample-size-calculation.html#one-sample-mean-2-sided-equality" id="toc-one-sample-mean-2-sided-equality"><span class="toc-section-number">8.5.1</span> One Sample Mean 2-Sided Equality</a></li>
<li><a href="sample-size-calculation.html#sample-mean-non-inferiority-or-superiority" id="toc-sample-mean-non-inferiority-or-superiority"><span class="toc-section-number">8.5.2</span> 1-Sample Mean Non-Inferiority or Superiority</a></li>
<li><a href="sample-size-calculation.html#sample-mean-equivalence" id="toc-sample-mean-equivalence"><span class="toc-section-number">8.5.3</span> 1-Sample Mean Equivalence</a></li>
<li><a href="sample-size-calculation.html#sample-means-2-sided-equality" id="toc-sample-means-2-sided-equality"><span class="toc-section-number">8.5.4</span> 2-Sample Means, 2-Sided Equality</a></li>
<li><a href="sample-size-calculation.html#sample-means-1-sided" id="toc-sample-means-1-sided"><span class="toc-section-number">8.5.5</span> 2-Sample Means, 1-Sided</a></li>
<li><a href="sample-size-calculation.html#sample-means-non-inferiority-or-superiority" id="toc-sample-means-non-inferiority-or-superiority"><span class="toc-section-number">8.5.6</span> 2-Sample Means Non-Inferiority or Superiority</a></li>
<li><a href="sample-size-calculation.html#sample-means-equivalence" id="toc-sample-means-equivalence"><span class="toc-section-number">8.5.7</span> 2-Sample Means Equivalence</a></li>
<li><a href="sample-size-calculation.html#t-test-using-pwr.t.test-or-pwr.t2n.test" id="toc-t-test-using-pwr.t.test-or-pwr.t2n.test"><span class="toc-section-number">8.5.8</span> T-Test using <code>pwr.t.test</code> or <code>pwr.t2n.test</code></a></li>
<li><a href="sample-size-calculation.html#test-k-means" id="toc-test-k-means"><span class="toc-section-number">8.5.9</span> Test k Means</a></li>
<li><a href="sample-size-calculation.html#anova-using-pwr.anova.test" id="toc-anova-using-pwr.anova.test"><span class="toc-section-number">8.5.10</span> Anova using <code>pwr.anova.test</code></a></li>
<li><a href="sample-size-calculation.html#average-bioequivalence" id="toc-average-bioequivalence"><span class="toc-section-number">8.5.11</span> Average Bioequivalence</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#other-methods" id="toc-other-methods"><span class="toc-section-number">8.6</span> Other Methods</a>
<ul>
<li><a href="sample-size-calculation.html#odds-ratio" id="toc-odds-ratio"><span class="toc-section-number">8.6.1</span> Odds Ratio</a></li>
<li><a href="sample-size-calculation.html#correlation" id="toc-correlation"><span class="toc-section-number">8.6.2</span> Correlation</a></li>
<li><a href="sample-size-calculation.html#correlated-binary-data-ophthalmologic-studies" id="toc-correlated-binary-data-ophthalmologic-studies"><span class="toc-section-number">8.6.3</span> Correlated Binary Data: Ophthalmologic Studies</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#multiple-test" id="toc-multiple-test"><span class="toc-section-number">8.7</span> Multiple test</a>
<ul>
<li><a href="sample-size-calculation.html#definitions-of-power" id="toc-definitions-of-power"><span class="toc-section-number">8.7.1</span> Definitions of Power</a></li>
<li><a href="sample-size-calculation.html#bonferroni-tests-individual-power" id="toc-bonferroni-tests-individual-power"><span class="toc-section-number">8.7.2</span> Bonferroni Tests (Individual Power)</a></li>
<li><a href="sample-size-calculation.html#tukeys-method-individual-power" id="toc-tukeys-method-individual-power"><span class="toc-section-number">8.7.3</span> Tukey’s method (Individual Power)</a></li>
<li><a href="sample-size-calculation.html#dunnetts-two-sided-tests-individual-power" id="toc-dunnetts-two-sided-tests-individual-power"><span class="toc-section-number">8.7.4</span> Dunnett’s Two-Sided Tests (Individual Power)</a></li>
<li><a href="sample-size-calculation.html#combined-power-simpower-and-plotsimpower" id="toc-combined-power-simpower-and-plotsimpower"><span class="toc-section-number">8.7.5</span> Combined Power %SimPower and %PlotSimPower</a></li>
<li><a href="sample-size-calculation.html#dunnett-set-up-close-tests-in-r" id="toc-dunnett-set-up-close-tests-in-r"><span class="toc-section-number">8.7.6</span> Dunnett Set up Close Tests in R</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#time-to-event-data" id="toc-time-to-event-data"><span class="toc-section-number">8.8</span> Time-To-Event Data</a>
<ul>
<li><a href="sample-size-calculation.html#cox-ph-2-sided-equality" id="toc-cox-ph-2-sided-equality"><span class="toc-section-number">8.8.1</span> Cox PH, 2-Sided Equality</a></li>
<li><a href="sample-size-calculation.html#log-rank-tests-for-competing-risks" id="toc-log-rank-tests-for-competing-risks"><span class="toc-section-number">8.8.2</span> Log-Rank Tests for Competing Risks</a></li>
</ul></li>
<li><a href="sample-size-calculation.html#estimation-in-diagnostic-test" id="toc-estimation-in-diagnostic-test"><span class="toc-section-number">8.9</span> Estimation in diagnostic test</a>
<ul>
<li><a href="sample-size-calculation.html#adequate-sensitivityspecificity" id="toc-adequate-sensitivityspecificity"><span class="toc-section-number">8.9.1</span> Adequate sensitivity/specificity</a></li>
<li><a href="sample-size-calculation.html#testing-sensitivity-or-specificity" id="toc-testing-sensitivity-or-specificity"><span class="toc-section-number">8.9.2</span> Testing sensitivity (or specificity)</a></li>
<li><a href="sample-size-calculation.html#likelihood-ratio-estimation" id="toc-likelihood-ratio-estimation"><span class="toc-section-number">8.9.3</span> Likelihood ratio estimation</a></li>
<li><a href="sample-size-calculation.html#roc-index-of-accuracy" id="toc-roc-index-of-accuracy"><span class="toc-section-number">8.9.4</span> ROC index of accuracy</a></li>
</ul></li>
</ul></li>
<li><a href="anova.html#anova" id="toc-anova"><span class="toc-section-number">9</span> ANOVA</a>
<ul>
<li><a href="anova.html#unstructured-models" id="toc-unstructured-models"><span class="toc-section-number">9.1</span> Unstructured Models</a></li>
<li><a href="anova.html#balanced-one-way-analysis-of-variance-anova" id="toc-balanced-one-way-analysis-of-variance-anova"><span class="toc-section-number">9.2</span> Balanced One-Way Analysis-of-Variance (ANOVA)</a>
<ul>
<li><a href="anova.html#modeling-assumptions-and-basic-analysis" id="toc-modeling-assumptions-and-basic-analysis"><span class="toc-section-number">9.2.1</span> Modeling Assumptions and Basic Analysis</a></li>
<li><a href="anova.html#parameter-estimates" id="toc-parameter-estimates"><span class="toc-section-number">9.2.2</span> Parameter Estimates</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">9.2.3</span> R Implementation</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">9.2.4</span> SAS Implementation</a></li>
<li><a href="anova.html#model-diagnosis" id="toc-model-diagnosis"><span class="toc-section-number">9.2.5</span> Model Diagnosis</a></li>
</ul></li>
<li><a href="anova.html#unbalanced-one-way-anova-and-analysis-of-covariance-ancova" id="toc-unbalanced-one-way-anova-and-analysis-of-covariance-ancova"><span class="toc-section-number">9.3</span> Unbalanced One-Way ANOVA and Analysis-of-Covariance (ANCOVA)</a></li>
<li><a href="anova.html#two-ways-anova-test" id="toc-two-ways-anova-test"><span class="toc-section-number">9.4</span> Two-Ways ANOVA Test</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">9.4.1</span> Introduction</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">9.4.2</span> R implementation</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">9.4.3</span> SAS Implementation</a></li>
<li><a href="anova.html#unbalanced-design" id="toc-unbalanced-design"><span class="toc-section-number">9.4.4</span> Unbalanced design</a></li>
</ul></li>
<li><a href="anova.html#heteroscedastic-responses" id="toc-heteroscedastic-responses"><span class="toc-section-number">9.5</span> Heteroscedastic Responses</a></li>
<li><a href="anova.html#repeated-measures-anova-data" id="toc-repeated-measures-anova-data"><span class="toc-section-number">9.6</span> Repeated Measures ANOVA Data</a></li>
<li><a href="anova.html#multivariate-responses-with-normally-distributed-data" id="toc-multivariate-responses-with-normally-distributed-data"><span class="toc-section-number">9.7</span> Multivariate Responses with Normally Distributed Data</a></li>
<li><a href="anova.html#independent-observations-from-parametric-nonnormal-distributions" id="toc-independent-observations-from-parametric-nonnormal-distributions"><span class="toc-section-number">9.8</span> Independent Observations from Parametric Nonnormal Distributions</a></li>
<li><a href="anova.html#dependent-observations-from-parametric-nonnormal-distributions" id="toc-dependent-observations-from-parametric-nonnormal-distributions"><span class="toc-section-number">9.9</span> Dependent Observations from Parametric Nonnormal Distributions</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparison" id="toc-multiple-comparison"><span class="toc-section-number">10</span> Multiple-Comparison</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">10.1</span> Introduction</a>
<ul>
<li><a href="multiple-comparison.html#multiplicity-problem" id="toc-multiplicity-problem"><span class="toc-section-number">10.1.1</span> Multiplicity Problem</a></li>
<li><a href="multiple-comparison.html#error-rates" id="toc-error-rates"><span class="toc-section-number">10.1.2</span> Error Rates</a></li>
<li><a href="multiple-comparison.html#the-adjusted-p" id="toc-the-adjusted-p"><span class="toc-section-number">10.1.3</span> The adjusted P</a></li>
<li><a href="multiple-comparison.html#basic-statistical-concepts" id="toc-basic-statistical-concepts"><span class="toc-section-number">10.1.4</span> Basic Statistical Concepts</a></li>
<li><a href="multiple-comparison.html#functions-in-glht-package-in-r" id="toc-functions-in-glht-package-in-r"><span class="toc-section-number">10.1.5</span> Functions in glht package in R</a></li>
</ul></li>
<li><a href="multiple-comparison.html#bonferroni-and-šidák-methods" id="toc-bonferroni-and-šidák-methods"><span class="toc-section-number">10.2</span> Bonferroni and Šidák Methods</a>
<ul>
<li><a href="multiple-comparison.html#lsd-least-significance-difference" id="toc-lsd-least-significance-difference"><span class="toc-section-number">10.2.1</span> LSD (least significance difference)</a></li>
<li><a href="multiple-comparison.html#šidák" id="toc-šidák"><span class="toc-section-number">10.2.2</span> Šidák</a></li>
<li><a href="multiple-comparison.html#bonferroni" id="toc-bonferroni"><span class="toc-section-number">10.2.3</span> Bonferroni</a></li>
<li><a href="multiple-comparison.html#schweder-spjøtvoll-p-value-plot" id="toc-schweder-spjøtvoll-p-value-plot"><span class="toc-section-number">10.2.4</span> Schweder-Spjøtvoll p-Value Plot</a></li>
</ul></li>
<li><a href="multiple-comparison.html#mcp-among-treatment-means-in-the-one-way-balanced-anova" id="toc-mcp-among-treatment-means-in-the-one-way-balanced-anova"><span class="toc-section-number">10.3</span> MCP among Treatment Means in the One-Way Balanced ANOVA</a>
<ul>
<li><a href="multiple-comparison.html#ls-means" id="toc-ls-means"><span class="toc-section-number">10.3.1</span> LS-Means</a></li>
<li><a href="multiple-comparison.html#the-multivariate-t-distribution" id="toc-the-multivariate-t-distribution"><span class="toc-section-number">10.3.2</span> The Multivariate t Distribution</a></li>
<li><a href="multiple-comparison.html#calculating-the-critical-value-c_alpha" id="toc-calculating-the-critical-value-c_alpha"><span class="toc-section-number">10.3.3</span> Calculating the Critical Value <span class="math inline">\(c_{\alpha}\)</span></a></li>
<li><a href="multiple-comparison.html#all-pairwise-comparisons-and-studentized-range-distribution" id="toc-all-pairwise-comparisons-and-studentized-range-distribution"><span class="toc-section-number">10.3.4</span> All Pairwise Comparisons and Studentized Range Distribution</a></li>
<li><a href="multiple-comparison.html#tukeys-method-for-all-pairwise-comparisons" id="toc-tukeys-method-for-all-pairwise-comparisons"><span class="toc-section-number">10.3.5</span> Tukey’s Method for All Pairwise Comparisons</a></li>
<li><a href="multiple-comparison.html#displaying-pairwise-comparisons-graphically" id="toc-displaying-pairwise-comparisons-graphically"><span class="toc-section-number">10.3.6</span> Displaying Pairwise Comparisons Graphically</a></li>
<li><a href="multiple-comparison.html#dunnetts-two-sided-comparisons-with-a-control-and-dunnetts-two-sided-range-distribution" id="toc-dunnetts-two-sided-comparisons-with-a-control-and-dunnetts-two-sided-range-distribution"><span class="toc-section-number">10.3.7</span> Dunnett’s Two-Sided Comparisons with a Control and Dunnett’s Two-Sided Range Distribution</a></li>
<li><a href="multiple-comparison.html#dunnetts-one-sided-comparisons-with-a-control" id="toc-dunnetts-one-sided-comparisons-with-a-control"><span class="toc-section-number">10.3.8</span> Dunnett’s One-Sided Comparisons with a Control</a></li>
<li><a href="multiple-comparison.html#maximum-modulus-distribution-multiple-inferences-for-independent-estimates" id="toc-maximum-modulus-distribution-multiple-inferences-for-independent-estimates"><span class="toc-section-number">10.3.9</span> Maximum Modulus Distribution, Multiple Inferences for Independent Estimates</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparisons-among-treatment-means-in-the-one-way-unbalanced-anova" id="toc-multiple-comparisons-among-treatment-means-in-the-one-way-unbalanced-anova"><span class="toc-section-number">10.4</span> Multiple Comparisons among Treatment Means in the One-Way Unbalanced ANOVA</a>
<ul>
<li><a href="multiple-comparison.html#the-model-and-estimates" id="toc-the-model-and-estimates"><span class="toc-section-number">10.4.1</span> The Model and Estimates</a></li>
<li><a href="multiple-comparison.html#tukey-kramer-method" id="toc-tukey-kramer-method"><span class="toc-section-number">10.4.2</span> Tukey-Kramer Method</a></li>
<li><a href="multiple-comparison.html#alternative-simulation-based-method" id="toc-alternative-simulation-based-method"><span class="toc-section-number">10.4.3</span> Alternative Simulation-Based Method</a></li>
<li><a href="multiple-comparison.html#pairwise-comparisons-with-control" id="toc-pairwise-comparisons-with-control"><span class="toc-section-number">10.4.4</span> Pairwise Comparisons with Control</a></li>
<li><a href="multiple-comparison.html#comparisons-with-the-average-meananalysis-of-means-anom" id="toc-comparisons-with-the-average-meananalysis-of-means-anom"><span class="toc-section-number">10.4.5</span> Comparisons with the Average Mean–Analysis of Means (ANOM)</a></li>
</ul></li>
<li><a href="multiple-comparison.html#generalizations-for-the-analysis-of-covariance-ancova-model" id="toc-generalizations-for-the-analysis-of-covariance-ancova-model"><span class="toc-section-number">10.5</span> Generalizations for the Analysis of Covariance (ANCOVA) model</a>
<ul>
<li><a href="multiple-comparison.html#dunnett-hsu-factor-analytic-approximation" id="toc-dunnett-hsu-factor-analytic-approximation"><span class="toc-section-number">10.5.1</span> Dunnett-Hsu Factor Analytic Approximation</a></li>
<li><a href="multiple-comparison.html#hsu-nelson-simulation-based-approximation-cvadjust-method" id="toc-hsu-nelson-simulation-based-approximation-cvadjust-method"><span class="toc-section-number">10.5.2</span> Hsu-Nelson Simulation-Based Approximation: CVADJUST Method</a></li>
<li><a href="multiple-comparison.html#comparisons-in-ancova-models-with-interaction" id="toc-comparisons-in-ancova-models-with-interaction"><span class="toc-section-number">10.5.3</span> Comparisons in ANCOVA Models with Interaction</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-inferences-for-infinite-sets-of-parameters" id="toc-multiple-inferences-for-infinite-sets-of-parameters"><span class="toc-section-number">10.6</span> Multiple Inferences for Infinite Sets of Parameters</a>
<ul>
<li><a href="multiple-comparison.html#scheffés-method" id="toc-scheffés-method"><span class="toc-section-number">10.6.1</span> Scheffés Method</a></li>
<li><a href="multiple-comparison.html#finding-the-maximal-contrast" id="toc-finding-the-maximal-contrast"><span class="toc-section-number">10.6.2</span> Finding the Maximal Contrast</a></li>
<li><a href="multiple-comparison.html#working-hotelling-method" id="toc-working-hotelling-method"><span class="toc-section-number">10.6.3</span> Working-Hotelling method</a></li>
<li><a href="multiple-comparison.html#discrete-approximation-method" id="toc-discrete-approximation-method"><span class="toc-section-number">10.6.4</span> Discrete approximation method</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparisons-under-heteroscedasticity" id="toc-multiple-comparisons-under-heteroscedasticity"><span class="toc-section-number">10.7</span> Multiple Comparisons under Heteroscedasticity</a>
<ul>
<li><a href="multiple-comparison.html#introduction-of-heteroscedasticity" id="toc-introduction-of-heteroscedasticity"><span class="toc-section-number">10.7.1</span> Introduction of heteroscedasticity</a></li>
<li><a href="multiple-comparison.html#maxt-method-under-heteroscedasticity" id="toc-maxt-method-under-heteroscedasticity"><span class="toc-section-number">10.7.2</span> MaxT Method under Heteroscedasticity</a></li>
<li><a href="multiple-comparison.html#minp-method-under-heteroscedasticity" id="toc-minp-method-under-heteroscedasticity"><span class="toc-section-number">10.7.3</span> MinP Method under Heteroscedasticity</a></li>
</ul></li>
<li><a href="multiple-comparison.html#closed-and-stepwise-testing-methods" id="toc-closed-and-stepwise-testing-methods"><span class="toc-section-number">10.8</span> Closed and Stepwise Testing Methods</a>
<ul>
<li><a href="multiple-comparison.html#closed-family-of-hypotheses" id="toc-closed-family-of-hypotheses"><span class="toc-section-number">10.8.1</span> Closed Family of Hypotheses</a></li>
<li><a href="multiple-comparison.html#bonferroni-holm-method" id="toc-bonferroni-holm-method"><span class="toc-section-number">10.8.2</span> Bonferroni-Holm Method</a></li>
<li><a href="multiple-comparison.html#šidák-holm-method" id="toc-šidák-holm-method"><span class="toc-section-number">10.8.3</span> Šidák-Holm Method</a></li>
<li><a href="multiple-comparison.html#closed-fisher-combination-method" id="toc-closed-fisher-combination-method"><span class="toc-section-number">10.8.4</span> Closed Fisher Combination Method</a></li>
<li><a href="multiple-comparison.html#simes-hommel-method" id="toc-simes-hommel-method"><span class="toc-section-number">10.8.5</span> Simes-Hommel Method</a></li>
<li><a href="multiple-comparison.html#hochbergs-ok-step-up" id="toc-hochbergs-ok-step-up"><span class="toc-section-number">10.8.6</span> Hochberg’s O(k) Step-Up</a></li>
<li><a href="multiple-comparison.html#sequential-testing-with-fixed-sequences" id="toc-sequential-testing-with-fixed-sequences"><span class="toc-section-number">10.8.7</span> Sequential Testing with Fixed Sequences</a></li>
<li><a href="multiple-comparison.html#sequential-testing-using-gatekeeping-methods" id="toc-sequential-testing-using-gatekeeping-methods"><span class="toc-section-number">10.8.8</span> Sequential Testing Using Gatekeeping Methods</a></li>
</ul></li>
<li><a href="multiple-comparison.html#closed-testing-of-pairwise-comparisons-and-general-contrasts" id="toc-closed-testing-of-pairwise-comparisons-and-general-contrasts"><span class="toc-section-number">10.9</span> Closed Testing of Pairwise Comparisons and General Contrasts</a>
<ul>
<li><a href="multiple-comparison.html#incorporating-logical-constraints" id="toc-incorporating-logical-constraints"><span class="toc-section-number">10.9.1</span> Incorporating Logical Constraints</a></li>
<li><a href="multiple-comparison.html#shaffers-method" id="toc-shaffers-method"><span class="toc-section-number">10.9.2</span> Shaffer’s Method</a></li>
<li><a href="multiple-comparison.html#extended-shaffer-royen-method" id="toc-extended-shaffer-royen-method"><span class="toc-section-number">10.9.3</span> Extended Shaffer-Royen Method</a></li>
<li><a href="multiple-comparison.html#step-down-dunnett-test" id="toc-step-down-dunnett-test"><span class="toc-section-number">10.9.4</span> Step-down Dunnett test</a></li>
</ul></li>
<li><a href="multiple-comparison.html#multiple-comparisons-with-binary-data" id="toc-multiple-comparisons-with-binary-data"><span class="toc-section-number">10.10</span> Multiple Comparisons with Binary Data</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">10.10.1</span> Introduction</a></li>
<li><a href="multiple-comparison.html#multivariate-two-sample-binary-outcomes" id="toc-multivariate-two-sample-binary-outcomes"><span class="toc-section-number">10.10.2</span> Multivariate Two-Sample Binary Outcomes</a></li>
</ul></li>
</ul></li>
<li><a href="correlation-and-regression.html#correlation-and-regression" id="toc-correlation-and-regression"><span class="toc-section-number">11</span> Correlation and Regression</a>
<ul>
<li><a href="sample-size-calculation.html#correlation" id="toc-correlation"><span class="toc-section-number">11.1</span> Correlation</a>
<ul>
<li><a href="correlation-and-regression.html#pearson-correlation-coefficient" id="toc-pearson-correlation-coefficient"><span class="toc-section-number">11.1.1</span> Pearson correlation coefficient</a></li>
<li><a href="correlation-and-regression.html#spearmans-rank-correlation-coefficient" id="toc-spearmans-rank-correlation-coefficient"><span class="toc-section-number">11.1.2</span> Spearman’s rank correlation coefficient</a></li>
<li><a href="correlation-and-regression.html#kendall-rank-correlation-coefficient" id="toc-kendall-rank-correlation-coefficient"><span class="toc-section-number">11.1.3</span> Kendall rank correlation coefficient</a></li>
<li><a href="correlation-and-regression.html#intraclass-correlation" id="toc-intraclass-correlation"><span class="toc-section-number">11.1.4</span> Intraclass correlation</a></li>
<li><a href="correlation-and-regression.html#visualize-the-correlation-in-r" id="toc-visualize-the-correlation-in-r"><span class="toc-section-number">11.1.5</span> Visualize the correlation in R</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#ordinary-least-squares-ols" id="toc-ordinary-least-squares-ols"><span class="toc-section-number">11.2</span> Ordinary least squares (OLS)</a>
<ul>
<li><a href="correlation-and-regression.html#assumpions" id="toc-assumpions"><span class="toc-section-number">11.2.1</span> Assumpions</a></li>
<li><a href="correlation-and-regression.html#interpretation" id="toc-interpretation"><span class="toc-section-number">11.2.2</span> Interpretation</a></li>
<li><a href="correlation-and-regression.html#matrix-solution" id="toc-matrix-solution"><span class="toc-section-number">11.2.3</span> Matrix Solution</a></li>
<li><a href="correlation-and-regression.html#gauss-markov-theorem" id="toc-gauss-markov-theorem"><span class="toc-section-number">11.2.4</span> Gauss-Markov Theorem</a></li>
<li><a href="correlation-and-regression.html#limitation" id="toc-limitation"><span class="toc-section-number">11.2.5</span> limitation</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#model-statistics" id="toc-model-statistics"><span class="toc-section-number">11.3</span> Model Statistics</a>
<ul>
<li><a href="correlation-and-regression.html#residuals-standard-error" id="toc-residuals-standard-error"><span class="toc-section-number">11.3.1</span> Residuals Standard Error</a></li>
<li><a href="correlation-and-regression.html#r-squared-and-adjusted-r-squared" id="toc-r-squared-and-adjusted-r-squared"><span class="toc-section-number">11.3.2</span> R-Squared and Adjusted R-Squared</a></li>
<li><a href="correlation-and-regression.html#t-statistic" id="toc-t-statistic"><span class="toc-section-number">11.3.3</span> T Statistic</a></li>
<li><a href="correlation-and-regression.html#f-statistic" id="toc-f-statistic"><span class="toc-section-number">11.3.4</span> F Statistic</a></li>
<li><a href="correlation-and-regression.html#confidence-intervals" id="toc-confidence-intervals"><span class="toc-section-number">11.3.5</span> Confidence Intervals</a></li>
<li><a href="correlation-and-regression.html#likelihood-ratio-test" id="toc-likelihood-ratio-test"><span class="toc-section-number">11.3.6</span> Likelihood-ratio test</a></li>
<li><a href="correlation-and-regression.html#accuracy" id="toc-accuracy"><span class="toc-section-number">11.3.7</span> Accuracy</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#model-diagnostics" id="toc-model-diagnostics"><span class="toc-section-number">11.4</span> Model Diagnostics</a>
<ul>
<li><a href="correlation-and-regression.html#checking-error-assumptions" id="toc-checking-error-assumptions"><span class="toc-section-number">11.4.1</span> Checking Error Assumptions</a></li>
<li><a href="correlation-and-regression.html#finding-unusual-observations" id="toc-finding-unusual-observations"><span class="toc-section-number">11.4.2</span> Finding Unusual Observations</a></li>
<li><a href="correlation-and-regression.html#checking-the-structure-of-the-model" id="toc-checking-the-structure-of-the-model"><span class="toc-section-number">11.4.3</span> Checking the Structure of the Model</a></li>
</ul></li>
<li><a href="correlation-and-regression.html#sas-implementation-proc-reg" id="toc-sas-implementation-proc-reg"><span class="toc-section-number">11.5</span> SAS implementation Proc Reg</a>
<ul>
<li><a href="correlation-and-regression.html#options" id="toc-options"><span class="toc-section-number">11.5.1</span> Options</a></li>
<li><a href="correlation-and-regression.html#diagnose" id="toc-diagnose"><span class="toc-section-number">11.5.2</span> Diagnose</a></li>
</ul></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">11.6</span> R implementation</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#advanced-linear-regression" id="toc-advanced-linear-regression"><span class="toc-section-number">12</span> Advanced Linear Regression</a>
<ul>
<li><a href="advanced-linear-regression.html#model-selection" id="toc-model-selection"><span class="toc-section-number">12.1</span> Model Selection</a>
<ul>
<li><a href="advanced-linear-regression.html#selection-methods" id="toc-selection-methods"><span class="toc-section-number">12.1.1</span> Selection Methods</a></li>
<li><a href="advanced-linear-regression.html#selection-criteria" id="toc-selection-criteria"><span class="toc-section-number">12.1.2</span> Selection Criteria</a></li>
<li><a href="advanced-linear-regression.html#k--fold-cross-validation" id="toc-k--fold-cross-validation"><span class="toc-section-number">12.1.3</span> k- Fold Cross validation</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#practical-difficulties-using-ols" id="toc-practical-difficulties-using-ols"><span class="toc-section-number">12.2</span> Practical Difficulties using OLS</a></li>
<li><a href="advanced-linear-regression.html#skewness" id="toc-skewness"><span class="toc-section-number">12.3</span> Skewness</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">12.3.1</span> Introduction</a></li>
<li><a href="advanced-linear-regression.html#baisc-transformation" id="toc-baisc-transformation"><span class="toc-section-number">12.3.2</span> Baisc Transformation</a></li>
<li><a href="advanced-linear-regression.html#box-cox-power-transformation" id="toc-box-cox-power-transformation"><span class="toc-section-number">12.3.3</span> Box-Cox Power Transformation</a></li>
</ul></li>
<li><a href="ggplot2.html#scale" id="toc-scale"><span class="toc-section-number">12.4</span> Scale</a></li>
<li><a href="advanced-linear-regression.html#interaction" id="toc-interaction"><span class="toc-section-number">12.5</span> Interaction</a>
<ul>
<li><a href="advanced-linear-regression.html#simple-slopes-analysis" id="toc-simple-slopes-analysis"><span class="toc-section-number">12.5.1</span> Simple slopes analysis</a></li>
<li><a href="advanced-linear-regression.html#plotting-interactions" id="toc-plotting-interactions"><span class="toc-section-number">12.5.2</span> Plotting Interactions</a></li>
<li><a href="advanced-linear-regression.html#check-linearity-assumption" id="toc-check-linearity-assumption"><span class="toc-section-number">12.5.3</span> Check linearity assumption</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#collinearity" id="toc-collinearity"><span class="toc-section-number">12.6</span> Collinearity</a></li>
<li><a href="advanced-linear-regression.html#problems-with-the-error" id="toc-problems-with-the-error"><span class="toc-section-number">12.7</span> Problems with the Error</a>
<ul>
<li><a href="advanced-linear-regression.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">12.7.1</span> Generalized Least Squares</a></li>
<li><a href="advanced-linear-regression.html#weighted-least-squares" id="toc-weighted-least-squares"><span class="toc-section-number">12.7.2</span> Weighted Least Squares</a></li>
<li><a href="advanced-linear-regression.html#robust-regression" id="toc-robust-regression"><span class="toc-section-number">12.7.3</span> Robust Regression</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#shrinkage-methods" id="toc-shrinkage-methods"><span class="toc-section-number">12.8</span> Shrinkage Methods</a>
<ul>
<li><a href="advanced-linear-regression.html#principal-components-analzsis" id="toc-principal-components-analzsis"><span class="toc-section-number">12.8.1</span> Principal Components Analzsis</a></li>
<li><a href="advanced-linear-regression.html#partial-least-squares" id="toc-partial-least-squares"><span class="toc-section-number">12.8.2</span> Partial Least Squares</a></li>
<li><a href="advanced-linear-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">12.8.3</span> Ridge Regression</a></li>
</ul></li>
</ul></li>
<li><a href="logistic-regression.html#logistic-regression" id="toc-logistic-regression"><span class="toc-section-number">13</span> Logistic Regression</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">13.1</span> Introduction</a>
<ul>
<li><a href="logistic-regression.html#violation-of-assumptions-of-ordinary-least-squares-ols" id="toc-violation-of-assumptions-of-ordinary-least-squares-ols"><span class="toc-section-number">13.1.1</span> Violation of assumptions of Ordinary least squares (OLS)</a></li>
<li><a href="logistic-regression.html#more-fundamental-problem-outside-01" id="toc-more-fundamental-problem-outside-01"><span class="toc-section-number">13.1.2</span> More fundamental problem outside [0,1]</a></li>
<li><a href="logistic-regression.html#logistic-regression-model" id="toc-logistic-regression-model"><span class="toc-section-number">13.1.3</span> Logistic Regression Model</a></li>
<li><a href="logistic-regression.html#estimation-of-the-logistic-model" id="toc-estimation-of-the-logistic-model"><span class="toc-section-number">13.1.4</span> Estimation of the Logistic Model</a></li>
<li><a href="logistic-regression.html#convergence-problems" id="toc-convergence-problems"><span class="toc-section-number">13.1.5</span> Convergence Problems</a></li>
<li><a href="logistic-regression.html#use-exact-methods." id="toc-use-exact-methods."><span class="toc-section-number">13.1.6</span> Use exact methods.</a></li>
<li><a href="logistic-regression.html#use-penalized-likelihood" id="toc-use-penalized-likelihood"><span class="toc-section-number">13.1.7</span> Use penalized likelihood</a></li>
</ul></li>
<li><a href="logistic-regression.html#logit-modell" id="toc-logit-modell"><span class="toc-section-number">13.2</span> Logit Modell</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">13.2.1</span> Introduction</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">13.2.2</span> R Implementation</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">13.2.3</span> SAS Implementation</a></li>
<li><a href="logistic-regression.html#multicollinearity" id="toc-multicollinearity"><span class="toc-section-number">13.2.4</span> Multicollinearity</a></li>
<li><a href="logistic-regression.html#goodness-of-fit-statistics-pearson-deviance" id="toc-goodness-of-fit-statistics-pearson-deviance"><span class="toc-section-number">13.2.5</span> Goodness-of-Fit Statistics Pearson deviance</a></li>
<li><a href="logistic-regression.html#hosmer-and-lemeshow-goodness-of-fit-test" id="toc-hosmer-and-lemeshow-goodness-of-fit-test"><span class="toc-section-number">13.2.6</span> Hosmer and Lemeshow Goodness-of-Fit Test</a></li>
<li><a href="logistic-regression.html#statistics-measuring-predictive-power-r2" id="toc-statistics-measuring-predictive-power-r2"><span class="toc-section-number">13.2.7</span> Statistics Measuring Predictive Power <span class="math inline">\(R^2\)</span></a></li>
<li><a href="logistic-regression.html#roc-curves" id="toc-roc-curves"><span class="toc-section-number">13.2.8</span> ROC Curves</a></li>
<li><a href="logistic-regression.html#predicted-values-residuals-and-influence-statistics" id="toc-predicted-values-residuals-and-influence-statistics"><span class="toc-section-number">13.2.9</span> Predicted Values, Residuals, and Influence Statistics</a></li>
<li><a href="logistic-regression.html#unobserved-heterogeneity" id="toc-unobserved-heterogeneity"><span class="toc-section-number">13.2.10</span> Unobserved Heterogeneity</a></li>
</ul></li>
<li><a href="logistic-regression.html#illustration-in-sas" id="toc-illustration-in-sas"><span class="toc-section-number">13.3</span> Illustration in SAS</a>
<ul>
<li><a href="logistic-regression.html#effects-of-predictor-variables" id="toc-effects-of-predictor-variables"><span class="toc-section-number">13.3.1</span> Effects of Predictor Variables</a></li>
<li><a href="logistic-regression.html#odds-ratio-plot" id="toc-odds-ratio-plot"><span class="toc-section-number">13.3.2</span> Odds ratio plot</a></li>
</ul></li>
<li><a href="logistic-regression.html#probit-modell" id="toc-probit-modell"><span class="toc-section-number">13.4</span> Probit Modell</a>
<ul>
<li><a href="logistic-regression.html#introduction-2" id="toc-introduction-2"><span class="toc-section-number">13.4.1</span> Introduction</a></li>
<li><a href="logistic-regression.html#r-implemetation" id="toc-r-implemetation"><span class="toc-section-number">13.4.2</span> R Implemetation</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">13.4.3</span> SAS Implementation</a></li>
</ul></li>
<li><a href="logistic-regression.html#complementary-log-log-modell" id="toc-complementary-log-log-modell"><span class="toc-section-number">13.5</span> Complementary log-log-Modell</a>
<ul>
<li><a href="logistic-regression.html#r-implemetation-1" id="toc-r-implemetation-1"><span class="toc-section-number">13.5.1</span> R Implemetation</a></li>
</ul></li>
<li><a href="logistic-regression.html#multicategory-logit-models" id="toc-multicategory-logit-models"><span class="toc-section-number">13.6</span> Multicategory Logit Models</a>
<ul>
<li><a href="logistic-regression.html#multinomialverteilung" id="toc-multinomialverteilung"><span class="toc-section-number">13.6.1</span> Multinomialverteilung</a></li>
<li><a href="logistic-regression.html#nominal-response" id="toc-nominal-response"><span class="toc-section-number">13.6.2</span> Nominal Response</a></li>
<li><a href="logistic-regression.html#ordinal-response-cumulative-logit-model" id="toc-ordinal-response-cumulative-logit-model"><span class="toc-section-number">13.6.3</span> Ordinal Response: Cumulative Logit Model</a></li>
</ul></li>
<li><a href="logistic-regression.html#adjacent-categories-model" id="toc-adjacent-categories-model"><span class="toc-section-number">13.7</span> Adjacent Categories Model</a></li>
<li><a href="logistic-regression.html#continuation-ratio-model" id="toc-continuation-ratio-model"><span class="toc-section-number">13.8</span> Continuation Ratio Model</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#advanced-logistic-regression" id="toc-advanced-logistic-regression"><span class="toc-section-number">14</span> Advanced Logistic Regression</a>
<ul>
<li><a href="advanced-logistic-regression.html#logit-analysis-of-contingency-tables" id="toc-logit-analysis-of-contingency-tables"><span class="toc-section-number">14.1</span> Logit Analysis of Contingency Tables</a>
<ul>
<li><a href="advanced-logistic-regression.html#two-way-table" id="toc-two-way-table"><span class="toc-section-number">14.1.1</span> Two-Way Table</a></li>
<li><a href="advanced-logistic-regression.html#three-way-table" id="toc-three-way-table"><span class="toc-section-number">14.1.2</span> Three-Way Table</a></li>
<li><a href="advanced-logistic-regression.html#four-way-table" id="toc-four-way-table"><span class="toc-section-number">14.1.3</span> Four-Way Table</a></li>
<li><a href="advanced-logistic-regression.html#overdispersion" id="toc-overdispersion"><span class="toc-section-number">14.1.4</span> Overdispersion</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#loglinear-analysis-of-contingency-tables" id="toc-loglinear-analysis-of-contingency-tables"><span class="toc-section-number">14.2</span> Loglinear Analysis of Contingency Tables</a>
<ul>
<li><a href="advanced-logistic-regression.html#two-way-table-1" id="toc-two-way-table-1"><span class="toc-section-number">14.2.1</span> Two-way Table</a></li>
<li><a href="advanced-logistic-regression.html#problem-of-zeros" id="toc-problem-of-zeros"><span class="toc-section-number">14.2.2</span> Problem of Zeros</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#discrete-choice-analysis" id="toc-discrete-choice-analysis"><span class="toc-section-number">14.3</span> Discrete Choice Analysis</a>
<ul>
<li><a href="advanced-logistic-regression.html#logistic-strata" id="toc-logistic-strata"><span class="toc-section-number">14.3.1</span> Logistic Strata</a></li>
<li><a href="advanced-logistic-regression.html#conditional-logit-model" id="toc-conditional-logit-model"><span class="toc-section-number">14.3.2</span> Conditional logit model</a></li>
<li><a href="advanced-logistic-regression.html#ranked-data" id="toc-ranked-data"><span class="toc-section-number">14.3.3</span> Ranked Data</a></li>
<li><a href="advanced-logistic-regression.html#heteroscedastic-extreme-value-hev-model" id="toc-heteroscedastic-extreme-value-hev-model"><span class="toc-section-number">14.3.4</span> Heteroscedastic extreme value (HEV) Model</a></li>
<li><a href="advanced-logistic-regression.html#nested-logit-model" id="toc-nested-logit-model"><span class="toc-section-number">14.3.5</span> Nested logit model</a></li>
</ul></li>
<li><a href="advanced-logistic-regression.html#longitudinal-and-other-clustered-data" id="toc-longitudinal-and-other-clustered-data"><span class="toc-section-number">14.4</span> Longitudinal and Other Clustered Data</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">14.4.1</span> Introduction</a></li>
<li><a href="advanced-logistic-regression.html#robust-standard-errors" id="toc-robust-standard-errors"><span class="toc-section-number">14.4.2</span> Robust Standard Errors</a></li>
<li><a href="advanced-logistic-regression.html#gee-estimation-with-proc-genmod" id="toc-gee-estimation-with-proc-genmod"><span class="toc-section-number">14.4.3</span> GEE Estimation with PROC GENMOD</a></li>
<li><a href="advanced-logistic-regression.html#mixed-models-with-proc-glimmix" id="toc-mixed-models-with-proc-glimmix"><span class="toc-section-number">14.4.4</span> Mixed Models with PROC GLIMMIX</a></li>
<li><a href="advanced-logistic-regression.html#fixed-effects-with-conditional-logistic-regression" id="toc-fixed-effects-with-conditional-logistic-regression"><span class="toc-section-number">14.4.5</span> Fixed-Effects with Conditional Logistic Regression</a></li>
<li><a href="advanced-logistic-regression.html#hybrid-method" id="toc-hybrid-method"><span class="toc-section-number">14.4.6</span> Hybrid Method</a></li>
</ul></li>
</ul></li>
<li><a href="count-data-regression.html#count-data-regression" id="toc-count-data-regression"><span class="toc-section-number">15</span> Count Data Regression</a>
<ul>
<li><a href="count-data-regression.html#introduction-of-count-data-regression" id="toc-introduction-of-count-data-regression"><span class="toc-section-number">15.1</span> Introduction of Count Data Regression</a></li>
<li><a href="count-data-regression.html#poisson-regression" id="toc-poisson-regression"><span class="toc-section-number">15.2</span> Poisson regression</a>
<ul>
<li><a href="count-data-regression.html#model" id="toc-model"><span class="toc-section-number">15.2.1</span> Model</a></li>
<li><a href="count-data-regression.html#interpretation-of-estimated-coefficients" id="toc-interpretation-of-estimated-coefficients"><span class="toc-section-number">15.2.2</span> Interpretation of Estimated Coefficients</a></li>
<li><a href="advanced-logistic-regression.html#overdispersion" id="toc-overdispersion"><span class="toc-section-number">15.2.3</span> Overdispersion</a></li>
<li><a href="count-data-regression.html#adjustment-for-varying-time-spans" id="toc-adjustment-for-varying-time-spans"><span class="toc-section-number">15.2.4</span> Adjustment for Varying Time Spans</a></li>
<li><a href="count-data-regression.html#sas-implementation-using-proc-genmod" id="toc-sas-implementation-using-proc-genmod"><span class="toc-section-number">15.2.5</span> SAS implementation using PROC GENMOD</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">15.2.6</span> R implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#negative-binomial-regression" id="toc-negative-binomial-regression"><span class="toc-section-number">15.3</span> Negative Binomial Regression</a>
<ul>
<li><a href="count-data-regression.html#model-1" id="toc-model-1"><span class="toc-section-number">15.3.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">15.3.2</span> SAS implementation</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">15.3.3</span> R implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#zero-truncated-poisson-regression-model" id="toc-zero-truncated-poisson-regression-model"><span class="toc-section-number">15.4</span> Zero-truncated Poisson Regression Model</a>
<ul>
<li><a href="count-data-regression.html#model-2" id="toc-model-2"><span class="toc-section-number">15.4.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">15.4.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-2" id="toc-r-implementation-2"><span class="toc-section-number">15.4.3</span> R implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#zero-insflated-model" id="toc-zero-insflated-model"><span class="toc-section-number">15.5</span> Zero-Insflated Model</a>
<ul>
<li><a href="count-data-regression.html#model-3" id="toc-model-3"><span class="toc-section-number">15.5.1</span> Model</a></li>
<li><a href="count-data-regression.html#interpretation-of-estimated-coefficients-1" id="toc-interpretation-of-estimated-coefficients-1"><span class="toc-section-number">15.5.2</span> Interpretation of Estimated Coefficients</a></li>
<li><a href="parametric-test.html#sas-implementation-2" id="toc-sas-implementation-2"><span class="toc-section-number">15.5.3</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-3" id="toc-r-implementation-3"><span class="toc-section-number">15.5.4</span> R Implementation</a></li>
</ul></li>
<li><a href="count-data-regression.html#hurdle-models" id="toc-hurdle-models"><span class="toc-section-number">15.6</span> Hurdle models</a>
<ul>
<li><a href="count-data-regression.html#model-4" id="toc-model-4"><span class="toc-section-number">15.6.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation-3" id="toc-sas-implementation-3"><span class="toc-section-number">15.6.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-4" id="toc-r-implementation-4"><span class="toc-section-number">15.6.3</span> R Implementation</a></li>
</ul></li>
</ul></li>
<li><a href="proportion-response-regression.html#proportion-response-regression" id="toc-proportion-response-regression"><span class="toc-section-number">16</span> Proportion Response Regression</a>
<ul>
<li><a href="proportion-response-regression.html#beta-regression" id="toc-beta-regression"><span class="toc-section-number">16.1</span> Beta Regression</a>
<ul>
<li><a href="count-data-regression.html#model" id="toc-model"><span class="toc-section-number">16.1.1</span> Model</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">16.1.2</span> SAS Implementation</a></li>
<li><a href="proportion-response-regression.html#r-implementation-betareg" id="toc-r-implementation-betareg"><span class="toc-section-number">16.1.3</span> R Implementation “betareg”</a></li>
</ul></li>
<li><a href="proportion-response-regression.html#zero-inflated-beta-regression" id="toc-zero-inflated-beta-regression"><span class="toc-section-number">16.2</span> Zero-inflated Beta Regression</a></li>
<li><a href="proportion-response-regression.html#one-inflated-beta-regression" id="toc-one-inflated-beta-regression"><span class="toc-section-number">16.3</span> One-inflated Beta Regression</a></li>
<li><a href="proportion-response-regression.html#zero-one-inflated-beta-regression" id="toc-zero-one-inflated-beta-regression"><span class="toc-section-number">16.4</span> Zero-one-inflated Beta Regression</a></li>
</ul></li>
<li><a href="survival-analysis.html#survival-analysis" id="toc-survival-analysis"><span class="toc-section-number">17</span> Survival Analysis</a>
<ul>
<li><a href="survival-analysis.html#preliminary" id="toc-preliminary"><span class="toc-section-number">17.1</span> Preliminary</a>
<ul>
<li><a href="survival-analysis.html#probability-density-function" id="toc-probability-density-function"><span class="toc-section-number">17.1.1</span> Probability density function</a></li>
<li><a href="survival-analysis.html#cumulative-distribution-function" id="toc-cumulative-distribution-function"><span class="toc-section-number">17.1.2</span> Cumulative distribution function</a></li>
<li><a href="survival-analysis.html#survival-function" id="toc-survival-function"><span class="toc-section-number">17.1.3</span> Survival function</a></li>
<li><a href="survival-analysis.html#hazard-function" id="toc-hazard-function"><span class="toc-section-number">17.1.4</span> Hazard function</a></li>
<li><a href="survival-analysis.html#cumulative-hazard-function" id="toc-cumulative-hazard-function"><span class="toc-section-number">17.1.5</span> Cumulative hazard function</a></li>
<li><a href="survival-analysis.html#mean-residual-life" id="toc-mean-residual-life"><span class="toc-section-number">17.1.6</span> Mean Residual Life</a></li>
<li><a href="survival-analysis.html#relation-between-functions" id="toc-relation-between-functions"><span class="toc-section-number">17.1.7</span> Relation between functions</a></li>
</ul></li>
<li><a href="survival-analysis.html#kaplan-meier-estimator" id="toc-kaplan-meier-estimator"><span class="toc-section-number">17.2</span> Kaplan-Meier estimator</a>
<ul>
<li><a href="survival-analysis.html#km-introduction" id="toc-km-introduction"><span class="toc-section-number">17.2.1</span> KM Introduction</a></li>
<li><a href="survival-analysis.html#nelson-aalen-estimator-of-the-cumulative-hazard-function" id="toc-nelson-aalen-estimator-of-the-cumulative-hazard-function"><span class="toc-section-number">17.2.2</span> Nelson-Aalen estimator of the cumulative hazard function</a></li>
<li><a href="survival-analysis.html#survival-curve-in-sas" id="toc-survival-curve-in-sas"><span class="toc-section-number">17.2.3</span> Survival curve in SAS</a></li>
<li><a href="survival-analysis.html#km-survival-plots-in-sas" id="toc-km-survival-plots-in-sas"><span class="toc-section-number">17.2.4</span> KM Survival Plots in SAS</a></li>
<li><a href="survival-analysis.html#convert-personal-level-to-personal-period-in-r" id="toc-convert-personal-level-to-personal-period-in-r"><span class="toc-section-number">17.2.5</span> Convert Personal-level to Personal-period in R</a></li>
<li><a href="survival-analysis.html#package-survfit-in-r" id="toc-package-survfit-in-r"><span class="toc-section-number">17.2.6</span> Package survfit in R</a></li>
<li><a href="survival-analysis.html#km-survival-plots-in-r" id="toc-km-survival-plots-in-r"><span class="toc-section-number">17.2.7</span> KM Survival Plots in R</a></li>
</ul></li>
<li><a href="survival-analysis.html#compare-the-survival-function" id="toc-compare-the-survival-function"><span class="toc-section-number">17.3</span> Compare the survival function</a>
<ul>
<li><a href="survival-analysis.html#tests-of-equality-of-the-survival-function" id="toc-tests-of-equality-of-the-survival-function"><span class="toc-section-number">17.3.1</span> Tests of equality of the survival function</a></li>
<li><a href="survival-analysis.html#other-nonparametric-tests-for-strata-statement" id="toc-other-nonparametric-tests-for-strata-statement"><span class="toc-section-number">17.3.2</span> Other nonparametric tests for STRATA statement</a></li>
<li><a href="survival-analysis.html#multiple-comparisons" id="toc-multiple-comparisons"><span class="toc-section-number">17.3.3</span> Multiple comparisons</a></li>
<li><a href="survival-analysis.html#comparing-survival-functions-using-log-rank-hr" id="toc-comparing-survival-functions-using-log-rank-hr"><span class="toc-section-number">17.3.4</span> Comparing survival functions using Log-Rank HR</a></li>
<li><a href="survival-analysis.html#mantel-haenszel-hr" id="toc-mantel-haenszel-hr"><span class="toc-section-number">17.3.5</span> Mantel-Haenszel HR</a></li>
<li><a href="survival-analysis.html#analysis-of-covariance-adjustment" id="toc-analysis-of-covariance-adjustment"><span class="toc-section-number">17.3.6</span> Analysis-of-covariance (Adjustment)</a></li>
</ul></li>
<li><a href="survival-analysis.html#accelerated-failure-time-aft-model" id="toc-accelerated-failure-time-aft-model"><span class="toc-section-number">17.4</span> Accelerated failure time (AFT) model</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">17.4.1</span> Introduction</a></li>
<li><a href="survival-analysis.html#proc-lifereg" id="toc-proc-lifereg"><span class="toc-section-number">17.4.2</span> PROC LIFEREG</a></li>
<li><a href="survival-analysis.html#residuum-distribution" id="toc-residuum-distribution"><span class="toc-section-number">17.4.3</span> Residuum distribution</a></li>
<li><a href="survival-analysis.html#exponential-model" id="toc-exponential-model"><span class="toc-section-number">17.4.4</span> Exponential Model</a></li>
<li><a href="survival-analysis.html#weibull-model" id="toc-weibull-model"><span class="toc-section-number">17.4.5</span> Weibull Model</a></li>
<li><a href="survival-analysis.html#log-normal-model" id="toc-log-normal-model"><span class="toc-section-number">17.4.6</span> Log-Normal Model</a></li>
<li><a href="survival-analysis.html#log-logistic-model" id="toc-log-logistic-model"><span class="toc-section-number">17.4.7</span> Log-Logistic Model</a></li>
<li><a href="survival-analysis.html#fit-statistics-for-model-comparsion" id="toc-fit-statistics-for-model-comparsion"><span class="toc-section-number">17.4.8</span> Fit statistics for model comparsion</a></li>
<li><a href="survival-analysis.html#graphical-method-for-distinguishing-different-distributions-in-sas" id="toc-graphical-method-for-distinguishing-different-distributions-in-sas"><span class="toc-section-number">17.4.9</span> Graphical method for distinguishing different distributions in SAS</a></li>
<li><a href="survival-analysis.html#prediction-and-hazard-function" id="toc-prediction-and-hazard-function"><span class="toc-section-number">17.4.10</span> Prediction and hazard function</a></li>
<li><a href="survival-analysis.html#left-censoring-and-interval-censoring" id="toc-left-censoring-and-interval-censoring"><span class="toc-section-number">17.4.11</span> Left Censoring and Interval Censoring</a></li>
</ul></li>
<li><a href="survival-analysis.html#cox-proportional-hazards-model" id="toc-cox-proportional-hazards-model"><span class="toc-section-number">17.5</span> Cox Proportional Hazards Model</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">17.5.1</span> Introduction</a></li>
<li><a href="survival-analysis.html#parameter-estimate" id="toc-parameter-estimate"><span class="toc-section-number">17.5.2</span> Parameter estimate</a></li>
<li><a href="survival-analysis.html#parameter-test" id="toc-parameter-test"><span class="toc-section-number">17.5.3</span> Parameter test</a></li>
<li><a href="survival-analysis.html#graphs-of-the-survival-and-baseline-hazard-function-in-sas" id="toc-graphs-of-the-survival-and-baseline-hazard-function-in-sas"><span class="toc-section-number">17.5.4</span> Graphs of the survival and baseline hazard function in SAS</a></li>
<li><a href="survival-analysis.html#check-proportional-hazards" id="toc-check-proportional-hazards"><span class="toc-section-number">17.5.5</span> Check proportional hazards</a></li>
<li><a href="survival-analysis.html#dealing-with-nonproportionality" id="toc-dealing-with-nonproportionality"><span class="toc-section-number">17.5.6</span> Dealing with nonproportionality</a></li>
<li><a href="correlation-and-regression.html#model-diagnostics" id="toc-model-diagnostics"><span class="toc-section-number">17.5.7</span> Model Diagnostics</a></li>
</ul></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#advanced-survival-analysis" id="toc-advanced-survival-analysis"><span class="toc-section-number">18</span> Advanced Survival Analysis</a>
<ul>
<li><a href="advanced-survival-analysis.html#tied-or-discrete-data" id="toc-tied-or-discrete-data"><span class="toc-section-number">18.1</span> Tied or Discrete Data</a>
<ul>
<li><a href="advanced-survival-analysis.html#introduction-of-tie" id="toc-introduction-of-tie"><span class="toc-section-number">18.1.1</span> Introduction of Tie</a></li>
<li><a href="advanced-survival-analysis.html#discrete-time" id="toc-discrete-time"><span class="toc-section-number">18.1.2</span> Discrete time</a></li>
<li><a href="advanced-survival-analysis.html#notation-and-definitions" id="toc-notation-and-definitions"><span class="toc-section-number">18.1.3</span> Notation and Definitions</a></li>
<li><a href="advanced-survival-analysis.html#discrete-cox-regression" id="toc-discrete-cox-regression"><span class="toc-section-number">18.1.4</span> Discrete Cox Regression</a></li>
<li><a href="advanced-survival-analysis.html#discrete-time-regression-models" id="toc-discrete-time-regression-models"><span class="toc-section-number">18.1.5</span> Discrete-Time Regression Models</a></li>
<li><a href="advanced-survival-analysis.html#the-glm-framework-and-person-period-data" id="toc-the-glm-framework-and-person-period-data"><span class="toc-section-number">18.1.6</span> The GLM Framework and Person-Period Data</a></li>
<li><a href="advanced-survival-analysis.html#discrete-time-survival-analysis-in-r" id="toc-discrete-time-survival-analysis-in-r"><span class="toc-section-number">18.1.7</span> Discrete-Time Survival Analysis in R</a></li>
<li><a href="advanced-survival-analysis.html#discrete-cause-specific-hazards-model" id="toc-discrete-cause-specific-hazards-model"><span class="toc-section-number">18.1.8</span> Discrete Cause-Specific Hazards Model</a></li>
<li><a href="advanced-survival-analysis.html#discrete-subdistribution-hazard-model" id="toc-discrete-subdistribution-hazard-model"><span class="toc-section-number">18.1.9</span> Discrete Subdistribution Hazard Model</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#time-dependent-covariates" id="toc-time-dependent-covariates"><span class="toc-section-number">18.2</span> Time-dependent covariates</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">18.2.1</span> Introduction</a></li>
<li><a href="advanced-survival-analysis.html#programming-method" id="toc-programming-method"><span class="toc-section-number">18.2.2</span> Programming method</a></li>
<li><a href="advanced-survival-analysis.html#counting-method" id="toc-counting-method"><span class="toc-section-number">18.2.3</span> Counting method</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#additive-hazards-regression-model" id="toc-additive-hazards-regression-model"><span class="toc-section-number">18.3</span> Additive Hazards Regression Model</a>
<ul>
<li><a href="advanced-survival-analysis.html#preview" id="toc-preview"><span class="toc-section-number">18.3.1</span> Preview</a></li>
<li><a href="advanced-survival-analysis.html#lin-and-yings-additive-hazards-model" id="toc-lin-and-yings-additive-hazards-model"><span class="toc-section-number">18.3.2</span> Lin and Ying’s additive hazards model</a></li>
<li><a href="advanced-survival-analysis.html#aalens-additive-hazards-model" id="toc-aalens-additive-hazards-model"><span class="toc-section-number">18.3.3</span> Aalen’s Additive Hazards Model</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#competing-risk" id="toc-competing-risk"><span class="toc-section-number">18.4</span> Competing Risk</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">18.4.1</span> Introduction</a></li>
<li><a href="advanced-survival-analysis.html#type-specific-hazards" id="toc-type-specific-hazards"><span class="toc-section-number">18.4.2</span> Type-specific hazards</a></li>
<li><a href="advanced-survival-analysis.html#covariate-effects-via-cox-model" id="toc-covariate-effects-via-cox-model"><span class="toc-section-number">18.4.3</span> Covariate effects via COX model</a></li>
<li><a href="advanced-survival-analysis.html#cumulative-incidence-function-cif" id="toc-cumulative-incidence-function-cif"><span class="toc-section-number">18.4.4</span> Cumulative incidence function (CIF)</a></li>
<li><a href="advanced-survival-analysis.html#subdistribution-hazard-function" id="toc-subdistribution-hazard-function"><span class="toc-section-number">18.4.5</span> Subdistribution hazard function</a></li>
<li><a href="advanced-survival-analysis.html#cause-specific-hazard-function" id="toc-cause-specific-hazard-function"><span class="toc-section-number">18.4.6</span> Cause-specific hazard function</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#clustered-events" id="toc-clustered-events"><span class="toc-section-number">18.5</span> Clustered Events</a>
<ul>
<li><a href="advanced-survival-analysis.html#introduction-4" id="toc-introduction-4"><span class="toc-section-number">18.5.1</span> Introduction</a></li>
<li><a href="advanced-survival-analysis.html#proportional-hazards-model-which-adopts-a-marginal" id="toc-proportional-hazards-model-which-adopts-a-marginal"><span class="toc-section-number">18.5.2</span> Proportional hazards model which adopts a marginal</a></li>
<li><a href="advanced-survival-analysis.html#frailty-model" id="toc-frailty-model"><span class="toc-section-number">18.5.3</span> Frailty model</a></li>
</ul></li>
<li><a href="advanced-survival-analysis.html#non-proportional-hazards-in-survival-analysis" id="toc-non-proportional-hazards-in-survival-analysis"><span class="toc-section-number">18.6</span> Non-proportional hazards in Survival Analysis</a>
<ul>
<li><a href="advanced-survival-analysis.html#weighted-piecewise-log-rank-test" id="toc-weighted-piecewise-log-rank-test"><span class="toc-section-number">18.6.1</span> Weighted Piecewise Log-Rank Test</a></li>
<li><a href="advanced-survival-analysis.html#restricted-mean-survival-time-difference" id="toc-restricted-mean-survival-time-difference"><span class="toc-section-number">18.6.2</span> Restricted Mean Survival Time Difference</a></li>
<li><a href="advanced-survival-analysis.html#maximum-combination-test" id="toc-maximum-combination-test"><span class="toc-section-number">18.6.3</span> Maximum Combination Test</a></li>
</ul></li>
</ul></li>
<li><a href="mixed-model.html#mixed-model" id="toc-mixed-model"><span class="toc-section-number">19</span> Mixed Model</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">19.1</span> Introduction</a>
<ul>
<li><a href="mixed-model.html#correlated-response-data" id="toc-correlated-response-data"><span class="toc-section-number">19.1.1</span> Correlated response data</a></li>
<li><a href="mixed-model.html#hierarchical-and-marginal-model" id="toc-hierarchical-and-marginal-model"><span class="toc-section-number">19.1.2</span> Hierarchical and Marginal model</a></li>
<li><a href="mixed-model.html#mle-in-marginal-model" id="toc-mle-in-marginal-model"><span class="toc-section-number">19.1.3</span> MLE in Marginal model</a></li>
<li><a href="mixed-model.html#reml-in-marginal-model" id="toc-reml-in-marginal-model"><span class="toc-section-number">19.1.4</span> REML in Marginal model</a></li>
<li><a href="mixed-model.html#variance-correction" id="toc-variance-correction"><span class="toc-section-number">19.1.5</span> Variance correction</a></li>
<li><a href="mixed-model.html#hypothesis-tests" id="toc-hypothesis-tests"><span class="toc-section-number">19.1.6</span> Hypothesis tests</a></li>
<li><a href="mixed-model.html#residual-structure" id="toc-residual-structure"><span class="toc-section-number">19.1.7</span> Residual Structure</a></li>
<li><a href="mixed-model.html#converge-problems" id="toc-converge-problems"><span class="toc-section-number">19.1.8</span> Converge problems</a></li>
<li><a href="mixed-model.html#preface-of-linear-mixed-model" id="toc-preface-of-linear-mixed-model"><span class="toc-section-number">19.1.9</span> Preface of linear mixed model</a></li>
</ul></li>
<li><a href="mixed-model.html#random-slope-and-intercept-model" id="toc-random-slope-and-intercept-model"><span class="toc-section-number">19.2</span> Random Slope and Intercept Model</a>
<ul>
<li><a href="mixed-model.html#model-introduction" id="toc-model-introduction"><span class="toc-section-number">19.2.1</span> Model Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation" id="toc-sas-implementation"><span class="toc-section-number">19.2.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation" id="toc-r-implementation"><span class="toc-section-number">19.2.3</span> R Implementation</a></li>
</ul></li>
<li><a href="mixed-model.html#covariance-structure" id="toc-covariance-structure"><span class="toc-section-number">19.3</span> Covariance Structure</a>
<ul>
<li><a href="mixed-model.html#model-introduction-1" id="toc-model-introduction-1"><span class="toc-section-number">19.3.1</span> Model Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-1" id="toc-sas-implementation-1"><span class="toc-section-number">19.3.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-1" id="toc-r-implementation-1"><span class="toc-section-number">19.3.3</span> R Implementation</a></li>
</ul></li>
<li><a href="mixed-model.html#hierarchical-regression-model-for-normal-response" id="toc-hierarchical-regression-model-for-normal-response"><span class="toc-section-number">19.4</span> Hierarchical Regression Model for Normal Response</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">19.4.1</span> Introduction</a></li>
<li><a href="parametric-test.html#sas-implementation-2" id="toc-sas-implementation-2"><span class="toc-section-number">19.4.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-2" id="toc-r-implementation-2"><span class="toc-section-number">19.4.3</span> R Implementation</a></li>
</ul></li>
<li><a href="mixed-model.html#generalized-estimating-equation" id="toc-generalized-estimating-equation"><span class="toc-section-number">19.5</span> Generalized Estimating Equation</a>
<ul>
<li><a href="mixed-model.html#introduction-of-gee" id="toc-introduction-of-gee"><span class="toc-section-number">19.5.1</span> Introduction of GEE</a></li>
<li><a href="parametric-test.html#sas-implementation-3" id="toc-sas-implementation-3"><span class="toc-section-number">19.5.2</span> SAS Implementation</a></li>
<li><a href="parametric-test.html#r-implementation-3" id="toc-r-implementation-3"><span class="toc-section-number">19.5.3</span> R Implementation</a></li>
</ul></li>
</ul></li>
<li><a href="glmm-and-gam.html#glmm-and-gam" id="toc-glmm-and-gam"><span class="toc-section-number">20</span> GLMM and GAM</a>
<ul>
<li><a href="glmm-and-gam.html#genaralised-linear-model" id="toc-genaralised-linear-model"><span class="toc-section-number">20.1</span> Genaralised linear model</a>
<ul>
<li><a href="glmm-and-gam.html#review" id="toc-review"><span class="toc-section-number">20.1.1</span> Review</a></li>
<li><a href="glmm-and-gam.html#exponential-families" id="toc-exponential-families"><span class="toc-section-number">20.1.2</span> Exponential Families</a></li>
<li><a href="glmm-and-gam.html#testing-linear-hypotheses" id="toc-testing-linear-hypotheses"><span class="toc-section-number">20.1.3</span> Testing linear Hypotheses</a></li>
<li><a href="glmm-and-gam.html#maximum-likelihood-estimation-in-glm" id="toc-maximum-likelihood-estimation-in-glm"><span class="toc-section-number">20.1.4</span> Maximum Likelihood Estimation in GLM</a></li>
<li><a href="glmm-and-gam.html#irls-algorithm-for-estimating-glm" id="toc-irls-algorithm-for-estimating-glm"><span class="toc-section-number">20.1.5</span> IRLS Algorithm for Estimating GLM</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#generalized-linear-mixed-model" id="toc-generalized-linear-mixed-model"><span class="toc-section-number">20.2</span> Generalized Linear Mixed Model</a>
<ul>
<li><a href="glmm-and-gam.html#backgroud" id="toc-backgroud"><span class="toc-section-number">20.2.1</span> Backgroud</a></li>
<li><a href="glmm-and-gam.html#lmm-to-glmm" id="toc-lmm-to-glmm"><span class="toc-section-number">20.2.2</span> LMM to GLMM</a></li>
<li><a href="glmm-and-gam.html#link-functions-and-families" id="toc-link-functions-and-families"><span class="toc-section-number">20.2.3</span> Link Functions and Families</a></li>
<li><a href="glmm-and-gam.html#parameter-estimation" id="toc-parameter-estimation"><span class="toc-section-number">20.2.4</span> Parameter estimation</a></li>
<li><a href="glmm-and-gam.html#logistic-model-with-fixed-and-random-effectss" id="toc-logistic-model-with-fixed-and-random-effectss"><span class="toc-section-number">20.2.5</span> logistic model with fixed and random effectss</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#generalized-additive-models" id="toc-generalized-additive-models"><span class="toc-section-number">20.3</span> Generalized Additive Models</a>
<ul>
<li><a href="glmm-and-gam.html#concept" id="toc-concept"><span class="toc-section-number">20.3.1</span> Concept</a></li>
</ul></li>
</ul></li>
<li><a href="missing-data.html#missing-data" id="toc-missing-data"><span class="toc-section-number">21</span> Missing Data</a>
<ul>
<li><a href="missing-data.html#missing-mechanisms" id="toc-missing-mechanisms"><span class="toc-section-number">21.1</span> Missing mechanisms</a></li>
<li><a href="missing-data.html#compatibility-and-congeniality" id="toc-compatibility-and-congeniality"><span class="toc-section-number">21.2</span> Compatibility and Congeniality</a></li>
<li><a href="missing-data.html#single-imputation" id="toc-single-imputation"><span class="toc-section-number">21.3</span> Single imputation</a></li>
<li><a href="missing-data.html#multiple-imputation" id="toc-multiple-imputation"><span class="toc-section-number">21.4</span> Multiple imputation</a>
<ul>
<li><a href="missing-data.html#joint-modeling-jm" id="toc-joint-modeling-jm"><span class="toc-section-number">21.4.1</span> Joint Modeling (JM)</a></li>
<li><a href="missing-data.html#multiple-imputation-by-fully-conditional-specification-mice" id="toc-multiple-imputation-by-fully-conditional-specification-mice"><span class="toc-section-number">21.4.2</span> Multiple Imputation by Fully Conditional Specification (MICE)</a></li>
</ul></li>
<li><a href="missing-data.html#bayesian-linear-regression" id="toc-bayesian-linear-regression"><span class="toc-section-number">21.5</span> Bayesian linear regression</a></li>
<li><a href="missing-data.html#predictive-mean-matching" id="toc-predictive-mean-matching"><span class="toc-section-number">21.6</span> Predictive Mean Matching</a></li>
<li><a href="missing-data.html#mice-using-random-forest" id="toc-mice-using-random-forest"><span class="toc-section-number">21.7</span> MICE using random forest</a></li>
</ul></li>
<li><a href="meta-analysis.html#meta-analysis" id="toc-meta-analysis"><span class="toc-section-number">22</span> Meta Analysis</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">22.1</span> Introduction</a>
<ul>
<li><a href="meta-analysis.html#meta-analysis-for-different-data" id="toc-meta-analysis-for-different-data"><span class="toc-section-number">22.1.1</span> meta-analysis for different data</a></li>
</ul></li>
<li><a href="meta-analysis.html#fixed-effect-model-for-continuous-outcomes" id="toc-fixed-effect-model-for-continuous-outcomes"><span class="toc-section-number">22.2</span> Fixed Effect Model for Continuous Outcomes</a>
<ul>
<li><a href="meta-analysis.html#effect-measures" id="toc-effect-measures"><span class="toc-section-number">22.2.1</span> Effect Measures</a></li>
<li><a href="meta-analysis.html#standardized-mean-difference" id="toc-standardized-mean-difference"><span class="toc-section-number">22.2.2</span> Standardized Mean Difference</a></li>
<li><a href="meta-analysis.html#inverse-variance-weighted-average-method" id="toc-inverse-variance-weighted-average-method"><span class="toc-section-number">22.2.3</span> Inverse variance-weighted average method</a></li>
<li><a href="meta-analysis.html#generic-inverse-variance-meta-analysis-metagen" id="toc-generic-inverse-variance-meta-analysis-metagen"><span class="toc-section-number">22.2.4</span> Generic inverse variance meta-analysis <code>metagen</code></a></li>
<li><a href="meta-analysis.html#weighted-sum-of-z-scores" id="toc-weighted-sum-of-z-scores"><span class="toc-section-number">22.2.5</span> Weighted Sum of Z-Scores</a></li>
</ul></li>
<li><a href="meta-analysis.html#random-effects-model-for-continuous-outcomes" id="toc-random-effects-model-for-continuous-outcomes"><span class="toc-section-number">22.3</span> Random Effects Model for Continuous Outcomes</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">22.3.1</span> Introduction</a></li>
<li><a href="meta-analysis.html#implementation" id="toc-implementation"><span class="toc-section-number">22.3.2</span> Implementation</a></li>
<li><a href="meta-analysis.html#hartung-knapp-adjustment" id="toc-hartung-knapp-adjustment"><span class="toc-section-number">22.3.3</span> Hartung-Knapp Adjustment</a></li>
</ul></li>
<li><a href="meta-analysis.html#meta-regression" id="toc-meta-regression"><span class="toc-section-number">22.4</span> Meta-Regression</a></li>
<li><a href="meta-analysis.html#meta-analysis-with-binary-outcomes" id="toc-meta-analysis-with-binary-outcomes"><span class="toc-section-number">22.5</span> Meta-Analysis with Binary Outcomes</a>
<ul>
<li><a href="meta-analysis.html#effect-measures-1" id="toc-effect-measures-1"><span class="toc-section-number">22.5.1</span> Effect Measures</a></li>
<li><a href="meta-analysis.html#implementation-1" id="toc-implementation-1"><span class="toc-section-number">22.5.2</span> Implementation</a></li>
<li><a href="meta-analysis.html#estimation-in-sparse-data---continuity-correction" id="toc-estimation-in-sparse-data---continuity-correction"><span class="toc-section-number">22.5.3</span> Estimation in Sparse Data - Continuity correction</a></li>
<li><a href="meta-analysis.html#peto-odds-ratio" id="toc-peto-odds-ratio"><span class="toc-section-number">22.5.4</span> Peto Odds Ratio</a></li>
<li><a href="meta-analysis.html#fixed-effect-model-inverse-variance-method" id="toc-fixed-effect-model-inverse-variance-method"><span class="toc-section-number">22.5.5</span> Fixed Effect Model: Inverse Variance Method</a></li>
<li><a href="meta-analysis.html#fixed-effect-model-mantelhaenszel-method" id="toc-fixed-effect-model-mantelhaenszel-method"><span class="toc-section-number">22.5.6</span> Fixed Effect Model: Mantel–Haenszel Method</a></li>
<li><a href="meta-analysis.html#random-effects-model" id="toc-random-effects-model"><span class="toc-section-number">22.5.7</span> Random Effects Model</a></li>
</ul></li>
</ul></li>
<li><a href="time-series-analysis.html#time-series-analysis" id="toc-time-series-analysis"><span class="toc-section-number">23</span> Time Series Analysis</a>
<ul>
<li><a href="time-series-analysis.html#fundational-concepts" id="toc-fundational-concepts"><span class="toc-section-number">23.1</span> Fundational Concepts</a>
<ul>
<li><a href="time-series-analysis.html#means-variances-and-covariances" id="toc-means-variances-and-covariances"><span class="toc-section-number">23.1.1</span> Means, Variances, and Covariances</a></li>
<li><a href="time-series-analysis.html#properties-of-covariance" id="toc-properties-of-covariance"><span class="toc-section-number">23.1.2</span> Properties of covariance</a></li>
<li><a href="time-series-analysis.html#properties-of-expectation" id="toc-properties-of-expectation"><span class="toc-section-number">23.1.3</span> Properties of Expectation</a></li>
<li><a href="time-series-analysis.html#properties-of-variance" id="toc-properties-of-variance"><span class="toc-section-number">23.1.4</span> Properties of Variance</a></li>
<li><a href="time-series-analysis.html#the-random-walk" id="toc-the-random-walk"><span class="toc-section-number">23.1.5</span> The Random Walk</a></li>
<li><a href="time-series-analysis.html#a-moving-average" id="toc-a-moving-average"><span class="toc-section-number">23.1.6</span> A Moving Average</a></li>
<li><a href="time-series-analysis.html#strictly-stationarity" id="toc-strictly-stationarity"><span class="toc-section-number">23.1.7</span> Strictly Stationarity</a></li>
<li><a href="time-series-analysis.html#weakly-or-second-order-stationary" id="toc-weakly-or-second-order-stationary"><span class="toc-section-number">23.1.8</span> Weakly (or second-order) stationary</a></li>
<li><a href="time-series-analysis.html#white-noise" id="toc-white-noise"><span class="toc-section-number">23.1.9</span> White Noise</a></li>
<li><a href="time-series-analysis.html#deterministic-versus-stochastic-trends" id="toc-deterministic-versus-stochastic-trends"><span class="toc-section-number">23.1.10</span> Deterministic Versus Stochastic Trends</a></li>
</ul></li>
<li><a href="time-series-analysis.html#arma-models" id="toc-arma-models"><span class="toc-section-number">23.2</span> ARMA models</a>
<ul>
<li><a href="time-series-analysis.html#general-linear-processes" id="toc-general-linear-processes"><span class="toc-section-number">23.2.1</span> General Linear Processes</a></li>
<li><a href="time-series-analysis.html#moving-average-processes" id="toc-moving-average-processes"><span class="toc-section-number">23.2.2</span> Moving Average Processes</a></li>
<li><a href="time-series-analysis.html#autoregressive-processes" id="toc-autoregressive-processes"><span class="toc-section-number">23.2.3</span> Autoregressive Processes</a></li>
<li><a href="time-series-analysis.html#the-mixed-autoregressive-moving-average-model" id="toc-the-mixed-autoregressive-moving-average-model"><span class="toc-section-number">23.2.4</span> The Mixed Autoregressive Moving Average Model</a></li>
<li><a href="time-series-analysis.html#invertibility" id="toc-invertibility"><span class="toc-section-number">23.2.5</span> Invertibility</a></li>
<li><a href="time-series-analysis.html#fit-the-ar-model-in-r" id="toc-fit-the-ar-model-in-r"><span class="toc-section-number">23.2.6</span> Fit the AR model in R</a></li>
<li><a href="time-series-analysis.html#fit-the-ma-model-in-r" id="toc-fit-the-ma-model-in-r"><span class="toc-section-number">23.2.7</span> Fit the MA model in R</a></li>
</ul></li>
<li><a href="time-series-analysis.html#arima-models" id="toc-arima-models"><span class="toc-section-number">23.3</span> ARIMA Models</a>
<ul>
<li><a href="time-series-analysis.html#stationarity-through-differencing" id="toc-stationarity-through-differencing"><span class="toc-section-number">23.3.1</span> Stationarity Through Differencing</a></li>
<li><a href="time-series-analysis.html#arima-integrated-autoregressive-moving-average-model" id="toc-arima-integrated-autoregressive-moving-average-model"><span class="toc-section-number">23.3.2</span> ARIMA: Integrated autoregressive moving average model</a></li>
<li><a href="time-series-analysis.html#ima11-model" id="toc-ima11-model"><span class="toc-section-number">23.3.3</span> IMA(1,1) Model</a></li>
<li><a href="time-series-analysis.html#ari11-model" id="toc-ari11-model"><span class="toc-section-number">23.3.4</span> ARI(1,1) Model</a></li>
</ul></li>
<li><a href="time-series-analysis.html#time-series-graphics" id="toc-time-series-graphics"><span class="toc-section-number">23.4</span> Time series graphics</a>
<ul>
<li><a href="time-series-analysis.html#time-plots" id="toc-time-plots"><span class="toc-section-number">23.4.1</span> Time plots</a></li>
<li><a href="time-series-analysis.html#seasonal-plots" id="toc-seasonal-plots"><span class="toc-section-number">23.4.2</span> Seasonal plots</a></li>
<li><a href="time-series-analysis.html#scatterplots-matrices" id="toc-scatterplots-matrices"><span class="toc-section-number">23.4.3</span> Scatterplots matrices</a></li>
<li><a href="time-series-analysis.html#lag-plots" id="toc-lag-plots"><span class="toc-section-number">23.4.4</span> Lag plots</a></li>
<li><a href="time-series-analysis.html#autocorrelation" id="toc-autocorrelation"><span class="toc-section-number">23.4.5</span> Autocorrelation</a></li>
<li><a href="time-series-analysis.html#white-noise-1" id="toc-white-noise-1"><span class="toc-section-number">23.4.6</span> White noise</a></li>
</ul></li>
</ul></li>
<li><a href="clinic-trail-design.html#clinic-trail-design" id="toc-clinic-trail-design"><span class="toc-section-number">24</span> Clinic Trail Design</a>
<ul>
<li><a href="clinic-trail-design.html#regulation" id="toc-regulation"><span class="toc-section-number">24.1</span> Regulation</a></li>
<li><a href="clinic-trail-design.html#randomization" id="toc-randomization"><span class="toc-section-number">24.2</span> Randomization</a>
<ul>
<li><a href="clinic-trail-design.html#simple-randomization" id="toc-simple-randomization"><span class="toc-section-number">24.2.1</span> Simple randomization</a></li>
<li><a href="clinic-trail-design.html#block-randomization" id="toc-block-randomization"><span class="toc-section-number">24.2.2</span> Block randomization</a></li>
<li><a href="clinic-trail-design.html#stratified-randomization" id="toc-stratified-randomization"><span class="toc-section-number">24.2.3</span> Stratified randomization</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#phase-i-trials-design" id="toc-phase-i-trials-design"><span class="toc-section-number">24.3</span> Phase I Trials Design</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">24.3.1</span> Introduction</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#pharmacokinetic-analysis-pk-package" id="toc-pharmacokinetic-analysis-pk-package"><span class="toc-section-number">24.4</span> Pharmacokinetic Analysis (PK package）</a>
<ul>
<li><a href="clinic-trail-design.html#auc" id="toc-auc"><span class="toc-section-number">24.4.1</span> AUC</a></li>
<li><a href="clinic-trail-design.html#auc-in-complete-data-design" id="toc-auc-in-complete-data-design"><span class="toc-section-number">24.4.2</span> AUC in complete data design</a></li>
<li><a href="clinic-trail-design.html#auc-in-repeated-complete-data-design" id="toc-auc-in-repeated-complete-data-design"><span class="toc-section-number">24.4.3</span> AUC in repeated complete data design</a></li>
<li><a href="clinic-trail-design.html#bioequivalence-between-aucs" id="toc-bioequivalence-between-aucs"><span class="toc-section-number">24.4.4</span> Bioequivalence between AUCs</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-biexponential-model" id="toc-two-phase-half-life-estimation-by-biexponential-model"><span class="toc-section-number">24.4.5</span> Two-phase half-life estimation by biexponential model</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-linear-fitting" id="toc-two-phase-half-life-estimation-by-linear-fitting"><span class="toc-section-number">24.4.6</span> Two-phase half-life estimation by linear fitting</a></li>
<li><a href="clinic-trail-design.html#estimation-of-various-pk-parameters" id="toc-estimation-of-various-pk-parameters"><span class="toc-section-number">24.4.7</span> Estimation of various PK parameters</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#phase-ii-trials-design" id="toc-phase-ii-trials-design"><span class="toc-section-number">24.5</span> Phase II Trials Design</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">24.5.1</span> Introduction</a></li>
<li><a href="clinic-trail-design.html#gehans-design" id="toc-gehans-design"><span class="toc-section-number">24.5.2</span> Gehan’s design</a></li>
<li><a href="clinic-trail-design.html#flemings-two-stage-design" id="toc-flemings-two-stage-design"><span class="toc-section-number">24.5.3</span> Fleming’s Two-Stage design</a></li>
<li><a href="clinic-trail-design.html#simons-2-stage-design" id="toc-simons-2-stage-design"><span class="toc-section-number">24.5.4</span> Simon’s 2-Stage Design</a></li>
<li><a href="clinic-trail-design.html#jonckheere-terptsra-jt-trend-test" id="toc-jonckheere-terptsra-jt-trend-test"><span class="toc-section-number">24.5.5</span> Jonckheere-Terptsra (JT) trend test</a></li>
<li><a href="clinic-trail-design.html#cochran-armitage-ca-trend-test" id="toc-cochran-armitage-ca-trend-test"><span class="toc-section-number">24.5.6</span> Cochran-Armitage (CA) trend test</a></li>
<li><a href="clinic-trail-design.html#mcp-mod" id="toc-mcp-mod"><span class="toc-section-number">24.5.7</span> MCP-Mod</a></li>
<li><a href="clinic-trail-design.html#two-stage-phase-ii-design-for-response-and-toxicity" id="toc-two-stage-phase-ii-design-for-response-and-toxicity"><span class="toc-section-number">24.5.8</span> Two Stage Phase II Design for Response and Toxicity</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#phase-iii-trials-design" id="toc-phase-iii-trials-design"><span class="toc-section-number">24.6</span> Phase III Trials Design</a>
<ul>
<li><a href="clinic-trail-design.html#non-inferiority-and-equivalence-three-armed-trial" id="toc-non-inferiority-and-equivalence-three-armed-trial"><span class="toc-section-number">24.6.1</span> Non-inferiority and Equivalence Three-armed trial</a></li>
<li><a href="clinic-trail-design.html#pigeot-method" id="toc-pigeot-method"><span class="toc-section-number">24.6.2</span> Pigeot Method</a></li>
</ul></li>
<li><a href="clinic-trail-design.html#medical-devices-postmarketing-surveillance-pms" id="toc-medical-devices-postmarketing-surveillance-pms"><span class="toc-section-number">24.7</span> Medical Devices Postmarketing Surveillance (PMS)</a>
<ul>
<li><a href="clinic-trail-design.html#phase-iv-and-pms" id="toc-phase-iv-and-pms"><span class="toc-section-number">24.7.1</span> Phase IV and PMS</a></li>
</ul></li>
</ul></li>
<li><a href="group-sequential-design.html#group-sequential-design" id="toc-group-sequential-design"><span class="toc-section-number">25</span> Group Sequential Design</a>
<ul>
<li><a href="group-sequential-design.html#classical-designs-without-futility-stopping" id="toc-classical-designs-without-futility-stopping"><span class="toc-section-number">25.1</span> Classical Designs without futility stopping</a>
<ul>
<li><a href="group-sequential-design.html#pocock-method" id="toc-pocock-method"><span class="toc-section-number">25.1.1</span> Pocock Method</a></li>
<li><a href="group-sequential-design.html#obrien-fleming-method" id="toc-obrien-fleming-method"><span class="toc-section-number">25.1.2</span> O’Brien &amp; Fleming Method</a></li>
<li><a href="group-sequential-design.html#wang-tsiatis-method" id="toc-wang-tsiatis-method"><span class="toc-section-number">25.1.3</span> Wang &amp; Tsiatis Method</a></li>
<li><a href="group-sequential-design.html#rejection-bounds-and-local-p-values" id="toc-rejection-bounds-and-local-p-values"><span class="toc-section-number">25.1.4</span> Rejection bounds and Local p-values</a></li>
<li><a href="group-sequential-design.html#power-and-sample-size" id="toc-power-and-sample-size"><span class="toc-section-number">25.1.5</span> Power and Sample size</a></li>
</ul></li>
<li><a href="group-sequential-design.html#classical-designs-with-binding-futility-stopping" id="toc-classical-designs-with-binding-futility-stopping"><span class="toc-section-number">25.2</span> Classical Designs with binding futility stopping</a>
<ul>
<li><a href="group-sequential-design.html#symmetric-designs" id="toc-symmetric-designs"><span class="toc-section-number">25.2.1</span> Symmetric designs</a></li>
<li><a href="group-sequential-design.html#one-sided-designs" id="toc-one-sided-designs"><span class="toc-section-number">25.2.2</span> One-Sided Designs</a></li>
</ul></li>
<li><a href="group-sequential-design.html#alpha-spending-function-approach" id="toc-alpha-spending-function-approach"><span class="toc-section-number">25.3</span> Alpha Spending Function Approach</a></li>
<li><a href="group-sequential-design.html#r-implementation-using-rpact" id="toc-r-implementation-using-rpact"><span class="toc-section-number">25.4</span> R Implementation using rpact</a>
<ul>
<li><a href="group-sequential-design.html#basic-functions" id="toc-basic-functions"><span class="toc-section-number">25.4.1</span> Basic Functions</a></li>
<li><a href="group-sequential-design.html#getdesigngroupsequential-defining-efficacy-boundaries" id="toc-getdesigngroupsequential-defining-efficacy-boundaries"><span class="toc-section-number">25.4.2</span> <code>getDesignGroupSequential</code> defining efficacy boundaries</a></li>
</ul></li>
<li><a href="group-sequential-design.html#sample-size" id="toc-sample-size"><span class="toc-section-number">25.5</span> Sample Size</a>
<ul>
<li><a href="group-sequential-design.html#sample-sizes-for-different-types-of-endpoints-without-ia" id="toc-sample-sizes-for-different-types-of-endpoints-without-ia"><span class="toc-section-number">25.5.1</span> Sample Sizes for Different Types of Endpoints without IA</a></li>
<li><a href="group-sequential-design.html#two-groups-continuous-endpoint-without-ia" id="toc-two-groups-continuous-endpoint-without-ia"><span class="toc-section-number">25.5.2</span> Two groups continuous endpoint (without IA)</a></li>
<li><a href="group-sequential-design.html#two-groups-binary-endpoint-without-ia" id="toc-two-groups-binary-endpoint-without-ia"><span class="toc-section-number">25.5.3</span> Two groups binary endpoint (without IA)</a></li>
<li><a href="group-sequential-design.html#group-sequential-designs-for-conti-and-binary" id="toc-group-sequential-designs-for-conti-and-binary"><span class="toc-section-number">25.5.4</span> Group-sequential designs for conti and binary</a></li>
<li><a href="group-sequential-design.html#survival-endpoint" id="toc-survival-endpoint"><span class="toc-section-number">25.5.5</span> Survival endpoint</a></li>
</ul></li>
</ul></li>
<li><a href="adaptive-designs.html#adaptive-designs" id="toc-adaptive-designs"><span class="toc-section-number">26</span> Adaptive designs</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">26.1</span> Introduction</a>
<ul>
<li><a href="adaptive-designs.html#early-termination-due-to-futility" id="toc-early-termination-due-to-futility"><span class="toc-section-number">26.1.1</span> Early termination due to futility</a></li>
<li><a href="adaptive-designs.html#early-termination-due-to-efficacy" id="toc-early-termination-due-to-efficacy"><span class="toc-section-number">26.1.2</span> Early termination due to efficacy</a></li>
<li><a href="adaptive-designs.html#sample-size-reassessment" id="toc-sample-size-reassessment"><span class="toc-section-number">26.1.3</span> Sample size reassessment</a></li>
<li><a href="adaptive-designs.html#change-or-modification-of-the-primary-endpoint" id="toc-change-or-modification-of-the-primary-endpoint"><span class="toc-section-number">26.1.4</span> Change or modification of the primary endpoint</a></li>
<li><a href="adaptive-designs.html#discontinuing-treatment-arms" id="toc-discontinuing-treatment-arms"><span class="toc-section-number">26.1.5</span> Discontinuing treatment arms</a></li>
<li><a href="adaptive-designs.html#switching-between-superiority-and-non-inferiority" id="toc-switching-between-superiority-and-non-inferiority"><span class="toc-section-number">26.1.6</span> Switching between superiority and non-inferiority</a></li>
<li><a href="adaptive-designs.html#selection-of-the-patient-population" id="toc-selection-of-the-patient-population"><span class="toc-section-number">26.1.7</span> Selection of the patient population</a></li>
</ul></li>
<li><a href="adaptive-designs.html#general-theory" id="toc-general-theory"><span class="toc-section-number">26.2</span> General Theory</a>
<ul>
<li><a href="adaptive-designs.html#stopping-boundary" id="toc-stopping-boundary"><span class="toc-section-number">26.2.1</span> Stopping Boundary</a></li>
<li><a href="adaptive-designs.html#power-and-adjusted-p-value" id="toc-power-and-adjusted-p-value"><span class="toc-section-number">26.2.2</span> Power and Adjusted p-value</a></li>
<li><a href="adaptive-designs.html#stopping-probabilities-design-evaluation" id="toc-stopping-probabilities-design-evaluation"><span class="toc-section-number">26.2.3</span> Stopping Probabilities (Design Evaluation)</a></li>
<li><a href="adaptive-designs.html#expected-duration-of-an-adaptive-trial-design-evaluation" id="toc-expected-duration-of-an-adaptive-trial-design-evaluation"><span class="toc-section-number">26.2.4</span> Expected Duration of an Adaptive Trial (Design Evaluation)</a></li>
<li><a href="adaptive-designs.html#expected-sample-sizes-design-evaluation" id="toc-expected-sample-sizes-design-evaluation"><span class="toc-section-number">26.2.5</span> Expected Sample Sizes (Design Evaluation)</a></li>
<li><a href="adaptive-designs.html#conditional-power-and-futility-index" id="toc-conditional-power-and-futility-index"><span class="toc-section-number">26.2.6</span> Conditional Power and futility index</a></li>
</ul></li>
<li><a href="adaptive-designs.html#methods" id="toc-methods"><span class="toc-section-number">26.3</span> Methods</a>
<ul>
<li><a href="adaptive-designs.html#four-inroduction" id="toc-four-inroduction"><span class="toc-section-number">26.3.1</span> Four Inroduction</a></li>
<li><a href="adaptive-designs.html#sample-size-re-estimation" id="toc-sample-size-re-estimation"><span class="toc-section-number">26.3.2</span> Sample size re-estimation</a></li>
<li><a href="adaptive-designs.html#additional-considerations" id="toc-additional-considerations"><span class="toc-section-number">26.3.3</span> Additional Considerations</a></li>
</ul></li>
<li><a href="adaptive-designs.html#combination-of-p-values" id="toc-combination-of-p-values"><span class="toc-section-number">26.4</span> Combination of p-values</a>
<ul>
<li><a href="adaptive-designs.html#method-based-on-individual-p-values" id="toc-method-based-on-individual-p-values"><span class="toc-section-number">26.4.1</span> Method Based on Individual p-values</a></li>
<li><a href="adaptive-designs.html#method-based-on-the-sum-of-p-values" id="toc-method-based-on-the-sum-of-p-values"><span class="toc-section-number">26.4.2</span> Method Based on the Sum of p-values</a></li>
<li><a href="adaptive-designs.html#method-with-product-of-p-values" id="toc-method-with-product-of-p-values"><span class="toc-section-number">26.4.3</span> Method with Product of p-values</a></li>
<li><a href="adaptive-designs.html#r-implementing" id="toc-r-implementing"><span class="toc-section-number">26.4.4</span> R Implementing</a></li>
</ul></li>
<li><a href="adaptive-designs.html#inverse-normal-combination-function" id="toc-inverse-normal-combination-function"><span class="toc-section-number">26.5</span> Inverse normal combination function</a>
<ul>
<li><a href="adaptive-designs.html#method-with-linear-combination-of-z-scores" id="toc-method-with-linear-combination-of-z-scores"><span class="toc-section-number">26.5.1</span> Method with Linear Combination of z-Scores</a></li>
<li><a href="adaptive-designs.html#weighted-inverse-normal-method" id="toc-weighted-inverse-normal-method"><span class="toc-section-number">26.5.2</span> Weighted inverse normal method</a></li>
</ul></li>
<li><a href="adaptive-designs.html#conditional-error-function-method-cefm-and-conditional-power" id="toc-conditional-error-function-method-cefm-and-conditional-power"><span class="toc-section-number">26.6</span> Conditional Error Function Method (CEFM) and Conditional Power</a>
<ul>
<li><a href="adaptive-designs.html#proschanhunsberger-method" id="toc-proschanhunsberger-method"><span class="toc-section-number">26.6.1</span> Proschan–Hunsberger Method</a></li>
<li><a href="adaptive-designs.html#denne-method" id="toc-denne-method"><span class="toc-section-number">26.6.2</span> Denne Method</a></li>
</ul></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#pk-and-pd-analysis" id="toc-pk-and-pd-analysis"><span class="toc-section-number">27</span> PK and PD Analysis</a>
<ul>
<li><a href="pk-and-pd-analysis.html#pharmacokinetic-concepts" id="toc-pharmacokinetic-concepts"><span class="toc-section-number">27.1</span> Pharmacokinetic Concepts</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">27.1.1</span> Introduction</a></li>
<li><a href="pk-and-pd-analysis.html#pk-analysis-package-in-r" id="toc-pk-analysis-package-in-r"><span class="toc-section-number">27.1.2</span> PK Analysis Package in R</a></li>
<li><a href="pk-and-pd-analysis.html#one-compartment-models-intravenous-bolus-administration" id="toc-one-compartment-models-intravenous-bolus-administration"><span class="toc-section-number">27.1.3</span> One-Compartment Models-Intravenous bolus administration</a></li>
<li><a href="pk-and-pd-analysis.html#one-compartment-models-constant-rate-infusion" id="toc-one-compartment-models-constant-rate-infusion"><span class="toc-section-number">27.1.4</span> One-Compartment Models-Constant rate infusion</a></li>
<li><a href="pk-and-pd-analysis.html#integration-of-clearance-and-volume" id="toc-integration-of-clearance-and-volume"><span class="toc-section-number">27.1.5</span> Integration of clearance and volume</a></li>
<li><a href="pk-and-pd-analysis.html#one-compartment-models-extravascular-administration" id="toc-one-compartment-models-extravascular-administration"><span class="toc-section-number">27.1.6</span> One-Compartment Models-Extravascular administration</a></li>
<li><a href="pk-and-pd-analysis.html#plasma-and-urine-data" id="toc-plasma-and-urine-data"><span class="toc-section-number">27.1.7</span> Plasma and Urine Data</a></li>
<li><a href="pk-and-pd-analysis.html#multi-compartment-catenary-and-mammillary-models" id="toc-multi-compartment-catenary-and-mammillary-models"><span class="toc-section-number">27.1.8</span> Multi-Compartment-Catenary and mammillary models</a></li>
<li><a href="pk-and-pd-analysis.html#two-compartment-model-intravenous-bolus-administration" id="toc-two-compartment-model-intravenous-bolus-administration"><span class="toc-section-number">27.1.9</span> Two-compartment model-Intravenous bolus administration</a></li>
<li><a href="pk-and-pd-analysis.html#two-compartment-model-constant-rate-infusion" id="toc-two-compartment-model-constant-rate-infusion"><span class="toc-section-number">27.1.10</span> Two-compartment model-Constant rate infusion</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#non-compartmental-analysis-nca" id="toc-non-compartmental-analysis-nca"><span class="toc-section-number">27.2</span> Non-Compartmental Analysis (NCA)</a>
<ul>
<li><a href="pk-and-pd-analysis.html#nca-vs-regression-analysis" id="toc-nca-vs-regression-analysis"><span class="toc-section-number">27.2.1</span> NCA vs regression analysis</a></li>
<li><a href="pk-and-pd-analysis.html#computational-methods---linear-trapezoidal-rule" id="toc-computational-methods---linear-trapezoidal-rule"><span class="toc-section-number">27.2.2</span> Computational methods - Linear trapezoidal rule</a></li>
<li><a href="pk-and-pd-analysis.html#computational-methods---log-linear-trapezoidal-rule" id="toc-computational-methods---log-linear-trapezoidal-rule"><span class="toc-section-number">27.2.3</span> Computational methods - Log-linear trapezoidal rule</a></li>
<li><a href="pk-and-pd-analysis.html#pertinent-pharmacokinetic-estimates" id="toc-pertinent-pharmacokinetic-estimates"><span class="toc-section-number">27.2.4</span> Pertinent pharmacokinetic estimates</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#calculation-pk-package" id="toc-calculation-pk-package"><span class="toc-section-number">27.3</span> Calculation (PK package）</a>
<ul>
<li><a href="clinic-trail-design.html#auc" id="toc-auc"><span class="toc-section-number">27.3.1</span> AUC</a></li>
<li><a href="clinic-trail-design.html#auc-in-complete-data-design" id="toc-auc-in-complete-data-design"><span class="toc-section-number">27.3.2</span> AUC in complete data design</a></li>
<li><a href="clinic-trail-design.html#auc-in-repeated-complete-data-design" id="toc-auc-in-repeated-complete-data-design"><span class="toc-section-number">27.3.3</span> AUC in repeated complete data design</a></li>
<li><a href="clinic-trail-design.html#bioequivalence-between-aucs" id="toc-bioequivalence-between-aucs"><span class="toc-section-number">27.3.4</span> Bioequivalence between AUCs</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-biexponential-model" id="toc-two-phase-half-life-estimation-by-biexponential-model"><span class="toc-section-number">27.3.5</span> Two-phase half-life estimation by biexponential model</a></li>
<li><a href="clinic-trail-design.html#two-phase-half-life-estimation-by-linear-fitting" id="toc-two-phase-half-life-estimation-by-linear-fitting"><span class="toc-section-number">27.3.6</span> Two-phase half-life estimation by linear fitting</a></li>
<li><a href="clinic-trail-design.html#estimation-of-various-pk-parameters" id="toc-estimation-of-various-pk-parameters"><span class="toc-section-number">27.3.7</span> Estimation of various PK parameters</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#pharmacodynamic-concepts" id="toc-pharmacodynamic-concepts"><span class="toc-section-number">27.4</span> Pharmacodynamic Concepts</a>
<ul>
<li><a href="parametric-test.html#introduction-1" id="toc-introduction-1"><span class="toc-section-number">27.4.1</span> Introduction</a></li>
<li><a href="pk-and-pd-analysis.html#response" id="toc-response"><span class="toc-section-number">27.4.2</span> Response</a></li>
<li><a href="pk-and-pd-analysis.html#law-of-mass-action" id="toc-law-of-mass-action"><span class="toc-section-number">27.4.3</span> Law of Mass Action</a></li>
<li><a href="pk-and-pd-analysis.html#pharmacodynamic-models" id="toc-pharmacodynamic-models"><span class="toc-section-number">27.4.4</span> Pharmacodynamic Models</a></li>
<li><a href="pk-and-pd-analysis.html#interaction-models" id="toc-interaction-models"><span class="toc-section-number">27.4.5</span> Interaction Models</a></li>
</ul></li>
<li><a href="pk-and-pd-analysis.html#pk-and-pd-data-transfer" id="toc-pk-and-pd-data-transfer"><span class="toc-section-number">27.5</span> PK and PD data transfer</a>
<ul>
<li><a href="pk-and-pd-analysis.html#adpp-specification" id="toc-adpp-specification"><span class="toc-section-number">27.5.1</span> ADPP Specification</a></li>
<li><a href="pk-and-pd-analysis.html#adpp" id="toc-adpp"><span class="toc-section-number">27.5.2</span> ADPP</a></li>
<li><a href="pk-and-pd-analysis.html#adpc-specification" id="toc-adpc-specification"><span class="toc-section-number">27.5.3</span> ADPC Specification</a></li>
<li><a href="pk-and-pd-analysis.html#adpc" id="toc-adpc"><span class="toc-section-number">27.5.4</span> ADPC</a></li>
</ul></li>
</ul></li>
<li><a href="cdisc.html#cdisc" id="toc-cdisc"><span class="toc-section-number">28</span> CDISC</a>
<ul>
<li><a href="cdisc.html#study-data-tabulation-model-sdtm" id="toc-study-data-tabulation-model-sdtm"><span class="toc-section-number">28.1</span> Study Data Tabulation Model (SDTM)</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">28.1.1</span> Introduction</a></li>
<li><a href="cdisc.html#model-concepts-and-terms" id="toc-model-concepts-and-terms"><span class="toc-section-number">28.1.2</span> Model Concepts and Terms</a></li>
<li><a href="cdisc.html#sdtm-domains" id="toc-sdtm-domains"><span class="toc-section-number">28.1.3</span> SDTM Domains</a></li>
<li><a href="cdisc.html#sdtm-define.xml" id="toc-sdtm-define.xml"><span class="toc-section-number">28.1.4</span> SDTM Define.xml</a></li>
<li><a href="cdisc.html#extract-transform-load-etl" id="toc-extract-transform-load-etl"><span class="toc-section-number">28.1.5</span> Extract-Transform-Load (ETL)</a></li>
<li><a href="cdisc.html#example-building-dm-sdtm-datasets" id="toc-example-building-dm-sdtm-datasets"><span class="toc-section-number">28.1.6</span> Example Building DM SDTM Datasets</a></li>
</ul></li>
<li><a href="cdisc.html#sdtm-sas-macro" id="toc-sdtm-sas-macro"><span class="toc-section-number">28.2</span> SDTM SAS Macro</a>
<ul>
<li><a href="cdisc.html#make_define" id="toc-make_define"><span class="toc-section-number">28.2.1</span> ％make_define</a></li>
<li><a href="cdisc.html#make_codelist_formats" id="toc-make_codelist_formats"><span class="toc-section-number">28.2.2</span> %make_codelist_formats</a></li>
<li><a href="cdisc.html#make_empty_dataset" id="toc-make_empty_dataset"><span class="toc-section-number">28.2.3</span> %make_empty_dataset</a></li>
<li><a href="cdisc.html#make_dtc_date" id="toc-make_dtc_date"><span class="toc-section-number">28.2.4</span> %make_dtc_date</a></li>
<li><a href="cdisc.html#make_sdtm_dy" id="toc-make_sdtm_dy"><span class="toc-section-number">28.2.5</span> %make_sdtm_dy</a></li>
<li><a href="cdisc.html#make_sort_order" id="toc-make_sort_order"><span class="toc-section-number">28.2.6</span> %make_sort_order</a></li>
<li><a href="cdisc.html#create_stdm_domains" id="toc-create_stdm_domains"><span class="toc-section-number">28.2.7</span> %Create_STDM_Domains</a></li>
<li><a href="cdisc.html#detectduplicates" id="toc-detectduplicates"><span class="toc-section-number">28.2.8</span> %DetectDuplicates</a></li>
<li><a href="cdisc.html#changedvarnum" id="toc-changedvarnum"><span class="toc-section-number">28.2.9</span> %ChangedVarNum</a></li>
<li><a href="cdisc.html#changedlabels" id="toc-changedlabels"><span class="toc-section-number">28.2.10</span> %ChangedLabels</a></li>
</ul></li>
<li><a href="cdisc.html#analysis-data-model-adam" id="toc-analysis-data-model-adam"><span class="toc-section-number">28.3</span> Analysis Data Model (ADaM)</a>
<ul>
<li><a href="cdisc.html#compare-with-sdtm" id="toc-compare-with-sdtm"><span class="toc-section-number">28.3.1</span> Compare with SDTM</a></li>
<li><a href="cdisc.html#types-of-adam-metadata" id="toc-types-of-adam-metadata"><span class="toc-section-number">28.3.2</span> 4 types of ADaM metadata</a></li>
<li><a href="cdisc.html#subject-level-analysis-dataset-adsl" id="toc-subject-level-analysis-dataset-adsl"><span class="toc-section-number">28.3.3</span> Subject-Level Analysis Dataset (ADSL)</a></li>
<li><a href="cdisc.html#the-basic-data-structure-bds" id="toc-the-basic-data-structure-bds"><span class="toc-section-number">28.3.4</span> The Basic Data Structure (BDS)</a></li>
<li><a href="cdisc.html#example-building-adsl-datasets" id="toc-example-building-adsl-datasets"><span class="toc-section-number">28.3.5</span> Example Building ADSL Datasets</a></li>
<li><a href="cdisc.html#example-building-adam-basic-data-structure-bds-datasets" id="toc-example-building-adam-basic-data-structure-bds-datasets"><span class="toc-section-number">28.3.6</span> Example Building ADaM Basic Data Structure (BDS) Datasets</a></li>
<li><a href="cdisc.html#example-building-adae-adverse-event-analysis-datasets-datasets" id="toc-example-building-adae-adverse-event-analysis-datasets-datasets"><span class="toc-section-number">28.3.7</span> Example Building ADAE – Adverse Event Analysis Datasets Datasets</a></li>
</ul></li>
<li><a href="cdisc.html#adam-sas-macro" id="toc-adam-sas-macro"><span class="toc-section-number">28.4</span> ADaM SAS Macro</a>
<ul>
<li><a href="cdisc.html#make_define-1" id="toc-make_define-1"><span class="toc-section-number">28.4.1</span> %make_define</a></li>
<li><a href="cdisc.html#create_adam_dataset" id="toc-create_adam_dataset"><span class="toc-section-number">28.4.2</span> %create_adam_dataset</a></li>
<li><a href="cdisc.html#make_empty_dataset-1" id="toc-make_empty_dataset-1"><span class="toc-section-number">28.4.3</span> %make_empty_dataset</a></li>
<li><a href="cdisc.html#dtc2dt" id="toc-dtc2dt"><span class="toc-section-number">28.4.4</span> %DTC2DT</a></li>
<li><a href="cdisc.html#imputed_date" id="toc-imputed_date"><span class="toc-section-number">28.4.5</span> %imputed_date</a></li>
<li><a href="cdisc.html#mergsupp" id="toc-mergsupp"><span class="toc-section-number">28.4.6</span> %mergsupp</a></li>
</ul></li>
<li><a href="cdisc.html#project-example-mediwound1" id="toc-project-example-mediwound1"><span class="toc-section-number">28.5</span> Project Example MEDIWOUND1</a>
<ul>
<li><a href="cdisc.html#study-design" id="toc-study-design"><span class="toc-section-number">28.5.1</span> Study Design</a></li>
<li><a href="cdisc.html#primary-objective" id="toc-primary-objective"><span class="toc-section-number">28.5.2</span> Primary Objective</a></li>
<li><a href="cdisc.html#statistical-analysis" id="toc-statistical-analysis"><span class="toc-section-number">28.5.3</span> Statistical Analysis</a></li>
<li><a href="cdisc.html#cdisc-programming" id="toc-cdisc-programming"><span class="toc-section-number">28.5.4</span> CDISC Programming</a></li>
</ul></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#regularization-penalized-regression" id="toc-regularization-penalized-regression"><span class="toc-section-number">29</span> Regularization Penalized Regression</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">29.1</span> Introduction</a>
<ul>
<li><a href="regularization-penalized-regression.html#motivation" id="toc-motivation"><span class="toc-section-number">29.1.1</span> Motivation</a></li>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">29.1.2</span> Data preparation</a></li>
<li><a href="regularization-penalized-regression.html#best-subset-regression" id="toc-best-subset-regression"><span class="toc-section-number">29.1.3</span> Best subset regression</a></li>
</ul></li>
<li><a href="advanced-linear-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">29.2</span> Ridge Regression</a>
<ul>
<li><a href="regularization-penalized-regression.html#modeling" id="toc-modeling"><span class="toc-section-number">29.2.1</span> Modeling</a></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#lasso-regression" id="toc-lasso-regression"><span class="toc-section-number">29.3</span> Lasso Regression</a>
<ul>
<li><a href="regularization-penalized-regression.html#modelling" id="toc-modelling"><span class="toc-section-number">29.3.1</span> Modelling</a></li>
<li><a href="regularization-penalized-regression.html#glmnet-cross-validation" id="toc-glmnet-cross-validation"><span class="toc-section-number">29.3.2</span> glmnet cross validation</a></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#elasticnet" id="toc-elasticnet"><span class="toc-section-number">29.4</span> ElasticNet</a>
<ul>
<li><a href="regularization-penalized-regression.html#modelling-1" id="toc-modelling-1"><span class="toc-section-number">29.4.1</span> Modelling</a></li>
<li><a href="regularization-penalized-regression.html#classification" id="toc-classification"><span class="toc-section-number">29.4.2</span> Classification</a></li>
</ul></li>
</ul></li>
<li><a href="bayesian-theory.html#bayesian-theory" id="toc-bayesian-theory"><span class="toc-section-number">30</span> Bayesian Theory</a>
<ul>
<li><a href="bayesian-theory.html#introduction-of-bayesian" id="toc-introduction-of-bayesian"><span class="toc-section-number">30.1</span> Introduction of Bayesian</a>
<ul>
<li><a href="bayesian-theory.html#frequency-and-bayesian" id="toc-frequency-and-bayesian"><span class="toc-section-number">30.1.1</span> Frequency and Bayesian</a></li>
<li><a href="bayesian-theory.html#bayesian-and-classical-methods" id="toc-bayesian-and-classical-methods"><span class="toc-section-number">30.1.2</span> Bayesian and classical methods</a></li>
<li><a href="bayesian-theory.html#bayes-rule" id="toc-bayes-rule"><span class="toc-section-number">30.1.3</span> Bayes’ Rule</a></li>
<li><a href="bayesian-theory.html#bootstrap" id="toc-bootstrap"><span class="toc-section-number">30.1.4</span> Bootstrap</a></li>
<li><a href="bayesian-theory.html#posterior-distribution" id="toc-posterior-distribution"><span class="toc-section-number">30.1.5</span> Posterior Distribution</a></li>
<li><a href="bayesian-theory.html#bayesian-credible-intervals" id="toc-bayesian-credible-intervals"><span class="toc-section-number">30.1.6</span> Bayesian Credible Intervals</a></li>
</ul></li>
<li><a href="anova.html#parameter-estimates" id="toc-parameter-estimates"><span class="toc-section-number">30.2</span> Parameter estimates</a>
<ul>
<li><a href="bayesian-theory.html#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation"><span class="toc-section-number">30.2.1</span> Maximum likelihood estimation</a></li>
<li><a href="bayesian-theory.html#maximum-a-posteriori-estimation" id="toc-maximum-a-posteriori-estimation"><span class="toc-section-number">30.2.2</span> Maximum a posteriori estimation</a></li>
<li><a href="bayesian-theory.html#bayesian-model" id="toc-bayesian-model"><span class="toc-section-number">30.2.3</span> Bayesian Model</a></li>
</ul></li>
<li><a href="bayesian-theory.html#prior-distributions" id="toc-prior-distributions"><span class="toc-section-number">30.3</span> Prior Distributions</a>
<ul>
<li><a href="bayesian-theory.html#conjugate-prior-distributions" id="toc-conjugate-prior-distributions"><span class="toc-section-number">30.3.1</span> Conjugate Prior Distributions</a></li>
<li><a href="bayesian-theory.html#non-informativ-priors" id="toc-non-informativ-priors"><span class="toc-section-number">30.3.2</span> Non-informativ Priors</a></li>
</ul></li>
<li><a href="bayesian-theory.html#mcmc" id="toc-mcmc"><span class="toc-section-number">30.4</span> MCMC</a>
<ul>
<li><a href="bayesian-theory.html#monte-carlo-simulation" id="toc-monte-carlo-simulation"><span class="toc-section-number">30.4.1</span> Monte Carlo Simulation</a></li>
<li><a href="bayesian-theory.html#概率分布采样" id="toc-概率分布采样"><span class="toc-section-number">30.4.2</span> 概率分布采样</a></li>
<li><a href="bayesian-theory.html#接受-拒绝采样" id="toc-接受-拒绝采样"><span class="toc-section-number">30.4.3</span> 接受-拒绝采样</a></li>
<li><a href="bayesian-theory.html#markov-chain" id="toc-markov-chain"><span class="toc-section-number">30.4.4</span> Markov Chain</a></li>
<li><a href="bayesian-theory.html#马尔科夫链的收敛性质" id="toc-马尔科夫链的收敛性质"><span class="toc-section-number">30.4.5</span> 马尔科夫链的收敛性质</a></li>
<li><a href="bayesian-theory.html#基于马尔科夫链采样" id="toc-基于马尔科夫链采样"><span class="toc-section-number">30.4.6</span> 基于马尔科夫链采样</a></li>
<li><a href="bayesian-theory.html#mcmc采样" id="toc-mcmc采样"><span class="toc-section-number">30.4.7</span> MCMC采样</a></li>
<li><a href="bayesian-theory.html#m-h采样" id="toc-m-h采样"><span class="toc-section-number">30.4.8</span> M-H采样</a></li>
<li><a href="bayesian-theory.html#gibbs采样" id="toc-gibbs采样"><span class="toc-section-number">30.4.9</span> Gibbs采样</a></li>
</ul></li>
<li><a href="bayesian-theory.html#regression-and-variable-selection" id="toc-regression-and-variable-selection"><span class="toc-section-number">30.5</span> Regression and Variable Selection</a>
<ul>
<li><a href="bayesian-theory.html#classical-least-squares-estimator" id="toc-classical-least-squares-estimator"><span class="toc-section-number">30.5.1</span> Classical Least Squares Estimator</a></li>
<li><a href="bayesian-theory.html#the-jeffreys-prior-analysis" id="toc-the-jeffreys-prior-analysis"><span class="toc-section-number">30.5.2</span> The Jeffreys Prior Analysis</a></li>
<li><a href="bayesian-theory.html#zellners-g-prior-analysis" id="toc-zellners-g-prior-analysis"><span class="toc-section-number">30.5.3</span> Zellner’s G-prior analysis</a></li>
</ul></li>
<li><a href="missing-data.html#bayesian-linear-regression" id="toc-bayesian-linear-regression"><span class="toc-section-number">30.6</span> Bayesian linear regression</a></li>
<li><a href="bayesian-theory.html#item-response-theory" id="toc-item-response-theory"><span class="toc-section-number">30.7</span> Item Response Theory</a>
<ul>
<li><a href="bayesian-theory.html#item-response-theory-1" id="toc-item-response-theory-1"><span class="toc-section-number">30.7.1</span> Item response theory</a></li>
<li><a href="bayesian-theory.html#em-algorithm" id="toc-em-algorithm"><span class="toc-section-number">30.7.2</span> EM algorithm</a></li>
<li><a href="bayesian-theory.html#mcmc-algorithm" id="toc-mcmc-algorithm"><span class="toc-section-number">30.7.3</span> MCMC algorithm</a></li>
<li><a href="bayesian-theory.html#unidimensional-irt-models" id="toc-unidimensional-irt-models"><span class="toc-section-number">30.7.4</span> Unidimensional IRT Models</a></li>
</ul></li>
</ul></li>
<li><a href="smoothing.html#smoothing" id="toc-smoothing"><span class="toc-section-number">31</span> Smoothing</a>
<ul>
<li><a href="smoothing.html#smoothing-1" id="toc-smoothing-1"><span class="toc-section-number">31.1</span> Smoothing</a>
<ul>
<li><a href="smoothing.html#bin-smoothing" id="toc-bin-smoothing"><span class="toc-section-number">31.1.1</span> Bin smoothing</a></li>
<li><a href="smoothing.html#kernels" id="toc-kernels"><span class="toc-section-number">31.1.2</span> Kernels</a></li>
<li><a href="smoothing.html#local-weighted-regression-loess" id="toc-local-weighted-regression-loess"><span class="toc-section-number">31.1.3</span> Local weighted regression (loess)</a></li>
</ul></li>
<li><a href="smoothing.html#loess-regression" id="toc-loess-regression"><span class="toc-section-number">31.2</span> Loess Regression</a></li>
</ul></li>
<li><a href="knn.html#knn" id="toc-knn"><span class="toc-section-number">32</span> KNN</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">32.1</span> Introduction</a>
<ul>
<li><a href="knn.html#idee" id="toc-idee"><span class="toc-section-number">32.1.1</span> Idee</a></li>
<li><a href="knn.html#加权最近邻法" id="toc-加权最近邻法"><span class="toc-section-number">32.1.2</span> 加权最近邻法</a></li>
<li><a href="knn.html#knn算法三要素" id="toc-knn算法三要素"><span class="toc-section-number">32.1.3</span> KNN算法三要素</a></li>
<li><a href="knn.html#优缺点" id="toc-优缺点"><span class="toc-section-number">32.1.4</span> 优缺点</a></li>
</ul></li>
<li><a href="knn.html#knn算法的实现方式" id="toc-knn算法的实现方式"><span class="toc-section-number">32.2</span> KNN算法的实现方式</a>
<ul>
<li><a href="knn.html#brute-force" id="toc-brute-force"><span class="toc-section-number">32.2.1</span> Brute-force</a></li>
<li><a href="knn.html#kd树实现" id="toc-kd树实现"><span class="toc-section-number">32.2.2</span> KD树实现</a></li>
<li><a href="knn.html#球树实现" id="toc-球树实现"><span class="toc-section-number">32.2.3</span> 球树实现</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">32.3</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">32.3.1</span> Data Preparation</a></li>
<li><a href="knn.html#knn-modelling" id="toc-knn-modelling"><span class="toc-section-number">32.3.2</span> KNN Modelling</a></li>
<li><a href="knn.html#加权最近邻法-1" id="toc-加权最近邻法-1"><span class="toc-section-number">32.3.3</span> 加权最近邻法</a></li>
<li><a href="knn.html#over-training" id="toc-over-training"><span class="toc-section-number">32.3.4</span> Over-training</a></li>
</ul></li>
</ul></li>
<li><a href="svm.html#svm" id="toc-svm"><span class="toc-section-number">33</span> SVM</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">33.1</span> Introduction</a>
<ul>
<li><a href="svm.html#perceptron" id="toc-perceptron"><span class="toc-section-number">33.1.1</span> Perceptron</a></li>
<li><a href="svm.html#函数间隔与几何间隔" id="toc-函数间隔与几何间隔"><span class="toc-section-number">33.1.2</span> 函数间隔与几何间隔</a></li>
<li><a href="svm.html#svm支持向量" id="toc-svm支持向量"><span class="toc-section-number">33.1.3</span> SVM支持向量</a></li>
<li><a href="svm.html#svm模型目标函数与优化" id="toc-svm模型目标函数与优化"><span class="toc-section-number">33.1.4</span> SVM模型目标函数与优化</a></li>
<li><a href="svm.html#线性可分svm的算法过程" id="toc-线性可分svm的算法过程"><span class="toc-section-number">33.1.5</span> 线性可分SVM的算法过程</a></li>
<li><a href="svm.html#线性svm的软间隔最大化" id="toc-线性svm的软间隔最大化"><span class="toc-section-number">33.1.6</span> 线性SVM的软间隔最大化</a></li>
<li><a href="svm.html#线性不可分支持向量机与核函数" id="toc-线性不可分支持向量机与核函数"><span class="toc-section-number">33.1.7</span> 线性不可分支持向量机与核函数</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">33.2</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">33.2.1</span> Data Preparation</a></li>
<li><a href="svm.html#svm-modelling" id="toc-svm-modelling"><span class="toc-section-number">33.2.2</span> SVM Modelling</a></li>
<li><a href="advanced-linear-regression.html#model-selection" id="toc-model-selection"><span class="toc-section-number">33.2.3</span> Model Selection</a></li>
<li><a href="svm.html#character-selection" id="toc-character-selection"><span class="toc-section-number">33.2.4</span> Character selection</a></li>
</ul></li>
</ul></li>
<li><a href="tree-models.html#tree-models" id="toc-tree-models"><span class="toc-section-number">34</span> Tree models</a>
<ul>
<li><a href="tree-models.html#decision-tree-model" id="toc-decision-tree-model"><span class="toc-section-number">34.1</span> Decision Tree Model</a>
<ul>
<li><a href="tree-models.html#decision-tree-algorithm" id="toc-decision-tree-algorithm"><span class="toc-section-number">34.1.1</span> Decision tree algorithm</a></li>
<li><a href="tree-models.html#id3-algorithm" id="toc-id3-algorithm"><span class="toc-section-number">34.1.2</span> ID3 Algorithm</a></li>
<li><a href="tree-models.html#c4.5-algorithm" id="toc-c4.5-algorithm"><span class="toc-section-number">34.1.3</span> C4.5 Algorithm</a></li>
<li><a href="tree-models.html#cart-algorithm" id="toc-cart-algorithm"><span class="toc-section-number">34.1.4</span> CART Algorithm</a></li>
<li><a href="tree-models.html#pruning" id="toc-pruning"><span class="toc-section-number">34.1.5</span> Pruning</a></li>
<li><a href="tree-models.html#package-rpart" id="toc-package-rpart"><span class="toc-section-number">34.1.6</span> Package ‘rpart’</a></li>
</ul></li>
<li><a href="tree-models.html#random-forest" id="toc-random-forest"><span class="toc-section-number">34.2</span> Random Forest</a>
<ul>
<li><a href="tree-models.html#bootstrap-bagging" id="toc-bootstrap-bagging"><span class="toc-section-number">34.2.1</span> Bootstrap (Bagging)</a></li>
<li><a href="tree-models.html#bagging算法流程" id="toc-bagging算法流程"><span class="toc-section-number">34.2.2</span> bagging算法流程</a></li>
<li><a href="tree-models.html#random-forest-algorithm" id="toc-random-forest-algorithm"><span class="toc-section-number">34.2.3</span> Random Forest Algorithm</a></li>
<li><a href="tree-models.html#random-forest-promotion" id="toc-random-forest-promotion"><span class="toc-section-number">34.2.4</span> Random forest promotion</a></li>
<li><a href="tree-models.html#package-randomforest" id="toc-package-randomforest"><span class="toc-section-number">34.2.5</span> Package ‘randomForest’</a></li>
</ul></li>
<li><a href="regularization-penalized-regression.html#modelling" id="toc-modelling"><span class="toc-section-number">34.3</span> Modelling</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">34.3.1</span> Data preparation</a></li>
<li><a href="tree-models.html#regression-tree-1" id="toc-regression-tree-1"><span class="toc-section-number">34.3.2</span> Regression tree</a></li>
<li><a href="tree-models.html#classification-tree-1" id="toc-classification-tree-1"><span class="toc-section-number">34.3.3</span> Classification tree</a></li>
<li><a href="tree-models.html#random-forest-for-regression" id="toc-random-forest-for-regression"><span class="toc-section-number">34.3.4</span> Random forest for regression</a></li>
<li><a href="tree-models.html#random-forest-for-classification" id="toc-random-forest-for-classification"><span class="toc-section-number">34.3.5</span> Random forest for classification</a></li>
<li><a href="tree-models.html#皮玛印第安人糖尿病数据集" id="toc-皮玛印第安人糖尿病数据集"><span class="toc-section-number">34.3.6</span> 皮玛印第安人糖尿病数据集</a></li>
<li><a href="tree-models.html#使用随机森林进行特征选择" id="toc-使用随机森林进行特征选择"><span class="toc-section-number">34.3.7</span> 使用随机森林进行特征选择</a></li>
</ul></li>
<li><a href="tree-models.html#gradient-boosting" id="toc-gradient-boosting"><span class="toc-section-number">34.4</span> Gradient Boosting</a></li>
<li><a href="tree-models.html#gradient-descent" id="toc-gradient-descent"><span class="toc-section-number">34.5</span> Gradient Descent</a>
<ul>
<li><a href="tree-models.html#gradient" id="toc-gradient"><span class="toc-section-number">34.5.1</span> Gradient</a></li>
<li><a href="tree-models.html#gradient-descent-1" id="toc-gradient-descent-1"><span class="toc-section-number">34.5.2</span> Gradient Descent</a></li>
<li><a href="tree-models.html#gradient-descent-algorithm" id="toc-gradient-descent-algorithm"><span class="toc-section-number">34.5.3</span> Gradient Descent Algorithm</a></li>
<li><a href="tree-models.html#gradient-descent-familiy" id="toc-gradient-descent-familiy"><span class="toc-section-number">34.5.4</span> Gradient Descent Familiy</a></li>
<li><a href="tree-models.html#gbdt分类算法" id="toc-gbdt分类算法"><span class="toc-section-number">34.5.5</span> GBDT分类算法</a></li>
<li><a href="tree-models.html#package-gbm" id="toc-package-gbm"><span class="toc-section-number">34.5.6</span> Package ‘gbm’</a></li>
<li><a href="tree-models.html#极限梯度提升分类" id="toc-极限梯度提升分类"><span class="toc-section-number">34.5.7</span> 极限梯度提升——分类</a></li>
</ul></li>
<li><a href="tree-models.html#cubist-model" id="toc-cubist-model"><span class="toc-section-number">34.6</span> Cubist Model</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">34.6.1</span> Introduction</a></li>
<li><a href="tree-models.html#application-data-preparation" id="toc-application-data-preparation"><span class="toc-section-number">34.6.2</span> Application Data Preparation</a></li>
<li><a href="tree-models.html#fit-continious-outcome" id="toc-fit-continious-outcome"><span class="toc-section-number">34.6.3</span> Fit Continious Outcome</a></li>
<li><a href="tree-models.html#variable-importance" id="toc-variable-importance"><span class="toc-section-number">34.6.4</span> Variable Importance</a></li>
<li><a href="tree-models.html#summary-display" id="toc-summary-display"><span class="toc-section-number">34.6.5</span> Summary display</a></li>
<li><a href="tree-models.html#specific-parts" id="toc-specific-parts"><span class="toc-section-number">34.6.6</span> specific parts</a></li>
<li><a href="tree-models.html#ensembles-by-committees" id="toc-ensembles-by-committees"><span class="toc-section-number">34.6.7</span> Ensembles By Committees</a></li>
<li><a href="tree-models.html#nearestneighbors-adjustmemt" id="toc-nearestneighbors-adjustmemt"><span class="toc-section-number">34.6.8</span> Nearest–neighbors Adjustmemt</a></li>
<li><a href="tree-models.html#optimize-parameters" id="toc-optimize-parameters"><span class="toc-section-number">34.6.9</span> Optimize parameters</a></li>
<li><a href="tree-models.html#logistic-cv" id="toc-logistic-cv"><span class="toc-section-number">34.6.10</span> Logistic CV</a></li>
</ul></li>
</ul></li>
<li><a href="pca.html#pca" id="toc-pca"><span class="toc-section-number">35</span> PCA</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">35.1</span> Introduction</a>
<ul>
<li><a href="pca.html#component" id="toc-component"><span class="toc-section-number">35.1.1</span> Component</a></li>
<li><a href="pca.html#pca算法" id="toc-pca算法"><span class="toc-section-number">35.1.2</span> PCA算法</a></li>
<li><a href="pca.html#主成分旋转" id="toc-主成分旋转"><span class="toc-section-number">35.1.3</span> 主成分旋转</a></li>
<li><a href="pca.html#kernelized-pca" id="toc-kernelized-pca"><span class="toc-section-number">35.1.4</span> Kernelized PCA</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">35.2</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">35.2.1</span> Data preparation</a></li>
<li><a href="regularization-penalized-regression.html#modeling" id="toc-modeling"><span class="toc-section-number">35.2.2</span> Modeling</a></li>
</ul></li>
</ul></li>
<li><a href="cluster-analysis.html#cluster-analysis" id="toc-cluster-analysis"><span class="toc-section-number">36</span> Cluster Analysis</a>
<ul>
<li><a href="cluster-analysis.html#hierarchical-clustering" id="toc-hierarchical-clustering"><span class="toc-section-number">36.1</span> Hierarchical Clustering</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">36.1.1</span> Introduction</a></li>
<li><a href="cluster-analysis.html#hierarchical-clustering-algorithms" id="toc-hierarchical-clustering-algorithms"><span class="toc-section-number">36.1.2</span> Hierarchical clustering algorithms</a></li>
<li><a href="cluster-analysis.html#measure-the-dissimilarity-between-two-clusters-of-observations" id="toc-measure-the-dissimilarity-between-two-clusters-of-observations"><span class="toc-section-number">36.1.3</span> Measure the dissimilarity between two clusters of observations</a></li>
</ul></li>
<li><a href="cluster-analysis.html#k-means-clustering" id="toc-k-means-clustering"><span class="toc-section-number">36.2</span> K-means Clustering</a>
<ul>
<li><a href="cluster-analysis.html#algorithm" id="toc-algorithm"><span class="toc-section-number">36.2.1</span> Algorithm</a></li>
<li><a href="cluster-analysis.html#k-means" id="toc-k-means"><span class="toc-section-number">36.2.2</span> K-Means++</a></li>
<li><a href="cluster-analysis.html#elkan-k-means" id="toc-elkan-k-means"><span class="toc-section-number">36.2.3</span> elkan K-Means</a></li>
<li><a href="cluster-analysis.html#mini-batch-k-means" id="toc-mini-batch-k-means"><span class="toc-section-number">36.2.4</span> Mini Batch K-Means</a></li>
</ul></li>
<li><a href="cluster-analysis.html#gowers-coefficient-and-pam" id="toc-gowers-coefficient-and-pam"><span class="toc-section-number">36.3</span> Gower’s coefficient and PAM</a>
<ul>
<li><a href="cluster-analysis.html#gowers-coefficient" id="toc-gowers-coefficient"><span class="toc-section-number">36.3.1</span> Gower’s coefficient</a></li>
<li><a href="cluster-analysis.html#不同数据类型的相异度计算-距离法" id="toc-不同数据类型的相异度计算-距离法"><span class="toc-section-number">36.3.2</span> 不同数据类型的相异度计算 (距离法)</a></li>
<li><a href="cluster-analysis.html#pam" id="toc-pam"><span class="toc-section-number">36.3.3</span> PAM</a></li>
</ul></li>
<li><a href="cluster-analysis.html#birch-clustering" id="toc-birch-clustering"><span class="toc-section-number">36.4</span> BIRCH Clustering</a>
<ul>
<li><a href="cluster-analysis.html#birch-introduction" id="toc-birch-introduction"><span class="toc-section-number">36.4.1</span> BIRCH Introduction</a></li>
<li><a href="cluster-analysis.html#聚类特征cf与聚类特征树cf-tree" id="toc-聚类特征cf与聚类特征树cf-tree"><span class="toc-section-number">36.4.2</span> 聚类特征CF与聚类特征树CF Tree</a></li>
<li><a href="cluster-analysis.html#cf-tree的生成" id="toc-cf-tree的生成"><span class="toc-section-number">36.4.3</span> CF Tree的生成</a></li>
<li><a href="cluster-analysis.html#birch算法" id="toc-birch算法"><span class="toc-section-number">36.4.4</span> BIRCH算法</a></li>
</ul></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">36.5</span> Application</a>
<ul>
<li><a href="regularization-penalized-regression.html#data-preparation" id="toc-data-preparation"><span class="toc-section-number">36.5.1</span> Data preparation</a></li>
<li><a href="cluster-analysis.html#hierarchical-clustering-1" id="toc-hierarchical-clustering-1"><span class="toc-section-number">36.5.2</span> Hierarchical Clustering</a></li>
<li><a href="cluster-analysis.html#k-means-clustering-1" id="toc-k-means-clustering-1"><span class="toc-section-number">36.5.3</span> K-means Clustering</a></li>
<li><a href="cluster-analysis.html#gowers-coefficient-and-pam-1" id="toc-gowers-coefficient-and-pam-1"><span class="toc-section-number">36.5.4</span> Gower’s coefficient and PAM</a></li>
</ul></li>
</ul></li>
<li><a href="linear-discriminant-analysis-lda.html#linear-discriminant-analysis-lda" id="toc-linear-discriminant-analysis-lda"><span class="toc-section-number">37</span> linear discriminant analysis (LDA)</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">37.1</span> Introduction</a>
<ul>
<li><a href="linear-discriminant-analysis-lda.html#naive-bayes" id="toc-naive-bayes"><span class="toc-section-number">37.1.1</span> Naive Bayes</a></li>
<li><a href="linear-discriminant-analysis-lda.html#controlling-prevalence" id="toc-controlling-prevalence"><span class="toc-section-number">37.1.2</span> Controlling prevalence</a></li>
<li><a href="linear-discriminant-analysis-lda.html#qda" id="toc-qda"><span class="toc-section-number">37.1.3</span> QDA</a></li>
<li><a href="linear-discriminant-analysis-lda.html#lda" id="toc-lda"><span class="toc-section-number">37.1.4</span> LDA</a></li>
</ul></li>
<li><a href="linear-discriminant-analysis-lda.html#discriminant-analysis-algorithm" id="toc-discriminant-analysis-algorithm"><span class="toc-section-number">37.2</span> Discriminant analysis algorithm</a>
<ul>
<li><a href="knn.html#idee" id="toc-idee"><span class="toc-section-number">37.2.1</span> Idee</a></li>
<li><a href="linear-discriminant-analysis-lda.html#瑞利商rayleigh-quotient" id="toc-瑞利商rayleigh-quotient"><span class="toc-section-number">37.2.2</span> 瑞利商（Rayleigh quotient）</a></li>
<li><a href="linear-discriminant-analysis-lda.html#广义瑞利商-genralized-rayleigh-quotient" id="toc-广义瑞利商-genralized-rayleigh-quotient"><span class="toc-section-number">37.2.3</span> 广义瑞利商 genralized Rayleigh quotient</a></li>
<li><a href="linear-discriminant-analysis-lda.html#lda算法流程" id="toc-lda算法流程"><span class="toc-section-number">37.2.4</span> LDA算法流程</a></li>
<li><a href="linear-discriminant-analysis-lda.html#lda-application" id="toc-lda-application"><span class="toc-section-number">37.2.5</span> LDA Application</a></li>
<li><a href="linear-discriminant-analysis-lda.html#qda-1" id="toc-qda-1"><span class="toc-section-number">37.2.6</span> QDA</a></li>
</ul></li>
</ul></li>
<li><a href="neural-network.html#neural-network" id="toc-neural-network"><span class="toc-section-number">38</span> Neural Network</a>
<ul>
<li><a href="index.html#introduction" id="toc-introduction"><span class="toc-section-number">38.1</span> Introduction</a></li>
<li><a href="neural-network.html#反向传播方法进行训练的前馈神经网络" id="toc-反向传播方法进行训练的前馈神经网络"><span class="toc-section-number">38.2</span> 反向传播方法进行训练的前馈神经网络</a></li>
<li><a href="glmm-and-gam.html#application" id="toc-application"><span class="toc-section-number">38.3</span> Application</a>
<ul>
<li><a href="neural-network.html#数据准备" id="toc-数据准备"><span class="toc-section-number">38.3.1</span> 数据准备</a></li>
<li><a href="neural-network.html#模型构建" id="toc-模型构建"><span class="toc-section-number">38.3.2</span> 模型构建</a></li>
</ul></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">As a Statistician</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-comparison" class="section level1" number="10">
<h1><span class="header-section-number">Chapter 10</span> Multiple-Comparison</h1>
<div id="htmlwidget-a394c5136589fa0d97a8" style="width:672px;height:480px;" class="markmap html-widget"></div>
<script type="application/json" data-for="htmlwidget-a394c5136589fa0d97a8">{"x":{"data":"# \n## Multiple-Comparison\n### Introduction\n#### Multiplicity Problem\n#### Error Rates\n##### Comparisonwise Error Rate (CER)\n##### Familywise Error Rate (FWE) \n##### Control of the FWE: Weak and Strong\n##### Directional Decisions and Type III Error Rates\n##### False Discovery Rate (FDR)\n#### The adjusted P\n#### Basic Statistical Concepts\n#### Functions in glht package in R\n### Bonferroni and Šidák Methods\n#### LSD (least significance difference)\n#### Šidák\n#### Bonferroni\n#### Schweder-Spjøtvoll p-Value Plot \n### MCP among Treatment Means in the One-Way Balanced ANOVA \n#### LS-Means    \n#### The Multivariate t Distribution\n#### Calculating the Critical Value $c_$\n#### All Pairwise Comparisons and Studentized Range Distribution\n#### Tukey's Method for All Pairwise Comparisons\n#### Displaying Pairwise Comparisons Graphically\n#### Dunnett's Two-Sided Comparisons with a Control and Dunnett's Two-Sided Range Distribution\n#### Dunnett's One-Sided Comparisons with a Control\n#### Maximum Modulus Distribution, Multiple Inferences for Independent Estimates\n### Multiple Comparisons among Treatment Means in the One-Way Unbalanced ANOVA \n#### The Model and Estimates\n#### Tukey-Kramer Method \n#### Alternative Simulation-Based Method\n#### Pairwise Comparisons with Control \n#### Comparisons with the Average Mean–Analysis of Means (ANOM) \n### Generalizations for the Analysis of Covariance (ANCOVA) model\n#### Dunnett-Hsu Factor Analytic Approximation \n#### Hsu-Nelson Simulation-Based Approximation: CVADJUST Method\n#### Comparisons in ANCOVA Models with Interaction \n### Multiple Inferences for Infinite Sets of Parameters\n#### Scheffés Method\n#### Finding the Maximal Contrast\n#### Working-Hotelling method\n#### Discrete approximation method\n### Multiple Comparisons under Heteroscedasticity \n#### Introduction of heteroscedasticity\n#### Satterthwaite Approximation \n#### MaxT Method under Heteroscedasticity\n#### MinP Method under Heteroscedasticity\n### Closed and Stepwise Testing Methods \n#### Closed Family of Hypotheses\n#### Bonferroni-Holm Method \n#### Šidák-Holm Method \n#### Closed Fisher Combination Method \n#### Simes-Hommel Method \n#### Hochberg’s O(k) Step-Up\n#### Sequential Testing with Fixed Sequences \n#### Sequential Testing Using Gatekeeping Methods\n### Closed Testing of Pairwise Comparisons and General Contrasts\n#### Incorporating Logical Constraints\n#### Shaffer’s Method\n#### Extended Shaffer-Royen Method \n#### Step-down Dunnett test\n### Multiple Comparisons with Binary Data\n#### Introduction\n#### Multivariate Two-Sample Binary Outcomes","options":{"preset":"colorful","autoFit":true}},"evals":[],"jsHooks":[]}</script>
<div id="introduction" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> Introduction</h2>
<div id="multiplicity-problem" class="section level3" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> Multiplicity Problem</h3>
<p>There are real effects from multiplicity.</p>
<ul>
<li>confounding effects</li>
<li>nonresponse effects</li>
<li>placebo effects</li>
<li>learning effects</li>
<li>carryover effects</li>
</ul>
<p>The problem with all statistical tests is the fact that the (overall) error rate increases with increasing number of tests. <span class="math display">\[1 - (1 - \alpha)^m.\]</span></p>
</div>
<div id="error-rates" class="section level3" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> Error Rates</h3>
<div id="comparisonwise-error-rate-cer" class="section level4" number="10.1.2.1">
<h4><span class="header-section-number">10.1.2.1</span> Comparisonwise Error Rate (CER)</h4>
<p>Typical inferences are performed using the <span class="math inline">\(95 \%\)</span> confidence level or <span class="math inline">\(5 \%\)</span> significance level. In either case, the comparisonwise error rate (CER) is <span class="math inline">\(5 \%\)</span>. For confidence intervals, CER is defined as
<span class="math display">\[\mathrm{CER}=P(\text{Interval does not contain the parameter}).\]</span>
A typical two-sided confidence interval has the form</p>
<p>(parameter estimate) <span class="math inline">\(\pm\)</span> (critical value) <span class="math inline">\(\times\)</span> (standard error of the estimate).</p>
<p>For example, if the parameter of interest is a population mean <span class="math inline">\(\mu\)</span>, and the data are normally distributed, then the usual two-sided <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\mu\)</span> is
<span class="math display">\[
\bar{y} \pm t_{975, n-1} \times s_{y} / \sqrt{n}
\]</span>
where
- <span class="math inline">\(\bar{y}\)</span> is the estimate of the population mean
- <span class="math inline">\(s_{y}\)</span> is the sample standard deviation
- <span class="math inline">\(n\)</span> is the sample size
- <span class="math inline">\(s_{y} / \sqrt{n}\)</span> is the standard error of the estimated mean.</p>
<p>The critical value is <span class="math inline">\(t_{975, n-1}\)</span>, which is the <span class="math inline">\(1-0.05 / 2\)</span> quantile of the <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. A one-sided upper confidence interval for <span class="math inline">\(\mu\)</span> might be all values below
<span class="math display">\[
\bar{y}+t_{.95, n-1} \times s_{y} / \sqrt{n}
\]</span>
For tests of hypotheses, CER is defined as
<span class="math display">\[
\mathrm{CER}=P\left(\text { Reject } H_{0} \mid H_{0}\right. \text { is true). }
\]</span></p>
</div>
<div id="familywise-error-rate-fwe" class="section level4" number="10.1.2.2">
<h4><span class="header-section-number">10.1.2.2</span> Familywise Error Rate (FWE)</h4>
<p><strong>FWE for Simultaneous Confidence Intervals</strong></p>
<p>The FWE is the probability of at least one erroneous inference, defined for simultaneous confidence intervals as
<span class="math display">\[\text{FWE (at least one interval is incorrect) 1 (all intervals are correct).}\]</span></p>
<p><strong>FWE for Multiple Tests of Hypotheses</strong></p>
<p>The family-wise error rate is defined as the probability of rejecting at least one of the true <span class="math inline">\(H_0\)</span></p>
<p>In the case of multiple tests of hypotheses, some of the hypotheses <span class="math inline">\(H_{0 j}\)</span> could be true, and others could be false. Suppose the true state of nature is that the particular null hypotheses corresponding to <span class="math inline">\(j_{1}, \ldots, j_{m}\)</span> are true, and all other null hypotheses are false. In other words, <span class="math inline">\(H_{0 j_{1}}, H_{0 j_{2}}, \ldots, H_{0 j_{m}}\)</span> are true, and the remaining <span class="math inline">\((k-m)\)</span> hypotheses are false. The FWE is then defined as</p>
<p><span class="math display">\[FWE =P( \text{reject at least one of} H_{0 j_{1}}, H_{0 j_{2}}, \ldots, H_{0 j_{m}} \mid H_{0 j_{1}}, H_{0 j_{2}}, \ldots, H_{0 j_{m}} \text{all are true})\]</span>.</p>
</div>
<div id="control-of-the-fwe-weak-and-strong" class="section level4" number="10.1.2.3">
<h4><span class="header-section-number">10.1.2.3</span> Control of the FWE: Weak and Strong</h4>
<p>An MCP is said to control the FWE in the weak sense if it controls the FWE under the complete null configuration, but not under all other configurations. Despite the fact that the terms “weak control” and “strong control” are used in conjunction with FWE, you should note that they really refer to different error rates. <strong>Weak control refers only to controlling the probability that the complete null hypothesis is rejected</strong>, and allows Type I errors in excess of the usual 5% value (for example, for the component hypotheses).</p>
<p>A method that controls the FWE in the strong sense will result in a <strong>Type I error for any component hypothesis no more than 5% of the time</strong>.</p>
</div>
<div id="directional-decisions-and-type-iii-error-rates" class="section level4" number="10.1.2.4">
<h4><span class="header-section-number">10.1.2.4</span> Directional Decisions and Type III Error Rates</h4>
<p>A directional error (sometimes called a Type III error) is defined as the probability of misclassifying the sign of an effect. If you reject the hypothesis H0 : μ = 0 in favor of the (twosided) alternative HA : μ ≠ 0 using a CER= 0.05 level test, can you then claim that the sign of the true mean μ is the same as the sign of the estimated mean y ?</p>
<p>A type III error is where you correctly reject the null hypothesis, but it’s rejected for the wrong reason. This compares to a Type I error (incorrectly rejecting the null hypothesis) and a Type II error (not rejecting the null when you should). Type III errors are not considered serious, as they do mean you arrive at the correct decision. They usually happen because of random chance and are a rare occurrence.</p>
<p>You can also think of a Type III error as giving the right answer (i.e. correctly rejecting the null) to the wrong question. In other words, both your null and alternate hypotheses may be poorly worded or completely incorrect.</p>
<p>For MCPs, the Type III FWE is the probability that the sign of any tested effect is misclassified.</p>
</div>
<div id="false-discovery-rate-fdr" class="section level4" number="10.1.2.5">
<h4><span class="header-section-number">10.1.2.5</span> False Discovery Rate (FDR)</h4>
<p>Benjamini and Hochberg (1995) referred to the expected proportion of erroneously rejected null
hypotheses among the rejected ones as the False Discovery Rate, or FDR. Formally, for a given
family of k hypotheses and a given MCP, let R= number of hypotheses rejected, and let V = the
(unknown) number of erroneously rejected ones. Define V/R = 0 in case R=0. Then FDR is the
expected value of V/R</p>
<p><span class="math display">\[
\begin{array}{cccc}
\hline &amp; H_{0} \text { accepted } &amp; H_{0} \text { rejected } &amp; \text { Total } \\
\hline H_{0} \text { true } &amp; m-V &amp; V &amp; m \\
H_{0} \text { false } &amp; k-m-R+V &amp; R-V &amp; k-m \\
\text { Total } &amp; k-R &amp; R &amp; k \\
\hline
\end{array}
\]</span></p>
<p><span class="math display">\[
\mathrm{FDR}=E(V / R)
\]</span>
(assuming <span class="math inline">\(0 / 0\)</span> is defined as 0 ), whereas
<span class="math display">\[
\mathrm{FWE}=P(V&gt;0)
\]</span>
Under the overall null hypothesis, FDR and FWE are equal, since in this case <span class="math inline">\(V / R=1\)</span> when there is at least one rejection, and <span class="math inline">\(V / R=0\)</span> when there are no rejections.</p>
</div>
</div>
<div id="the-adjusted-p" class="section level3" number="10.1.3">
<h3><span class="header-section-number">10.1.3</span> The adjusted P</h3>
<p>Marginal p-value is based on the marginal p-values, which do not account for a multiplicity adjustment.</p>
<p>The adjusted P value is the smallest familywise significance level at which a particular comparison will be declared statistically significant as part of the multiple comparison testing. A separate adjusted P value is computed for each comparison in a family of comparisons.</p>
<p>The following show the R code about teh comparsion of adjusted and un-adjusted p-values</p>
<pre><code>library(multcomp)
data(thuesen,package = &quot;ISwR&quot;)
thuesen &lt;- read.sas7bdat(&quot;~/Desktop/SASUniversityEdition/myfolders/Daten/thuesen.sas7bdat&quot;)

thuesen.lm &lt;- lm(short.velocity ~ blood.glucose,data = thuesen)
thuesen.mc &lt;- glht(thuesen.lm, linfct = diag(2))

## With adjustment.
summary(thuesen.mc, 
        test = adjusted(type = &quot;bonferroni&quot;))
## without adjustment.
summary(thuesen.mc, test = univariate())</code></pre>
<p>Furthermore, there are different methods for p value adjust.</p>
<pre><code>Input = (&quot;
Food               Raw.p
 Blue_fish         .34
 Bread             .594
 Butter            .212
 Carbohydrates     .384
 Cereals_and_pasta .074
 Dairy_products    .94
 Eggs              .275
 Fats              .696
 Fruit             .269
 Legumes           .341
 Nuts              .06
&quot;)
Data = read.table(textConnection(Input),header=TRUE)
## Order data by p-value
Data = Data[order(Data$Raw.p),]

## Perform p-value adjustments and add to data frame
Data$Bonferroni = 
      p.adjust(Data$Raw.p, 
               method = &quot;bonferroni&quot;)
Data$BH = 
      p.adjust(Data$Raw.p, 
               method = &quot;BH&quot;)
Data$Holm = 
      p.adjust(Data$ Raw.p, 
               method = &quot;holm&quot;)
Data$Hochberg = 
      p.adjust(Data$ Raw.p, 
               method = &quot;hochberg&quot;)
Data$Hommel = 
      p.adjust(Data$ Raw.p, 
               method = &quot;hommel&quot;)
Data$BY = 
      p.adjust(Data$ Raw.p, 
               method = &quot;BY&quot;)

                Food Raw.p Bonferroni     BH Holm Hochberg    Hommel BY
11              Nuts 0.060      0.660 0.4070 0.66     0.66 0.5485714  1
5  Cereals_and_pasta 0.074      0.814 0.4070 0.74     0.74 0.5920000  1
3             Butter 0.212      1.000 0.5280 1.00     0.94 0.8700000  1
9              Fruit 0.269      1.000 0.5280 1.00     0.94 0.9280000  1
7               Eggs 0.275      1.000 0.5280 1.00     0.94 0.9280000  1
1          Blue_fish 0.340      1.000 0.5280 1.00     0.94 0.9400000  1
10           Legumes 0.341      1.000 0.5280 1.00     0.94 0.9400000  1
4      Carbohydrates 0.384      1.000 0.5280 1.00     0.94 0.9400000  1
2              Bread 0.594      1.000 0.7260 1.00     0.94 0.9400000  1
8               Fats 0.696      1.000 0.7656 1.00     0.94 0.9400000  1
6     Dairy_products 0.940      1.000 0.9400 1.00     0.94 0.9400000  1</code></pre>
</div>
<div id="basic-statistical-concepts" class="section level3" number="10.1.4">
<h3><span class="header-section-number">10.1.4</span> Basic Statistical Concepts</h3>
<p>The hypotheses described here are for the two-sample t-test, a common test for comparing two groups.
The assumptions of the two-sample t-test are important: random, independent samples from the two groups,
common variances, and normally distributed data.</p>
<ul>
<li>The null hypothesis is <span class="math inline">\(H_{0}: \mu_{1}=\mu_{2} ;\)</span> that is, the hypotheses that the population means are equal.</li>
<li>The alternative hypothesis is <span class="math inline">\(H_{A}: \mu_{1} \neq \mu_{2} ;\)</span> that is, the hypotheses that the population means are not equal.</li>
<li>The test statistic is <span class="math inline">\(T=\frac{\bar{X}_{1}-\bar{X}_{2}}{s_{p} \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}}\)</span>, where <span class="math inline">\(s_{p}^{2}=\frac{\left(n_{1}-1\right) s_{1}^{2}+\left(n_{2}-1\right) s_{2}^{2}}{n_{1}+n_{2}-2}\)</span>.</li>
<li>The decision rule is to reject <span class="math inline">\(H_{0}\)</span> if <span class="math inline">\(|T| \geq t_{1-\alpha / 2, n-2}\)</span>, where <span class="math inline">\(t_{1-\alpha / 2, n-2}\)</span> is the critical value.</li>
<li>The <span class="math inline">\(p\)</span> -value is the probability of observing a test statistic as large as or larger than the <span class="math inline">\(|T|\)</span> that was observed in the study, assuming the null hypothesis is true.</li>
</ul>
<p>By construction, the <span class="math inline">\(p\)</span> -value is found <span class="math inline">\(\leq \alpha\)</span> wherever <span class="math inline">\(|T| \geq t_{1-\alpha / 2, n-2} .\)</span> Thus, when all of the assumptions are satisfied,
<span class="math display">\[
P\left(p \leq \alpha \mid H_{0} \text { is true }\right)=\alpha
\]</span>
This leads to an important point:</p>
<p><strong>When the null hypothesis is true and when all assumptions are satisfied, the <span class="math inline">\(p\)</span> -value has a uniform distribution.</strong></p>
<p>From the parameter, the adjusted and unadjusted p value can be calculated</p>
<pre><code>## Calculation without adjustment.
## regression coefficients β and their covariance matrix

betahat &lt;- coef(thuesen.lm)
Vbetahat &lt;- vcov(thuesen.lm)
##  compute two individual t test statistics and correlation matrix
C &lt;- diag(2)
Sigma &lt;- diag(1 / sqrt(diag(C %*% Vbetahat %*% t(C))))
t &lt;- Sigma %*% C %*% betahat
Cor &lt;- Sigma %*% (C %*% Vbetahat %*% t(C)) %*% t(Sigma)


## Use the pmvt function of the mvtnorm package to calculate the adjusted p value from the basic bivariate t distribution
library(&quot;mvtnorm&quot;)
thuesen.df &lt;- nrow(thuesen) - length(betahat)
q &lt;- sapply(abs(t), function(x) 1 - pmvt(-rep(x, 2), 
                                         rep(x, 2), 
                                         corr = Cor,
                                         df = thuesen.df))
##  获得了多重调整的p值 q1 &lt;0.001且q2 = 0.064

##  compute the critical value u1−α 计算临界值
delta &lt;- rep(0, 2)
myfct &lt;- function(x, conf) {
  lower &lt;- rep(-x, 2)
  upper &lt;- rep(x, 2)
  pmvt(lower, upper, df = thuesen.df, corr = Cor,
           delta, abseps = 0.0001)[1] - conf
}
u &lt;- uniroot(myfct, lower = 1, upper = 5, conf = 0.95)$root
round(u, 3)</code></pre>
</div>
<div id="functions-in-glht-package-in-r" class="section level3" number="10.1.5">
<h3><span class="header-section-number">10.1.5</span> Functions in glht package in R</h3>
<table>
<colgroup>
<col width="58%" />
<col width="41%" />
</colgroup>
<thead>
<tr class="header">
<th>Functions</th>
<th>Descriptions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>glht.mc$model</code></td>
<td>The fitted model</td>
</tr>
<tr class="even">
<td><code>glht.mc$linfct</code></td>
<td>linear conflict functions</td>
</tr>
<tr class="odd">
<td><code>glht.mc$vcov</code></td>
<td>Covariance matrix</td>
</tr>
<tr class="even">
<td><code>glht.res &lt;- summary(glht.mc)  glht.res$test$pvalues</code></td>
<td>P-values</td>
</tr>
<tr class="odd">
<td><code>summary(warpbreaks.mc, test = Ftest())</code></td>
<td>Global F-Test</td>
</tr>
<tr class="even">
<td><code>summary(warpbreaks.mc, test = Chisqtest())</code></td>
<td>Wald测试</td>
</tr>
<tr class="odd">
<td><code>summary(warpbreaks.mc, test = univariate())</code></td>
<td>未调整的p值, 不考虑多重性执行了m个单独t检验</td>
</tr>
<tr class="even">
<td><code>summary(warpbreaks.mc, test = adjusted(type = "bonferroni"))</code></td>
<td>Bonferroni校正</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bonferroni-and-šidák-methods" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Bonferroni and Šidák Methods</h2>
<div id="lsd-least-significance-difference" class="section level3" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> LSD (least significance difference)</h3>
<p>least significant difference method. First proposed by Fisher, it is essentially a t-test.</p>
<p>For Two independent sample t test:</p>
<p><span class="math display">\[t=\frac{\bar{X}_{1}-\bar{X}_{2}}{\sqrt{S_{c}^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}}\]</span>
<span class="math display">\[S_{c}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}}{n_{1}+n_{2}-2}\]</span>
is the variance of the joint estimate of the two samples, under the premise that the sample variance is uniform</p>
<p>The LSD method also performs a t-test of pairwise comparison. The difference is that under the premise of meeting the homogeneity of variance, the LSD method uses the joint variance of <strong>all samples</strong> to estimate the standard error of the mean difference, rather than the <strong>joint variance of the two samples</strong> to be compared. Take the comparison of the mean difference between the three samples as an example, the formula is</p>
<!-- LSD法采用所有样本的联合方差来估计均数差的标准误，而不是要比较的两个样本的联合方差。 -->
<p><span class="math display">\[\begin{aligned}
&amp;S_{c}^{2}=\frac{\left(n_{1}-1\right) S_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2}+\left(n_{3}-1\right) S_{3}^{2}}{n_{1}+n_{2}+n_{3}-3}
\end{aligned}\]</span></p>
<p>The LSD method calculates the smallest significant difference, namely
<span class="math display">\[\begin{aligned}
&amp;L S D=t_{\alpha / 2} \sqrt{S_{c}^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)}
\end{aligned}\]</span></p>
<blockquote>
<p>The test level of LSD method for single comparison is still α. The LSD test has the highest sensitivity, but increases the probability of Type 1 error as the frequency of comparisons increases. To solve this problem, the Sidak method and the Bonferroni method appeared.</p>
</blockquote>
</div>
<div id="šidák" class="section level3" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Šidák</h3>
<p>The Sidak method is also a t test, and the calculation formula is the same as that of the LSD method. But the Sidak method adjusts for a. If there are k groups, the number of pairwise comparisons for the k groups is <span class="math inline">\(c=\frac{k(k-1)}{2}\)</span> Then after c comparisons, the cumulative probability of making a class of errors is:
<span class="math inline">\(1-\left(1-\alpha_{a}\right)^{c}\)</span> makes the above formula equal to 0.05, which can be reversed to deduce the adjusted <span class="math inline">\(\alpha_{a} \quad\)</span> . For example, after 6 post-hoc comparisons, the Sidak method = 0.0085, and <span class="math inline">\(\alpha_{a}\)</span> is used as the significance level of a single comparison. Obviously, <span class="math inline">\(\alpha_{a}\)</span> becomes smaller. Since <span class="math inline">\(\alpha_{a}\)</span> subtracts
You, the conclusion tends to accept the null hypothesis, so this method is much more conservative than the LSD method.</p>
<p>The rationale for this method is the Boole inequality:
<span class="math display">\[
P\left(A_{1} \text { or } A_{2} \text { or } \ldots \text { or } A_{k}\right) \leq P\left(A_{1}\right)+P\left(A_{2}\right)+\cdots+P\left(A_{k}\right)
\]</span></p>
<p><span class="math display">\[
P\left(\left\{\text { Reject } H_{01}\right\} \text { or }\left\{\text { Reject } H_{02}\right\}\right) \leq P\left(\text { Reject } H_{01}\right)+P\left(\text { Reject } H_{02}\right)
\]</span></p>
<p>For the Šidák method, recall that you can reject an individual hypothesis <span class="math inline">\(H_{0 j}\)</span> if <span class="math inline">\(p_{j} \leq 1-(1-\alpha)^{1 / k}\)</span>;
or equivalently, when <span class="math inline">\(1-\left(1-p_{j}\right)^{k} \leq \alpha\)</span>, where <span class="math inline">\(\alpha\)</span> is the desired FWE level. This gives you the Šidák adjusted <span class="math inline">\(p\)</span> -values.
Šidák Adjusted <span class="math inline">\(p\)</span> -value for Hypothesis <span class="math inline">\(H_{0 j}\)</span>;
<span class="math display">\[
\tilde{p}_{j}=1-\left(1-p_{j}\right)^{k} .
\]</span></p>
</div>
<div id="bonferroni" class="section level3" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> Bonferroni</h3>
<p>The Bonferroni method is similar to the Sidak method, and α is also adjusted on the basis of the LSD method. The adjustment method is based on Bonferroni’s inequality. If there are k groups, the calculation formula is
<span class="math display">\[\alpha^* = \alpha / k\]</span></p>
<p>The Bonferroni method is generally considered to be the most conservative. When the number of comparisons is small, the effect of this method is better. When the number of comparisons is large (such as k&gt;10), the adjustment of <span class="math inline">\(\alpha\)</span> is somewhat overcorrected and the effect is not as good as Sidak</p>
<pre><code>library(multcomp)
## Create a matrix where each *row* is a contrast
K &lt;- rbind(c(1, -1/2, -1/2), ## ctrl vs. average of trt1 and trt2
           c(1, -1, 0))      ## ctrl vs. trt1
fit.gh &lt;- glht(fit, linfct = mcp(group = K))

## Individual p-values
summary(fit.gh, test = adjusted(&quot;none&quot;))

## Bonferroni corrected p-values
summary(fit.gh, test = adjusted(&quot;bonferroni&quot;))</code></pre>
<p>While the Boole inequality is directly applicable to multiple hypothesis testing, the Bonferroni
inequality is directly applicable to <strong>simultaneous confidence intervals</strong>. As an example, suppose
that you have constructed k=10 simultaneous confidence intervals, all at the CER level
0.05/k=0.05/10=0.005, corresponding to 99.5% confidence intervals. Then the simultaneous
confidence level is</p>
<p><span class="math display">\[
\begin{array}{l}
P(\{\text { Interval } 1 \text { correct }\} \text { and } \ldots \text { and }\{\text { Interval } 10 \text { correct }\}) \\
\geq 1-\{P(\text { Interval } 1 \text { incorrect })+\cdots+P(\text { Interval } 10 \text { incorrect })\} \\
=1-10(0.005) \\
=0.95 .
\end{array}
\]</span></p>
<p>Bonferroni Adjusted <span class="math inline">\(p\)</span> -value for Hypothesis <span class="math inline">\(H_{0 j}\)</span>;
<span class="math display">\[
\tilde{p}_{j}=\left\{\begin{array}{ccc}
k p_{j} &amp; \text { if } &amp; k p_{j} \leq 1 \\
1 &amp; \text { if } &amp; k p_{j}&gt;1
\end{array}\right.
\]</span></p>
<p><strong>Bonferroni and Šidák Adjusted p-Values Using the DATA Step</strong></p>
<pre><code>data pvals1;
 input test pval @@;
 bon_adjp = min(1,10*pval);
 sid_adjp = 1 - (1-pval)**10;
datalines;
1 0.0911 2 0.8912
3 0.0001 4 0.5718
5 0.0132 6 0.9011
7 0.2012 8 0.0289
9 0.0498 10 0.0058
;
proc sort data=pvals1 out=pvals1;
 by pval;
proc print data=pvals1;
run; </code></pre>
<p><strong>Bonferroni and Šidák Adjusted p-Values Using PROC MULTTEST</strong></p>
<pre><code>proc multtest inpvalues(pval)=pvals1 bon sid out=outp;
proc sort data=outp out=outp;
 by pval;
proc print data=outp label;
run;</code></pre>
<p>Bonferroni and Šidák methods are easy to implement, and they correspond naturally to
confidence intervals. Šidák’s method provides slightly more power, but occasionally does not
control the FWE. However, when confidence intervals are not required, adaptive procedures are
more powerful, although they might not control the FWE in some cases. Simulation studies
should be used to understand this issue.</p>
<ul>
<li>For inferences with dependent data: ⇒ Use Bonferroni tests or intervals.</li>
<li>For inferences with independent data: ⇒ Use Šidák tests or intervals.</li>
</ul>
</div>
<div id="schweder-spjøtvoll-p-value-plot" class="section level3" number="10.2.4">
<h3><span class="header-section-number">10.2.4</span> Schweder-Spjøtvoll p-Value Plot</h3>
<p>This plot, which is very useful for assessing multiplicity, depicts the relationship between values <span class="math inline">\(q=1-p\)</span> and their rank order. Specifically, if <span class="math inline">\(q_{(1)} \leq \ldots \leq q_{(k)}\)</span> are the ordered values of the <span class="math inline">\(q\)</span> ’s, then <span class="math inline">\(q_{(1)}=1-p_{(k)}, q_{(2)}=1-p_{(k-1)}\)</span>, etc. The method is to plot the <span class="math inline">\(\left(j, q_{(j)}\right)\)</span> pairs. If the hypotheses all are truly null, then the <span class="math inline">\(p\)</span> -values will behave like a sample from the uniform distribution, and the graph should lie approximately on a straight diagonal line. Deviations from linearity, particularly points in the upper-right corner of the graph that are below the extended trend line from the points in the lower-left corner, suggest hypotheses that are false, since their <span class="math inline">\(p\)</span> -values are too small to be consistent with the uniform distribution.</p>
<pre><code>*** Schweder-Spjøtvoll p-Value Plot Using PROC MULTTEST ;
data pvals1;
 input test pval @@;
 bon_adjp = min(1,10*pval);
 sid_adjp = 1 - (1-pval)**10;
datalines;
1 0.0911 2 0.8912
3 0.0001 4 0.5718
5 0.0132 6 0.9011
7 0.2012 8 0.0289
9 0.0498 10 0.0058
;

ods graphics on;
proc multtest inpvalues(pval)=pvals1 plots= RawUniformPlot;
run;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/Schweder-Spj%C3%B8tvoll%201.PNG" alt="Figure: Schweder-Spjøtvoll (Uniform Probability) Plot" width="100%" />
<p class="caption">
(#fig:Schweder-Spjøtvoll p-Value Plot)Figure: Schweder-Spjøtvoll (Uniform Probability) Plot
</p>
</div>
<p>How does the plot look when there are no true effects</p>
<pre><code>ods graphics on;
proc multtest inpvalues(probt)=ttests plots= RawUniformPlot;
run;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/Schweder-Spj%C3%B8tvoll%202.PNG" alt="Figure: Plot of p-Values for the Cold Study" width="100%" />
<p class="caption">
(#fig:Plot of p-Values for the Cold Study)Figure: Plot of p-Values for the Cold Study
</p>
</div>
<p><strong>Adaptive Methods</strong></p>
<p>FWE of an MCP depends upon the number of true null hypotheses, m. In order to protect the FWE in all possible circumstances, you had to protect it for the complete null hypothesis where all nulls are true (i.e., where m=k). Thus, in the Bonferroni method, you use k as a divisor for the critical value (and as a multiplier for the adjusted p-value). If you know m, the number of true nulls, then you may use m as a divisor (or multiplier for adjusted p-values) instead of k, and still control the FWE. From the examination of the Schweder-Spjøtvoll plot, you can estimate the total number of true null hypotheses <span class="math inline">\(\hat m\)</span>, and modify the critical value of the Bonferroni procedure by rejecting any hypothesis<span class="math inline">\(H_{0 j}\)</span> for which <span class="math inline">\(p_{j} \leq \alpha / \hat{m} .\)</span></p>
<p><strong>Adaptive Holm (AHOLM) method specified in the following program.</strong></p>
<pre><code>*** Estimating the Number of Null Hypotheses;
ods graphics on;
proc multtest inpvalues(pval)=pvals1
 plots= RawUniformPlot aholm;
run;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/Schweder-Spj%C3%B8tvoll%203.PNG" alt="Figure: Estimating the Number of True Nulls Using Hochberg and Benjamini’s Method" width="100%" />
<p class="caption">
(#fig:g Hochberg and Benjamini’s)Figure: Estimating the Number of True Nulls Using Hochberg and Benjamini’s Method
</p>
</div>
</div>
</div>
<div id="mcp-among-treatment-means-in-the-one-way-balanced-anova" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> MCP among Treatment Means in the One-Way Balanced ANOVA</h2>
<div id="ls-means" class="section level3" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> LS-Means</h3>
<p>Least square means are means for groups that are adjusted for means of other factors in the model.</p>
<p>A least square mean, or LS-mean, is the predicted average within a certain category for a “balanced”
population; for this reason, the LS-means are also called the “estimated population marginal
means” (Searle, Speed, and Milliken, 1980).</p>
<p>LS-means correspond to Type III tests in the same way that arithmetic means correspond to
Type I tests; as with Type III tests, they are intended to be used with complicated, possibly
unbalanced models as simple means can be used with simple models. Also, as Type III tests are
identical to Type I tests for simple models, so LS-means are the same as arithmetic means when
the latter are appropriate.</p>
<pre><code>*** Selling Prices of Homes;
data House;
 input Location$ Price Sqfeet Age @@;
datalines;
A 213.5 2374 4 A 219.9 2271 8 A 227.9 2088 5
A 192.5 1645 8 A 203.0 1814 6 A 242.1 2553 7
A 220.5 1921 9 A 205.5 1854 2 A 201.2 1536 9
A 194.7 1677 3 A 229.0 2342 5 A 208.7 1862 4
A 199.7 1894 7 A 212.0 1774 9 A 204.8 1476 8
A 186.1 1466 7 A 203.5 1800 8 A 193.0 1491 5
A 199.5 1749 8 A 198.1 1690 7 A 244.8 2741 5
A 196.3 1460 5 A 195.1 1614 6 A 225.8 2244 6
A 226.9 2165 6 A 204.7 1828 4 B 174.2 1503 6
B 169.9 1689 6 B 177.0 1638 2 B 167.0 1276 6
B 198.9 2101 9 B 181.2 1668 5 B 185.7 2123 4
B 199.8 2208 5 B 155.7 1273 8 B 220.1 2519 4
B 209.1 2303 6 B 182.4 1800 3 B 202.7 2336 8
B 192.0 2100 6 B 184.1 1697 4 C 190.8 1674 4
C 198.2 2307 7 C 194.6 2152 5 C 187.9 1948 9
D 202.5 2258 2 D 181.3 1965 6 D 186.1 1772 3
D 194.7 2385 1 D 164.7 1345 4 D 193.5 2220 8
D 180.1 1883 8 D 192.3 2012 6 D 180.6 1898 5
E 205.3 2362 7 E 206.3 2362 7 E 184.3 1963 9
E 176.6 1941 7 E 182.4 1975 5 E 198.8 2529 6
E 186.8 2079 5 E 188.5 2190 4 E 177.5 1897 5
E 186.9 1946 4
; </code></pre>
<p><strong>Calculate the least squares mean in R</strong></p>
<p>Remark:</p>
<ul>
<li>Least squares mean according to reference grid
<ul>
<li>The combination of reference levels forms the reference table</li>
<li>If it is a factor, then each level of the factor is used as a reference level;</li>
<li>If it is a covariate, use the population mean of the covariate as the reference level;
*Once the reference table is established, the least squares mean is a simple forecast based on the table, or the marginal means of a list of forecast values.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="multiple-comparison.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lsmeans)</span>
<span id="cb11-2"><a href="multiple-comparison.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(oranges)</span></code></pre></div>
<pre><code>##   store day price1 price2  sales1  sales2
## 1     1   1     37     61 11.3208  0.0047
## 2     1   2     37     37 12.9151  0.0037
## 3     1   3     45     53 18.8947  7.5429
## 4     1   4     41     41 14.6739  7.0652
## 5     1   5     57     41  8.6493 21.2085
## 6     1   6     49     33  9.5238 16.6667</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="multiple-comparison.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(oranges)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    36 obs. of  6 variables:
##  $ store : Factor w/ 6 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 1 1 1 2 2 2 2 ...
##  $ day   : Factor w/ 6 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 2 3 4 5 6 1 2 3 4 ...
##  $ price1: int  37 37 45 41 57 49 49 53 53 53 ...
##  $ price2: int  61 37 53 41 41 33 49 53 45 53 ...
##  $ sales1: num  11.32 12.92 18.89 14.67 8.65 ...
##  $ sales2: num  0.0047 0.0037 7.5429 7.0652 21.2085 ...</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="multiple-comparison.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Build a model</span></span>
<span id="cb15-2"><a href="multiple-comparison.html#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="do">### store and day are factor variables, so they are used as fixed effects</span></span>
<span id="cb15-3"><a href="multiple-comparison.html#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="do">### price1 and price2 are used as covariates;</span></span>
<span id="cb15-4"><a href="multiple-comparison.html#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="multiple-comparison.html#cb15-5" aria-hidden="true" tabindex="-1"></a>oranges.lm1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(sales1 <span class="sc">~</span> price1 <span class="sc">+</span> price2 <span class="sc">+</span> store <span class="sc">+</span> day , <span class="at">data =</span> oranges)</span>
<span id="cb15-6"><a href="multiple-comparison.html#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(oranges.lm1)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: sales1
##           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## price1     1 516.59  516.59 29.0996 1.763e-05 ***
## price2     1  62.73   62.73  3.5334  0.072873 .  
## store      5 212.95   42.59  2.3991  0.068548 .  
## day        5 433.10   86.62  4.8793  0.003456 ** 
## Residuals 23 408.31   17.75                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="multiple-comparison.html#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Create a reference Grid</span></span>
<span id="cb17-2"><a href="multiple-comparison.html#cb17-2" aria-hidden="true" tabindex="-1"></a>oranges.rg1 <span class="ot">&lt;-</span> <span class="fu">ref.grid</span>(oranges.lm1)</span>
<span id="cb17-3"><a href="multiple-comparison.html#cb17-3" aria-hidden="true" tabindex="-1"></a>oranges.rg1</span></code></pre></div>
<pre><code>## &#39;emmGrid&#39; object with variables:
##     price1 = 51.222
##     price2 = 48.556
##     store = 1, 2, 3, 4, 5, 6
##     day = 1, 2, 3, 4, 5, 6</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="multiple-comparison.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Obtain the predicted value of different reference level combinations</span></span>
<span id="cb19-2"><a href="multiple-comparison.html#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="do">### Using summary() or predict()</span></span>
<span id="cb19-3"><a href="multiple-comparison.html#cb19-3" aria-hidden="true" tabindex="-1"></a>oranges.rg1.prediction <span class="ot">&lt;-</span> <span class="fu">summary</span>(oranges.rg1)</span>
<span id="cb19-4"><a href="multiple-comparison.html#cb19-4" aria-hidden="true" tabindex="-1"></a>oranges.rg1.prediction</span></code></pre></div>
<pre><code>##  price1 price2 store day prediction   SE df
##    51.2   48.6 1     1         2.92 2.72 23
##    51.2   48.6 2     1         4.96 2.38 23
##    51.2   48.6 3     1         3.20 2.38 23
##    51.2   48.6 4     1         6.20 2.36 23
##    51.2   48.6 5     1         5.54 2.36 23
##    51.2   48.6 6     1        10.56 2.37 23
##    51.2   48.6 1     2         3.85 2.70 23
##    51.2   48.6 2     2         5.89 2.34 23
##    51.2   48.6 3     2         4.13 2.34 23
##    51.2   48.6 4     2         7.13 2.35 23
##    51.2   48.6 5     2         6.47 2.33 23
##    51.2   48.6 6     2        11.49 2.34 23
##    51.2   48.6 1     3        11.02 2.53 23
##    51.2   48.6 2     3        13.06 2.42 23
##    51.2   48.6 3     3        11.30 2.42 23
##    51.2   48.6 4     3        14.30 2.43 23
##    51.2   48.6 5     3        13.64 2.36 23
##    51.2   48.6 6     3        18.66 2.35 23
##    51.2   48.6 1     4         6.10 2.65 23
##    51.2   48.6 2     4         8.14 2.35 23
##    51.2   48.6 3     4         6.38 2.35 23
##    51.2   48.6 4     4         9.38 2.39 23
##    51.2   48.6 5     4         8.72 2.34 23
##    51.2   48.6 6     4        13.74 2.34 23
##    51.2   48.6 1     5        12.80 2.44 23
##    51.2   48.6 2     5        14.84 2.47 23
##    51.2   48.6 3     5        13.08 2.47 23
##    51.2   48.6 4     5        16.08 2.52 23
##    51.2   48.6 5     5        15.42 2.40 23
##    51.2   48.6 6     5        20.44 2.37 23
##    51.2   48.6 1     6         8.75 2.79 23
##    51.2   48.6 2     6        10.79 2.34 23
##    51.2   48.6 3     6         9.03 2.34 23
##    51.2   48.6 4     6        12.03 2.36 23
##    51.2   48.6 5     6        11.37 2.35 23
##    51.2   48.6 6     6        16.39 2.37 23</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="multiple-comparison.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="do">### Get LS Mean for day</span></span>
<span id="cb21-2"><a href="multiple-comparison.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lsmeans</span>(oranges.rg1,<span class="st">&quot;day&quot;</span>)</span></code></pre></div>
<pre><code>##  day lsmean   SE df lower.CL upper.CL
##  1     5.56 1.77 23     1.91     9.22
##  2     6.49 1.73 23     2.92    10.07
##  3    13.66 1.75 23    10.04    17.29
##  4     8.74 1.73 23     5.16    12.33
##  5    15.44 1.79 23    11.75    19.14
##  6    11.39 1.77 23     7.74    15.05
## 
## Results are averaged over the levels of: store 
## Confidence level used: 0.95</code></pre>
<p><strong>coefficients</strong></p>
<p>Construct confidence intervals for and perform hypothesis tests on linear combinations using the ESTIMATE statement;
The ESTIMATE statement specifies the coefficients in the vector <span class="math inline">\(\mathbf{c}\)</span> that define the linear combination <span class="math inline">\(\mathbf{c}^{\prime} \boldsymbol{\beta}\)</span> that you want to estimate.</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age;
 estimate &#39;gamma&#39; Intercept 1 Location 0 0 0 0 0 Sqfeet 0 Age 0 ;
 estimate &#39;m1-m2&#39; Intercept 0 Location 1 -1 0 0 0 Sqfeet 0 Age 0 ;
run; quit; </code></pre>
<p><strong>Inference for Estimable Linear Combinations</strong></p>
<p><span class="math display">\[
\frac{\mathbf{c}^{\prime} \hat{\beta}-\mathbf{c}^{\prime} \boldsymbol{\beta}}{\text { s.e. }\left(\mathbf{c}^{\prime} \boldsymbol{\beta}\right)} \sim t_{d / \varepsilon}
\]</span>
where the standard error of <span class="math inline">\(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\)</span> is
<span class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)=\hat{\sigma} \sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{c}} \text { . }
\]</span>
The <span class="math inline">\(t\)</span> -statistic for testing <span class="math inline">\(H_{0}: \mathbf{c}^{\prime} \boldsymbol{\beta}=0\)</span> is then
<span class="math display">\[
t=\frac{\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}}{\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)}
\]</span>
and the two-sided <span class="math inline">\(p\)</span> -value is
<span class="math display">\[
p=P\left(\left|T_{d j e}\right| \geq|t|\right)=2 P\left(T_{d f e} \geq|t|\right) .
\]</span></p>
<p>In order to compute the confidence interval for the ‘m1-m2’ linear combination, use the
CLPARM option on the MODEL statement, as in the following program.</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age / clparm;
 estimate &#39;m1-m2&#39; Intercept 0 Location 1 -1 0 0 0 Sqfeet 0 Age 0 ;
run; quit;</code></pre>
</div>
<div id="the-multivariate-t-distribution" class="section level3" number="10.3.2">
<h3><span class="header-section-number">10.3.2</span> The Multivariate t Distribution</h3>
<p>Most of the classical MCPs fall under the general umbrella of “MaxT methods”; that is, they are based on the distribution of the <strong>maximum of multiple t-statistics.</strong></p>
<p>Confidence intervals for the estimable functions <span class="math inline">\(\mathbf{c}_{i}^{\prime} \boldsymbol{\beta}\)</span> have the form
<span class="math display">\[
\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}} \pm c_{\alpha} s . e .\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)
\]</span>
where <span class="math inline">\(c_{\alpha}\)</span> is a critical value that is selected to make the <span class="math inline">\(\mathrm{FWE}=\alpha\)</span> for the set of confidence intervals for the family <span class="math inline">\(\mathbf{c}_{1}^{\prime} \boldsymbol{\beta}, \mathbf{c}_{2}^{\prime} \boldsymbol{\beta}, \ldots, \mathbf{c}_{k}^{\prime} \boldsymbol{\beta}\)</span>.</p>
<p>To find the right <span class="math inline">\(c_{\alpha}\)</span>, you can use the joint distribution of the statistics
<span class="math display">\[
T_{i}=\frac{\mathbf{c}_{i}^{\prime} \hat{\boldsymbol{\beta}}-\mathbf{c}_{i}^{\prime} \boldsymbol{\beta}}{\operatorname{s.e.}\left(\mathbf{c}_{i}^{\prime} \hat{\boldsymbol{\beta}}\right)}, \quad i=1, \ldots, k
\]</span>
The collection of random variables <span class="math inline">\(\left\{T_{1}, T_{2}, \ldots, T_{k}\right\}\)</span> has the multivariate <span class="math inline">\(t\)</span> distribution when the classical linear model assumptions are valid.</p>
<p>If <span class="math inline">\(\mathbf{Z}=\left(Z_{1}, \ldots, Z_{k}\right)\)</span> is distributed as multivariate normal with zero mean with known covariance matrix <span class="math inline">\(\mathbf{R}\)</span>, and if <span class="math inline">\(V\)</span> is distributed as Chi-Square with <span class="math inline">\(d f\)</span> degrees of freedom, independent of <span class="math inline">\(\mathbf{Z}\)</span>, then
<span class="math display">\[
\mathbf{T}=\frac{\mathbf{Z}}{\sqrt{V / d f}}
\]</span>
has the multivariate <span class="math inline">\(t\)</span> distribution with dispersion matrix <span class="math inline">\(\mathbf{R}\)</span> and degrees of freedom <span class="math inline">\(d f\)</span>.</p>
<p>First, define the contrast matrix
<span class="math display">\[
\mathbf{C}=\left(\mathbf{c}_{1}, \ldots, \mathbf{c}_{k}\right)
\]</span>
Then you can write the estimates of the set of <span class="math inline">\(k\)</span> estimable linear combinations as the <span class="math inline">\(k \times 1\)</span> vector <span class="math inline">\(\mathbf{C}^{\prime} \hat{\boldsymbol{\beta}}\)</span>, which is distributed as multivariate normal when the assumptions are true:
<span class="math display">\[
\mathbf{C}^{\prime} \hat{\boldsymbol{\beta}} \sim \boldsymbol{N}_{k}\left(\mathbf{C}^{\prime} \boldsymbol{\beta}, \sigma^{2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{C}\right)
\]</span>
(If the X matrix contains random variables, then this is the conditional distribution, given the observed <span class="math inline">\(\mathbf{X}\)</span>.)
From this expression you can derive <span class="math inline">\(Z\)</span> -statistics:
<span class="math display">\[
Z_{i}=\frac{\mathbf{c}_{i}^{\prime} \hat{\boldsymbol{\beta}}-\mathbf{c}_{i}^{\prime} \boldsymbol{\beta}}{\sigma \sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{c}}} \sim N(0,1)
\]</span>
You can write the entire set of <span class="math inline">\(Z\)</span> -statistics in matrix/vector notation as
<span class="math display">\[
\mathbf{Z}=\left(\sigma^{2} \mathbf{D}\right)^{-1 / 2}\left(\mathbf{C}^{\prime} \hat{\boldsymbol{\beta}}-\mathbf{C}^{\prime} \boldsymbol{\beta}\right),
\]</span>
where <span class="math inline">\(\mathbf{D}\)</span> is the diagonal matrix having diagonal elements <span class="math inline">\(\mathbf{c}_{i}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{c}_{i}\)</span>, thus
<span class="math display">\[
\mathbf{Z} \sim N_{k}\left(0, \mathbf{D}^{-1 / 2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{C D}^{-1 / 2}\right)
\]</span>
The <span class="math inline">\(\mathbf{R}\)</span> matrix is the <strong>covariance matrix</strong> of the <span class="math inline">\(\mathbf{Z}\)</span> vector:
<span class="math display">\[
\mathbf{R}=\mathbf{D}^{-1 / 2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{C} \mathbf{D}^{-1 / 2}
\]</span></p>
<p>Notice that
- <span class="math inline">\(\mathbf{R}\)</span> is the correlation matrix of the <span class="math inline">\(Z \mathrm{~s}\)</span> as there are <span class="math inline">\(1 \mathrm{~s}\)</span> on the diagonal.
- <span class="math inline">\(\mathbf{R}\)</span> is a known matrix, depending on no unknown parameters.
- The correlations between the <span class="math inline">\(Z\)</span> ’s depend on
+ the set of linear combinations to be estimated (determined by C), and
+ the design of the study and the model used for the analysis (determined by <span class="math inline">\(\mathbf{X}\)</span> ).</p>
<p>Now, to get the vector of <span class="math inline">\(t\)</span> statistics, you can write
<span class="math display">\[
\mathbf{T}=\frac{\mathbf{Z}}{s / \sigma}
\]</span>
To remove the <span class="math inline">\(\sigma\)</span> in the <span class="math inline">\(Z\)</span> statistic and replace it with <span class="math inline">\(s\)</span>.
Under the model assumptions,
<span class="math display">\[
\frac{d f \times s^{2}}{\sigma^{2}} \sim \chi_{d f}^{2}
\]</span>
and is independent of <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, thus establishing the representation of <span class="math inline">\(\mathbf{T}\)</span> as
<span class="math display">\[
\mathbf{T}=\frac{\mathbf{Z}}{\sqrt{V / d f}}
\]</span>
and hence that it has the multivariate <span class="math inline">\(t\)</span> distribution with dispersion matrix <span class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{C} \mathbf{D}^{-1 / 2}\)</span></p>
<p><strong>Obtaining the R Matrix for Multiple Comparisons</strong></p>
<pre><code>proc orthoreg data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmestimate Location
 &#39;m1-m2&#39; 1 -1 0 0 0,
 &#39;m2-m3&#39; 0 1 -1 0 0,
 &#39;m3-m4&#39; 0 0 1 -1 0,
 &#39;m4-m5&#39; 0 0 0 1 -1 / corr;
run;</code></pre>
</div>
<div id="calculating-the-critical-value-c_alpha" class="section level3" number="10.3.3">
<h3><span class="header-section-number">10.3.3</span> Calculating the Critical Value <span class="math inline">\(c_{\alpha}\)</span></h3>
<p>Suppose for simplicity that the critical value <span class="math inline">\(c_{\alpha}\)</span> is for two-sided intervals and tests. There are many ways that you can find it, or at least approximate it. First, you might try to integrate the multivariate <span class="math inline">\(t\)</span> distribution and solve for <span class="math inline">\(c_{\alpha}\)</span> :
<span class="math display">\[
\int_{-c_{\alpha}}^{c_{c}} \ldots \int_{-c_{\alpha}}^{c_{c}} f\left(t_{1}, \ldots, t_{k} ; d f, \mathbf{R}\right) d t_{1} \ldots d t_{k}=1-\alpha
\]</span>
This approach is often impractical because the complicated form of the multivariate <span class="math inline">\(t\)</span> distribution function <span class="math inline">\(f\left(t_{1}, \ldots, t_{k} ; d f, \mathbf{R}\right)\)</span> precludes analytical integration; numerical integration methods also can founder if there are too many dimensions <span class="math inline">\(k\)</span>.</p>
<p>The value <span class="math inline">\(c_{\alpha}\)</span> is found the following ways:</p>
<ul>
<li><strong>Exact Analytic Solution</strong>: When the data are balanced and the comparisons are simple, the multivariate <span class="math inline">\(t\)</span> integral simplifies and is solvable in terms of known and special mathematical distribution functions like “Tukey’s studentized range distribution” and “Dunnett’s range distribution”<br />
</li>
<li><strong>Conservative Analytic Solution</strong>: In some cases with unbalanced data and/or more complex comparisons, the exact analytic solution provides a conservative solution in that the <span class="math inline">\(c_{\alpha}\)</span> is larger than it needs to be.</li>
<li><strong>Approximate Analytic Solution</strong>: In some cases, with unbalanced data and/or more complex comparisons, the exact analytic solution provides an approximate solution in that the <span class="math inline">\(c_{\alpha}\)</span> is perhaps larger than it needs to be, or perhaps smaller.</li>
<li><strong>Simple Monte Carlo Solution</strong>: By simulating many multivariate <span class="math inline">\(t\)</span> vectors, you can estimate the <span class="math inline">\(1-\alpha\)</span> quantile of <span class="math inline">\(\max T\)</span>.</li>
<li><strong>Control Variate Monte Carlo Solution</strong>: This method also proceeds by simulating multivariate <span class="math inline">\(t\)</span> vectors, but then using control variates to reduce the variance of the estimate of the <span class="math inline">\(1-\alpha\)</span> quantile of <span class="math inline">\(\max \mathrm{T}\)</span>.</li>
<li><strong>Quasi-Monte Carlo Solution</strong>: This method proceeds by approximating the multiple integral shown above by using a systematic grid of <span class="math inline">\(t\)</span> vectors. The method can often provide much better accuracy with far fewer <span class="math inline">\(t\)</span> vectors (Genz and Bretz, 2009).</li>
</ul>
</div>
<div id="all-pairwise-comparisons-and-studentized-range-distribution" class="section level3" number="10.3.4">
<h3><span class="header-section-number">10.3.4</span> All Pairwise Comparisons and Studentized Range Distribution</h3>
<p>In general, there are such comparisons.</p>
<p><span class="math display">\[
\left(\begin{array}{l}
g \\
2
\end{array}\right)=\frac{g !}{2 !(g-2) !}=\frac{g(g-1)}{2}
\]</span>
For all simultaneous pairwise comparisons <span class="math inline">\(\mu_{i}-\mu_{i^{\prime}}, 1 \leq i, i^{\prime} \leq g\)</span>, the critical value <span class="math inline">\(c_{\alpha}\)</span> must satisfy
<span class="math display">\[
P\left(\bar{y}_{i}-\bar{y}_{i^{\prime}}-c_{\alpha} \hat{\sigma} \sqrt{2 / n} \leq \mu_{i}-\mu_{i^{\prime}} \leq \bar{y}_{i}-\bar{y}_{i^{\prime}}+c_{\alpha} \hat{\sigma} \sqrt{2 / n}, \text { for all } i, i^{\prime}\right)=1-\alpha
\]</span>
or equivalently
<span class="math display">\[
P\left(\max _{i, i^{\prime}} \frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)\right|}{\hat{\sigma} \sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span></p>
<p>This formula shows the “MaxT”. In the balanced ANOVA, the
MaxT statistic has a particularly simple form because the denominator standard error
<span class="math inline">\(\hat{\sigma} \sqrt{2 / n}\)</span> is the same for all <span class="math inline">\(t\)</span> -statistics. This simplification, along with the special structure of the set of all pairwise comparisons, allows for <span class="math inline">\(c_{\alpha}\)</span> to be calculated analytically from the studentized range distribution. When the standard errors differ for the various <span class="math inline">\(t\)</span> -statistics, more complex approximations such as simulation-based methods are needed.</p>
<p><strong>Studentized Range Distribution</strong></p>
<p>If <span class="math inline">\(Z_{1}, \ldots, Z_{g}\)</span> are independent standard normal random variables, and <span class="math inline">\(V\)</span> is a random variable distributed as chi-square with <span class="math inline">\(v\)</span> degrees of freedom, independent of the <span class="math inline">\(Z \mathrm{~s}\)</span>, then
<span class="math display">\[
Q_{g, v}^{R}=\max _{i, i^{\prime}} \frac{\left|Z_{i}-Z_{i^{\prime}}\right|}{\sqrt{V / v}}
\]</span>
has the studentized range distribution with parameters <span class="math inline">\(g\)</span> and <span class="math inline">\(r\)</span>.
With this definition and some algebraic manipulation, along with well-known results concerning distributions involving normally distributed variables, you can show that <span class="math inline">\(c_{\alpha}\)</span> satisfies
<span class="math display">\[
P\left(\frac{Q_{g, g(n-1)}^{R}}{\sqrt{2}} \leq c_{\alpha}\right)=1-\alpha
\]</span>
or equivalently that
<span class="math display">\[
c_{\alpha}=\frac{q_{1-\alpha, g, g(n-1)}^{R}}{\sqrt{2}}
\]</span>
where <span class="math inline">\(q_{1-\alpha_{m}}^{R}\)</span> is the <span class="math inline">\(1-\alpha\)</span> quantile of the studentized range distribution.</p>
<p><strong>“Hand Calculation” of Studentized Range Critical Value</strong></p>
<p>The quantiles <span class="math inline">\(q_{1-\alpha_{\alpha}}^{R}\)</span> of the studentized range distribution can be calculated using the PROBMC
function in SAS, which evaluates the cumulative probability distribution function of the random variable <span class="math inline">\(Q_{g, v}^{R} .\)</span></p>
<pre><code>data;
 qval = probmc(&quot;RANGE&quot;,.,.95,45,5);
 c_alpha = qval/sqrt(2);
run; </code></pre>
<p><strong>Implementation</strong></p>
<p>Obtaining Pairwise Comparisons Using the LSMEANS Statement</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmeans Location / tdiff;
run; quit;</code></pre>
<p>Pairwise Comparisons with a Control, For example, perhaps region B is considered the premium region, and you wish
to know how other regions compare with it.</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmeans Location / tdiff=control(&#39;B&#39;);
run; quit;</code></pre>
</div>
<div id="tukeys-method-for-all-pairwise-comparisons" class="section level3" number="10.3.5">
<h3><span class="header-section-number">10.3.5</span> Tukey’s Method for All Pairwise Comparisons</h3>
<p>Confidence intervals for all pairwise comparisons in the balanced ANOVA that use the critical value <span class="math inline">\(c_{\alpha}=q_{1-\alpha, g, g(n-1)}^{R} / \sqrt{2}\)</span> from the studentized range distribution are commonly said to be constructed by “Tukey’s Method,” after Tukey (1953). The intervals may also be called “Tukey intervals” in this case. When testing hypotheses <span class="math inline">\(H_{0}: \mu_{i}-\mu_{i^{\prime}}=0\)</span>, either by checking to see if 0 is inside the Tukey interval or by comparing <span class="math inline">\(\left|t_{i, i^{\prime}}\right|\)</span> to <span class="math inline">\(c_{\alpha}=q_{1-\alpha, g, g(n-1)}^{R} / \sqrt{2}\)</span>, the tests are called “Tukey tests.”</p>
<p><strong>Compare the Tukey intervals with the Bonferroni intervals</strong></p>
<p>Since there are <span class="math inline">\(5 \times 4 / 2=10\)</span> pairwise comparisons among the five groups, the Bonferroni critical value uses <span class="math inline">\(\alpha^{\prime}=0.05 / 10=0.005\)</span>, and the critical value nnis <span class="math inline">\(t_{0.9975,45}=2.9521\)</span>. The reason for the difference between the Bonferroni critical value and the Tukey critical value, <span class="math inline">\(2.9521\)</span> vs. <span class="math inline">\(2.84145\)</span>, is that the Tukey critical value is <strong>based on the precise distribution of the 10 pairwise statistics</strong> <span class="math inline">\(\left\{\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)\right\} /(\hat{\sigma} \sqrt{2 / n}) .\)</span> There are correlations among these statistics because there are
many common random elements. For example, the statistics <span class="math inline">\(\left\{\left(\bar{y}_{1}-\mu_{1}\right)-\left(\bar{y}_{2}-\mu_{2}\right)\right\} /(\hat{\sigma} \sqrt{2 / n})\)</span> and <span class="math inline">\(\left\{\left(\bar{y}_{1}-\mu_{1}\right)-\left(\bar{y}_{3}-\mu_{3}\right)\right\} /(\hat{\sigma} \sqrt{2 / n})\)</span> are <strong>correlated</strong> because both contain the common random elements <span class="math inline">\(\bar{y}_{1}\)</span> and <span class="math inline">\(\hat{\sigma}\)</span>.</p>
<p>In summary, Tukey’s intervals control the FWE precisely (under the assumptions of the model), while the Bonferroni intervals over-control and the unadjusted intervals under-control.</p>
<p><strong>SAS Implementation</strong></p>
<pre><code>***  PROC GLM Calculation of Tukey Adjusted p-Values;
proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 lsmeans Diet/pdiff adjust=tukey;
run; quit;</code></pre>
<p><strong>Simultaneous Intervals for Mean Differences</strong></p>
<ul>
<li>Unadjusted Intervals</li>
<li>Bonferroni Intervals</li>
<li>Tukey Intervals</li>
</ul>
<pre><code>proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 means Diet/cldiff t bon tukey;
run; </code></pre>
<p><strong>R Implementation</strong></p>
<pre><code>## contrMat specify other contrast matrices in advance, such as &quot;Dunnett&quot;, &quot;Williams&quot;
## Tukey 1
data(warpbreaks)
warpbreaks.aov &lt;- aov(breaks ~ tension, data = warpbreaks)
warpbreaks.mc &lt;- glht(warpbreaks.aov, 
                      linfct = mcp(tension = &quot;Tukey&quot;))
                      
## alternative 1
glht(warpbreaks.aov,linfct = mcp(tension = c(&quot;M - L = 0&quot;,
                                             &quot;H - L = 0&quot;,
                                             &quot;H - M = 0&quot;)))

## alternative 2                  
contr &lt;- rbind(&quot;M - L&quot; = c(-1,  1, 0),
               &quot;H - L&quot; = c(-1,  0, 1),
               &quot;H - M&quot; = c( 0, -1, 1));
glht(warpbreaks.aov, linfct = mcp(tension = contr))

## alternative 3
glht(warpbreaks.aov,
     linfct = cbind(0, contr %*% contr.treatment(3)))
     
     
## Multiple Comparisons of Means: Tukey Contrasts
## Linear Hypotheses:
##           Estimate
## M - L == 0  -10.000
## H - L == 0  -14.722
## H - M == 0   -4.722


## Calculate and plot simultaneous confidence intervals
warpbreaks.ci &lt;- confint(warpbreaks.mc, level = 0.95)
warpbreaks.ci
 
## Unadjusted (marginal) confidence interval
confint(warpbreaks.mc, calpha = univariate_calpha())</code></pre>
<p><strong>The Tukey Adjusted p-Value</strong></p>
<p><span class="math display">\[
\tilde{p}_{i, i^{\prime}}=P\left(Q_{g, g(n-1)}^{R} \geq \sqrt{2}\left|t_{i, i}\right|\right)
\]</span>
By comparison, the ordinary (unadjusted) <span class="math inline">\(p\)</span> -value is given by <span class="math inline">\(p_{i, i^{\prime}}=2 P\left(T_{g(n-1)} \geq t_{i, i} \mid\right)\)</span>, where <span class="math inline">\(T_{V}\)</span> denotes a Student’s <span class="math inline">\(t\)</span> -distributed random variable with <span class="math inline">\(v\)</span> degrees of freedom (here, <span class="math inline">\(v=g(n-1))\)</span>.</p>
<pre><code>**** “By Hand” Calculation of Raw and Tukey Adjusted p-Values;
data;
 n=10; g=5; df=g*(n-1);
 Mean_A=12.05; Mean_B=11.02; MSE=0.993422;
 tstat_AB = (Mean_A-Mean_B)/(sqrt(MSE)*sqrt(2/n));
 raw_p = 2*(1-probt(abs(tstat_AB),df));
 adj_p = 1-probmc(&#39;RANGE&#39;,sqrt(2)*abs(tstat_AB),.,df,g);
run; 
</code></pre>
</div>
<div id="displaying-pairwise-comparisons-graphically" class="section level3" number="10.3.6">
<h3><span class="header-section-number">10.3.6</span> Displaying Pairwise Comparisons Graphically</h3>
<p><strong>Graphical Presentation for Comparing Means: LINES Option SAS</strong></p>
<p>LINES option, which provides a listing of the means in descending order
and a text graph that displays the results of the tests.</p>
<pre><code>proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 means Diet/tukey lines;
run; </code></pre>
<p><strong>Graphical Presentation for Comparing Means: The Diffogram</strong></p>
<p>An alternative presentation of the simultaneous confidence intervals is known as the mean-mean scatterplot (Hsu, 1996); in SAS, it is called a diffogram. First, all non-redundant pairs <span class="math inline">\(\left(\bar{y}_{i}, \bar{y}_{i^{\prime}}\right)\)</span>
are plotted on a two-dimensional plot. Then the confidence intervals are represented as <span class="math inline">\(-45^{\circ}\)</span> lines emanating symmetrically from the centers <span class="math inline">\(\left(\bar{y}_{i}, \bar{y}_{i}\right)\)</span>, scaled in such a way that the line covers the <span class="math inline">\(45^{\circ}\)</span> line when the interval covers 0 ; see Figure <span class="math inline">\(4.2\)</span> below.</p>
<pre><code>ods graphics on;
proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 lsmeans Diet/cl adjust=tukey;
run;
quit;
ods graphics off; </code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/Turkey_Diffgram.PNG" alt="Figure: Diffogram indicating Comparisons of Diets" width="100%" />
<p class="caption">
(#fig:Turkey Diffogram)Figure: Diffogram indicating Comparisons of Diets
</p>
</div>
<p><strong>R Implementation</strong></p>
<pre><code>## CI Plot
plot(warpbreaks.ci, main = &quot;&quot;, 
     ylim = c(0.5, 3.5),xlab = &quot;Breaks&quot;)</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/Turkey_Plots.png" alt="Figure: Turkey CI Plots" width="100%" />
<p class="caption">
(#fig:Turkey CI Plots)Figure: Turkey CI Plots
</p>
</div>
<pre><code>## CI Boxplots
warpbreaks.cld &lt;- cld(warpbreaks.mc)
plot(warpbreaks.cld)</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/Turkey_Boxplots.png" alt="Figure: CI Boxplots" width="100%" />
<p class="caption">
(#fig:Turkey CI Boxplots)Figure: CI Boxplots
</p>
</div>
</div>
<div id="dunnetts-two-sided-comparisons-with-a-control-and-dunnetts-two-sided-range-distribution" class="section level3" number="10.3.7">
<h3><span class="header-section-number">10.3.7</span> Dunnett’s Two-Sided Comparisons with a Control and Dunnett’s Two-Sided Range Distribution</h3>
<p>If you want to make a claim about whether the treated groups’ means are either larger or
smaller than the control group mean, then you should use two-sided intervals.</p>
<p><span class="math inline">\(\bar{y}_{0}\)</span> denote the mean of the control group, you need a <span class="math inline">\(c_{\alpha}\)</span> for which
<span class="math display">\[
P\left(\bar{y}_{i}-\bar{y}_{0}-c_{\alpha} \hat{\sigma} \sqrt{2 / n} \leq \mu_{i}-\mu_{0} \leq \bar{y}_{i}-\bar{y}_{0}+c_{\alpha} \hat{\sigma} \sqrt{2 / n}, \text { for all } i\right)=1-\alpha
\]</span>
Algebraically rearranging terms, you see that <span class="math inline">\(c_{\alpha}\)</span> must satisfy
<span class="math display">\[
P\left(\max _{i} \frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{0}-\mu_{0}\right)\right|}{\hat{\sigma} \sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span>
the critical value <span class="math inline">\(c_{\alpha}\)</span> can be calculated analytically from Dunnett’s two-sided range distribution.</p>
<p><strong>Dunnett’s two-sided range distribution</strong></p>
<p>If <span class="math inline">\(Z_{0}, Z_{1}, \ldots, Z_{g}\)</span> are independent standard normal random variables, and <span class="math inline">\(V\)</span> is a random variable
distributed as chi-square with <span class="math inline">\(v\)</span> degrees of freedom, independent of the <span class="math inline">\(Z \mathrm{~s}\)</span>, then
<span class="math display">\[
Q_{g, v}^{D 2}=\frac{\max _{i}\left|Z_{i}-Z_{0}\right|}{\sqrt{2 V / v}}
\]</span>
has Dunnett’s two-sided range distribution with parameters <span class="math inline">\(g\)</span> and <span class="math inline">\(v\)</span>.</p>
<pre><code>*** “By Hand Calculation” of Dunnett&#39;s Two-Sided Critical Value;
data;
 c_alpha = probmc(&quot;DUNNETT2&quot;,.,.95,21,6);
run;
proc print;
run;
 
### Calculate critical values for Dunnett procedure given alpha, df1 and df2 in R;

qDunnett &lt;- function (p, df, k, rho,
                      type = c(&quot;two-sided&quot;, &quot;one-sided&quot;))
{
  type &lt;- match.arg(type)
  alpha &lt;- 1 - p
  if (type == &quot;two-sided&quot;) {
    alpha &lt;- alpha/2
  }
  S &lt;- matrix(rho, nrow=k, ncol=k) + (1-rho)*diag(k)
  if (type == &quot;two-sided&quot;) {
    f &lt;- function(d, df, k, S, p) {
      mnormt::sadmvt(df=df, lower=rep(-d,k), upper=rep(d,k),
                      mean=rep(0,k), S=S, maxpts=2000*k) - p
    }
  }
  else {
    f &lt;- function(d, df, k, S, p) {
      mnormt::pmt(d, S=S, df=df) - p
    }
  }
  d &lt;- uniroot(f,
               df = df, k = k, S = S, p=p,
               lower=qt(1 - alpha, df),
               upper=qt(1 - alpha/k, df),
               tol=.Machine$double.eps, maxiter=5000)$root
  return(d)
}


p &lt;- 0.95; df &lt;- 24; rho &lt;- 0.5; k &lt;- 3
nCDunnett::qNCDun(p=p, nu=df, rho=rho,
                  delta=rep(0,times=k), two.sided=T)
qDunnett(p, df, k, rho)</code></pre>
<p><strong>SAS Implementation</strong></p>
<pre><code>data Tox;
 input Trt @;
 do j = 1 to 4;
 input Gain @; output;
 end;
datalines;
0 97.76 102.56 96.08 125.12
1 91.28 129.20 90.80 72.32
2 67.28 85.76 95.60 73.28
3 80.24 64.88 64.88 78.56
4 96.08 98.24 77.84 95.36 
5 57.68 89.84 98.48 92.72
6 68.72 85.28 68.72 74.24
;

*** Boxplots;
ods graphics on;
proc glm data=Tox;
 class Trt;
 model Gain=Trt;
 means Trt/dunnett;
run; quit;
ods graphics off;</code></pre>
<p><strong>Displaying Two-Sided Dunnett Comparisons Graphically</strong></p>
<pre><code>means Trt/dunnett;

*** Or;
lsmeans Trt/adjust=dunnett;</code></pre>
<p><strong>R Implementation</strong></p>
<pre><code>data(&quot;recovery&quot;, package = &quot;multcomp&quot;)
recovery.aov &lt;- aov(minutes ~ blanket, data = recovery)
recovery.mc &lt;- glht(recovery.aov,
                    linfct = mcp(blanket = &quot;Dunnett&quot;),
                    alternative = &quot;less&quot;)   ## one-sided test
                    
## Alternative
contr &lt;- rbind(&quot;b1 -b0&quot; = c(-1, 1, 0, 0), 
               &quot;b2 -b0&quot; = c(-1, 0, 1, 0),
               &quot;b3 -b0&quot; = c(-1, 0, 0, 1))
summary(glht(recovery.aov, linfct = mcp(blanket = contr),
             alternative = &quot;less&quot;))
             
## KI und Plot
recovery.ci &lt;- confint(recovery.mc, level = 0.95)</code></pre>
<p><strong>Specify linear combination variante from Dunnett</strong></p>
<pre><code>## Variante from Dunnett
contr2 &lt;- rbind(&quot;b2 -b0&quot; = c(-1,  0, 1, 0),
                &quot;b2 -b1&quot; = c( 0, -1, 1, 0),
                &quot;b3 -b0&quot; = c(-1,  0, 0, 1),
                &quot;b3 -b1&quot; = c( 0, -1, 0, 1))
summary(glht(recovery.aov, linfct = mcp(blanket = contr2),
             alternative = &quot;less&quot;))
             
             
Linear Hypotheses:
            Estimate Std. Error t value Pr(&lt;t)    
b2 -b0 &gt;= 0  -7.4667     1.6038  -4.656 &lt;0.001 ***
b2 -b1 &gt;= 0  -5.3333     2.1150  -2.522 0.0278 *  
b3 -b0 &gt;= 0  -1.6667     0.8848  -1.884 0.1054    
b3 -b1 &gt;= 0   0.4667     1.6383   0.285 0.9150    </code></pre>
</div>
<div id="dunnetts-one-sided-comparisons-with-a-control" class="section level3" number="10.3.8">
<h3><span class="header-section-number">10.3.8</span> Dunnett’s One-Sided Comparisons with a Control</h3>
<p>If you want to reject the null hypothesis only when the treated groups’ means are on one side of
(e.g., lower than) the control group mean, and if you are willing to <em>ignore any difference in the opposite direction</em>, then you can <em>get more power</em> by using one-sided tests or one-sided
confidence intervals.</p>
<p>Thus, to obtain the critical points for lower-tailed inferences, you need a <span class="math inline">\(c_{\alpha}\)</span> for which
<span class="math display">\[
P\left(\mu_{i}-\mu_{0} \leq \bar{y}_{i}-\bar{y}_{0}+c_{\alpha} \hat{\sigma} \sqrt{2 / n}, \text { for all } i\right)=1-\alpha
\]</span>
For upper-tailed inferences, you need a <span class="math inline">\(c_{\alpha}\)</span> for which
<span class="math display">\[
P\left(\mu_{i}-\mu_{0} \geq \bar{y}_{i}-\bar{y}_{0}-c_{\alpha} \hat{\sigma} \sqrt{2 / n}, \text { for all } i\right)=1-\alpha
\]</span>
Rearranging terms algebraically and, in the case of lower-tail inference <span class="math inline">\(c_{\alpha}\)</span> must satisfy
<span class="math display">\[
P\left(\max _{i} \frac{\left(\bar{y}_{0}-\mu_{0}\right)-\left(\bar{y}_{i}-\mu_{i}\right)}{\hat{\sigma} \sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span>
and in the case of upper-tail inference <span class="math inline">\(c_{\alpha}\)</span> must satisfy
<span class="math display">\[
P\left(\max _{i} \frac{\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{0}-\mu_{0}\right)}{\hat{\sigma} \sqrt{2 / n}} \leq c_{\alpha}\right)=1-\alpha
\]</span></p>
<p><strong>SAS Implementation</strong></p>
<pre><code>ods graphics on;
proc glm data=Tox;
 class Trt;
 model Gain=Trt;
 means Trt/dunnettl;
run; quit;
ods graphics off; </code></pre>
<p><strong>Graphing the One-Sided Dunnett Comparisons</strong></p>
<pre><code>lsmeans Trt/pdiff=controll;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/Dunnett_OneSide.PNG" alt="Figure: Displaying One-Sided Dunnett Comparisons Graphically" width="100%" />
<p class="caption">
(#fig:One-Sided Dunnett Comparisons)Figure: Displaying One-Sided Dunnett Comparisons Graphically
</p>
</div>
</div>
<div id="maximum-modulus-distribution-multiple-inferences-for-independent-estimates" class="section level3" number="10.3.9">
<h3><span class="header-section-number">10.3.9</span> Maximum Modulus Distribution, Multiple Inferences for Independent Estimates</h3>
<p>Whereas the distributions used in
Tukey’s and Dunnett’s tests concern estimates that are dependent, the studentized maximum
modulus distribution concerns estimates that are independent. The most common applications of
this distribution are to confidence intervals for means and to orthogonal comparisons</p>
<p><strong>Simultaneous Intervals for the Treatment Means</strong></p>
<p>Suppose that you want simultaneous confidence intervals for the group means themselves, rather than for their differences. <span class="math inline">\(c_{\alpha}\)</span> for which
<span class="math display">\[
P\left(\bar{y}_{i}-c_{\alpha} \hat{\sigma} / \sqrt{n} \leq \mu_{i} \leq \bar{y}_{i}+c_{\alpha} \hat{\sigma} / \sqrt{n}, \text { for all } i\right)=1-\alpha
\]</span>
Rearranging terms algebraically,
<span class="math display">\[
P\left(\max _{i} \frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)\right|}{\hat{\sigma} / \sqrt{n}} \leq c_{\alpha}\right)=1-\alpha
\]</span>
Since the <span class="math inline">\(\bar{y}_{i}\)</span> are independent, the <span class="math inline">\(t_{i}=\left(\bar{y}_{i}-\mu_{i}\right) /(\hat{\sigma} / \sqrt{n})\)</span> values are nearly independent, too.
They’re not quite independent because they share a common pooled variance estimate <span class="math inline">\(\hat{\sigma}^{2}\)</span>. Thus, you could use Šidák’s method, to approximate <span class="math inline">\(c_{\alpha}\)</span> as the <span class="math inline">\(1-(1-\alpha)^{1 / g}\)</span> quantile of the <span class="math inline">\(t\)</span> -distribution. However, an exact value for <span class="math inline">\(c_{\alpha}\)</span> can be calculated using Tukey’s (1953) maximum modulus distribution.</p>
<p><strong>The Maximum Modulus Distribution</strong></p>
<p>If <span class="math inline">\(Z_{0}, Z_{1}, \ldots, Z_{g}\)</span> are independent standard normal random variables, and <span class="math inline">\(V\)</span> is a random variable distributed as chi-square with <span class="math inline">\(v\)</span> degrees of freedom, independent of the <span class="math inline">\(Z \mathrm{~s}\)</span>, then
<span class="math display">\[
Q_{g, v}^{M M}=\frac{\max _{i}\left|Z_{i}\right|}{\sqrt{V / v}}
\]</span>
has the maximum modulus distribution with parameters <span class="math inline">\(g\)</span> and <span class="math inline">\(v\)</span>.
You can see that the <span class="math inline">\(c_{\alpha}\)</span> for the simultaneous confidence intervals satisfies
<span class="math display">\[
P\left(Q_{g, g(n-1)}^{M M} \leq c_{\alpha}\right)=1-\alpha
\]</span>
or in other words, <span class="math inline">\(c_{\alpha}=q_{1-\alpha, g, g(n-1)}^{M M}\)</span>, where <span class="math inline">\(q_{1-\alpha, r}^{M M}\)</span> is the <span class="math inline">\(1-\alpha\)</span> quantile of the maximum modulus distribution.</p>
<p><strong>SAS Implementation</strong></p>
<pre><code>*** Simultaneous Confidence Intervals for Means;
proc glm data=Wloss;
 class Diet;
 model Wloss=Diet;
 means Diet / clm smm sidak;
run; </code></pre>
<p>Since the intervals are almost independent, Šidák’s adjustment provides a very close
approximation to the maximum modulus method. Using the maximum modulus
distribution yields very slightly (about 0.2%) tighter intervals.</p>
</div>
</div>
<div id="multiple-comparisons-among-treatment-means-in-the-one-way-unbalanced-anova" class="section level2" number="10.4">
<h2><span class="header-section-number">10.4</span> Multiple Comparisons among Treatment Means in the One-Way Unbalanced ANOVA</h2>
<p>For unbalanced sample sizes, s, the simple distributions such as Tukey’s studentized range and Dunnett’s range distributions no longer are valid. The standard errors differ from contrast to contrast, and the simple range distributions can no longer be used directly.</p>
<div id="the-model-and-estimates" class="section level3" number="10.4.1">
<h3><span class="header-section-number">10.4.1</span> The Model and Estimates</h3>
<p><span class="math display">\[
y_{i j}=\mu_{i}+\varepsilon_{i j}
\]</span>
with independent, homoscedastic, and normally distributed <span class="math inline">\(\varepsilon_{i j}\)</span> having mean zero.</p>
<p>In the balanced case, the within-group samples all have the same size <span class="math inline">\(n\)</span>. In the unbalanced case, we allow them to differ, denoting the size of the <span class="math inline">\(i^{\text {th }}\)</span> sample by <span class="math inline">\(n_{i}\)</span>, for <span class="math inline">\(i=1, \ldots, g\)</span>. The estimated parameters are <span class="math inline">\(\hat{\mu}_{i}=\bar{y}_{i}=\left(1 / n_{i}\right) \sum_{j=1}^{n_{i}} y_{i j}\)</span>, and <span class="math inline">\(\hat{\sigma}^{2}=\Sigma_{i=1}^{g}\left\{\left(n_{i}-1\right) s_{i}^{2}\right\} / \Sigma_{i=1}^{g}\left(n_{i}-1\right)\)</span>, where <span class="math inline">\(s_{i}^{2}\)</span> is the
ordinary sample variance estimate for group <span class="math inline">\(i, s_{i}^{2}=\sum_{j=1}^{n_{i}}\left(y_{i j}-\bar{y}_{i}\right)^{2} /\left(n_{i}-1\right)\)</span>. The degrees of freedom for the estimate of <span class="math inline">\(\sigma^{2}\)</span> is the error degrees of freedom <span class="math inline">\(d f e=\sum_{i=1}^{g}\left(n_{i}-1\right)=N-g\)</span>, where
<span class="math inline">\(N=\Sigma_{i=1}^{g} n_{i}\)</span> is the total of all within-group sample sizes.</p>
<p><strong>All Pairwise Comparisons</strong></p>
<p>The confidence intervals for the difference of means <span class="math inline">\(\mu_{i}-\mu_{i^{\prime}}\)</span> have the form
<span class="math display">\[
\bar{y}_{i}-\bar{y}_{i^{\prime}} \pm c_{\alpha} \hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i^{\prime}}}
\]</span>
where <span class="math inline">\(\bar{y}_{i}-\bar{y}_{i^{\prime}}\)</span> is the usual least-squares estimate of <span class="math inline">\(\mu_{i}-\mu_{i^{\prime}}\)</span> and <span class="math inline">\(\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}}\)</span> is its standard error. In the case of non-multiplicity-adjusted confidence intervals, you set <span class="math inline">\(c_{\alpha}\)</span> to be the <span class="math inline">\(1-\alpha / 2\)</span> quantile of the <span class="math inline">\(t_{d f e}\)</span> distribution, <span class="math inline">\(t_{1-\alpha / 2, d f e}\)</span>, with <span class="math inline">\(d f e=N-g\)</span>. As always, you can construct Bonferroni-adjusted confidence intervals by setting <span class="math inline">\(c_{\alpha}=t_{1-\alpha^{\prime} / 2, d f e}\)</span>, where <span class="math inline">\(\alpha^{\prime}=\alpha / k, k\)</span> being the number of inferences (e.g., pairwise comparisons) in the family. And, as always, you can improve upon the Bonferroni value by taking into account the distribution of the differences.</p>
<p>Mathematically, <span class="math inline">\(c_{\alpha}\)</span> must satisfy
<span class="math inline">\(P\left(\bar{y}_{i}-\bar{y}_{i}-c_{\alpha} \hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}} \leq \mu_{i}-\mu_{i^{\prime}} \leq \bar{y}_{i}-\bar{y}_{i^{\prime}}+c_{\alpha} \hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}}\right.\)</span>, for all <span class="math inline">\(\left.i, i^{\prime}\right)=1-\alpha\)</span>
or equivalently,
<span class="math display">\[
P\left(\max _{i, i^{\prime}} \frac{\left|\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)\right|}{\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}}} \leq c_{\alpha}\right)=1-\alpha
\]</span></p>
<p>Unlike the balanced case, the denominator of this expression, <span class="math inline">\(\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i^{\prime}}}\)</span>, is <strong>not constant</strong> for all <span class="math inline">\(\left(i, i^{\prime}\right)\)</span> pairs. Thus, the MaxT statistic does <strong>not have the studentized range distribution</strong>; its distribution is actually quite complicated.</p>
</div>
<div id="tukey-kramer-method" class="section level3" number="10.4.2">
<h3><span class="header-section-number">10.4.2</span> Tukey-Kramer Method</h3>
<p>Tukey (1953) and Kramer (1956) independently proposed a method to approximate the critical value <span class="math inline">\(c_{\alpha}\)</span> in unbalanced designs. Recall that when the sample sizes are all equal (i.e., when <span class="math inline">\(\left.n_{1}=\ldots=n_{g}=n\right)\)</span>, the statistic
<span class="math display">\[
\max _{i, i^{\prime}} \sqrt{2}\left|T_{i, i^{\prime}}\right|=\max _{i, i} \sqrt{2}\left|\frac{\left(\bar{y}_{i}-\mu_{i}\right)-\left(\bar{y}_{i^{\prime}}-\mu_{i^{\prime}}\right)}{\hat{\sigma} \sqrt{1 / n+1 / n}}\right|
\]</span>
is distributed as <span class="math inline">\(Q_{g, g(n-1)}^{R}\)</span>, which has the studentized range distribution</p>
<p>which gives the Tukey-Kramer simultaneous confidence intervals:
<span class="math display">\[
\bar{y}_{i}-\bar{y}_{i^{\prime}} \pm\left(q_{1-\alpha, g, d f e}^{R} / \sqrt{2}\right) \hat{\sigma} \sqrt{1 / n_{i}+1 / n_{i}}
\]</span>
Note that, as in the balanced case, the critical value <span class="math inline">\(c_{\alpha}\)</span> is the <span class="math inline">\(1-\alpha\)</span> quantile of the range distribution divided by <span class="math inline">\(\sqrt{2}\)</span>. Thus, there are no real differences in the form of the Tukey-Kramer intervals and the Tukey intervals.</p>
<p>If you apply the above confidence interval formula in the case where all <span class="math inline">\(n_{i}\)</span> are equal (to <span class="math inline">\(n\)</span> ), you get exactly the Tukey intervals for all pairwise comparisons.
However, the Tukey-Kramer intervals are not exact in the sense of providing an exact simultaneous <span class="math inline">\(1-\alpha\)</span> coverage rate and exact <span class="math inline">\(\mathrm{FWE}=\alpha\)</span> when the sample sizes are unequal. Hayter
(1984) proved that the method is in fact <strong>conservative</strong>: the true FWE is <strong>less than or equal</strong> to <span class="math inline">\(\alpha\)</span> for all possible sample size configurations.</p>
<p><strong>SAS Implementation</strong></p>
<p>When you specify TUKEY as an option for the MEANS statement, the Tukey-Kramer method
is used automatically when the sample sizes are unequal. This code produces the following
output.</p>
<pre><code>data Recover;
 input Blanket$ Minutes @@;
 datalines;
b0 15 b0 13 b0 12 b0 16 b0 16 b0 17 b0 13 b0 13 b0 16 b0 17
b0 17 b0 19 b0 17 b0 15 b0 13 b0 12 b0 16 b0 10 b0 17 b0 12
b1 13 b1 16 b1 9
b2 5 b2 8 b2 9
b3 14 b3 16 b3 16 b3 12 b3 7 b3 12 b3 13 b3 13 b3 9 b3 16
b3 13 b3 18 b3 13 b3 12 b3 13
;
proc sgplot data=Recover;
 vbox Minutes / category=Blanket;
run;
proc glm data=Recover;
 class Blanket;
 model Minutes=Blanket;
 means Blanket/tukey;
run; </code></pre>
</div>
<div id="alternative-simulation-based-method" class="section level3" number="10.4.3">
<h3><span class="header-section-number">10.4.3</span> Alternative Simulation-Based Method</h3>
<p>The Tukey-Kramer method is conservative because the critical value <span class="math inline">\(q_{1-\alpha, g, N-g}^{R}\)</span> is larger than the true <span class="math inline">\(c_{\alpha}\)</span>, which is the <span class="math inline">\(1-\alpha\)</span> quantile of the distribution of <span class="math inline">\(\max _{i, i}\left|T_{i, i}\right| .\)</span> To calculate the correct critical value analytically requires multidimensional integration using the <strong>multivariate <span class="math inline">\(t\)</span> distribution</strong>, you can approximate this critical value very easily <strong>by simulating from the multivariate <span class="math inline">\(t\)</span> distribution</strong> with <span class="math inline">\(d f e=N-g\)</span> and dispersion matrix <span class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{C} \mathbf{D}^{-1 / 2}\)</span>. The following simulation algorithm avoids the problem of having to specify the <span class="math inline">\(\mathbf{R}\)</span> matrix, and illustrates the concept of <strong>parametric resampling</strong>.</p>
<ol style="list-style-type: decimal">
<li>Generate a random sample <span class="math inline">\(y_{i j}^{*}\)</span> from the standard normal distribution.</li>
<li>Analyze the data exactly as you would if it were an actual data set, getting sample means <span class="math inline">\(\bar{y}_{i}^{*}\)</span> and a pooled variance estimate <span class="math inline">\(\left(\hat{\sigma}^{*}\right)^{2}\)</span>. Compute the test statistics for all pairwise comparisons, <span class="math inline">\(T_{i, i^{\prime}}^{*}=\left(\bar{y}_{i}^{*}-\bar{y}_{i^{\prime}}^{*}\right) /\left(\hat{\sigma}^{*} \sqrt{1 / n_{i}+1 / n_{i^{\prime}}}\right)\)</span>.</li>
<li>Calculate the value <span class="math inline">\(\operatorname{Max} \mathrm{T}=\max _{i, i^{\prime}}\left|T_{i, i^{\prime}}^{*}\right|\)</span> and store it.</li>
<li>Repeat steps 1-3 NSAMP times, and estimate <span class="math inline">\(c_{\alpha}\)</span> as the <span class="math inline">\(1-\alpha\)</span> quantile of the resulting
MaxT values. Call the resulting value <span class="math inline">\(\hat{c}_{\alpha}\)</span>.</li>
</ol>
<p><strong>Simulating the Critical Value for Recovery Data Using Parametric Resampling</strong></p>
<pre><code>data sim;
 array nsize{4} (20,3,3,15);
 do rep = 1 to 20000;
 do i=1 to dim(nsize);
 do j=1 to nsize{i};
 y = rannor(121211);
 output;
 end;
 end;
 end;
run;
ods listing close;
proc glm data=sim;
 by rep;
 class i;
 model y=i;
 lsmeans i/ tdiff;
 ods output Diff=GDiffs;
quit;
ods listing;
proc transpose data=GDiffs out=t(where=(_label_ &gt; RowName));
 by rep RowName;
 var _1 _2 _3 _4;
data t;
 set t;
 abst = abs(COL1);
 keep rep abst;
proc means noprint data=t;
 var abst;
 by rep;
 output out=maxt max=maxt;
run;
proc univariate;
 var maxt;
 ods select Quantiles;
run; </code></pre>
<p>Thus, the correct 95th percentile is estimated to be 2.646847, based on NSAMP=20000
simulations. The Tukey-Kramer approximation resulted in a slightly higher number, 2.68976,
which suggests a slight level of conservatism of the Tukey-Kramer method.</p>
<pre><code>100% Max 4.844511
99% 3.288458
95% 2.646847
90% 2.332767
75% Q3 1.851581
50% Median 1.381995
25% Q1 0.981263
10% 0.681271
5% 0.528405
1% 0.293808
0% Min 0.036276</code></pre>
<p>However, remember that the percentile estimated by simulation is subject to <strong>sampling error</strong>, so the precise degree of conservatism is unclear. Edwards and Berry (1987) suggest generating sufficient samples NSAMP so that <span class="math inline">\(P\left(\operatorname{Max} T \geq \hat{c}_{\alpha}\right)\)</span> (where <span class="math inline">\(\hat{c}_{\alpha}\)</span> is fixed and MaxT is random) is within an accuracy radius <span class="math inline">\(\gamma\)</span> of <span class="math inline">\(\alpha\)</span> with confidence <span class="math inline">\(100(1-\delta) \%\)</span>. You can adjust <span class="math inline">\(\alpha\)</span> using the ALPHA= option, and <span class="math inline">\(\gamma\)</span> and <span class="math inline">\(\delta\)</span> with the ACC <span class="math inline">\(=\)</span> and EPS <span class="math inline">\(=\)</span> suboptions of the ADJUST=SIMULATE option, respectively. By default, <span class="math inline">\(\alpha=0.05, \gamma=0.005\)</span>, and <span class="math inline">\(\delta=0.01 ;\)</span> the method yields <span class="math inline">\(\mathrm{NSAMP}=12,604\)</span> in this case. That is, using quantiles from a simulation of this size, a nominal <span class="math inline">\(95 \%\)</span> confidence interval for a mean difference will actually have between <span class="math inline">\(94.5 \%\)</span> and <span class="math inline">\(95.5 \%\)</span> confidence with probability <span class="math inline">\(0.99\)</span></p>
<p>If you specify the ADJUST=SIMULATE option then PROC GLM uses the simulationestimated quantile in forming multiplicity-adjusted confidence intervals for the differences. Although PROC GLM doesn’t display the actual value of the quantile by default, you can use the <strong>REPORT option</strong> for the simulation to print the quantile and other information,</p>
<pre><code>proc glm data=Recover;
 class Blanket;
 model Minutes=Blanket;
 lsmeans Blanket/cl adjust=simulate(seed=121211 report);
 ods select SimResults LSMeanDiffCL;
run;</code></pre>
<p><span class="math display">\[
\begin{array}{lcccc}
\hline &amp; \text { Simulation Results } &amp; &amp; \\
\text { Method } &amp; \text { 95% Quantile } &amp; \text { Estimated } &amp; \text {99% CI } \\
\text { Simulated } &amp; 2.634412 &amp; 0.0500 &amp;  0.0450 &amp; 0.0550\\
\text { Tukey-Kramer } &amp; 2.689757 &amp; 0.0432 &amp; 0.0385 &amp; 0.0478 \\
\text { Bonferroni } &amp; 2.787602 &amp; 0.0338 &amp; 0.0297 &amp; 0.0379 \\
\text { Sidak } &amp; 2.779230 &amp; 0.0346 &amp; 0.0304 &amp; 0.0388 \\
\text { GT-2 } &amp; 2.770830 &amp; 0.0350 &amp; 0.0308 &amp; 0.0392 \\
\text { Scheffe } &amp; 2.928547 &amp; 0.0237 &amp; 0.0202 &amp; 0.0272 \\
T &amp; 2.026192 &amp; 0.1870 &amp; 0.1780 &amp; 0.1959 \\
\hline
\end{array}
\]</span></p>
</div>
<div id="pairwise-comparisons-with-control" class="section level3" number="10.4.4">
<h3><span class="header-section-number">10.4.4</span> Pairwise Comparisons with Control</h3>
<p>Unlike the case of all pairwise comparisons, the critical value cα and the adjusted p-values can
be calculated analytically for Dunnett’s method in the case of all pairwise comparisons with a
control, even though the design is unbalanced. There is no need to use approximations, such as
the Tukey-Kramer or simulation-based.</p>
<p>Suppose the means are <span class="math inline">\(\bar{y}_{0}, \bar{y}_{1}, \ldots, \bar{y}_{g}\)</span>, where <span class="math inline">\(\bar{y}_{0}\)</span> denotes the sample mean for the control group.</p>
<p>To get the critical values and adjusted <span class="math inline">\(p\)</span> -values for two-sided intervals and tests, you need the distribution of
<span class="math display">\[
M_{2}=\max _{i} \frac{\left|\bar{y}_{i}-\bar{y}_{0}\right|}{\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{0}}}
\]</span>
The critical value <span class="math inline">\(c_{\alpha}\)</span> for the two-sided confidence intervals for <span class="math inline">\(\mu_{i}-\mu_{0}\)</span> is the <span class="math inline">\(1-\alpha\)</span> quantile of the distribution of <span class="math inline">\(M_{2}\)</span>, and adjusted <span class="math inline">\(p\)</span> -values for two-sided tests are given as
<span class="math inline">\(\tilde{p}_{i}=P\left(M_{2} \geq\left|t_{i}\right|\right)\)</span>, where <span class="math inline">\(t_{i}\)</span> is the test statistic for <span class="math inline">\(H_{0 i}: \mu_{i}-\mu_{0}=0\)</span>, i.e.,
<span class="math display">\[
t_{i}=\left(\bar{y}_{i}-\bar{y}_{0}\right) /\left(\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{0}}\right)
\]</span>
To get the critical values and adjusted <span class="math inline">\(p\)</span> -values for one-sided intervals and tests, you need the distribution of
<span class="math display">\[
M_{1}=\max _{i} \frac{\bar{y}_{i}-\bar{y}_{0}}{\hat{\sigma} \sqrt{1 / n_{i}+1 / n_{0}}}
\]</span>
The critical value <span class="math inline">\(c_{\alpha}\)</span> for the one-sided confidence bounds is the <span class="math inline">\(1-\alpha\)</span> quantile of the
distribution of <span class="math inline">\(M_{1}\)</span>. Adjusted <span class="math inline">\(p\)</span> -values for one-sided, upper-tail tests are given as <span class="math inline">\(\tilde{p}_{i}=P\left(M_{1} \geq t_{i}\right)\)</span>, and adjusted <span class="math inline">\(p\)</span> -values for one-sided, lower-tail tests are given as <span class="math inline">\(\tilde{p}_{i}=P\left(M_{1} \geq-t_{i}\right)\)</span></p>
<p><strong>Dunnett’s Two-Sided Comparisons with Unbalanced Data</strong></p>
<pre><code>ods graphics on;
proc glm data=Recover;
 class Blanket;
 model Minutes = Blanket;
 lsmeans Blanket/pdiff cl adjust=dunnett;
run;
ods graphics off;</code></pre>
<p><strong>Dunnett’s One-Sided Comparisons with Unbalanced Data</strong></p>
<pre><code>** “By Hand” Calculation of Dunnett&#39;s Exact One-Sided Critical Value 
    and Adjusted p-Value for Unbalanced ANOVA.
data;
 n0=20; n1=3; n2=3; n3=15;
 lambda1 = sqrt(n1/(n0+n1));
 lambda2 = sqrt(n2/(n0+n2));
 lambda3 = sqrt(n3/(n0+n3));
 c_alpha = probmc(&#39;DUNNETT1&#39;,.,.90,37,3,lambda1,lambda2,lambda3);
 t3 = -1.66666667/0.88477275;
 adjp_3 = 1-probmc(&#39;DUNNETT1&#39;,-t3,.,37,3,lambda1,lambda2,lambda3);
run; 


ods graphics on;
proc glm data=Recover;
 class Blanket;
 model Minutes = Blanket;
 lsmeans Blanket / pdiff=controll cl alpha=0.10;
run;
ods graphics off;</code></pre>
</div>
<div id="comparisons-with-the-average-meananalysis-of-means-anom" class="section level3" number="10.4.5">
<h3><span class="header-section-number">10.4.5</span> Comparisons with the Average Mean–Analysis of Means (ANOM)</h3>
<p>whether one group’s mean is confidently different from the average of the means for the set of groups as a
whole. Using this method, a quality control engineer can confidently identify troubled or
unusually good spots (e.g., a shift that is under- or over-performing) or a product formulation or
business process that should be abandoned or emulated.</p>
<pre><code>ods graphics on;
proc glm data=Recover;
 class Blanket;
 model Minutes = Blanket;
 lsmeans Blanket / pdiff=anom(weighted) cl alpha=0.10;
run;
ods graphics off; </code></pre>
</div>
</div>
<div id="generalizations-for-the-analysis-of-covariance-ancova-model" class="section level2" number="10.5">
<h2><span class="header-section-number">10.5</span> Generalizations for the Analysis of Covariance (ANCOVA) model</h2>
<p>A major difference is that the comparisons of interest in ANCOVA are differences of <strong>LS-means rather than ordinary means</strong>. This leads to some interesting graphical comparisons using regression functions. As in the unbalanced one-way case, the <strong>standard errors of estimated LS-mean differences are not constant</strong>, implying that simple range distributions (Tukey-type or Dunnett-type) cannot be used. Also, while for Dunnett comparisons there is an exact representation of the MaxT distribution in the case of unbalanced sample sizes without covariates, this is not the case when there are covariates. Hence, either simulation-based or analytic approximations must be used.</p>
<p>。</p>
<p>ANCOVA model with interaction may be written as
<span class="math display">\[
y_{i j}=\gamma+\mu_{i}+\beta x_{i j}+\varepsilon_{i j}
\]</span>
where parallelism is indicated by the common slope <span class="math inline">\(\beta\)</span> for all groups.</p>
<p>A recommendation is generally to use the SAS defaults (<strong>Tukey-Kramer, Dunnett-Hsu</strong>) for ANCOVA applications: although they are not exact, their accuracy is usually completely adequate from a practical perspective, and they avoid the troublesome issue of simulation nondeterminacy. Nevertheless, it is prudent to validate the default analysis using the simulation adjustments.</p>
<div id="dunnett-hsu-factor-analytic-approximation" class="section level3" number="10.5.1">
<h3><span class="header-section-number">10.5.1</span> Dunnett-Hsu Factor Analytic Approximation</h3>
<blockquote>
<p>Pairwise Comparisons in ANCOVA</p>
</blockquote>
<ul>
<li>Tukey’s range, Dunnett’s range, and the maximum modulus distributions to account for dependencies among the estimates.</li>
<li>The Range distribution becomes inexact in the case of unbalanced data, while the Dunnett one- and twosided distributions remain exact (with suitable modifications).</li>
<li>When you include covariates, none of these distributions is exact in general. The general alternative of simulation is still available, though, and quantiles can be simulated with relative ease and adequate accuracy using the ADJUST=SIMULATE option.</li>
</ul>
<p>There is an analytical <strong>approximation</strong> that works very well, providing critical values that, while not analytically exact, are exceptionally accurate. In fact, the deterministic error in this analytical approximation is usually much smaller than the Monte Carlo error of the simulation-based methods at reasonable sample sizes.</p>
<p>As has been discussed, evaluating the critical values and adjusted <span class="math inline">\(p\)</span> -values for the MaxT distribution is intractable unless the correlation matrix <span class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{C} \mathbf{D}^{-1 / 2}\)</span> between the constituent differences in the MaxT statistic has a certain symmetry, in which case the problem reduces to a feasible 2 -fold integral.</p>
<p>The required symmetry is provided by complete balance in the case of Tukey’s test, and by a factor analytic structure (cf. Hsu, 1992 ) in the case of Dunnett’s test. To be precise, the <span class="math inline">\(\mathbf{R}\)</span> matrix has the required symmetry for exact computation of Tukey’s test if the test statistics <span class="math inline">\(t_{i}\)</span> are studentized differences between</p>
<ul>
<li><span class="math inline">\(k(k-1) / 2\)</span> pairs of <span class="math inline">\(k\)</span> uncorrelated means with equal variances, that is, equal sample sizes</li>
<li><span class="math inline">\(k(k-1) / 2\)</span> pairs of <span class="math inline">\(k\)</span> LS-means from a variance-balanced design (for example, a balanced incomplete block design)</li>
</ul>
<p>In the case of comparisons with a control, the <span class="math inline">\(\mathbf{R}\)</span> matrix has the factor analytic structure for exact computation of Dunnett’s test if the <span class="math inline">\(t_{i}\)</span> ’s are studentized differences between</p>
<ul>
<li><span class="math inline">\(k-1\)</span> means and a control mean, all uncorrelated. Note that it is not required that the variances of the estimated means (that is, the sample sizes) be equal.</li>
<li><span class="math inline">\(k-1\)</span> LS-means and a control LS-mean from either a variance-balanced design, or a design in which the other factors are orthogonal to the treatment factor (for example, a randomized block design with proportional cell frequencies)</li>
</ul>
<p>However, other important situations that do not result in a correlation matrix <span class="math inline">\(\mathbf{R}\)</span> that has the symmetry required for exact computation include</p>
<ul>
<li>all pairwise differences with unequal sample sizes</li>
<li>differences between LS-means and a control LS-mean when there are covariates.</li>
</ul>
<p>In these situations, exact calculation of critical values and adjusted <span class="math inline">\(p\)</span> -values is intractable in general. For comparisons with a control when the correlation <span class="math inline">\(\mathbf{R}\)</span> does not have a factor analytic structure, Hsu (1992) suggests approximating <span class="math inline">\(\mathbf{R}\)</span> with a matrix <span class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span> that does have such a structure and, correspondingly, approximating the MaxT critical values and <span class="math inline">\(p\)</span> -values by assuming that the true correlation matrix is <span class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span>. The resulting critical values and adjusted <span class="math inline">\(p\)</span> values are calculated exactly for the correlation <span class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span>, but are approximate for the true correlation
R. (Approximating <span class="math inline">\(\mathbf{R}\)</span> in this way can also be viewed as computing “effective sample sizes” <span class="math inline">\(\tilde{n}_{i}\)</span> for the means and treating them as uncorrelated.)</p>
<p>When you request Dunnett’s test for LS-means (the PDIFF=CONTROL and
ADJUST=DUNNETT options), the GLM procedure automatically uses Hsu’s approximation
when appropriate</p>
<pre><code>proc glm data=House;
 class Location;
 model Price = Location Sqfeet;
 lsmeans Location / tdiff=control(&#39;B&#39;) pdiff cl;
run;
quit;</code></pre>
</div>
<div id="hsu-nelson-simulation-based-approximation-cvadjust-method" class="section level3" number="10.5.2">
<h3><span class="header-section-number">10.5.2</span> Hsu-Nelson Simulation-Based Approximation: CVADJUST Method</h3>
<blockquote>
<p>Pairwise Comparisons in ANCOVA</p>
</blockquote>
<ul>
<li>simple Monte Carlo method</li>
<li>simulate MaxT values for the correct correlation <span class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2} \mathbf{C}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-} \mathbf{C} \mathbf{D}^{-1 / 2}\)</span></li>
<li>simulate covariate of MaxT values with known distribution for the factor-analytic approximation correlation <span class="math inline">\(\mathbf{R}^{\mathrm{F}}\)</span></li>
</ul>
<p>A useful way to strengthen the simple Monte Carlo method of estimating confidence limits and p-values is to use the method of control variates. This method proceeds by simulating not only MaxT values for the correct correlation but also a covariate of MaxT values with known distribution for the factor-analytic approximation correlation discussed above. The conditional estimates for the correct distribution, conditional on the approximate but known one, can be much tighter than what you get with simple simulation (see Hsu and Nelson, 1998). To use this method, you can request it using the CVADJUST suboption of the ADJUST=SIMULATE option of the LSMEANS statement.</p>
<pre><code>lsmeans Location/tdiff=control(&#39;B&#39;) pdiff
 adjust=simulate(acc=0.0001 seed=121211 cvadjust report) cl;</code></pre>
</div>
<div id="comparisons-in-ancova-models-with-interaction" class="section level3" number="10.5.3">
<h3><span class="header-section-number">10.5.3</span> Comparisons in ANCOVA Models with Interaction</h3>
<p>The ANCOVA model with interaction may be written as
<span class="math display">\[
y_{i j}=\gamma+\mu_{i}+\beta x_{i j}+\beta_{i} x_{i j}+\varepsilon_{i j},
\]</span>
where <span class="math inline">\(i\)</span> denotes CLASS level and <span class="math inline">\(j\)</span> an observation within the CLASS level; where <span class="math inline">\(\gamma\)</span> is the overall intercept term and the <span class="math inline">\(\mu_{i}\)</span> parameterize deviations from the overall intercept for CLASS level <span class="math inline">\(i\)</span>, and where similarly <span class="math inline">\(\beta\)</span> is the overall slope term, and the <span class="math inline">\(\beta_{i}\)</span> correspond to deviations from the overall slope for CLASS level <span class="math inline">\(i\)</span>. The model is overparameterized, meaning that not all parameters can be estimated simultaneously without imposing additional constraints</p>
<pre><code>*** One-Way ANCOVA Analysis with Interaction;
ods graphics on;
proc glm data=House;
 class Location;
 model Price = Location Sqfeet location*sqfeet;
run;
quit;
ods graphics off;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/ACNOVA_Effect.PNG" alt="Figure: Fitted ANCOVA Model with Interaction" width="100%" />
<p class="caption">
(#fig:ACNOVA Effect)Figure: Fitted ANCOVA Model with Interaction
</p>
</div>
<p>There is some suggestion of interaction in that the effect of SQFEET on PRICE seems less in LOCATION C, but this may be an artifact due to small sample size, because the interaction is not statistically significant (for testing <span class="math inline">\(H_{0}: \beta_{1}=\ldots=\beta_{5}=0, F(4,54)=1.54, p=0.2045\)</span> ). Nevertheless, the graph illustrates clearly that comparisons of housing prices between levels of the CLASS variable differ, depending on the chosen value of the covariate.</p>
<p>In PROC GLM, the default for <strong>LSMEANS is to compare the CLASS levels at the average value(s) of the covariate(s)</strong>. In the housing example, the average value of SQFEET is <span class="math inline">\(1947.28125\)</span>, thus the statements</p>
<p><code>lsmeans Location / adjust=tukey cl;</code> is equel to <code>lsmeans Location / adjust=tukey cl at Sqfeet=1947.28125;</code></p>
</div>
</div>
<div id="multiple-inferences-for-infinite-sets-of-parameters" class="section level2" number="10.6">
<h2><span class="header-section-number">10.6</span> Multiple Inferences for Infinite Sets of Parameters</h2>
<p>It may also seem that definitive inferences are impossible with infinite families. After all, the Bonferroni method requires that you divide <span class="math inline">\(\alpha\)</span> by <span class="math inline">\(k\)</span>, the number of elements in the family. If <span class="math inline">\(k=\infty\)</span>, then this approach to multiplicity correction would require you to use <span class="math inline">\(\alpha / \infty\)</span>, which can only be defined as zero, for all your inferences. Since <span class="math inline">\(p\)</span> -values are always greater than zero, your tests will never be significant. Similarly, critical values using <span class="math inline">\(\alpha=0.0\)</span> can only be defined as infinitely large; hence, confidence intervals would be infinitely wide in this case, not to mention, infinitely useless as well.</p>
<p>Evidently, the Bonferroni approach is not appropriate for infinite contrasts. One problem is dependence: <strong>the greater the degree of dependence among the tests or intervals, the less appropriate is the Bonferroni correction</strong>. What often happens with infinite collections of tests is that, <strong>as more and more tests are considered, the dependencies among the tests increase</strong>. After a certain point, the dependencies become so great that essentially no more correction is needed.</p>
<p><strong>Summary Pre</strong></p>
<p>If you want to perform inferences for an infinite set of linear functions (contrasts or otherwise)
in the linear model, you can use either Scheffé’s method, the Working-Hotelling method, or the
discretization method.</p>
<ul>
<li>If you want to search through your data to identify the most significant contrasts, then
you should use the Scheffé critical value, since your family is virtually infinite.</li>
<li>If you want to calculate simultaneous confidence bands for regression functions or for
differences of regression functions, you can safely use the Working-Hotelling critical
value in many cases. However, since the Working-Hotelling critical value can be
conservative, you should use the discretization method with a reasonably large grid
with the ESTIMATE statement to assess the conservativeness of the Working-Hotelling
approach. If the Working-Hotelling approach is too conservative, then you should use
the discretization method.</li>
</ul>
<div id="scheffés-method" class="section level3" number="10.6.1">
<h3><span class="header-section-number">10.6.1</span> Scheffés Method</h3>
<p>This family is the set of all contrasts <span class="math display">\[\mathbf{c}_{\boldsymbol{i}} \boldsymbol{\mu}=c_{1} \mu_{1}+c_{2} \mu_{2}+\cdots+c_{g} \mu_{g}\]</span> where the sum of the elements is zero <span class="math inline">\(\left(\sum c_{i}=0.0\right)\)</span></p>
<p>Scheffé’s (1953) method involves finding the distribution of <span class="math inline">\(\max _{\mathbf{c}} T_{\mathrm{c}}^{2}\)</span>, where <span class="math inline">\(T_{\mathrm{c}}\)</span> is the <span class="math inline">\(t\)</span> statistic for the contrast <span class="math inline">\(\mathbf{c}^{\prime} \boldsymbol{\mu}\)</span>
<span class="math display">\[
T_{\mathrm{c}}=\frac{\mathbf{c}^{\prime} \hat{\mu}-\mathbf{c}^{\prime} \mu}{s . e .\left(\mathbf{c}^{\prime} \hat{\mu}\right)}
\]</span>
In the case of the one-way ANOVA without covariates (balanced or unbalanced), the standard error of <span class="math inline">\(\mathbf{c}^{\prime} \hat{\mu}\)</span> is
<span class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\mu}}\right)=\hat{\sigma} \sqrt{\sum \frac{c_{i}^{2}}{n_{i}}}
\]</span></p>
<p>Scheffé showed that the distribution of <span class="math inline">\(\max _{\mathrm{c}} T_{\mathrm{c}}^{2}\)</span> overall contrasts <span class="math inline">\(\mathbf{c}\)</span> (i.e, over the infinite set of <span class="math inline">\(\mathbf{c}=\left(c_{1}, \cdots, c_{g}\right)^{\prime}\)</span> for which <span class="math inline">\(c_{1}+\cdots+c_{g}=0\)</span> ) is <span class="math inline">\((g-1) F_{g-1, d f e}\)</span>, or the distribution of <span class="math inline">\((g-1)\)</span> times an <span class="math inline">\(F\)</span> distributed random variable with <span class="math inline">\((g-1)\)</span> numerator and <span class="math inline">\(d\)</span> fe denominator degrees of freedom. The term <span class="math inline">\(d f e\)</span> is, as usual, the error degrees of freedom.</p>
<p>Thus, the <span class="math inline">\(1-\alpha\)</span> quantile of the distribution of <span class="math inline">\(\max _{\mathfrak{c}}\left|T_{\mathrm{c}}\right|\)</span> is just <span class="math inline">\(c_{\alpha}=\sqrt{(g-1) F_{1-\alpha, g-1, d f e}}\)</span>, and the simultaneous Scheffé intervals are
<span class="math display">\[
\mathbf{c}^{\prime} \hat{\mu} \pm \sqrt{(g-1) F_{1-\alpha, g-1, d f e}} s . e .\left(\mathbf{c}^{\prime} \hat{\mu}\right)
\]</span></p>
<p><strong>SAS Implementation</strong></p>
<pre><code>data WLoss;
 do diet = &#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;,&#39;E&#39;;
 do i = 1 to 10;
 input wloss @@;
 output;
 end;
 end;
datalines;
12.4 10.7 11.9 11.0 12.4 12.3 13.0 12.5 11.2 13.1
 9.1 11.5 11.3 9.7 13.2 10.7 10.6 11.3 11.1 11.7
 8.5 11.6 10.2 10.9 9.0 9.6 9.9 11.3 10.5 11.2
 8.7 9.3 8.2 8.3 9.0 9.4 9.2 12.2 8.5 9.9
12.7 13.2 11.8 11.9 12.2 11.2 13.7 11.8 11.5 11.7
;
data WLossNew;
 set Wloss;
 Wloss=Wloss + 6*rannor(121211); /* Random error added */
run; 
proc glm data=Wlossnew;
 class Diet;
 model Wloss=Diet;
 means Diet / cldiff scheffe;
run; </code></pre>
<p><strong>This test controls the Type I experimentwise error rate, but it generally has a higher Type II error rate than Tukey’s for all pairwise comparisons.</strong> Scheffé’s method is consistent with the ANOVA <span class="math inline">\(F\)</span> -test. <strong>If the <span class="math inline">\(F\)</span> -test is insignificant, then Scheffé’s method will not judge any mean difference or contrast to be significant. And if the <span class="math inline">\(F\)</span> -test is significant, then Scheffé’s method will judge at least one mean contrast to be significant, though this may not be one of the pairwise contrasts</strong>.</p>
<pre><code>***Critical Value of F;
data;
 fwe = 0.05;
 g = 5;
 dfe = 45;
 fcrit = finv(1-fwe,g-1,dfe);
 c_alpha = sqrt((g-1)*fcrit); 
run;</code></pre>
<p><strong>Scheffé adjusted p-values</strong></p>
<p>You can use Scheffé adjusted <span class="math inline">\(p\)</span> -values and compare them to <span class="math inline">\(0.05 .\)</span> The adjusted <span class="math inline">\(p\)</span> -values for the Scheffé procedure are given by
<span class="math display">\[
\tilde{p}=P\left(\sqrt{(g-1) F_{g-1, d f e}} \geq\left|t_{\mathrm{c}}\right|\right)=1-P\left(F_{g-1, d f_{e}}&lt;t_{\mathrm{c}}^{2} /(g-1)\right) .
\]</span></p>
<p><strong>Specified contrasts</strong></p>
<p>However, if some of the comparisons are selected post hoc (i.e., after looking at the data), then the seeming family size of k=16 used for Bonferroni is not valid. Had the specified contrasts indeed been preselected, then Bonferroni would be more appropriate than Scheffé, but the simulation-consistent method would be more appropriate than either Bonferroni or Scheffé.</p>
</div>
<div id="finding-the-maximal-contrast" class="section level3" number="10.6.2">
<h3><span class="header-section-number">10.6.2</span> Finding the Maximal Contrast</h3>
<pre><code>data House;
 input Location$ Price Sqfeet age @@;
datalines;
A 213.5 2374 4 A 219.9 2271 8 A 227.9 2088 5
A 192.5 1645 8 A 203.0 1814 6 A 242.1 2553 7
A 220.5 1921 9 A 205.5 1854 2 A 201.2 1536 9
A 194.7 1677 3 A 229.0 2342 5 A 208.7 1862 4
A 199.7 1894 7 A 212.0 1774 9 A 204.8 1476 8
A 186.1 1466 7 A 203.5 1800 8 A 193.0 1491 5
A 199.5 1749 8 A 198.1 1690 7 A 244.8 2741 5
A 196.3 1460 5 A 195.1 1614 6 A 225.8 2244 6
A 226.9 2165 6 A 204.7 1828 4 B 174.2 1503 6
B 169.9 1689 6 B 177.0 1638 2 B 167.0 1276 6
B 198.9 2101 9 B 181.2 1668 5 B 185.7 2123 4
B 199.8 2208 5 B 155.7 1273 8 B 220.1 2519 4
B 209.1 2303 6 B 182.4 1800 3 B 202.7 2336 8
B 192.0 2100 6 B 184.1 1697 4 C 190.8 1674 4
C 198.2 2307 7 C 194.6 2152 5 C 187.9 1948 9
D 202.5 2258 2 D 181.3 1965 6 D 186.1 1772 3
D 194.7 2385 1 D 164.7 1345 4 D 193.5 2220 8
D 180.1 1883 8 D 192.3 2012 6 D 180.6 1898 5
E 205.3 2362 7 E 206.3 2362 7 E 184.3 1963 9
E 176.6 1941 7 E 182.4 1975 5 E 198.8 2529 6
E 186.8 2079 5 E 188.5 2190 4 E 177.5 1897 5
E 186.9 1946 4
;
%let classvar = Location;
proc glm data= House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmeans Location / out=stats cov;
data Cov; set stats; keep Cov:;
proc iml;
 use stats; read all var {&amp;classvar LSMean};
 use Cov; read all into V;
 nclass = nrow(&amp;classvar);
 CBase = j(1,nclass-1) // -i(nclass-1);
 /* 1 - j contrasts, j = 2,...,nclass */
 num = (CBase`*LSMean)*(CBase`*LSMean)`;
 den = CBase`*V*CBase;
 evec = eigvec(num*inv(den));
 C = evec[,1]`*inv(den)*CBase`;
 C = C/sum((C&gt;0)#C);
 print C [label =&quot;Most Significant &amp;classvar Contrast&quot;
 colname=&amp;classvar];
quit;

***Testing a Discovered Contrast;
proc orthoreg data=House;
 class Location;
 model Price = Location Sqfeet Age;
 lsmestimate Location
 &#39;A-B&#39; 3 -3 ,
 &#39;A-C&#39; 3 0 -3 ,
 &#39;A-D&#39; 3 0 0 -3 ,
 &#39;A-E&#39; 3 0 0 0 -3 ,
 &#39;A-[B,D,E]&#39; 3 -1 0 -1 -1 / divisor=3 adjust=scheffe cl;
 ods output LSMEstimates=LSME;
proc print data=LSME noobs label;
 where (Label = &quot;A-[B,D,E]&quot;);
 var Label Estimate StdErr tValue probt Adjp AdjLower AdjUpper;
run; </code></pre>
<p><span class="math display">\[
\begin{array}{lrrrrr}
\hline &amp; {\text { Most Significant Location Contrast }} \\
A &amp; B &amp; C &amp; D &amp; E \\
1 &amp; -0.307122 &amp; -0.074921 &amp; -0.249097 &amp; -0.36886 \\
\hline
\end{array}
\]</span></p>
</div>
<div id="working-hotelling-method" class="section level3" number="10.6.3">
<h3><span class="header-section-number">10.6.3</span> Working-Hotelling method</h3>
<blockquote>
<p>Confidence Band for a Simple Linear Regression</p>
</blockquote>
<p>For simple linear regression model
<span class="math display">\[
y_{i}=\beta_{0}+\beta_{1} x_{i}+\varepsilon_{i}
\]</span>
<span class="math display">\[\left(\hat{\beta}_{0}, \hat{\beta}_{1}\right)=\hat{\boldsymbol{\beta}}=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Y}\]</span>
The simultaneous confidence intervals for <span class="math inline">\(\beta_{0}+\beta_{1} x\)</span> for all <span class="math inline">\(a \leq x \leq b\)</span>. The intervals have the usual form
<span class="math display">\[
\hat{\beta}_{0}+\hat{\beta}_{1} x \pm c_{\alpha} s . e .\left(\hat{\beta}_{0}+\hat{\beta}_{1} x\right),
\]</span>
<span class="math display">\[
\text { s.e. }\left(\hat{\beta}_{0}+\hat{\beta}_{1} x\right)=\hat{\sigma} \sqrt{\mathbf{x}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{x}}
\]</span>
<span class="math inline">\(\hat{\sigma}=\)</span> RMSE , and <span class="math inline">\(\mathbf{x}^{\prime}=(1 x)\)</span>. The difficult question is, <strong>how to choose <span class="math inline">\(c_{\alpha} ?\)</span></strong></p>
<p>Even if the bounds a and b are both finite, the set of inferences still is infinite because there are
infinitely many points in the interval from a to b. Thus, the solution to the problem requires
something similar to the Scheffé method. The <strong>Working-Hotelling method</strong> uses the same essential technique as the Scheffé method. It
is based on the fact that the intervals
<span class="math display">\[
\ell_{0} \hat{\beta}_{0}+\ell_{1} \hat{\beta}_{1} \pm \sqrt{2 F_{1-\alpha, 2, n-2}} \hat{\sigma} \sqrt{l^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \boldsymbol{l}}
\]</span>
are exact simultaneous <span class="math inline">\(1-\alpha\)</span> confidence intervals for the parameters <span class="math inline">\(l^{\prime} \beta=\ell_{0} \beta_{0}+\ell_{1} \beta_{1}\)</span>, over the infinite set of all linear combinations <span class="math inline">\(\boldsymbol{l}=\left(\ell_{0}, \ell_{1}\right)^{\prime} .\)</span></p>
<p><strong>Problem</strong>: Too conservative. The infinite family contains all points in the range <span class="math inline">\(-\infty&lt;x&lt;+\infty\)</span>, which is too big, since you are only interested in a finite interval <span class="math inline">\(a \leq x \leq b\)</span>.</p>
</div>
<div id="discrete-approximation-method" class="section level3" number="10.6.4">
<h3><span class="header-section-number">10.6.4</span> Discrete approximation method</h3>
<blockquote>
<p>Confidence Band for a Simple Linear Regression</p>
</blockquote>
<p>Rather than use the conservative Working-Hotelling approach, you can use the exact distribution of <span class="math inline">\(\max _{a \leq x \leq b}\left|T_{x}\right|\)</span>, where <span class="math inline">\(T_{x}\)</span> is the usual <span class="math inline">\(t\)</span> statistic
<span class="math display">\[
T_{x}=\frac{\hat{\beta}_{0}+\hat{\beta}_{1} x-\left(\beta_{0}+\beta_{1} x\right)}{\text { s.e. }\left(\hat{\beta}_{0}+\hat{\beta}_{1} x\right)}
\]</span>
Letting <span class="math inline">\(c_{\alpha}\)</span> be the <span class="math inline">\(1-\alpha\)</span> quantile of the distribution of <span class="math inline">\(\max _{a \leq x \leq b}\left|T_{x}\right|\)</span>, the simultaneous confidence intervals are
<span class="math display">\[
\hat{\beta}_{0}+\hat{\beta}_{1} x \pm c_{\alpha} \text { s.e. }\left(\hat{\beta}_{0}+\hat{\beta}_{1} x\right) .
\]</span>
These intervals will be narrower than the Working-Hotelling intervals, and they will be exact in the sense that they will contain the true regression line with exactly <span class="math inline">\((1-\alpha) \times 100\)</span> percent confidence.</p>
<pre><code>***Simultaneous Confidence Bounds for Regression Function;
data House;
 input Location$ Price Sqfeet age @@;
datalines;
A 213.5 2374 4 A 219.9 2271 8 A 227.9 2088 5
A 192.5 1645 8 A 203.0 1814 6 A 242.1 2553 7
A 220.5 1921 9 A 205.5 1854 2 A 201.2 1536 9
A 194.7 1677 3 A 229.0 2342 5 A 208.7 1862 4
A 199.7 1894 7 A 212.0 1774 9 A 204.8 1476 8
A 186.1 1466 7 A 203.5 1800 8 A 193.0 1491 5
A 199.5 1749 8 A 198.1 1690 7 A 244.8 2741 5
A 196.3 1460 5 A 195.1 1614 6 A 225.8 2244 6
A 226.9 2165 6 A 204.7 1828 4 B 174.2 1503 6
B 169.9 1689 6 B 177.0 1638 2 B 167.0 1276 6
B 198.9 2101 9 B 181.2 1668 5 B 185.7 2123 4
B 199.8 2208 5 B 155.7 1273 8 B 220.1 2519 4
B 209.1 2303 6 B 182.4 1800 3 B 202.7 2336 8
B 192.0 2100 6 B 184.1 1697 4 C 190.8 1674 4
C 198.2 2307 7 C 194.6 2152 5 C 187.9 1948 9
D 202.5 2258 2 D 181.3 1965 6 D 186.1 1772 3
D 194.7 2385 1 D 164.7 1345 4 D 193.5 2220 8
D 180.1 1883 8 D 192.3 2012 6 D 180.6 1898 5
E 205.3 2362 7 E 206.3 2362 7 E 184.3 1963 9
E 176.6 1941 7 E 182.4 1975 5 E 198.8 2529 6
E 186.8 2079 5 E 188.5 2190 4 E 177.5 1897 5
E 186.9 1946 4
; 
proc orthoreg data=House(where=(Location=&#39;A&#39;));
 model Price=Sqfeet;
 estimate
 &quot;1000&quot; Intercept 1 Sqfeet 1000 ,
 &quot;1200&quot; Intercept 1 Sqfeet 1200 ,
 &quot;1400&quot; Intercept 1 Sqfeet 1400 ,
 &quot;1600&quot; Intercept 1 Sqfeet 1600 ,
 &quot;1800&quot; Intercept 1 Sqfeet 1800 ,
 &quot;2000&quot; Intercept 1 Sqfeet 2000 ,
 &quot;2200&quot; Intercept 1 Sqfeet 2200 ,
 &quot;2400&quot; Intercept 1 Sqfeet 2400 ,
 &quot;2600&quot; Intercept 1 Sqfeet 2600 ,
 &quot;2800&quot; Intercept 1 Sqfeet 2800 ,
 &quot;3000&quot; Intercept 1 Sqfeet 3000
 / adjust=simulate(acc=.0002 seed=121211 report) cl;
 ods output Estimates=Estimates;
proc print data=Estimates noobs label;
 var Label Estimate StdErr tValue probt Adjp AdjLower AdjUpper;
proc sgplot data=Estimates(rename=(Estimate=Price label=Sqfeet));
 series x = Sqfeet Y = Price;
 series x = Sqfeet Y = AdjLower;
 series x = Sqfeet Y = Adjupper;
 title &#39;Confidence Bounds for Mean Price&#39;;
run; 

*** For Working-Hotelling confidence bounds;
*** estimate --- / adjust=scheffe cl;</code></pre>
<div class="figure" style="text-align: center">
<img src="02_Plots/discrete_approximation.png" alt="Figure:1 Simultaneous Confidence Bounds (Discrete Approximation) for Mean Price of Houses in Location ‘A’" width="100%" />
<p class="caption">
(#fig:Discrete approximation)Figure:1 Simultaneous Confidence Bounds (Discrete Approximation) for Mean Price of Houses in Location ‘A’
</p>
</div>
</div>
</div>
<div id="multiple-comparisons-under-heteroscedasticity" class="section level2" number="10.7">
<h2><span class="header-section-number">10.7</span> Multiple Comparisons under Heteroscedasticity</h2>
<div id="introduction-of-heteroscedasticity" class="section level3" number="10.7.1">
<h3><span class="header-section-number">10.7.1</span> Introduction of heteroscedasticity</h3>
<p><strong>Results from Homoscedastic</strong></p>
<p>With extreme heteroscedasticity, Tukey’s method can fail miserably. The problem is
that the estimated error variance that is used for all comparisons is a weighted average of the
within-group variance estimates. If the true variances differ widely between groups, then this
overall weighted average will be too large for some of the pairwise comparisons and too small
for others. As a consequence, it may be more likely that some comparisons will be erroneously
flagged as “significant;” and conversely, it may also be more likely that other comparisons will
be erroneously flagged as “insignificant.”</p>
<p><strong>Under homoscedasticity and uncorrelated errors assumptions</strong></p>
<p>Linear model <span class="math inline">\(\mathbf{Y}=\mathbf{X} \beta+\boldsymbol{\varepsilon}\)</span> with all assumptions satisfied, and <span class="math inline">\(\mathbf{X}\)</span> of full column
rank. Then the covariance matrix of <span class="math inline">\(\hat{\boldsymbol{\beta}}=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{Y}\)</span> is, by standard statistical theory,
<span class="math display">\[
\operatorname{Cov}(\hat{\boldsymbol{\beta}})=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \operatorname{Cov}(\mathbf{Y})\left\{\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime}\right\}^{\prime}
\]</span>
When <span class="math inline">\(\mathbf{Y}\)</span> is homoscedastic - that is, when <span class="math inline">\(\operatorname{Cov}(\mathbf{Y})=\sigma^{2} I-\)</span> a little matrix algebra makes life simpler:
<span class="math display">\[
\operatorname{Cov}(\hat{\boldsymbol{\beta}})=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime}\left(\sigma^{2} I\right)\left\{\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime}\right\}^{\prime}=\sigma^{2}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}
\]</span></p>
<p>This latter form gives the standard error of <span class="math inline">\(\mathbf{c}^{\prime} \hat{\beta}\)</span> since <span class="math inline">\(\operatorname{Var}\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)=\mathbf{c}^{\prime} \operatorname{Cov}(\hat{\boldsymbol{\beta}}) \mathbf{c}=\sigma^{2} \mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{c}\)</span>.
Taking the square root of the variance and supplying the estimate for <span class="math inline">\(\sigma^{2}\)</span> gives the formula s.e. <span class="math inline">\(\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)=\hat{\sigma} \sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{c}}\)</span>.</p>
<p><strong>Under heteroscedasticity</strong></p>
<p>In this case, <span class="math inline">\(\operatorname{Cov}(\mathbf{Y})=\mathbf{V}\)</span>, a diagonal matrix where the
<span class="math inline">\(i^{\text {th }}\)</span> diagonal element is <span class="math inline">\(\sigma_{j}^{2}\)</span> if observation <span class="math inline">\(i\)</span> is in group <span class="math inline">\(j\)</span>.</p>
<p>The estimation of <span class="math inline">\(\beta\)</span>, obtaining what are known as generalized least squares (GLS) estimates:
<span class="math display">\[
\hat{\boldsymbol{\beta}}_{G L S}=\left(\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{Y}
\]</span>
The method that uses GLS will be referred to as “the High Road,” because the GLS estimate is the best linear unbiased estimate (BLUE) for <span class="math inline">\(\beta\)</span> when <span class="math inline">\(\mathbf{V}\)</span> is known. The High Road standard errors of the estimated contrasts are given by the reasonably simple form
<span class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}_{G L S}\right)=\sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{V}^{-1} \mathbf{X}\right)^{-1} \mathbf{c}}
\]</span>
In practice, <span class="math inline">\(\mathbf{V}\)</span> must be estimated, leading to the “estimated generalized least squares” (EGLS) estimate
<span class="math display">\[
\hat{\boldsymbol{\beta}}_{E G L S}=\left(\mathbf{X}^{\prime} \hat{\mathbf{V}}^{-1} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \hat{\mathbf{V}}^{-1} \mathbf{Y}
\]</span></p>
<p>The EGLS estimate is no longer the BLUE of <span class="math inline">\(\beta\)</span>, but is typically <strong>more efficient than the ordinary least squares (OLS) estimate</strong> when <span class="math inline">\(n\)</span> is large.</p>
<p>So much for the High Road. If you want to take the Low Road instead, you’ll use the OLS estimate with the correct standard errors. If <span class="math inline">\(\operatorname{Cov}(\mathbf{Y})=\mathbf{V}\)</span>, then
<span class="math display">\[
\operatorname{Cov}\left(\hat{\boldsymbol{\beta}}_{\text {OLS }}\right)=\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \mathbf{V} \mathbf{X}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1}
\]</span>
Supplying the estimated <span class="math inline">\(\mathbf{V}\)</span> gives you the more complicated formula for the Low Road standard errors:
<span class="math display">\[
\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}_{O L S}\right)=\sqrt{\mathbf{c}^{\prime}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{X}^{\prime} \hat{\mathbf{V}} \mathbf{X}\left(\mathbf{X}^{\prime} \mathbf{X}\right)^{-1} \mathbf{c}} .
\]</span>
### Satterthwaite Approximation</p>
<p><strong>No more <span class="math inline">\(t\)</span> -distribution</strong></p>
<p>Whether you take the High Road or the Low Road, OLS or EGLS, the usual <span class="math inline">\(t\)</span> -distribution no longer applies; specifically the statistic
<span class="math display">\[
t=\frac{\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}-\mathbf{c}^{\prime} \boldsymbol{\beta}}{\text { s.e. }\left(\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}\right)}
\]</span>
is not distributed as <span class="math inline">\(t\)</span> with <span class="math inline">\(n-\operatorname{rank}(\mathbf{X})\)</span> degrees of freedom when <span class="math inline">\(\mathbf{Y}\)</span> is normal. Of course, in the unlikely case that <span class="math inline">\(\mathbf{V}\)</span> is known, the <span class="math inline">\(t\)</span> statistic is distributed as <span class="math inline">\(\mathrm{N}(0,1)\)</span>. But when you have to use <span class="math inline">\(\hat{\mathbf{V}}\)</span> in place of <span class="math inline">\(\mathbf{V}\)</span>, there is extra variability in the distribution that should make a <span class="math inline">\(t\)</span> distribution approximation closer than a normal approximation. Still, there is no exact distribution in general, and you are stuck with an approximation of one sort or another.</p>
<p><strong>Satterthwaite degrees</strong></p>
<p>Satterthwaite formula gives a datadependent and approximate degrees of freedom for the distribution of the <span class="math inline">\(t\)</span> -statistic. For comparing <span class="math inline">\(\mu_{i}\)</span> with <span class="math inline">\(\mu_{i^{\prime}}\)</span>, the Satterthwaite degrees of freedom formula gives
<span class="math display">\[
d f_{i, i^{\prime}}=\frac{\left(\hat{\sigma}_{i}^{2} / n_{i}+\hat{\sigma}_{i^{\prime}}^{2} / n_{i^{\prime}}\right)^{2}}{\left(\hat{\sigma}_{i}^{2} / n_{i}\right)^{2} /\left(n_{i}-1\right)+\left(\hat{\sigma}_{i^{\prime}}^{2} / n_{i^{\prime}}\right)^{2} /\left(n_{i^{\prime}}-1\right)} .
\]</span>
Thus, rather than having a common <span class="math inline">\(t\)</span> distribution for all comparisons, you use <span class="math inline">\(t\)</span> distributions with different degrees of freedom for every comparison.</p>
<pre><code>*** Satterthwaite-Based Multiple Comparisons with Bonferroni Adjustments Using PROC MIXED
proc mixed data=UPSIT;
 class Agegroup;
 model Smell = Agegroup / ddfm=Satterth;
 repeated / group=Agegroup;
 lsmeans Agegroup/adjust=Bonferroni cl;
 ods output Diffs=Diffs;
proc print data=Diffs noobs label;
 var Agegroup _Agegroup Estimate StdErr df probt
 Adjp AdjLower AdjUpper;
run; 

*** PROC GLIMMIX allows for non-normal distributions and has additional multiple comparisons enhancements
proc glimmix data=UPSIT;
 class Agegroup;
 model Smell = Agegroup / ddfm=Satterth;
 random _residual_ / group=Agegroup;
 lsmeans Agegroup / adjust=Bonferroni adjdfe=row cl lines;
run; </code></pre>
</div>
<div id="maxt-method-under-heteroscedasticity" class="section level3" number="10.7.2">
<h3><span class="header-section-number">10.7.2</span> MaxT Method under Heteroscedasticity</h3>
<p>The Bonferroni method is conservative because it does <strong>not account for dependence among the t statistics</strong>. The distribution of MaxT that correctly incorporates these dependencies, either via exact analytic solution, approximate analytic solution, or simulation-based analytic solution.</p>
<p>No matter whether EGLS or OLS is used to estimate <span class="math inline">\(\beta\)</span> (the “High Road” and the “Low Road” of the previous section), the covariance matrix of <span class="math inline">\(\hat{\beta}\)</span> will depend on <span class="math inline">\(\mathbf{V}\)</span>. Replace <span class="math inline">\(\mathbf{V}\)</span> by its estimate <span class="math inline">\(\hat{\mathbf{V}}\)</span>, and call the estimated covariance matrix <span class="math inline">\(s^{2}(\hat{\boldsymbol{\beta}})\)</span>. Then the estimated covariance matrix of the set of contrasts <span class="math inline">\(\mathbf{C}^{\prime} \hat{\beta}\)</span> is <span class="math inline">\(\mathbf{C}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\} \mathbf{C}\)</span>, and the estimated covariance matrix of the set of <span class="math inline">\(t\)</span> statistics
<span class="math display">\[
\left\{t_{i}\right\}=\left\{\frac{\mathbf{c}^{\prime} \hat{\boldsymbol{\beta}}-\mathbf{c}_{i} \boldsymbol{\beta}}{\operatorname{see}\left(\mathbf{c}_{i}^{\prime} \boldsymbol{\beta}\right)}\right\}=\left\{\frac{\mathbf{c}_{i} \hat{\boldsymbol{\beta}}-\mathbf{c}_{\boldsymbol{i}} \boldsymbol{\beta}}{\left[\mathbf{c}_{i}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\} \mathbf{c}_{i}\right]^{1 / 2}}\right\}
\]</span>
also happens to be a correlation matrix <span class="math inline">\(\mathbf{R}=\mathbf{D}^{-1 / 2} \mathbf{C}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\} \mathbf{C} \mathbf{D}^{-1 / 2}\)</span>, where <span class="math inline">\(\mathbf{D}\)</span> is the diagonal
matrix having diagonal elements <span class="math inline">\(\mathbf{c}_{i}^{\prime}\left\{s^{2}(\hat{\boldsymbol{\beta}})\right\} \mathbf{c}_{i}\)</span>.</p>
<p>The task is to simulate the distribution of MaxT, where the correlation matrix of the <span class="math inline">\(t\)</span> statistics is given by <span class="math inline">\(\mathbf{R}\)</span>. This is straightforward when the degrees of freedom are constant across <span class="math inline">\(t\)</span> statistics, but when there are differing degrees of freedom, it is more complex. Here is an approximate method for generating one value of MaxT from such a distribution:</p>
<p><strong>Simulating Correlated T Values with Different Marginal Degrees of Freedom</strong></p>
<ol style="list-style-type: decimal">
<li>Generate <span class="math inline">\(\mathbf{Z}\)</span> as multivariate normal with mean zero and covariance matrix <span class="math inline">\(\mathbf{R}\)</span>.</li>
<li>Generate a scalar uniform random variable, <span class="math inline">\(U\)</span>, independent of the vector <span class="math inline">\(\mathbf{Z}\)</span>.</li>
<li>Letting <span class="math inline">\(F_{\mathrm{v}}\)</span> denote the cdf of a chi-square random variable with <span class="math inline">\(\mathrm{v}\)</span> degrees of freedom, calculate <span class="math inline">\(d_{i}=\sqrt{F_{v_{i}}^{-1}(U) / v_{i}}\)</span>, where <span class="math inline">\(v_{i}\)</span> is the degrees of freedom for the <span class="math inline">\(i^{\text {th }}\)</span> test statistic.</li>
<li>Define <span class="math inline">\(\mathbf{d}\)</span> as <span class="math inline">\(\mathbf{d}=\operatorname{diag}\left\{d_{i}\right\}\)</span>, and let <span class="math inline">\(\mathbf{T}=\mathbf{d}^{-1} \mathbf{Z}\)</span>.</li>
<li>Let MaxT <span class="math inline">\(=\max (\mathbf{T})\)</span>.</li>
</ol>
</div>
<div id="minp-method-under-heteroscedasticity" class="section level3" number="10.7.3">
<h3><span class="header-section-number">10.7.3</span> MinP Method under Heteroscedasticity</h3>
<p>The potential inconsistency between MaxT and Bonferroni whenever the T-statistics have different marginal distributions, which is the case when there are differing degrees of freedom, or when the response is discrete. Westfall and Young presented a solution <strong>based on the minimum p-value instead of the maximum t value</strong>. This so-called MinP method is available in PROC MULTTEST for nonparametric and semiparametric applications</p>
<p>Construction of simultaneous confidence intervals, consider the problem of obtaining balanced marginal confidence intervals with a simulation-consistent method where the marginal t distributions have varying degrees of freedom. It will need a different critical value <span class="math inline">\(c_{i \alpha}\)</span> for every interval <span class="math inline">\(\hat{\theta}_{i}-c_{i \alpha}\)</span> s.e. <span class="math inline">\(\left(\hat{\theta}_{i}\right)\)</span>, and you want the following to hold:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\quad P\left(\left|T_{i}\right|&lt;c_{i \alpha}\right.\)</span>, all <span class="math inline">\(\left.i\right)=1-\alpha\)</span>, so that the FWE is <span class="math inline">\(\alpha\)</span>, and</li>
<li><span class="math inline">\(\quad P\left(\left|T_{i}\right|&lt;c_{i \alpha}\right)=1-\alpha^{\prime}\)</span>, so that the marginal confidence levels are the same value <span class="math inline">\(1-\alpha^{\prime}\)</span>.</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
&amp; P\left(\left|T_{i}\right|&lt;F_{v_{i}}^{-1}\left(1-\alpha^{\prime} / 2\right), \text { all } i\right) &amp;=1-\alpha \\
\Leftrightarrow &amp; P\left(F_{v_{i}}\left(\left|T_{i}\right|\right)&lt;1-\alpha^{\prime} / 2, \text { all } i\right) &amp;=1-\alpha \\
\Leftrightarrow &amp; P\left(2\left\{1-F_{v_{i}}\left(\left|T_{i}\right|\right)\right\}&gt;\alpha^{\prime}, \text { all } i\right) &amp;=1-\alpha \\
\Leftrightarrow &amp; P\left(P_{i} \leq \alpha^{\prime}, \text { some } i\right) &amp;=\alpha \\
\Leftrightarrow &amp; P\left(\min P_{i} \leq \alpha^{\prime}\right) &amp;=\alpha
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(P_{i}=2\left\{1-F_{v_{i}}\left(\left|T_{i}\right|\right)\right\} .\)</span> Thus <span class="math inline">\(\alpha^{\prime}\)</span> is the <span class="math inline">\(\alpha\)</span> quantile of the distribution of the minimum <span class="math inline">\(p\)</span> value- the MinP distribution, which can be computed by simulating correlated <span class="math inline">\(T_{i}\)</span> values</p>
</div>
</div>
<div id="closed-and-stepwise-testing-methods" class="section level2" number="10.8">
<h2><span class="header-section-number">10.8</span> Closed and Stepwise Testing Methods</h2>
<p><span class="math display">\[
\begin{array}{l}
\hline \text { if you... } \\
\hline \begin{array}{l}
\text { want to declare any significance, and are unsure } \\
\text { about dependence structure }
\end{array} &amp; \text { Bonferroni-Holm } \\
\hline \begin{array}{l}
\text { want to declare any significance and are reasonably} \\
\text { sure that the tests are independent or positively } \\
\text { dependent }
\end{array} &amp; \text { Simes-Hommel } \\  
\hline \begin{array}{l}
\text { want to declare any significance and are sure that } \\
\text { the tests are independent and strongly reinforcing }
\end{array} &amp; \text { closed Fisher combination } \\
\hline \begin{array}{l}
\text { want to declare significance only in a pre-assigned } \\
\text { order }
\end{array} &amp; \text { fixed sequence tests } \\
\hline \begin{array}{l}
\text { want to declare any significance among a collection } \\
\text { of secondary hypotheses, but only after } \\
\text { significance of a primary hypothesis is achieved }
\end{array} &amp;  \text {gatekeeper tests } \\
\hline
\end{array}
\]</span></p>
<div id="closed-family-of-hypotheses" class="section level3" number="10.8.1">
<h3><span class="header-section-number">10.8.1</span> Closed Family of Hypotheses</h3>
<p><strong>Kohärenz and Konsonanz</strong></p>
<p>Ein multipler Test <span class="math inline">\(\varphi\)</span> für <span class="math inline">\((\Omega, \mathcal{A}, \mathcal{P}, \mathcal{H})\)</span> heißt kohärent, falls
<span class="math display">\[
\forall i, j \in I \text { mit } H_{i} \subseteq H_{j}:\left\{\varphi_{j}=1\right\} \Rightarrow\left\{\varphi_{i}=1\right\}
\]</span>
ist. Anderenfalls heißt <span class="math inline">\(\varphi\)</span> inkohärent.
Ein multipler Test <span class="math inline">\(\varphi=\left(\varphi_{i}: i \in I=1, \ldots, m\right)\)</span> für <span class="math inline">\((\Omega, \mathcal{A}, \mathcal{P}, \mathcal{H})\)</span> heißt konsonant, falls
<span class="math display">\[
\forall i \in I \text { mit } \exists j \in I: H_{i} \subset H_{j}:\left\{\varphi_{i}=1\right\} \subseteq \bigcup_{j: H_{j} \supset H_{i}}\left\{\varphi_{j}=1\right\}
\]</span>
Wird <span class="math inline">\(H i\)</span> von einem konsonanten multiplen Test <span class="math inline">\(\varphi\)</span> abgelehnt und gibt es echte Obermengen <span class="math inline">\(H j\)</span>
von <span class="math inline">\(H_{i}\)</span> in <span class="math inline">\(\mathcal{H}\)</span>, so wird auch mindestens eine dieser Obermengen von <span class="math inline">\(\varphi\)</span> abgelehnt. Anderenfalls
heißt <span class="math inline">\(\varphi\)</span> dissonant.</p>
<div class="figure" style="text-align: center"><span id="fig:Teststrategien"></span>
<img src="02_Plots/Close_Begin.PNG" alt="Figure: Closure Diagram with k=4 Basic Tests of Cold Remedy Endpoints" width="100%" />
<p class="caption">
Figure 10.1: Figure: Closure Diagram with k=4 Basic Tests of Cold Remedy Endpoints
</p>
</div>
<p><strong>The Closed Testing Method</strong></p>
<p>The closed diagram defined in the previous subsection is pretty complicated, but it essentially
gives you the entire flowchart for performing the closed testing method. The method proceeds
as follows:</p>
<ul>
<li>Test every member of the closed family by a (suitable) <span class="math inline">\(\alpha\)</span> -level test. (Here, <span class="math inline">\(\alpha\)</span> refers to nominal comparison-wise error rate.)</li>
<li>Reject a basic hypothesis if
<ul>
<li>ts corresponding <span class="math inline">\(\alpha\)</span> -level test rejects it, and</li>
<li>every intersection hypothesis that includes it is also rejected by its <span class="math inline">\(\alpha\)</span> -level test.</li>
</ul></li>
</ul>
<p>Thus, to determine whether the closed testing method rejects <span class="math inline">\(H_{1}: \delta_{1}=0\)</span>, you must reject <span class="math inline">\(H_{1}\)</span> using an <span class="math inline">\(\alpha\)</span> -level test, and you must reject each of <span class="math inline">\(H_{\{1,2\}}, H_{\{1,3\}}, H_{\{1,4\}}\)</span>, <span class="math inline">\(H_{\{1,2,3\}}, H_{\{1,2,4\}}, H_{\{1,3,4\}}\)</span>, and <span class="math inline">\(H_{\{1,2,3,4\}}\)</span>, all using <span class="math inline">\(\alpha\)</span> -level tests for each of these composite hypotheses.</p>
<p><strong>Adjusted p-Values</strong></p>
<p>The adjusted <span class="math inline">\(p\)</span> -value for hypothesis <span class="math inline">\(H_{i}\)</span> is the maximum of all <span class="math inline">\(p\)</span> -values for all intersection hypotheses in the closed family that includes <span class="math inline">\(H_{i}\)</span> as part of the intersection; formally, letting <span class="math inline">\(p_{S}\)</span> denote the <span class="math inline">\(p\)</span> -value for testing an intersection hypothesis <span class="math inline">\(H_{S}\)</span>, where <span class="math inline">\(S \subseteq\{1, \ldots, k\}\)</span>,
<span class="math display">\[
\tilde{p}_{i}=\max _{\{S \mid i \in S\}} p_{S} .
\]</span></p>
</div>
<div id="bonferroni-holm-method" class="section level3" number="10.8.2">
<h3><span class="header-section-number">10.8.2</span> Bonferroni-Holm Method</h3>
<p>The Bonferroni test for each member of the closed family. Denote by <span class="math inline">\(p_{i}\)</span> the <span class="math inline">\(p\)</span> -value for the basic hypothesis <span class="math inline">\(H_{i}\)</span>. Then each composite hypothesis <span class="math inline">\(H_{S}\)</span> will be tested by comparing <span class="math inline">\(\min _{i \in S} p_{i}\)</span> with <span class="math inline">\(\alpha / k^{*}\)</span>, where <span class="math inline">\(k^{*}\)</span> is the number of hypotheses in the set, also denoted by <span class="math inline">\(k^{*}=|S| .\)</span> Equivalently, you can calculate the Bonferroni <span class="math inline">\(p\)</span> -value for each test of the composite hypotheses <span class="math inline">\(H_{S}\)</span> as <span class="math inline">\(p_{S}=k^{*} \times\)</span> <span class="math inline">\(\min _{i \in S} p_{i}\)</span></p>
<p><strong>The Bonferroni-Holm Shortcut Closed Testing Procedure </strong></p>
<p>Let <span class="math inline">\(p_{(1)} \leq p_{(2)} \leq \ldots \leq p_{(k)}\)</span> be the ordered <span class="math inline">\(p\)</span> -values and <span class="math inline">\(H_{(1)}, H_{(2)}, \ldots, H_{(k)}\)</span> be the corresponding hypotheses.</p>
<ul>
<li>Step 1. Start by comparing <span class="math inline">\(p_{(1)}\)</span> with <span class="math inline">\(\alpha / k\)</span>. If larger, stop and retain all hypotheses <span class="math inline">\(H_{(1), \ldots,} H_{(k)}\)</span>; otherwise, reject <span class="math inline">\(H_{(1)}\)</span> and proceed.</li>
<li>Step 2. Compare <span class="math inline">\(p_{(2)}\)</span> with <span class="math inline">\(\alpha /(k-1)\)</span>. If larger, stop and retain <span class="math inline">\(H_{(2), \ldots} H_{(k)}\)</span>; otherwise, reject <span class="math inline">\(H_{(2)}\)</span> and proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1}\)</span>. Compare <span class="math inline">\(p_{(k-1)}\)</span> with <span class="math inline">\(\alpha / 2\)</span>. If larger, stop and retain <span class="math inline">\(H_{(k-1)}, H_{(k)}\)</span>; otherwise, reject <span class="math inline">\(H_{(k-1)}\)</span> and proceed.</li>
<li>Step k. Compare <span class="math inline">\(p_{(k)}\)</span> with <span class="math inline">\(\alpha\)</span>. If larger, stop and retain <span class="math inline">\(H_{(k)}\)</span>; otherwise, reject <span class="math inline">\(H_{(k)}\)</span>.</li>
</ul>
<p><strong>Bonferroni-Holm Adjusted p-Values</strong></p>
<p>Adjusted p-values make it simple to use multiple comparisons procedures⎯all you need to do is compare the adjusted p-value to your nominal FWE level.</p>
<ul>
<li>Step 1. For testing <span class="math inline">\(H_{(1)}, \tilde{p}_{(1)}=k p_{(1)}\)</span>.</li>
<li>Step 2. For testing <span class="math inline">\(H_{(2)}, \tilde{p}_{(2)}=\max \left(\tilde{p}_{(1)},(k-1) p_{(2)}\right)\)</span>.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1}\)</span>. For testing <span class="math inline">\(H_{(k-1)}, \tilde{p}_{(k-1)}=\max \left(\tilde{p}_{(k-2)}, 2 p_{(k-1)}\right) .\)</span></li>
<li>Step <span class="math inline">\(\boldsymbol{k}\)</span>. For testing <span class="math inline">\(H_{(k)}, \tilde{p}_{(k)}=\max \left(\tilde{p}_{(k-1)}, p_{(k)}\right)\)</span>.
A simple formula that covers all steps is
<span class="math display">\[
\tilde{p}_{(i)}=\max _{j \leq i}\left\{(k-j+1) p_{(j)}\right\} .
\]</span>
Since there is no need to report any p-value to be greater than 1.0
<span class="math display">\[
\tilde{p}_{(i)}=\min \left(1, \max _{j \leq i}\left\{(k-j+1) p_{(j)}\right\}\right) .
\]</span></li>
</ul>
<p><strong>Calculating Bonferroni-Holm Adjusted p-Values Using PROC MULTTEST</strong></p>
<pre><code>data prog13p1;
 input p @@;
 datalines;
0.0121 0.0142 0.1986 0.0191
;
proc multtest inpvalues(p)=prog13p1 holm;
run;</code></pre>
</div>
<div id="šidák-holm-method" class="section level3" number="10.8.3">
<h3><span class="header-section-number">10.8.3</span> Šidák-Holm Method</h3>
<p><strong>The Šidák-Holm Shortcut Closed Testing Procedure</strong></p>
<ul>
<li>Step 1. Start by comparing <span class="math inline">\(p_{(1)}\)</span> with <span class="math inline">\(1-(1-\alpha)^{1 / k}\)</span>. If larger, stop and retain all hypotheses <span class="math inline">\(H_{(1)}, \ldots, H_{(k)} ;\)</span> otherwise, reject <span class="math inline">\(H_{(1)}\)</span> and proceed.</li>
<li>Step 2. Compare <span class="math inline">\(p_{(2)}\)</span> with <span class="math inline">\(1-(1-\alpha)^{1 /(k-1)}\)</span>. If larger, stop and retain <span class="math inline">\(H_{(2)}, \ldots, H_{(k)}\)</span>; otherwise, reject <span class="math inline">\(H_{(2)}\)</span> and proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1}\)</span>. Compare <span class="math inline">\(p_{(k-1)}\)</span> with <span class="math inline">\(1-(1-\alpha)^{1 / 2}\)</span>. If larger, stop and retain <span class="math inline">\(H_{(k-1)}, H_{(k)}\)</span>; otherwise, reject <span class="math inline">\(H_{(k-1)}\)</span> and proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}\)</span>. Compare <span class="math inline">\(p^{(k)}\)</span> with <span class="math inline">\(\alpha\)</span>. If larger, stop and retain <span class="math inline">\(H^{(k)}\)</span>; otherwise, reject <span class="math inline">\(H^{(k)}\)</span>.</li>
</ul>
<p>Equivalently, and more simply, the results of the Šidák-Holm shortcut closed testing procedure can be displayed using adjusted <span class="math inline">\(p\)</span> -values:
<span class="math display">\[
\tilde{p}_{(i)}=\max _{j \leq i}\left\{1-\left(1-p_{(j)}\right)^{k-j+1}\right\}
\]</span>
Unlike the Bonferroni-Holm adjusted <span class="math inline">\(p\)</span> -values, the Šidák-Holm adjustment automatically satisfies <span class="math inline">\(\tilde{p}_{(i)} \leq 1.0\)</span>, so there is no need to truncate.</p>
<p><strong>Calculating Šidák-Holm Adjusted p-Values Using PROC MULTTEST</strong></p>
<pre><code>data prog13p1;
 input p @@;
 datalines;
0.0121 0.0142 0.1986 0.0191
;
proc multtest inpvalues(p)=prog13p1 stepsid;
run;</code></pre>
</div>
<div id="closed-fisher-combination-method" class="section level3" number="10.8.4">
<h3><span class="header-section-number">10.8.4</span> Closed Fisher Combination Method</h3>
<blockquote>
<p>Meta-analysis</p>
</blockquote>
<p>Composite hypotheses <span class="math inline">\(H_{S}\)</span> often occur in meta-analysis. For example, suppose companies A, B, and <span class="math inline">\(\mathrm{C}\)</span> all test a drug and find <span class="math inline">\(p\)</span> -values <span class="math inline">\(0.061,0.083\)</span>, and <span class="math inline">\(0.089\)</span> for efficacy. Even though the <span class="math inline">\(p\)</span> values individually are insignificant, is this still the case under the composite null hypothesis that there is no drug effect for all companies? Meta-analysis provides ways to combine data from disparate studies to answer questions such as this, ideally gaining power in alternative hypothesis directions of interest.</p>
<p>The Fisher combination test is popular in meta-analysis. Like the Šidák test, the Fisher combination test assumes that the <span class="math inline">\(p\)</span> -values are independent and uniformly distributed <span class="math inline">\(\left(p_{i} \sim_{\mathrm{iid}}\right.\)</span> <span class="math inline">\(\mathrm{U}(0,1))\)</span> when the composite null hypothesis is true. Suppose a generic composite hypothesis has <span class="math inline">\(p\)</span> -values <span class="math inline">\(p_{1}, \ldots, p_{k^{*}}\)</span> for the component hypotheses. Then the Fisher combination test rejects the composite hypothesis when
<span class="math display">\[
\sum_{i=1}^{k^{*}}-2 \ln \left(p_{i}\right) \geq \chi_{2 k^{*}, 1-\alpha}^{2}
\]</span>
where <span class="math inline">\(\chi_{2 k^{*}, 1-\alpha}^{2}\)</span> is the <span class="math inline">\(1-\alpha\)</span> quantile of the chi-squared distribution with <span class="math inline">\(2 k^{*}\)</span> degrees of freedom.</p>
<blockquote>
<p>综合假设HS经常发生在荟萃分析中。 例如，假设公司A，B和C都对一种药物进行了测试，并且发现功效的p值分别为0.061、0.083和0.089。 即使各个p值无关紧要，但在所有公司都没有药物效应的复合无效假设下，情况是否仍然如此？ 荟萃分析提供了各种方法，可将来自不同研究的数据相结合，以回答诸如此类的问题，理想情况下，可以在感兴趣的替代假设方向上获得影响力。
Fisher组合检验在荟萃分析中很流行。 像Šidák检验一样，Fisher组合检验假设当复合零假设为真时，p值是独立且均匀分布的.</p>
</blockquote>
<p><strong>Closed Fisher Combination Testing Using PROC MULTTEST</strong></p>
<pre><code>data subgroups;
 input pval @@;
 datalines;
0.0784 0.0481 0.0041 0.0794
0.0043 0.0873 0.1007 0.1550
;
proc multtest inpvals(pval)=subgroups fisher_c;
run;</code></pre>
</div>
<div id="simes-hommel-method" class="section level3" number="10.8.5">
<h3><span class="header-section-number">10.8.5</span> Simes-Hommel Method</h3>
<p>The Simes test (Simes, 1986 ) is another combination test, like the Fisher combination test. It also assumes that the <span class="math inline">\(p\)</span> -values are independent and uniformly distributed <span class="math inline">\(\left(p_{i} \sim_{\text {iid }} U(0,1)\right)\)</span> when the composite null hypothesis is true, although it has been shown to be valid (in the sense of not exceeding the nominal Type I error level) when the <span class="math inline">\(p\)</span> -values exhibit positive dependence structures as well (Sarkar, 1998). Suppose a generic composite test has ordered <span class="math inline">\(p\)</span> -values <span class="math inline">\(p_{(1)} \leq\)</span> <span class="math inline">\(\ldots \leq p_{\left(k^{*}\right)}\)</span> for the component tests. Then the Simes test rejects the composite hypothesis when
<span class="math display">\[
p_{\text {Simes }}=\min \left\{\frac{k^{*}}{1} p_{(1)}, \frac{k^{*}}{2} p_{(2)}, \ldots, \frac{k^{*}}{k^{*}} p_{\left(k^{*}\right)}\right\} \leq \alpha
\]</span></p>
<p>Notice that the Simes p-value is never larger than the p-value for the simple Bonferroni test since
<span class="math display">\[
p_{\text {Simes }} \leq k^{*} p_{(1)}=p_{\text {Bonferroni }}
\]</span></p>
<p><strong>Calculating Simes-Hommel Adjusted p-Values Using PROC MULTTEST</strong></p>
<pre><code>data prog13p1;
 input p @@;
 datalines;
0.0121 0.0142 0.1986 0.0191
;
proc multtest inpvalues(p)=prog13p1 holm hommel;
run; </code></pre>
</div>
<div id="hochbergs-ok-step-up" class="section level3" number="10.8.6">
<h3><span class="header-section-number">10.8.6</span> Hochberg’s O(k) Step-Up</h3>
<p>Hochberg (1988) devised a shortcut to the Simes-Hommel method that can be computed in k steps, like the Bonferroni-Holm method. It is less conservative than the Bonferroni-Holm method, but more conservative than the Simes-Hommel method: The adjusted p-values mathematically are as follows:</p>
<p><span class="math display">\[
\tilde{p}_{i, \text { Simes-Hommel }} \leq \tilde{p}_{i, \text { Hochberg }} \leq \tilde{p}_{i, \text { Bonferroni-Holm }} \leq \tilde{p}_{i, \text { Bonferroni }}
\]</span></p>
<p>The method’s justification rests on the validity of the Simes test, meaning that it requires independence or positive dependence. It is very similar to the Bonferroni-Holm method, except that the <span class="math inline">\(p\)</span> -values are evaluated from least significant to most significant. Hence, unlike the Bonferroni-Holm method, which is sometimes called a “step-down” procedure, the Hochberg method is called a “step-up” procedure. Here is the algorithm:</p>
<blockquote>
<p>该方法的合理性取决于Simes检验的有效性，这意味着它需要独立性或正相关性</p>
</blockquote>
<p><strong>Hochberg’s Conservative Shortcut to the Simes-Hommel Closed Testing Procedure</strong></p>
<ul>
<li>Step 1. Start by comparing <span class="math inline">\(p_{(k)}\)</span> with <span class="math inline">\(\alpha\)</span>. If smaller than or equal to <span class="math inline">\(\alpha\)</span>, stop and reject all hypotheses <span class="math inline">\(H_{(1), \ldots,} H_{(k)} ;\)</span> otherwise, retain <span class="math inline">\(H_{(k)}\)</span> and proceed.</li>
<li>Step 2. Compare <span class="math inline">\(p_{(k-1)}\)</span> with <span class="math inline">\(\alpha / 2\)</span>. If smaller than or equal to <span class="math inline">\(\alpha / 2\)</span>, stop and reject all <span class="math inline">\(H_{(1), \ldots}\)</span> <span class="math inline">\(H_{(k-1)}\)</span>; otherwise, retain <span class="math inline">\(H_{(k-1)}\)</span> and proceed.
<span class="math inline">\(\cdots\)</span></li>
<li>Step <span class="math inline">\(\boldsymbol{k}-\mathbf{1} .\)</span> Compare <span class="math inline">\(p_{(2)}\)</span> with <span class="math inline">\(\alpha /(k-1)\)</span>. If smaller than or equal to <span class="math inline">\(\alpha /(k-1)\)</span>, stop and reject <span class="math inline">\(H_{(1)}, H_{(2)}\)</span>; otherwise, retain <span class="math inline">\(H_{(2)}\)</span> and proceed.</li>
<li>Step <span class="math inline">\(\boldsymbol{k}\)</span>. Compare <span class="math inline">\(p_{(1)}\)</span> with <span class="math inline">\(\alpha / k\)</span>. If smaller than or equal to <span class="math inline">\(\alpha / k\)</span>, reject <span class="math inline">\(H_{(1)}\)</span>; otherwise, retain <span class="math inline">\(H_{(1)}\)</span>.</li>
</ul>
<p>The adjusted <span class="math inline">\(p\)</span> -values for this procedure are written simply as
<span class="math display">\[
\tilde{p}_{(i)}=\min _{i \leq j}\left\{(k-j+1) p_{(j)}\right\} \text { . }
\]</span></p>
</div>
<div id="sequential-testing-with-fixed-sequences" class="section level3" number="10.8.7">
<h3><span class="header-section-number">10.8.7</span> Sequential Testing with Fixed Sequences</h3>
<p>Suppose your hypotheses follow a logical sequence, in the sense that <span class="math inline">\(H_{1}\)</span> precedes (in implication or importance) <span class="math inline">\(H_{2}, H_{2}\)</span> precedes <span class="math inline">\(H_{3}\)</span>, and so on. Then you can test them in order: first test <span class="math inline">\(H_{1}\)</span>, and if rejected, then test <span class="math inline">\(H_{2}\)</span>, and if rejected, then test <span class="math inline">\(H_{3}\)</span>, etc. In contrast to the examples of the previous sections, the order of the hypotheses in this application is determined a priori by the researcher, rather than determined a posteriori by the ordering of the <span class="math inline">\(p\)</span> -values.</p>
<div class="figure" style="text-align: center">
<img src="02_Plots/Sequential_testing.png" alt="Figure: Fixed Sequence as a Closed Testing Procedure" width="100%" />
<p class="caption">
(#fig:Sequential Testing)Figure: Fixed Sequence as a Closed Testing Procedure
</p>
</div>
<p><strong>Adjusted p-Values for Fixed Sequence Testing</strong></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\tilde{p}_{1}=p_{1}\)</span></li>
<li><span class="math inline">\(\tilde{p}_{2}=\max \left(\tilde{p}_{1}, p_{2}\right)\)</span></li>
<li><span class="math inline">\(\tilde{p}_{3}=\max \left(\tilde{p}_{2}, p_{3}\right)\)</span></li>
<li>…</li>
</ol>
<p><strong>Adjusted p-Values from Fixed-Sequence Tests</strong></p>
<pre><code>data a;
 input p @@;
 if (_N_ = 1) then pseq = 0;
 pseq = max(pseq,p);
 retain pseq;
 datalines;
0.021 0.043 0.402 0.004
;
run;</code></pre>
</div>
<div id="sequential-testing-using-gatekeeping-methods" class="section level3" number="10.8.8">
<h3><span class="header-section-number">10.8.8</span> Sequential Testing Using Gatekeeping Methods</h3>
<p>Gatekeeping methods are a slight variation on fixed sequence methods. They are used when there is one test of primary importance, and several other tests (say <span class="math inline">\(h\)</span> ) of more or less <strong>equal importance</strong>. The family of tests includes all <span class="math inline">\(k=h+1\)</span> hypotheses.</p>
<p>The method is described simply: First, test the primary hypothesis at level <span class="math inline">\(\alpha\)</span>. If insignificant, do no further testing. If significant, test all <span class="math inline">\(h\)</span> secondaries at familywise <span class="math inline">\(\alpha\)</span> level for the <span class="math inline">\(h\)</span> remaining hypotheses. For example if there are <span class="math inline">\(h=3\)</span> secondaries and you are using the single-step Bonferroni method of Chapter 2, you would use <span class="math inline">\(\alpha / 3\)</span> rather than <span class="math inline">\(\alpha / 4\)</span> for the secondaries, despite the fact that the method controls the FWE for all <span class="math inline">\(k=4\)</span> tests.</p>
<p>The benefits of the gatekeeping method are
- no need to adjust the primary test for multiplicity at all
- smaller family size for the secondaries</p>
<div class="figure" style="text-align: center"><span id="fig:Gatekeeping"></span>
<img src="02_Plots/Sequential_Gatekeeping_testing.png" alt="Figure: Gatekeeping as a Closed Testing Procedure" width="100%" />
<p class="caption">
Figure 10.2: Figure: Gatekeeping as a Closed Testing Procedure
</p>
</div>
</div>
</div>
<div id="closed-testing-of-pairwise-comparisons-and-general-contrasts" class="section level2" number="10.9">
<h2><span class="header-section-number">10.9</span> Closed Testing of Pairwise Comparisons and General Contrasts</h2>
<div id="incorporating-logical-constraints" class="section level3" number="10.9.1">
<h3><span class="header-section-number">10.9.1</span> Incorporating Logical Constraints</h3>
<p><strong>Here is a graphical display of the closed family of all pairwise comparisons.</strong></p>
<div class="figure" style="text-align: center">
<img src="02_Plots/all_pairwise_comparisons.png" alt="Figure: Closed Family of All Pairwise Comparisons" width="100%" />
<p class="caption">
(#fig:all pairwise comparisons)Figure: Closed Family of All Pairwise Comparisons
</p>
</div>
<p><strong>logical constraints</strong></p>
<p>The reduced size of the closure tree in the case of all pairwise comparisons can be attributed to logical constraints among the hypotheses. If <span class="math inline">\(H_{12}: \mu_{1}=\mu_{2}\)</span> is true and <span class="math inline">\(H_{23}: \mu_{2}=\mu_{3}\)</span> is true, then logically, <span class="math inline">\(H_{13}: \mu_{1}=\mu_{3}\)</span> is constrained to be true.</p>
<p><strong>truncated closed testing</strong></p>
<p>Uses a special, order-dependent form of closed testing called truncated closed testing, in which inferences are constrained to be performed in the order of their unadjusted p-values: if a hypothesis H is accepted/rejected using the truncated closed testing method, then no hypothesis with a larger/smaller unadjusted p-value will be rejected/accepted. Equivalently, the method of performing such a multiple comparisons procedure has the following general form.</p>
<p>Order the hypotheses <span class="math inline">\(H_{(1)}, \ldots, H_{(k)}\)</span> by the strength of the evidence for them based on the data, <span class="math inline">\(H_{(1)}\)</span> being the most “significant.”</p>
<ol style="list-style-type: decimal">
<li>If the test for <span class="math inline">\(H_{(1)}\)</span> is not significant using closed testing, then stop and reject no hypothesis; otherwise, reject <span class="math inline">\(H_{(1)}\)</span> and continue.</li>
<li>If the test for <span class="math inline">\(H_{(2)}\)</span> is not significant using closed testing, then stop and reject no hypothesis among <span class="math inline">\(\left.H_{(2)}, \ldots, H_{(k k}\right)\)</span>; otherwise, reject <span class="math inline">\(H_{(2)}\)</span> and continue.</li>
<li>If the test for <span class="math inline">\(H_{(3)}\)</span> is not significant using closed testing, then stop and reject no hypothesis among <span class="math inline">\(H_{(3)}, \ldots, H_{(k k)}\)</span>; otherwise, reject <span class="math inline">\(H_{(3)}\)</span> and continue.</li>
</ol>
<p><strong>Difference</strong></p>
<ul>
<li>General closure: no order restriction for hypotheses in general closure. General closure allows you to test hypotheses in any order; hence it always finds as many rejections as truncated closure, and perhaps more.</li>
<li>Order constraint for truncated closed testing: benefit is that it guarantees that the order of multiplicity-adjusted inferences (from most to least significant) never contradicts the corresponding order of the unadjusted inferences. Truncated closure protects the FWE and has inherently better computational order than general closure, at the potential cost of a small amount of power; experience shows that such power loss is negligible.</li>
</ul>
<p>Different truncated closed testing procedures are distinguished by how the hypotheses are ordered and by how they are tested at each step. For example, the Bonferroni-Holm testing procedure orders hypotheses by their raw <span class="math inline">\(p\)</span> -values and tests <span class="math inline">\(H_{(i)}\)</span> by comparing <span class="math inline">\(p_{(i)}\)</span> to the critical value <span class="math inline">\(\alpha /(k-i+1)\)</span>. Shaffer’s method uses the same initial ordering but has different critical values.</p>
</div>
<div id="shaffers-method" class="section level3" number="10.9.2">
<h3><span class="header-section-number">10.9.2</span> Shaffer’s Method</h3>
<p>As with Bonferroni-Holm, hypotheses are ordered by their <strong>raw <span class="math inline">\(p\)</span> -values</strong>; however, instead of testing <span class="math inline">\(H_{(i)}\)</span> by comparing <span class="math inline">\(p_{(i)}\)</span> to <span class="math inline">\(\alpha(k-i+1)\)</span>, you <strong>compare it to <span class="math inline">\(\alpha / k_{i}\)</span></strong>, where <span class="math inline">\(k_{i}\)</span> is the maximum subset size of hypotheses among <span class="math inline">\(H_{(i)}, \ldots, H_{(k)}\)</span> that include <span class="math inline">\(H_{(i)}\)</span> and can possibly be true, given that <span class="math inline">\(H_{(1)}, \ldots\)</span> <span class="math inline">\(H_{(i-1)}\)</span> are false. Of course, <span class="math inline">\(k_{i}\)</span> can be no larger than <span class="math inline">\(k-i+1\)</span>, but as you saw above, it can be much smaller, making Shaffer’s method more powerful. Shaffer’s method is implemented in many SAS procedures using the STEPDOWN option of LSMEANS, along with the TYPE=LOGICAL suboption. The REPORT option displays the Bonferroni divisors <span class="math inline">\(k_{2}, k_{3}, \ldots\)</span> and other information.</p>
<pre><code>data Anova1;
 input G Y @@;
 datalines;
1 9.0 1 11.0
2 9.1 2 9.2 2 9.9 2 11.9 2 11.9 2 12.4 2 8.5 2 10.4 2 11.8 2 9.6
3 10.3 3 8.2 3 10.5 3 10.5 3 10.8 3 11.5 3 8.6 3 10 3 10.4 3 9.6
4 12.6 4 11.2 4 11.7 4 11.2 4 13 4 11.9 4 14 4 11.5 4 10.5 4 10.4
;
proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / pdiff stepdown(type=logical report);
run;</code></pre>
<p><span class="math display">\[
\begin{array}{l}
\hline
\text { Logically Consistent Step-wise Subsets } \\
\hline
\text { Subset Step Size } 1 &amp; \text { Hypotheses } \\
\hline
1 &amp; 1 &amp; 6 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
2 &amp; 2 &amp; 3 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
3 &amp; 2 &amp; 2 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
4 &amp; 3 &amp; 2 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
5 &amp; 4 &amp; 3 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 \\
6 &amp; 5 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
7 &amp; 6 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\hline
\end{array}
\]</span></p>
</div>
<div id="extended-shaffer-royen-method" class="section level3" number="10.9.3">
<h3><span class="header-section-number">10.9.3</span> Extended Shaffer-Royen Method</h3>
<p>The step-down methods for all pairwise comparisons discussed thus far have been based on the Bonferroni inequality, whose fundamental feature is that it <strong>ignores random correlations between the hypotheses being tested</strong>. As with single-step methods, you can use the true distribution of the MaxT statistic to sharpen step-down comparisons by taking correlations into account</p>
<blockquote>
<p>到目前为止讨论的所有成对比较的降压方法都是基于Bonferroni不等式的，其基本特征是它忽略了被测假设之间的随机相关性。</p>
</blockquote>
<p><strong>Using Correlations to Improve Holm’s Step-Down Method: Sequential Testing Method</strong></p>
<p>The hypotheses are ordered by their corresponding test statistics <span class="math inline">\(t_{(1)} \geq \ldots \geq t_{(k)}\)</span>, and <span class="math inline">\(H_{(i)}\)</span> is tested by comparing <span class="math inline">\(t_{(i)}\)</span> to <span class="math inline">\(c_{i \alpha}\)</span>, the <span class="math inline">\(1-\alpha\)</span> quantile of the distribution of <span class="math inline">\(\max _{j \in S_{i} T_{j}}\)</span>, where <span class="math inline">\(S_{i}\)</span> is the set of all hypotheses not yet rejected at stage <span class="math inline">\(i\)</span>. The results of the procedure can be re-expressed using adjusted <span class="math inline">\(p\)</span> -values:</p>
<ul>
<li>Stage 1: <span class="math inline">\(\tilde{p}_{(1)}=P\left(\max _{i \in\{1, \ldots, k\}} T_{i} \geq t_{(1)}\right)\)</span></li>
<li>Stage 2: <span class="math inline">\(\tilde{p}_{(2)}=\max \left\{\tilde{p}_{(1)}, P\left(\max _{i \in S_{2}} T_{i} \geq t_{(2)}\right)\right\}\)</span>
<span class="math inline">\(\cdots\)</span></li>
<li>Stage <span class="math inline">\(\boldsymbol{k}: \tilde{p}_{(k)}=\max \left\{\tilde{p}_{(k-1)}, p_{(k)}\right\}\)</span></li>
</ul>
<p><strong>The Effect of Using Correlations in Step-Down Tests</strong></p>
<pre><code>***Bonferroni-Holm method;
proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / stepdown(type=free);
 ods select diffs;
run;

***correlation-based free step-down method:
proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / adjust=simulate(acc=0.0005 seed=121211)
 stepdown(type=free);
 ods select diffs;
run; </code></pre>
<p><strong>Extended Shaffer-Royen (ESR)</strong></p>
<p>Because the Holm-Simulated method accounts for correlations, the adjusted p-values are smaller than those obtained using the Bonferroni inequality; i.e., they are smaller than the Bonferroni-Holm adjusted p-values. But you can do even better. Instead of using the Holm method (via either simulation or Bonferroni’s inequality), which does not account for logical constraints, you can reduce the subset sizes for which the critical values and adjusted p-values are obtained, and calculate the values again by simulating MaxT for all the subsets. This method is called the Extended Shaffer-Royen (ESR) method, after Shaffer (1986), who pioneered the method for finding the logical restrictions, and Royen (1989), who incorporated correlations in the balanced ANOVA.</p>
<blockquote>
<p>Holm-Simulated方法考虑了相关性，所以调整后的p值小于使用Bonferroni不等式获得的p值。 即，它们小于Bonferroni-Holm调整后的p值。 但是您可以做得更好。 代替使用不考虑逻辑约束的Holm方法（通过仿真或Bonferroni不等式），您可以减少获得临界值和调整后的p值的子集大小，然后通过模拟MaxT再次计算值 对于所有子集。 这种方法被称为扩展Shaffer-Royen（ESR）方法</p>
</blockquote>
<pre><code>proc orthoreg data=Anova1;
 class G;
 model Y = G;
 lsmeans G / adjust=simulate(acc=0.0005 seed=121211)
 stepdown(type=logical);
 ods select diffs;
run;</code></pre>
</div>
<div id="step-down-dunnett-test" class="section level3" number="10.9.4">
<h3><span class="header-section-number">10.9.4</span> Step-down Dunnett test</h3>
<p>The test was based on the calculation of a common critical point that exploits the correlation structure among the statistics, which are just the familiar pairwise t-tests of all group means with the control mean.</p>
<p>There are three pairwise hypotheses of interest, namely, <span class="math inline">\(\mu_{0}=\mu_{1}, \mu_{0}=\mu_{2}\)</span>, and <span class="math inline">\(\mu_{0}=\mu_{3}\)</span>. To form the closed family, you take all intersections among these pairwise hypotheses, and you get the following family:</p>
<ul>
<li>The original two-means homogeneity hypotheses: <span class="math inline">\(\mu_{0}=\mu_{1}, \mu_{0}=\mu_{2}\)</span>, and <span class="math inline">\(\mu_{0}=\mu_{3}\)</span>.</li>
<li>The three-means homogeneity hypotheses: <span class="math inline">\(\mu_{0}=\mu_{1}=\mu_{2}, \mu_{0}=\mu_{1}=\mu_{3}\)</span>, and <span class="math inline">\(\mu_{0}=\mu_{2}=\mu_{3}\)</span>.</li>
<li>The four-means homogeneity hypothesis: <span class="math inline">\(\mu_{0}=\mu_{1}=\mu_{2}=\mu_{3}\)</span>.</li>
</ul>
<p><strong>Key point</strong>: Dunnett comparisons are not logically restricted; truth of any subset of <span class="math inline">\(\mu_{0}=\mu_{1}, \mu_{0}=\mu_{2}\)</span>, and <span class="math inline">\(\mu_{0}=\mu_{3}\)</span> does not imply truth of a hypothesis outside the subset. So there is th full collection of <span class="math inline">\(2^{3}-1=7\)</span> hypotheses in this example.</p>
<div class="figure" style="text-align: center">
<img src="02_Plots/Dunnett_Close_Test.png" alt="Figure: Closed Family of Tests Based on Pairwise Comparisons with a Control" width="100%" />
<p class="caption">
(#fig:Dunnett Step-down)Figure: Closed Family of Tests Based on Pairwise Comparisons with a Control
</p>
</div>
<p><strong>SAS Implementation</strong></p>
<pre><code>*** &quot;By Hand” Calculation of Lower-Tailed Step-Down Dunnett Critical Values;
data _null_;
 dfe = 21;
 do j1=1 to 6;
 j = 6-j1+1;
 c_j = -probmc(&quot;DUNNETT1&quot;,.,.95,dfe,j);
 put j= c_j= 6.3;
 end;
run; 

*** Step-Down Dunnett Tests;
proc orthoreg data=Tox;
 class Trt;
 model Gain=Trt;
 lsmeans Trt / adjust=dunnett pdiff=controll stepdown;
run;</code></pre>
<p><strong>R Implementation</strong></p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="multiple-comparison.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;multcomp&quot;</span>)</span>
<span id="cb69-2"><a href="multiple-comparison.html#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;recovery&quot;</span>, <span class="at">package =</span> <span class="st">&quot;multcomp&quot;</span>)</span>
<span id="cb69-3"><a href="multiple-comparison.html#cb69-3" aria-hidden="true" tabindex="-1"></a>recovery.aov <span class="ot">&lt;-</span> <span class="fu">aov</span>(minutes <span class="sc">~</span> blanket, <span class="at">data =</span> recovery)</span>
<span id="cb69-4"><a href="multiple-comparison.html#cb69-4" aria-hidden="true" tabindex="-1"></a>recovery.mc <span class="ot">&lt;-</span> <span class="fu">glht</span>(recovery.aov,</span>
<span id="cb69-5"><a href="multiple-comparison.html#cb69-5" aria-hidden="true" tabindex="-1"></a>                    <span class="at">linfct =</span> <span class="fu">mcp</span>(<span class="at">blanket =</span> <span class="st">&quot;Dunnett&quot;</span>),</span>
<span id="cb69-6"><a href="multiple-comparison.html#cb69-6" aria-hidden="true" tabindex="-1"></a>                    <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>) </span>
<span id="cb69-7"><a href="multiple-comparison.html#cb69-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(recovery.mc, <span class="at">test =</span> <span class="fu">adjusted</span>(<span class="at">type =</span> <span class="st">&quot;free&quot;</span>))</span></code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Dunnett Contrasts
## 
## 
## Fit: aov(formula = minutes ~ blanket, data = recovery)
## 
## Linear Hypotheses:
##              Estimate Std. Error t value   Pr(&lt;t)    
## b1 - b0 &gt;= 0  -2.1333     1.6038  -1.330   0.0958 .  
## b2 - b0 &gt;= 0  -7.4667     1.6038  -4.656 5.86e-05 ***
## b3 - b0 &gt;= 0  -1.6667     0.8848  -1.884   0.0640 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- free method)</code></pre>
</div>
</div>
<div id="multiple-comparisons-with-binary-data" class="section level2" number="10.10">
<h2><span class="header-section-number">10.10</span> Multiple Comparisons with Binary Data</h2>
<div id="introduction-1" class="section level3" number="10.10.1">
<h3><span class="header-section-number">10.10.1</span> Introduction</h3>
<blockquote>
<p>对于典型的连续响应数据，考虑相关性的多重性调整并不是全部这与基于Bonferroni的简单调整有很大不同。可以肯定的是，合并相关性时，调整后的p值会稍小一些，并且在多个测试中，只要有可能，就应该合并相关性结构。但在大多数情况下，如果使用连续数据，则改进不会明显好于Bonferroni。
二进制数据，合并相关性的确比Bonferroni方法带来了真正的显着改进。如果使用正确的多重调整并结合了分布的离散性质，则调整后的p值很容易是Bonferronia调整后的p值的十分之一！</p>
</blockquote>
<p>The method for calculating adjusted <span class="math inline">\(p\)</span> -values in the binary case is identical to that for the continuous case discussed in Chapter <span class="math inline">\(16-\)</span> namely, adjusted <span class="math inline">\(p\)</span> -values are based on the distribution of the minimum <span class="math inline">\(p\)</span> -value,
<span class="math display">\[
\tilde{p}_{j}=P\left(\min _{i} P_{i} \leq p_{j}\right)
\]</span>
The thing is, with discrete data, the random <span class="math inline">\(p\)</span> -values <span class="math inline">\(P_{i}\)</span> for some individual tests may never be very small, so effectively they don’t really contribute to <span class="math inline">\(\min P_{i}\)</span>. This makes <span class="math inline">\(\min P_{i}\)</span> larger than might have been expected, which in turn makes the adjusted <span class="math inline">\(p\)</span> -value <span class="math inline">\(P\left(\min _{i} P_{i} \leq p_{j}\right)\)</span> smaller. That is, with discrete data, you don’t necessarily need to adjust for all hypotheses <span class="math inline">\(H_{j} .\)</span> The <strong>resampling-based methods</strong> automatically discount hypotheses where data are sparse. They achieve this by operating on the appropriate underlying discrete</p>
<blockquote>
<p>在二进制情况下，计算调整后的p值的方法与第16章中讨论的连续情况相同，即调整后的p值基于最小p值（min）的分布。问题在于，对于离散数据，某些单个测试的随机p值可能永远不会很小，因此实际上它们并没有真正影响最小Pi。这使min Pi大于预期，从而使调整后的p值P（mini Pi≤pj）较小。也就是说，对于离散数据，您不一定需要针对所有假设Hj进行调整。</p>
</blockquote>
<blockquote>
<p>PROC MULTTEST 允许使用自举或置换重采样(Bootstrap and Permutation Resampling)来放宽正态性假设。</p>
</blockquote>
</div>
<div id="multivariate-two-sample-binary-outcomes" class="section level3" number="10.10.2">
<h3><span class="header-section-number">10.10.2</span> Multivariate Two-Sample Binary Outcomes</h3>
<p>The case of multivariate two-sample analysis is a case where <strong>permutation analysis</strong> can provide exact tests under global permutation resampling.</p>
<p><strong>Example: Adverse Events in Clinical Trials</strong></p>
<blockquote>
<p>件必须在人类受试者上测试新药的安全性和有效性。安全性研究得出的数据通常具有多元二进制形式，即几个不良事件（即副作用）中的每一个的0/1指标。通常可能会发生很多不良事件，并且如果在不进行多重性调整的情况下测试所有此类事件，则可能会出现假阳性结果。这就是说，尽管药物通常确实有副作用，但基于简单的p≤0.05规则的统计确定可能会错误地过多地标记副作用。与任何筛选程序一样，存在错误和成本。不良事件分析中的I型错误意味着声称该药物实际上没有这种作用时会引起某种问题（例如头痛）。此类I类错误的成本包括药品的延迟批准，甚至可能取消优质药品的开发，这给制药公司和消费者都带来了成本。如果竞争对手生产基本上等同的药物，并且（正确地）发现不存在此类不良事件，那么I型错误的代价也可能非常高昂。</p>
</blockquote>
<blockquote>
<p>另一方面，II型错误（无法检测到真正的副作用的严重性）也非常严重，因为它们可能给公众造成不必要的痛苦，并可能给制药公司提起诉讼。由于担心II型错误，一些人提倡不强调多重性问题，甚至在未经调整的= 0.10水平上单独分析所有潜在的副作用。
另一方面，同时提供经过多重调整的p值和未经调整的p值当然是合理的，以评估任何不良事件研究的多重性问题的程度。理性地控制具有多种副作用的I型错误的可能性增加，而不是仅仅忽略它们。也就是说，由于类型I错误可能并且确实发生，因此数据分析应该以某种直接的方式来确认这一事实。 PROC MULTTEST的离散多重性调整方法为处理多重性问题提供了一种简单，有效且功能强大的方法</p>
</blockquote>
<p><strong>Resampling-Based Multiplicity Adjustment</strong></p>
<blockquote>
<p>研究了对照组和治疗组的反应，注意到27种不同不良事件的发生率。 第28个“事件”被定义为其他事件的组合，对于每组，数据表示为受试者总数，无不良事件发生的人数。 然后针对其他主题，分别列出不良事件的数量和发生的原因。</p>
</blockquote>
<pre><code>data Adverse; keep Group AE1-AE28;
 array AE{28};
 length Group $ 9;
 input Group nTotal nNone;
 do i = 1 to dim(AE); AE{i} = 0; end;
 do iobs = 1 to nNone; output; end;
 do iobs = 1 to nTotal-nNone;
 input nAE @@;
 do i = 1 to dim(AE); AE{i} = 0; end;
 do i = 1 to nAE; input iAE @@; AE{iAE} = 1; end;
 output;
 end;
 datalines;
Control 80 46
4 2 3 17 28 2 18 28 2 2 28 3 4 22 28
3 1 3 28 2 1 28 4 2 3 11 28 2 2 28
3 12 27 28 2 1 28 3 2 19 28 3 1 9 28
2 14 28 2 7 28 2 4 28 2 4 28
2 2 28 2 3 28 4 1 4 9 28 3 1 26 28
2 1 28 3 5 12 28 2 2 28 2 4 28
3 5 13 28 2 16 28 2 9 28 3 1 2 28
2 24 28 2 2 28 2 7 28 2 7 28
2 25 28 5 3 14 19 21 28
Treatment 80 44
2 23 28 2 1 28 3 1 4 28 2 2 28
2 1 28 4 1 3 6 28 4 1 5 8 28 3 1 21 28
3 1 10 28 3 3 8 28 5 1 2 3 10 28 3 2 15 28
2 1 28 3 2 6 28 4 1 5 9 28 3 1 5 28
3 1 15 28 2 7 28 2 7 28 3 1 8 28
3 1 6 28 3 1 3 28 3 1 6 28 3 2 8 28
3 1 4 28 3 1 2 28 3 1 20 28 3 1 4 28
3 1 2 28 2 1 28 4 1 5 16 28 3 2 8 28
2 1 28 4 1 4 5 28 2 3 28 2 3 28
;
proc multtest data=Adverse stepperm seed=121211 n=100000;
 class Group;
 test fisher(AE1-AE28/upper);
 contrast &quot;Treatment-Control&quot; -1 1;
 ods output Discrete=Discrete;
 ods output pValues=pValues;
run;
proc transpose data=Discrete(rename=(Group=_NAME_))
 out =Discrete(drop =_NAME_ );
 by notsorted Variable;
 var Percent;
data pValues; merge Discrete pValues;
 drop Contrast;
proc rank data=pValues out=pValues;
 var Raw;
 ranks Rank; 
proc print data=pValues noobs label;
 where (Rank &lt;= 6);
 var Variable Control Treatment Raw StepdownPermutation;
 title &quot;Fisher Exact (Raw) and Multivariate Permutation-Adjusted pValues&quot;;
run;
title;</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="anova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="correlation-and-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-Multiple-Comparison.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
